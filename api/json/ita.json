[
  {
    "text": "\n\n\n\n\n\nManage appointments, plans, budgets \u2014 it's easy with Microsoft 365.\n\n\n\n\n\r\n\t\t\t\t\t\t\t\t\t\tTry one month free\r\n\t\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\n\n\nMicrosoft\n\n\n\nSupport\n\n\n\n\nSupport\n\n\n\n\r\n                            Support\r\n                        \n\n\n\n\n Home \n\n\nMicrosoft 365\n\n\nOffice\n\n\nWindows\n\n\nSurface\n\n\nXbox\n\n\nDeals\n\n\n\nMore\n\n\n\n\n\nBuy Microsoft 365\n\n\n\n\n \n\n\n\n All Microsoft\n\n\n\n\nMicrosoft 365\n\n\nOffice\n\n\nWindows\n\n\nSurface\n\n\nXbox\n\n\nDeals\n\n\nSupport\n\n\n\n\nSoftware\n\n\nWindows Apps\n\n\nOneDrive\n\n\nOutlook\n\n\nSkype\n\n\nOneNote\n\n\nMicrosoft Teams\n\n\nMicrosoft Edge\n\n\n\n\nPCs & Devices  \n\n\nComputers\n\n\nShop Xbox\n\n\nAccessories\n\n\nVR & mixed reality\n\n\nPhones\n\n\n\n\nEntertainment\n\n\nXbox Game Pass Ultimate\n\n\nXbox Live Gold\n\n\nXbox games\n\n\nPC games\n\n\nWindows digital games\n\n\nMovies & TV\n\n\n\n\nBusiness\n\n\nMicrosoft Azure\n\n\nMicrosoft Dynamics 365\n\n\nMicrosoft 365\n\n\nMicrosoft Industry\n\n\nData platform\n\n\nMicrosoft Advertising\n\n\nPower Platform\n\n\nShop Business\n\n\n\n\nDeveloper & IT  \n\n\n.NET\n\n\nVisual Studio\n\n\nWindows Server\n\n\nWindows Dev Center\n\n\nDocs\n\n\nPower Apps\n\n\nHoloLens 2\n\n\n\n\nOther\n\n\nMicrosoft Rewards \n\n\nFree downloads & security\n\n\nEducation\n\n\nVirtual workshops and training\n\n\nGift cards\n\n\nLicensing\n\n\nMicrosoft Experience Center\n\n\n\n\nView Sitemap\n\n\n\n\n\n\n\n\n\n\nSearch\nSearch for help\n\n\n\n\n\n\nCancel\n\n\n\nSign in\n\n\n\n\n\n\n\n\n\n\n\n\n\nProducts\n\n\n\n\nMicrosoft 365\n\n\nOffice\n\n\nOutlook\n\n\nMicrosoft Teams\n\n\nOneDrive\n\n\nOneNote\n\n\nWindows\n\n\nMicrosoft Edge\n\n\nmore ...\n\n\n\n\n\nDevices\n\n\n\n\nSurface\n\n\nPC accessories\n\n\nMobile\n\n\nXbox\n\n\nHoloLens\n\n\nHardware warranties\n\n\n\n\nWhat's new\n\n\nAccount & billing\n\n\nTemplates\n\n\n\nMore support\n\n\n\n\nCommunity forums\n\n\nAdmins\n\n\nDeveloper\n\n\nEducation\n\n\nSmall business\n\n\nReport a support scam\n\n\n\n\n\n\n\n\n\n\n\nUse Snipping Tool to capture screenshots\n\n\n\nWindows 10 Windows 8.1 Windows 7 More...Less\n\n\n\nTake a snapshot to copy words or images from all or part of your PC screen. Use Snipping Tool to make changes or notes, then save, and share.\nWindows 10 has another screenshot app you might also like to try. When you open Snipping Tool, you\u2019ll see an invitation and keyboard shortcut to Snip & Sketch. For more info on this app, see How to take and annotate screenshots on Windows 10.\n\nCapture any of the following types of snips:\n\n\n\n\n\nFree-form snip\n\n\n\nDraw a free-form shape around an object.\n\n\n\n\n\nRectangular snip\n\n\n\nDrag the cursor around an object to form a rectangle.\n\n\n\n\n\nWindow snip\n\n\n\nSelect a window, such as a dialog box, that you want to capture.\n\n\n\n\n\nFull-screen snip\n\n\n\nCapture the entire screen.\n\n\n\n\n\nWhen you capture a snip, it's automatically copied to the Snipping Tool window where you make changes, save, and share.\u00a0\n\nOpen Snipping Tool\n\n\n\n\nFor Windows 10\n\n\nSelect the Start\u00a0 button, type snipping tool in the search box on the taskbar, and then select Snipping Tool from the list of results.\n\n\n\n\nFor Windows 8.1 / Windows RT 8.1\n\n\nSwipe in from the right edge of the screen, tap Search (or if you're using a mouse, point to the lower-right corner of the screen, move the mouse pointer up, and then select Search), type snipping tool in the search box, and then select Snipping Tool from the list of results.\n\n\n\n\nFor Windows 7\n\n\nSelect the Start\u00a0\u00a0button, then type snipping tool in the search box, and then select Snipping Tool from the list of results.\n\n\n\n\n\nWork with your screenshots\nWith your Snipping Tool open, select\u00a0one of the following to create and work with your screenshots.\n\n\nCapture a snip\n\n\nIn Snipping Tool, select\u00a0Mode.\u00a0In earlier versions of Windows, select the arrow next to the New\u00a0button.\u00a0Next, when you choose the kind of snip you want,\u00a0you\u2019ll see the whole screen change slightly to gray. Then, choosing from\u00a0anything currently displayed on the screen,\u00a0select the area of your screen that you want to capture.\n\n\n\n\n\n\n\nCapture a snip of a menu\n\n\n\n\nAfter you open Snipping Tool, open the menu that you want to capture. For Windows\u00a07, press the\u00a0Esc\u00a0key before opening the menu.\n\n\nPress\u00a0Ctrl + PrtScn\u00a0keys. The entire screen changes to gray\u00a0including the open menu.\n\n\nSelect\u00a0Mode, or\u00a0in earlier versions of Windows, select the arrow next to the\u00a0New\u00a0button.\u00a0Select the kind of snip you want, and then select the area of the screen capture that you want to capture.\n\n\n\n\n\n\nAnnotate a snip\n\n\nAfter you capture a snip, you can write or draw on or around it by selecting the\u00a0Pen\u00a0or\u00a0Highlighter\u00a0buttons. Select\u00a0Eraser\u00a0to remove the lines you've drawn.\n\n\n\n\nSave a snip\n\n\n\n\nAfter you capture a snip, select the\u00a0Save Snip\u00a0button.\n\n\nIn the Save As box, type a file name, location, and type, and then select\u00a0Save.\n\n\n\n\n\n\nRemove the URL\n\n\nWhen you capture a snip from a browser window and save it as an HTML file, the URL appears below the snip. To prevent the URL from appearing:\n\n\nIn the Snipping Tool, select the\u00a0Options\u00a0button.\n\n\nIn the\u00a0Snipping Tools Options box, clear the\u00a0Include URL below snips (HTML only)\u00a0check box,\u00a0then select\u00a0OK.\n\n\n\n\n\n\nShare a snip\n\n\nAfter you capture a snip, select the arrow next to the Send Snip button, and then select an option from the list.\u00a0\u00a0\n\n\n\n\nKeyboard shortcuts to use in Snipping Tool\n\n\n\n\n\n\nPress these keys\n\n\nTo do this\n\n\n\n\n\n\nAlt + M\n\n\nChoose a snipping mode.\n\n\n\n\nAlt + N\n\n\nCreate a new snip in the same mode as the last one.\n\n\n\n\nShift + arrow keys\n\n\nMove the cursor to select from different types of snips.\n\n\n\n\nAlt + D\n\n\nDelay capture by 1-5 seconds\n\n\n\n\nCtrl + C\n\n\nCopy the snip to clipboard\n\n\n\n\nCtrl +\n\n\nSave the snip\n\n\n\n\n\n\n\n\n\nEnlarge, rotate, or crop your snip\n\n\nWith your capture open in Snipping Tool, select\u00a0Edit\u00a0>\u00a0Edit with Paint 3D\u00a0to use features for sizing, color, text, and many other enhancements.\n\n\n\n\nPrint a snip\n\n\nIn the folder where you\u2019ve saved your snip, right click on the snip. Select\u00a0Print\u00a0from the options and make choices for how you want to print your image.\n\n\n\n\nPlace tool on the taskbar\n\n\nIn the search box on the taskbar, type\u00a0snipping tool. You\u2019ll see the Snipping Tool app and a list of actions you can take. Select\u00a0Pin to taskbar.\n\n\n\n\nDelay your screenshot\u00a0\n\n\nFirst, identify the menu or other components you want to capture. In Snipping Tool, select Delay and then select, for example, 5 seconds. Select Mode to start the 5-second countdown. Within 5 seconds, open a menu or otherwise compose your image. At 5 seconds, when you see the screen turn\u00a0gray, use the mouse to draw around the area you want.\u00a0\n\n\n\nRelated info\nFor info about other Windows 10 features, see\u00a0What's new in recent Windows 10 updates.\n\n\n\n\n\n\n\n\nNeed more help?\n\n\n\n\n\n\n\n\n\n\n \n\n\n\r\n\t\t\t\tJoin the discussion\r\n\t\t\t\nAsk the community\n\n\n\r\n\t\t\t\tGet support\r\n\t\t\t\nContact Us\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWas this information helpful?\n\n\nYes\nNo\n\n\n\n\nGreat! Any other feedback? The more you tell us, the more we can help.\nHow can we improve? The more you tell us, the more we can help.\n\n\n\nSend\nNo thanks\n\n\n\n\nThank you for your feedback!\n\n\nThank you for your feedback! It sounds like it might be helpful to connect you to one of our Office support agents.\n\nContact Support\n\n\n\n\n\n\u00d7\n\n\n\n\n\n\n\n\n\n\nWhat's new\n\n\nSurface Duo\n\n\nSurface Laptop Go\n\n\nSurface Pro X\n\n\nSurface Go 2\n\n\nSurface Book 3\n\n\nMicrosoft 365\n\n\nWindows 10 apps\n\n\nHoloLens 2\n\n\n\n\nMicrosoft Store\n\n\nAccount profile\n\n\nDownload Center\n\n\nMicrosoft Store support\n\n\nReturns\n\n\nOrder tracking\n\n\nVirtual workshops and training\n\n\nMicrosoft Store Promise\n\n\nFinancing\n\n\n\n\nEducation\n\n\nMicrosoft in education\n\n\nOffice for students\n\n\nOffice 365 for schools\n\n\nDeals for students & parents\n\n\nMicrosoft Azure in education\n\n\n\n\n\n\nEnterprise\n\n\nAzure\n\n\nAppSource \n\n\nAutomotive\n\n\nGovernment\n\n\nHealthcare\n\n\nManufacturing\n\n\nFinancial services\n\n\nRetail\n\n\n\n\nDeveloper\n\n\nMicrosoft Visual Studio\n\n\nWindows Dev Center\n\n\nDeveloper Center\n\n\nMicrosoft developer program\n\n\nChannel 9\n\n\nOffice Dev Center\n\n\nMicrosoft Garage\n\n\n\n\nCompany\n\n\nCareers\n\n\nAbout Microsoft\n\n\nCompany news\n\n\nPrivacy at Microsoft\n\n\nInvestors\n\n\nDiversity and inclusion\n\n\nAccessibility\n\n\nSecurity\n\n\n\n\n\n\nEnglish (United States)\n\n\n\nSitemap\n\n\nContact Microsoft\n\n\nPrivacy \n\n\nManage cookies\n\n\nTerms of use\n\n\nTrademarks\n\n\nSafety & eco\n\n\nAbout our ads\n\n\u00a9 Microsoft 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
  },
  {
    "text": "\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n \n\n\n\n\n \n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n\n \n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n \n\n \n\n\n\n\n\n\n\n\nMenu\n\n\n\n\n\n\n\n\n\n\n\n\nHome\n\n\n\n\n\n\n\n\n Science, Tech, Math\n\n\n\n Science\n \n\n Math\n \n\n Social Sciences\n \n\n Computer Science\n \n\n Animals & Nature\n \n\n\n\n Humanities\n\n\n\n History & Culture\n \n\n Visual Arts\n \n\n Literature\n \n\n English\n \n\n Geography\n \n\n Philosophy\n \n\n Issues\n \n\n\n\n Languages\n\n\n\n English as a Second Language\n \n\n Spanish\n \n\n French\n \n\n German\n \n\n Italian\n \n\n Japanese\n \n\n Mandarin\n \n\n Russian\n \n\n\n\n Resources\n\n\n\n For Students & Parents\n \n\n For Educators\n \n\n For Adult Learners\n \n\n\n\nAbout Us\n\n\n\n\n\nSearch\n\n\n\n\n\n\nClose\nSearch the site\n\n\nGO\n\n\n\n\n\n\n\n\n\n\n\n\n\nScience, Tech, Math\n\n\n\n\n\n\nScience\nMath\nSocial Sciences\nComputer Science\nAnimals & Nature\n\n\n\n\n\nHumanities\n\n\n\n\n\n\nHistory & Culture\nVisual Arts\nLiterature\nEnglish\nGeography\nPhilosophy\nIssues\n\n\n\n\n\nLanguages\n\n\n\n\n\n\nEnglish as a Second Language\nSpanish\nFrench\nGerman\nItalian\nJapanese\nMandarin\nRussian\n\n\n\n\n\nResources\n\n\n\n\n\n\nFor Students & Parents\nFor Educators\nFor Adult Learners\n\n\n\nAbout Us\nContact Us\nEditorial Guidelines\nPrivacy Policy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHumanities\n \n\u203a\nEnglish\n\n\nUnderstanding General-to-Specific Order in Composition\n\n\n\n\n\n\n\n\n\n\nShare\n\n\n\n\n\n\n\nFlipboard\n\n\n\n\n\n\n\nEmail\n\n\n\n\n\n\nPrint\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHulton Fine Art Collection/Getty Images\n\n\n\n\nEnglish\n\n\n\n \n\n\nEnglish Grammar\n\n\n\n\n\n\n An Introduction to Punctuation\n\n\n\n\n\n\n\n\n Writing\n\n\n\n\n\n\n\n\n\n\nBy\n\n\n\n\n\n\n\n\nRichard Nordquist\n\n\n\n\nEnglish and Rhetoric Professor\n\n\n\n\n\nPh.D., Rhetoric and English, University of Georgia\n\nM.A., Modern English and American Literature, University of Leicester\n\nB.A., English, State University of New York\n\n\nDr. Richard Nordquist is professor emeritus of rhetoric and English at Georgia Southern University and the author of several university-level grammar and composition textbooks.\n\n\n\nour editorial process\n\n\n\n\nRichard Nordquist\n\n\n\nUpdated February 12, 2020\n\n\n\n\n   Definition  \n\nIn composition, general-to-specific order is a\u00a0method of developing a paragraph, essay, or speech by moving from a broad observation about a topic to specific details in support of that topic.\u00a0\n\n\n\nAlso known as the deductive method of organization, general-to-specific order is more commonly used than the reverse method, specific-to-general order (the inductive method).\n\n\n   Examples and Observations  \n\nSteps for General-to-Specific Order in Body ParagraphsThis strategy is effective in cause/effect, comparison/contrast, classification, and argumentation essays. . . .1. The topic sentence should identify a general statement about the subject.2. The writer should choose details that make specific points about the general statement.3. The writer should make sure the reader can understand and relate to the specific examples. (Roberta L. Sejnost and Sharon Thiese, Reading and Writing Across Content Areas, 2nd ed. Corwin Press, 2007)\"Clearly, 'America the Beautiful' deserves to be our national anthem. For years now, it has been gaining popularity in school assemblies, at official state functions, and even in our ball parks. The music is simple, dignified, and--most important--easy to sing. The lyrics celebrate our history ('O beautiful for pilgrim feet . . .'), our land ('For purple mountain majesties above the fruited plain'), our heroes ('Who more than self their country loved'), and our future ('That sees beyond the years'). It is proud but not warlike, idealistic without sounding silly.\"(Body paragraph in \"Time for an Anthem the Country Can Sing\" [a student's revised argumentative essay])General-to-Specific Order in Introductory Paragraphs- Many opening paragraphs for college papers start with a general statement of the main idea in a topic sentence. Subsequent sentences contain specific examples that support or expand on that statement, and the paragraph ends with a thesis statement. Language is the road map of a culture. It tells you where its people come from and where they are going. A study of the English language reveals a dramatic history and astonishing versatility. It is the language of survivors, of conquerors, of laughter.- Rita Mae Brown, \"To the Victor Belongs the Language (Toby Fulwiler and Alan Hayakawa, The Blair Handbook. Prentice Hall, 2003)- \"Working part-time as a cashier at the Piggly Wiggly has given me a great opportunity to observe human behavior. Sometimes I think of the shoppers as white rats in a lab experiment and the aisles as a maze designed by a psychologist. Most of the rats--customers, I mean--follow a routine pattern, strolling up and down the aisles, checking through my chute, and then escaping through the exit hatch. But not everyone is so dependable. My research has revealed three distinct types of abnormal customer: the amnesiac, the super shopper, and the dawdler. . . .\"(Introduction to \"Shopping at the Pig\" [a student's revised classification essay])General-to-Specific Order in Technical Writing- \"General to a specific or deductive logical order . . . is the most common logical organisation used in technical communication. This logical pattern involves the process of moving from a general statement, premise, principle, or law to specific details. Technical writers and speakers find this logical sequence quite helpful in organising short informative talks and presentations, technical descriptions of objects and processes, classificatory information, and so on. . . .\"General to specific organisation follows a direct approach. It leaves very little to the imagination of readers or listeners because the writer/speaker makes everything clear in the beginning itself. Generalisations help readers/listeners to understand the details, examples, and illustrations quickly.\"(M. Ashraf Rizvi, Effective Technical Communication. Tata McGraw-Hill, 2005)- \"Now, once the tide is low, you are ready to begin crabbing. Drop your lines overboard, but not before you have tied them securely to the boat rail. Because crabs are sensitive to sudden movements, the lines must be slowly lifted until the chicken necks are visible just below the surface of the water. If you spy a crab nibbling the bait, snatch him up with a quick sweep of your scoop. The crab will be furious, snapping its claws and bubbling at the mouth. Drop the crab into the wooden crate before it has a chance to get revenge. You should leave the crabs brooding in the crate as you make your way home.\"(Body paragraph in \"How to Catch River Crabs\" [a student's process-analysis essay])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\nHow to Write a Narrative Essay or Speech\n\n\n\n\n\n\n \n\n\nExamples of Great Introductory Paragraphs\n\n\n\n\n\n\n \n\n\nSpatial Order in Composition\n\n\n\n\n\n\n \n\n\nDefinition and Examples of Climactic Order in Composition and Speech\n\n\n\n\n\n\n \n\n\nRevision Checklist for a Descriptive Paragraph\n\n\n\n\n\n\n \n\n\nHow to Teach Topic Sentences Using Models\n\n\n\n\n\n\n \n\n\nHow to Develop and Organize a Classification Essay\n\n\n\n\n\n\n \n\n\nSupporting Detail in Composition and Speech\n\n\n\n\n\n\n\n\n\n\n\n \n\n\nA Draft Classification Essay: Types of Shoppers\n\n\n\n\n\n\n \n\n\nHow to Organize a Descriptive Paragraph\n\n\n\n\n\n\n \n\n\n5 Examples of How to Write a Good Descriptive Paragraph\n\n\n\n\n\n\n \n\n\nWhat Is a Topic Sentence?\n\n\n\n\n\n\n \n\n\nPractice in Supporting a Topic Sentence with Specific Details\n\n\n\n\n\n\n \n\n\nAn Essay Revision Checklist\n\n\n\n\n\n\n \n\n\nThe Ultimate Guide to the 5-Paragraph Essay\n\n\n\n\n\n\n \n\n\nDefinition and Examples of Body Paragraphs in Composition\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHome\n\n\n\n\n\n\n\n\n\n\n\n\nLearn Something New Every Day\n\n\n\n\nEmail Address\n\n\nSign up\n\n\nThere was an error. Please try again.\n\n\n\nYou're in! Thanks for signing up.\n\nThere was an error. Please try again.\nThank you  for signing up.\n\n\n\n\nFollow Us\n\n\n\n\n\n\nFacebook\nFacebook\n\n\n\n\n\n\n\nFlipboard\nFlipboard\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScience, Tech, Math\n\n\n\nHumanities\n\n\n\nLanguages\n\n\n\nResources\n\n\n\n\nAbout Us\nAdvertise\nPrivacy Policy\nCookie Policy\nCareers\nEditorial Guidelines\nContact\nTerms of Use\nCalifornia Privacy Notice\n\n\n\n\n\n\n\n\n\n\nThoughtCo is part of the Dotdash publishing family.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
  },
  {
    "text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n \n\n\nToggle Menu\n\n\nHomeReadSign in\n\nSearch in book:\n\n\n\n\nSearch\n\n\n \n\n\n\n\n\n\nContents\n\n\nStudent and Instructor ResourcesCopyright InformationAcknowledgements and ContributorsVersion Information 1. Introduction to research1.0 Chapter introduction1.1 How do social workers know what to do?1.2 Science and social work1.3 Why should we care?1.4 Understanding research2. Beginning a research project2.0 Chapter introduction2.1 Getting started2.2 Sources of information2.3 Finding literature3. Reading and evaluating literature3.0 Chapter introduction3.1 Reading an empirical journal article3.2 Evaluating sources3.3 Refining your question4. Conducting a literature review4.0 Chapter introduction4.1 What is a literature review?4.2 Synthesizing literature4.3 Writing the literature review5. Ethics in social work research5.0 Chapter introduction5.1 Research on humans5.2 Specific ethical issues to consider5.3 Ethics at micro, meso, and macro levels5.4 The practice of science versus the uses of science6. Linking methods with theory6.0 Chapter introduction6.1 Micro, meso, and macro approaches6.2 Paradigms, theories, and how they shape a researcher\u2019s approach6.3 Inductive and deductive reasoning7. Design and causality7.0 Chapter introduction7.1 Types of research7.2 Causal relationships7.3 Unit of analysis and unit of observation7.4 Mixed Methods8. Creating and refining a research question8.0 Chapter introduction8.1 Empirical versus ethical questions8.2 Writing a good research question8.3 Quantitative research questions8.4 Qualitative research questions8.5 Feasibility and importance8.6 Matching question and design9. Defining and measuring concepts9.0 Chapter introduction9.1 Measurement9.2 Conceptualization9.3 Operationalization9.4 Measurement quality9.5 Complexities in quantitative measurement10. Sampling10.0 Chapter introduction10.1 Basic concepts of sampling10.2 Sampling in qualitative research10.3 Sampling in quantitative research10.4 A word of caution: Questions to ask about samples11. Survey research11.0 Chapter introduction11.1 Survey research: What is it and when should it be used?11.2 Strengths and weaknesses of survey research11.3 Types of surveys11.4 Designing effective questions and questionnaires12. Experimental design12.0 Chapter introduction12.1 Experimental design: What is it and when should it be used?12.2 Pre-experimental and quasi-experimental design12.3 The logic of experimental design12.4 Analyzing quantitative data13. Interviews and focus groups13.0 Chapter introduction13.1 Interview research: What is it and when should it be used?13.2 Qualitative interview techniques13.3 Issues to consider for all interview types13.4 Focus groups13.5 Analyzing qualitative data14. Unobtrusive research14.0 Chapter introduction14.1 Unobtrusive research: What is it and when should it be used?14.2 Strengths and weaknesses of unobtrusive research14.3 Unobtrusive data collected by you14.4 Secondary data analysis14.5 Reliability in unobtrusive research15. Real-world research15.0 Chapter introduction15.1 Evaluation research15.2 Single-subjects design15.3 Action research16. Reporting research16.0 Chapter introduction16.1 What to share and why we share16.2 Disseminating your findings16.3 The uniqueness of the social work perspective on science GlossaryPractice behavior indexAttributions index \n\n\nScientific Inquiry in Social Work\n\n\n\n\n\n\n\n\n\n\n\t6.3 Inductive and deductive reasoning\t\n\n\nLearning Objectives\n\nDescribe the inductive approach to research, and provide examples of inductive research\nDescribe the deductive approach to research, and provide examples of deductive research\nDescribe the ways that inductive and deductive approaches may be complementary\n\n\n\u00a0\nTheory structures and informs social work research. Conversely, social work research structures and informs theory. Students become aware of the reciprocal relationship between theory and research when they consider the relationships between the two in inductive and deductive approaches. In both cases, theory is crucial but the relationship between theory and research differs for each approach.\nInductive and deductive approaches to research are quite different, but they can also be complementary. Let\u2019s start by looking at each one and how they differ from one another. Then we\u2019ll move on to thinking about how they complement one another.\nInductive approaches and some examples\nWhen a researcher utilizes an inductive approach, they begin by collecting data that is relevant to their topic of interest. Once a substantial amount of data have been collected, the researcher will take a break from data collection to step back and get a bird\u2019s eye view of their data. At this stage, the researcher looks for patterns in the data, working to develop a theory that could explain those patterns. Thus, when researchers take an inductive approach, they start with a set of observations and then they move from those particular experiences to a more general set of propositions about those experiences. In other words, they move from data to theory, or from the specific to the general. Figure 6.1 outlines the steps involved with an inductive approach to research.\n\u00a0\nFigure 6.1 Inductive research\nThere are many good examples of inductive research, but we\u2019ll look at just a few here. One fascinating study in which the researchers took an inductive approach is Katherine Allen, Christine Kaestle, and Abbie Goldberg\u2019s (2011) study\u00a0[1] of how boys and young men learn about menstruation. To understand this process, Allen and her colleagues analyzed the written narratives of 23 young men in which the men described how they learned about menstruation, what they thought of it when they first learned about it, and what they think of it now. By looking for patterns across all 23 men\u2019s narratives, the researchers were able to develop a general theory of how boys and young men learn about this aspect of girls\u2019 and women\u2019s biology. They conclude that sisters play an important role in boys\u2019 early understanding of menstruation, that menstruation makes boys feel somewhat separated from girls, and that as they enter young adulthood and form romantic relationships, young men develop more mature attitudes about menstruation. Note how this study began with the data\u2014men\u2019s narratives of learning about menstruation\u2014and tried to develop a theory.\nIn another inductive study, Kristin Ferguson and colleagues (Ferguson, Kim, & McCoy, 2011)\u00a0[2] analyzed empirical data to better understand how best to meet the needs of young people who are experiencing homelessness. The authors analyzed data from focus groups with 20 young people at a homeless shelter. From these data they developed a set of recommendations for those interested in applied interventions that serve youth that are experiencing homelessness. The researchers also developed hypotheses for people who might wish to conduct further investigation of the topic. Though Ferguson and her colleagues did not test the hypotheses that they developed from their analysis, their study ends where most deductive investigations begin: with a theory and a hypothesis derived from that theory.\nDeductive approaches and some examples\nResearchers taking a deductive approach will start with a compelling social theory and then test its implications with data. In other words, they utilize the same steps as inductive research, but they will reverse the order, moving from general to more specific levels. Deductive research approach is most associated with scientific investigation. The researcher studies what others have done, reads existing theories of whatever phenomenon they are studying, and then tests hypotheses that emerge from those theories. Figure 6.2 outlines the steps involved with a deductive approach to research.\n\u00a0\nFigure 6.2 Deductive research\nAlthough not all social science researchers utilize a deductive approach, there are some excellent, recent examples of deductive research. We\u2019ll take a look at a couple of those next.\nIn a study of US law enforcement responses to hate crimes, Ryan King and colleagues (King, Messner, & Baller, 2009)\u00a0[3] hypothesized that law enforcement\u2019s response would be less vigorous in areas of the country that had a stronger history of racial violence. The authors developed their hypothesis from their reading of prior research and theories on the topic. They tested the hypothesis by analyzing data on states\u2019 lynching histories and hate crime responses. Overall, the authors found support for their hypothesis. One might associate this research with critical theory.\nIn another recent deductive study, Melissa Milkie and Catharine Warner (2011)\u00a0[4] studied the effects of different classroom environments on first graders\u2019 mental health. Based on prior research and theory, Milkie and Warner hypothesized that negative classroom features, such as a lack of basic supplies and even heat, would be associated with emotional and behavioral problems in children. One might associate this research with systems theory. The researchers found support for their hypothesis, demonstrating that policymakers should be more attentive to the mental health outcomes of children\u2019s school experiences, just as they track academic outcomes (American Sociological Association, 2011). [5]\nComplementary approaches\nWhile inductive and deductive approaches to research seem quite different, they can be rather complementary. In some cases, researchers will plan for their study to include multiple components, one inductive and the other deductive. In other cases, a researcher might begin their study planning to utilize only one approach but then discover along the way that the other approach is needed to help illuminate findings. Here is an example of each such case.\nThe original author of the textbook from which this textbook is adapted, Dr. Amy Blackstone, relates a story about her collaborative research on sexual harassment.\nWe began the study knowing that we would like to take both a deductive and an inductive approach in our work. We therefore administered a quantitative survey, the responses to which we could analyze in order to test hypotheses, and also conducted qualitative interviews with a number of the survey participants. The survey data were well suited to a deductive approach; we could analyze those data to test hypotheses that were generated based on theories of harassment. The interview data were well suited to an inductive approach; we looked for patterns across the interviews and then tried to make sense of those patterns by theorizing about them.\nFor one paper (Uggen & Blackstone, 2004),\u00a0[6] we began with a prominent feminist theory of the sexual harassment of adult women and developed a set of hypotheses outlining how we expected the theory to apply in the case of younger women\u2019s and men\u2019s harassment experiences. We then tested our hypotheses by analyzing the survey data. In general, we found support for the theory that posited that the current gender system, in which heteronormative men wield the most power in the workplace, explained workplace sexual harassment\u2014not just of adult women but of younger women and men as well. In a more recent paper (Blackstone, Houle, & Uggen, 2006), [7] we did not hypothesize about what we might find but instead inductively analyzed interview data, looking for patterns that might tell us something about how or whether workers\u2019 perceptions of harassment change as they age and gain workplace experience. From this analysis, we determined that workers\u2019 perceptions of harassment did indeed shift as they gained experience and that their later definitions of harassment were more stringent than those they held during adolescence. Overall, our desire to understand young workers\u2019 harassment experiences fully\u2014in terms of their objective workplace experiences, their perceptions of those experiences, and their stories of their experiences\u2014led us to adopt both deductive and inductive approaches in the work. (Blackstone, n.d., p. 21)\nResearchers may not set out to employ both approaches in their work, but sometimes their use of one approach leads them to the other. One such example is described eloquently in Russell Schutt\u2019s Investigating the Social World (2006).\u00a0[8] As Schutt describes, researchers Lawrence Sherman and Richard Berk (1984)\u00a0[9] conducted an experiment to test two competing theories of the effects of punishment on deterring deviance (in this case, domestic violence). Specifically, Sherman and Berk hypothesized that deterrence theory would provide a better explanation of the effects of arresting accused batterers than labeling theory. Deterrence theory predicts that arresting an accused spouse batterer will reduce future incidents of violence. Conversely, labeling theory predicts that arresting accused spouse batterers will increase future incidents. Figure 6.3 summarizes the two competing theories and the predictions that Sherman and Berk set out to test.\n\u00a0\nFigure 6.3 Predicting the effects of arrest on future spouse battery\nAfter conducting an experiment with the help of local police, Sherman and Berk found, that arrest did deter future incidents of violence, thus supporting their hypothesis that deterrence theory would better predict the effect of arrest. After conducting this research, they and other researchers went on to conduct similar experiments [10] in six additional cities (Berk, Campbell, Klap, & Western, 1992; Pate & Hamilton, 1992; Sherman & Smith, 1992). [11] The follow-up studies yielded mixed results. In some cases, arrest deterred future incidents of violence while in other cases, arrest did not. These results left the researchers with new data that they needed to explain, so they utilized an inductive approach to make sense of their latest empirical observations. The new studies revealed that arrest has a deterrent effect on individuals that are married and employed, while arrest may encourage future battering offenses in individuals that are unmarried and unemployed. Researchers thus turned to control theory to explain their observations, as it predicts that stakes in conformity are developed through social ties like marriage and employment.\n\u00a0\nFigure 6.4 Predicting the effects of arrest on future spouse battery: A new theory\n[12]\nSherman and Berk\u2019s research and the associated follow-up studies demonstrate that researchers can start with a deductive approach and move to inductive approach when confronted with new data that must be explained.\n\u00a0\n\nKey Takeaways\n\nThe inductive approach begins with a set of empirical observations, seeking patterns in those observations, and then theorizing about those patterns.\nThe deductive approach begins with a theory, developing hypotheses from that theory, and then collecting and analyzing data to test those hypotheses.\nInductive and deductive approaches to research can be employed together for a more complete understanding of the topic that a researcher is studying.\nThough researchers don\u2019t always set out to use both inductive and deductive strategies in their work, they sometimes find that new questions arise in the course of an investigation that can best be answered by employing both approaches.\n\n\n\u00a0\n\nGlossary\nDeductive approach\u2013 when a researcher studies what others have done, reads existing theories of whatever phenomenon they are studying, and then tests hypotheses that emerge from those theories\nInductive approach\u2013 when a researcher starts with a set of observations and then moves from particular experiences to a more general set of propositions about those experiences\n\n\u00a0\nAllen, K. R., Kaestle, C. E., & Goldberg, A. E. (2011). More than just a punctuation mark: How boys and young men learn about menstruation. Journal of Family Issues, 32, 129\u2013156. \u21b5Ferguson, K. M., Kim, M. A., & McCoy, S. (2011). Enhancing empowerment and leadership among homeless youth in agency and community settings: A grounded theory approach. Child and Adolescent Social Work Journal, 28, 1\u201322. \u21b5King, R. D., Messner, S. F., & Baller, R. D. (2009). Contemporary hate crimes, law enforcement, and the legacy of racial violence. American Sociological Review, 74, 291\u2013315. \u21b5Milkie, M. A., & Warner, C. H. (2011). Classroom learning environments and the mental health of first grade children. Journal of Health and Social Behavior, 52, 4\u201322. \u21b5The American Sociological Association wrote a press release on Milkie and Warner\u2019s findings: American Sociological Association. (2011). Study: Negative classroom environment adversely affects children\u2019s mental health. Retrieved from: https://www.sciencedaily.com/releases/2011/03/110309073717.htm \u21b5Uggen, C., & Blackstone, A. (2004). Sexual harassment as a gendered expression of power. American Sociological Review, 69, 64\u201392. \u21b5Blackstone, A., Houle, J., & Uggen, C. \u201cAt the time I thought it was great\u201d: Age, experience, and workers\u2019 perceptions of sexual harassment. Presented at the 2006 meetings of the American Sociological Association. \u21b5Schutt, R. K. (2006). Investigating the social world: The process and practice of research. Thousand Oaks, CA: Pine Forge Press. \u21b5Sherman, L. W., & Berk, R. A. (1984). The specific deterrent effects of arrest for domestic assault. American Sociological Review, 49, 261\u2013272. \u21b5The researchers did what\u2019s called replication. \u21b5Berk, R., Campbell, A., Klap, R., & Western, B. (1992). The deterrent effect of arrest in incidents of domestic violence: A Bayesian analysis of four field experiments. American Sociological Review, 57, 698\u2013708; Pate, A., & Hamilton, E. (1992). Formal and informal deterrents to domestic violence: The Dade county spouse assault experiment. American Sociological Review, 57, 691\u2013697; Sherman, L., & Smith, D. (1992). Crime, punishment, and stake in conformity: Legal and informal control of domestic violence. American Sociological Review, 57, 680\u2013690. \u21b5All figures in this section are copied from Blackstone, A. (2012) Principles of sociological inquiry: Qualitative and quantitative methods. Saylor Foundation. Retrieved from: https://saylordotorg.github.io/text_principles-of-sociological-inquiry-qualitative-and-quantitative-methods/ Shared under CC-BY-NC-SA 3.0 License (https://creativecommons.org/licenses/by-nc-sa/3.0/) \u21b5\n\n\n\n\n\n\t\t\t\t\t\t\t\t\t\tPrevious: 6.2 Paradigms, theories, and how they shape a researcher\u2019s approach\t\t\t\t\n\n\n\n\t\t\t\t\t\t\t\t\t\tNext: 7.0 Chapter introduction\t\t\t\t\t\n\n\n\n\nBack to top\n\n\n\n\n\nLicense\n\nScientific Inquiry in Social Work by Matthew DeCarlo is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License, except where otherwise noted. \n\n\nShare This Book\n\nShare on Twitter \n\n\n\n\n\n\n\n\n\n\n\n\n\nPowered by Pressbooks\n\nGuides and Tutorials\n|Contact\n\n\n\n\n\nPressbooks on YouTube\n\n\n\n\n\nPressbooks on Twitter\n\n\n\n\n\n\n\n\n\n\n\n\n"
  },
  {
    "text": "\nStudy ResourcesMain Menuby Schoolby Textbookby Literature TitleStudy Guides\nInfographicsby SubjectExpert Tutors\nContributingMain MenuEarn Free AccessUpload DocumentsRefer Your FriendsEarn MoneyBecome a TutorScholarshipsFor Educators\nLog in\nSign up\nFind\nStudy Resources\nby Schoolby Textbookby Literature Title\nStudy GuidesInfographicsby SubjectAsk\nExpert TutorsYou can ask !Earn by\nContributing\nEarn Free Access\nLearn More >Upload DocumentsRefer Your FriendsEarn MoneyBecome a TutorScholarships\nLearn More >Are you an educator?Log inSign up Harvard UniversityDGMDDGMD E-10Usually it is advantageous to move from general to specific questions OneUsually it is advantageous to move from general toSchool\nHarvard UniversityCourse Title\nDGMD E-10TypeNotesUploaded By\nyakosoloPages\n33This preview shows page 25 - 28 out of 33 pages.Usually, it is advantageous to move from general to\nspecific questions.\nOne technique is to start with the known (what you\nknow) and go to the unknown.\nSAMPLE WITNESS QUESTIONS\nHandout 8-8 has examples of Sample Questions that\nyou may be useful to you.\n\uf0b7\nWhat is your name, work address and phone\nnumber?\n\uf0b7\nWhat is your duty station (location) and position\n(job title)?\n\uf0b7\nWhat is your technical background, skills, or\nknowledge?\n\uf0b7\nTell us, in your own words, what you were doing\nin the hours prior to the accident, what you saw\nof the accident and what happened afterwards.\n\uf0b7\nWhat is your connection with those involved in\nthe accident?\n\uf0b7\nWhat attracted your attention to the accident?\n\uf0b7\nWhat was the position of the vehicle or\nequipment, and individual involved in the\naccident, when first seen?\n\uf0b7\nWhat was the direction of travel, fall, or final\nresting place of the vehicle or equipment, and\nindividual involved in the accident? (Have the\nParticipants Manual - Lesson 8\nDecember 12, 2009\nPage 25 of 33Unit Title:\nEvidence Gathering and Documentation\nLesson 8:\nNotes\nwitness draw a diagram, if appropriate).\n\uf0b7\nWhat was the weather at the time of the\naccident? Was it clear and sunny? Was it rainy\nor smoky? What was the wind conditions\n(velocity, gusty)?\n\uf0b7\nWhat actions did you take at the accident site?\n\uf0b7\nWere there any other witnesses around?\nDo the\npolice have your witnesses\u2019 names?\nSAMPLE WITNESS QUESTIONS\n(continued)\n\uf0b7\nDo you wear glasses or a hearing aid? What\ntype? Did you have your glasses or hearing aid\non?\n\uf0b7\nWhat do you think was the main cause of the\naccident?\n\uf0b7\nIs there any additional information you would like\nto provide?\n\uf0b7\nAlways close with: \u201cIf you think of any\nadditional information that would help us in\nthe investigation please contact us\u201d.\n\uf0b7\nLet them know that if you have additional\nquestions you may be contacting them again\nalso?\nCONDUCTING THE INTERVIEWS\nConsiderations that should be taken into account\nduring the interview process are:\nIn some instances, the witness may have to be taken to\nParticipants Manual - Lesson 8\nDecember 12, 2009\nPage 26 of 33Unit Title:\nEvidence Gathering and Documentation\nLesson 8:\nNotes\nthe accident site or crash scene after the initial\ninterview for clarification of their statement.\nAvoid collective interviews (interviewing more than one\nwitness at a time.)\nOne team member should ask the questions. Other\nmembers should only interrupt and ask questions with\nthe permission of the interview lead.\nDo not prejudge a witness. Keep an open mind. Be\nreceptive to all information regardless of its nature\u2014be\na good listener.\nCONDUCTING THE INTERVIEWS (continued)\nBe serious. Maintain control of the interview. Don\u2019t\nmake promises you can\u2019t keep. Avoid contemptuous\nattitudes. Avoid controversial matters. Respect the\nemotional state of the witness.\nPlace the witness at ease. Explain the purpose of the\ninterview is for accident prevention purposes and that\nyou only seek the facts related to the accident.You've reached the end of your free preview.Want to read all 33 pages?TERMFall '16PROFESSOR\nGreg MarinovichTAGS\nForensic evidence,\ninvestigator,\nEvidence law,\nUnit Title,\nevidence gatheringShare this link with a friend:\nCopied!Students who viewed this also studiedBuhach Colony High\u2022Science 2012Forensic Science 2012 Chapts 1-2.pdfForensic ScienceTestinvestigatorEvidence lawevidence collection46 pagesForensic Science 2012 Chapts 1-2.pdfBuhach Colony HighScience 2012notesnotesCoastal Carolina University\u2022CJC 212Chapter 03Forensic evidenceCrime sceneinvestigatorEvidence law33 pagesChapter 03Coastal Carolina UniversityCJC 212homeworkhomeworkNo School\u2022AA 1In CLASS Evidence Outline.docxNew TestamentCircumstantial evidenceEvidence law181 pagesIn CLASS Evidence Outline.docxNo SchoolAA 1No School\u2022AA 14 Collection of Crime-Scene Evidence.pdfForensic evidenceinvestigatorEvidence law55 pages4 Collection of Crime-Scene Evidence.pdfNo SchoolAA 1American InterContinental University\u2022CRJS 406physical-evidence-handbook-2017.pdfForensic ScienceThe BibleThe AmericanForensic evidence.........Physical Evidence Handbook312 pagesphysical-evidence-handbook-2017.pdfAmerican InterContinental UniversityCRJS 406Embry-Riddle Aeronautical University\u2022SFTY 409Instructor_Key_Midterm_ExamAviation accidents and incidentspool/question bankPost crash firesvertical soot pattern5 pagesInstructor_Key_Midterm_ExamEmbry-Riddle Aeronautical UniversitySFTY 409test_preptest_prepView moreForensic Science 2012 Chapts 1-2.pdfBuhach Colony HighScience 2012Forensic ScienceTestinvestigatorEvidence lawevidence collectionBuhach Colony High \u2022 Science 2012Forensic Science 2012 Chapts 1-2.pdfnotes98% Related46Chapter 03Coastal Carolina UniversityCJC 212Forensic evidenceCrime sceneinvestigatorEvidence lawCoastal Carolina University \u2022 CJC 212Chapter 03homework97% Related33In CLASS Evidence Outline.docxNo SchoolAA 1New TestamentCircumstantial evidenceEvidence lawNo School \u2022 AA 1In CLASS Evidence Outline.docx94% Related1814 Collection of Crime-Scene Evidence.pdfNo SchoolAA 1Forensic evidenceinvestigatorEvidence lawNo School \u2022 AA 14 Collection of Crime-Scene Evidence.pdf94% Related55physical-evidence-handbook-2017.pdfAmerican InterContinental UniversityCRJS 406Forensic ScienceThe BibleThe AmericanForensic evidence.........Physical Evidence HandbookAmerican InterContinental University \u2022 CRJS 406physical-evidence-handbook-2017.pdf93% Related312Instructor_Key_Midterm_ExamEmbry-Riddle Aeronautical UniversitySFTY 409Aviation accidents and incidentspool/question bankPost crash firesvertical soot patternEmbry-Riddle Aeronautical University \u2022 SFTY 409Instructor_Key_Midterm_Examtest_prep92% Related5View moreStudy on the goDownload the iOSDownload the Android appOther Related MaterialsHarvard University\u2022DGMD E-10pleasurev.1 -final.doc.........106 pagespleasurev.1 -final.docHarvard UniversityDGMD E-10test_preptest_prepHarvard University\u2022DGMD E-10Safeguarding document.docHuman Sexuality.........Human sexual behaviorDfES28 pagesSafeguarding document.docHarvard UniversityDGMD E-10notesnotesHarvard University\u2022DGMD E-10Flexogloss.docdoctor blade54 pagesFlexogloss.docHarvard UniversityDGMD E-10notesnotesHarvard University\u2022DGMD E-10Crogan_Stiegler_Philo_Technics_Activism.docJacques DerridaMartin HeideggerBernard StieglerStiegler65 pagesCrogan_Stiegler_Philo_Technics_Activism.docHarvard UniversityDGMD E-10notesnotesUniversity of Maryland\u2022COMM 60053219911-Actual-Thesis.pdfForensic ScienceForensic evidenceinvestigator183 pages53219911-Actual-Thesis.pdfUniversity of MarylandCOMM 600notesnotesCoastal Carolina University\u2022CJC 212Chapter 03Forensic evidenceCrime sceneinvestigatorEvidence law33 pagesChapter 03Coastal Carolina UniversityCJC 212homeworkhomeworkpleasurev.1 -final.docHarvard UniversityDGMD E-10.........Harvard University \u2022 DGMD E-10pleasurev.1 -final.doctest_prep106Safeguarding document.docHarvard UniversityDGMD E-10Human Sexuality.........Human sexual behaviorDfESHarvard University \u2022 DGMD E-10Safeguarding document.docnotes28Flexogloss.docHarvard UniversityDGMD E-10doctor bladeHarvard University \u2022 DGMD E-10Flexogloss.docnotes54Crogan_Stiegler_Philo_Technics_Activism.docHarvard UniversityDGMD E-10Jacques DerridaMartin HeideggerBernard StieglerStieglerHarvard University \u2022 DGMD E-10Crogan_Stiegler_Philo_Technics_Activism.docnotes6553219911-Actual-Thesis.pdfUniversity of MarylandCOMM 600Forensic ScienceForensic evidenceinvestigatorUniversity of Maryland \u2022 COMM 60053219911-Actual-Thesis.pdfnotes183Chapter 03Coastal Carolina UniversityCJC 212Forensic evidenceCrime sceneinvestigatorEvidence lawCoastal Carolina University \u2022 CJC 212Chapter 03homework33NEWFree for a limited time!Introducing Textbook Solutions. Get step-by-step explanations, verified by experts.Browse TextbooksFor a limited time, find answers and explanations to over 1.2 million textbook exercises for FREE!\n\nCompanyAbout Us\nScholarships\nSitemap\nStandardized Tests\nEducation Summit\nEducator ResourcesGet Course HeroiOS\nAndroid\nEducators\nCareersLeadership\nCareers\nCampus Rep ProgramHelpContact Us\nFAQ\nFeedbackLegalCopyright Policy\nAcademic Integrity\nOur Honor Code\nPrivacy Policy\nTerms of UseConnect with UsCollege Life\nFacebook\nTwitter\nLinkedIn\nYouTube\nInstagramCopyright \u00a9 2020. Course Hero, Inc.Course Hero is not sponsored or endorsed by any college or university."
  },
  {
    "text": "\n\n\nSkip to main content\n\n\n\n\nThis service is more advanced with JavaScript available\n\n\n\n\nAdvertisement\nHide\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSearch SpringerLink\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSearch\n\n\n\n\n\n\n\n\nHome\n\n\n\n\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Data Science Design Manual\n\n\n\n\n\n\n\nThe Data Science Design Manual\n                pp 351-390 |\n                Cite asMachine LearningAuthorsAuthors and affiliationsSteven\u00a0S.\u00a0SkienaChapterFirst Online: 02 July 2017 \n\n\n1\nCitations\n\n\n\n277k\nDownloads\n\n\n\n                Part of the\n                Texts in Computer Science\n                book series (TCS)AbstractFor much of my career, I was highly suspicious of the importance of machine learning. I sat through many talks over the years, with grandiose claims and very meager results. But it is clear that the tide has turned. The most interesting work in computer science today revolves around machine learning, both powerful new algorithms and exciting new applications.Any sufficiently advanced form of cheating is indistinguishable from learning.\u2013 Jan SchaumannThis is a preview of subscription content, log in to check access.PreviewUnable to display preview.\u00a0Download preview PDF.Unable to display preview.\u00a0Download preview PDF.Copyright information\u00a9\u00a0The Author(s)\u00a02017Authors and AffiliationsSteven\u00a0S.\u00a0Skiena1Email author1.Computer Science DepartmentStony Brook UniversityStony BrookUSA\n\n\nAbout this chapter\n\n\n\n\n        Cite this chapter as:\n    \nSkiena S.S. (2017) Machine Learning. In: The Data Science Design Manual. Texts in Computer Science. Springer, Cham. https://doi.org/10.1007/978-3-319-55444-0_11\n\n\n\nFirst Online\n02 July 2017\n\n\nDOI\nhttps://doi.org/10.1007/978-3-319-55444-0_11\n\n\nPublisher Name\nSpringer, Cham\n\n\nPrint ISBN\n978-3-319-55443-3\n\n\nOnline ISBN\n978-3-319-55444-0\n\n\neBook Packages\nComputer Science\nComputer Science (R0)\n\n\n\n\nBuy this book on publisher's site\n\n\nReprints and Permissions\n\n\n\n\n\n\nPersonalised recommendations\n\n\n\n\n\n\n\n\n\n\n\nCite\nchapter\n\n\n\nHow to cite?\n\n\n\n\n\n                    .RIS\n                \n\n\n                            Papers\n                        \n\n                            Reference Manager\n                        \n\n                            RefWorks\n                        \n\n                            Zotero\n                        \n\n\n\n\n\n\n\n                    .ENW\n                \n\n\n                            EndNote\n                        \n\n\n\n\n\n\n\n                    .BIB\n                \n\n\n                            BibTeX\n                        \n\n                            JabRef\n                        \n\n                            Mendeley\n                        \n\n\n\n\n\n\n\n            Buy options\n        \n\n\n\n\n\n\n\n\nActions\n\n\n\n\nLog in to check access\n\n\n\n\n\n\n\n\n\n\nBuy eBook\n\n\n                            EUR\u00a050.28\n                        \n\n\n\n\n\n\n\n\n\n\n\n\n\nBuy chapter (PDF)\n\n\n            EUR\u00a024.95\n        \n\n\n\n\n\n\nInstant download\nReadable on all devices\nOwn it forever\nLocal sales tax included if applicable\n\n\n\n\n\n            Buy Physical Book\n            \n\n\n\n\n\n\n\n        Learn about institutional subscriptions\n\n\n\n\n\n\nCite\nchapter\n\n\n\nHow to cite?\n\n\n\n\n\n                    .RIS\n                \n\n\n                            Papers\n                        \n\n                            Reference Manager\n                        \n\n                            RefWorks\n                        \n\n                            Zotero\n                        \n\n\n\n\n\n\n\n                    .ENW\n                \n\n\n                            EndNote\n                        \n\n\n\n\n\n\n\n                    .BIB\n                \n\n\n                            BibTeX\n                        \n\n                            JabRef\n                        \n\n                            Mendeley\n                        \n\n\n\n\n\n\n\n\n\n\nAdvertisement\nHide\n\n\n\n\n\n\n\n\n\n\n\nOver 10 million scientific documents at your fingertips\n\nSwitch Edition\n\nAcademic Edition\nCorporate Edition\n\n\n\n\n\n\n\n\nHome\n\n\nImpressum\n\n\nLegal information\n\n\nPrivacy statement\n\n\nCalifornia privacy statement\n\n\nHow we use cookies\n\n\nManage cookies/Do not sell my data\n\n\nAccessibility\n\n\nContact us\n\n\n\nSpringer Nature\n\n\n\n\n\u00a9 2020 Springer Nature Switzerland AG. Part of Springer Nature.\n\nNot logged in\nNot affiliated\n197.157.135.161\n\n\n\n\n\n\n\n"
  },
  {
    "text": "\n\n\n        Skip to main navigation\n      \n\n\n\n\n\n\n\n\n\n\nSite-wide links\n\nSkip to content\nRIT HomeRochester Institute of Technology\nNTID HomeNational Technical Institute for the Deaf\nSearch\n\n\n\n\nSearch\n\n\n\n\nDirectories\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSEA - Supporting English Acquisition\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\nHomeIntroductionPurposeAudienceInstructionsContributorsStructures and ProcessesWord OrderGrammatical SummaryBasic OrderDeviationsInterruptionMovementResearch FindingsOvergeneralizationExtent of DeviationMovementGuided PracticeIdentifyingJudgingAction StepsArticles and NounsGrammatical SummaryDefinition of ArticlesArticles and Types of NounsCount and Non-CountSingular and PluralSpecific and GeneralKnown and UnknownSelection of ArticlesGuided PracticeExpressing QuantityPlural FormsSpecific Versus GeneralKnown Versus UnknownJudging UsageArticles in SentencesArticles in a ParagraphAction StepsPassive VoiceGrammatical SummaryDefinitionStructureUseAgentsStative vs. TrueIntroductionEmotional StatesSummaryResearch FindingsSubtypesComprehensionProductionImplicationsGuided PracticeIdentifyingStativeSimplifyingAction StepsIntroductionSpecific Activities-ED/-ING Participles of Emotional response VerbsGrammatical SummaryWhat is a Verb?Verb FormationConfusionEmotional Response VerbsParticiplesUsing Concept SentencesGuided PracticeVerb or Adverb?Analyzing SentencesAppropriate ParticiplesCreating Concept SentencesAction StepsWh-QuestionsGrammatical SummaryDescriptionWord OrderTypes of Wh-QuestionsGapsOther StructuresResearch FindingsGuided PracticeIdentifying GapsProducingJudging DifficultyImplications and Action StepsSummaryImplicationsAction StepsReading Comprehension: Process and StrategiesProcess SummaryWhat is Reading?Before ReadingDuring ReadingAfter ReadingAction StepsReading and Writing in Content AreasIncorporating Reading and Writing Activities into Content Area CoursesBefore-Reading ActivitiesDuring-Reading ActivitiesAfter-Reading ActivitiesOther ActivitiesVocabulary Building IdeasParagraph StructureProcess SummaryTopic SentenceTopic PlacementParagraph BodyConcluding SentenceRhetorical OrganizationResearch FindingsGuided PracticeIdentifying ErrorsControlling IdeasIdentifying TopicAction StepsBasic Essay Structure: Introductory and Concluding ParagraphsProcess SummaryBasic Essay StructureIntroductory ParagraphsConcluding ParagraphsBasic Essay SampleResearch FindingsGuided PracticeAction StepsReference WordsProcess SummaryParts of SpeechDirection of ReferenceAntecedentsSummary of the Overview of Reference WordsResearch FindingsGuided PracticeAntecedentsAnaphoric, Cataphoric, Exophoric WordsReference WordsAction StepsExpressing Logical RelationshipsGrammatical SummaryConnectivesLogical RelationshipsAdditiveOppositional/ ContrastiveReason - ResultTimeConditionalExampleGuided PracticeAdditiveOppositional/ ContrastiveAdditive and OppositionalTimeClauses for TimeConjunctions to PrepositionsConjunctions to Conjunctive AdverbsReasons and ResultsConditionAppropriate ConjunctionsAppropriate Conjunctive AdverbsAppropriate PrepositionsAppropriate ConnectivesAction StepsLogical Subjects of InfinitivesGrammatical SummaryEnglish ClausesInterpreting Logical SubjectsProperties of VerbsFrom OutsideIn Passive SentencesPurpose or ReasonResearch FindingsKnowledge of InfinitivesDeaf Students' InterpretationAssessing Deaf Students' KnowledgeExplanation of ResultsImplicationsGuided PracticeIdentifyingJudging Sentence DifficultyAction StepsDescriptionSample TestAlternative TestWord KnowledgeGrammatical SummaryWhat are Morphemes?Models of Word KnowledgeMorphographic ApproachResearch FindingsGuided PracticeMorphemes Representing NumeralsIdentifying Root MorphographsParts of Speech PracticeWord Formation in ContextWord FamiliesAction StepsPhrasal VerbsGrammatical SummaryProductivitySyntaxSemanticsSynonymsResearch FindingsGuided PracticeSynonymsSyntaxAction StepsRelative ClausesGrammatical SummaryDescriptionFunctionsIntroducersConfusionGapsResearch FindingsKnowledge of Sentence TypesMore Difficult Relativized PositionsGuided PracticeIdentifyingProducingSimplifyingImplications and Action StepsReferencesFeedbackContact\n\n\n\n\n\n\n\n\nSpecific and General\n\n\n\n\n\n\n\n\nNouns of any kind (count or non-count, singular or plural) may be \"specific\" or \"general.\"\nA noun is specific when the writer wishes to talk about some thing or things in particular.\nA noun is general when the writer wishes to make a generalization about some thing or things.\nHere are some examples that contrast specific nouns with general nouns. The highlighted nouns in the first three examples are specific, whereas the highlighted nouns in the second three examples are general.\n\nMy dad's company made a profit this year.\n(profit = count, singular, and specific)\nIt hopes to make bigger profits next year.\n(profits = count, plural, and specific)\nThey will invest the money in new machinery.\n(money = non-count and specific)\nCompanies always try to make a profit.\n(profit = count, singular, and general)\nWithout profits, companies would go bankrupt.\n(profits = count, plural, and general)\nMoney is necessary to live.\n(money = non-count and general)\n\nNote that the equivalent nouns in the examples above are identical in form despite their different usage as specific or general. That is, in the first and the fourth examples, the highlighted noun is profit. In the first example, profit is specific because it refers to the particular profit that the company made this year. In the fourth example, profit is general because it does not refer to any particular profit; instead, it refers to a profit as a generalization, in this case, the goal of companies.\n\n\n\n\n\n\n\n\n\n\n\nMainMenu\n\n\nHome\n\n\nIntroduction\n\n\nStructures and Processes\n\n\nWord Order\n\n\nArticles and Nouns\n\n\nGrammatical Summary\n\n\nDefinition of Articles\n\n\nArticles and Types of Nouns\n\n\nCount and Non-Count\n\n\nSingular and Plural\n\n\nSpecific and General\n\n\nKnown and Unknown\n\n\n\n\nSelection of Articles\n\n\n\n\nGuided Practice\n\n\nAction Steps\n\n\n\n\nPassive Voice\n\n\n-ED/-ING Participles of Emotional response Verbs\n\n\nWh-Questions\n\n\nReading Comprehension: Process and Strategies\n\n\nReading and Writing in Content Areas\n\n\nParagraph Structure\n\n\nBasic Essay Structure: Introductory and Concluding Paragraphs\n\n\nReference Words\n\n\nExpressing Logical Relationships\n\n\nLogical Subjects of Infinitives\n\n\nWord Knowledge\n\n\nPhrasal Verbs\n\n\nRelative Clauses\n\n\n\n\nReferences\n\n\nFeedback\n\n\nContact\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCopyright \u00a9 Rochester Institute of Technology. All rights reserved. Terms of Use | Copyright Infringement\nRIT and NTID are registered trademarks of Rochester Institute of Technology.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
  },
  {
    "text": "\n\nSkip to main content\n\n\n\n\nThe Open UniversityExplore OpenLearnCreate and publishyour own free courses\n\n\n\n\n\n\n\n\n\n            Search for free courses and collections\n        \n\n\n\n\n\n\nSearch\n\nHomeGet startedCreate a courseFree coursesCollectionsSign up / Sign inExplore OpenLearnHomeGet startedCreate a courseFree coursesCollectionsSign in\n\n\n\n\n\n\n\n\n\n            Search for free courses and collections\n        \n\n\n\n\n\n\nSearch\n\nMy OpenLearn Create ProfilePersonalise your OpenLearn profileSave Your favourite contentGet recognition for your learningCreate accountAlready Registered?Sign inGet startedCreate a courseFree coursesPage path\nHome /\u00a0\u25b6\ufe0e Courses /\u00a0\u25b6\ufe0e Collections /\u00a0\u25b6\ufe0e Health Education and Training (HEAT) /\u00a0\u25b6\ufe0e HEAT_HMER_ET_1.0 /\u00a0\u25b6\ufe0e Contents /\u00a0\u25b6\ufe0e Health Management, Ethics and Research Module: 13.\u00a0\u00a0Writing Your Community Profile Report and Moving on to Small-Scale Research /\u00a0\u25b6\ufe0e 13.4.2\u00a0\u00a0Research objectives\n\n\nView as single page\n\n\n\n\n\n\nExcept for third party materials and/or otherwise stated (see terms and conditions) the content in OpenLearn is released for use under the terms of the Creative Commons Attribution-NonCommercial-Sharealike 2.0 licence.  In short this allows you to use the content throughout the world without payment\nfor non-commercial purposes in accordance with the Creative Commons non commercial\nsharealike licence.  Please read this licence in full along with OpenLearn terms\nand conditions before making use of the content.When using the content you must attribute us (The Open University) (the OU)\nand any identified author in accordance with the terms of the Creative Commons Licence.The Acknowledgements section is used to list, amongst other things, third party\n(Proprietary), licensed content which is not subject to Creative Commons licensing.  Proprietary\ncontent must be used (retained) intact and in context to the content at all times.  The\nAcknowledgements section  is also used to bring to your attention any other Special Restrictions\nwhich may apply to the content.  For example there may be times when the Creative Commons\nNon-Commercial Sharealike licence does not apply to any of the content even if owned by us (the\nOU).  In these stances, unless stated otherwise, the content may be used for personal and non-commercial\nuse.  We have also identified as Proprietary other material included in the content which is not subject\nto Creative Commons Licence.  These are: OU logos, trading names and may extend to certain photographic and\nvideo images and sound recordings and any other material as may be brought to your attention.Unauthorised use of any of the content may constitute a breach of the terms and conditions\nand/or intellectual property laws.We reserve the right to alter, amend or bring to an end any terms and conditions provided\nhere without notice.All rights falling outside the terms of the Creative Commons licence are retained or controlled\nby The Open University.Head of Intellectual Property, The Open University\n\n\n\nCourse contentExpandContentsHealth Management, Ethics and Research Module: Ethiopian Federal Ministry of HealthHealth Management, Ethics and Research Module: AcknowledgementsHealth Management, Ethics and Research Module: IntroductionHealth Management, Ethics and Research Module: 1.\u00a0\u00a0Health Services in EthiopiaHealth Management, Ethics and Research Module: 2.\u00a0\u00a0Management and Leadership in Community HealthcareHealth Management, Ethics and Research Module: 3.\u00a0\u00a0Planning Health ProgrammesHealth Management, Ethics and Research Module: 4.\u00a0\u00a0Implementing your Health PlansHealth Management, Ethics and Research Module: 5.\u00a0\u00a0Monitoring and ControlHealth Management, Ethics and Research Module: 6.\u00a0\u00a0Management of Supplies at Health Post LevelHealth Management, Ethics and Research Module: 7.\u00a0\u00a0Principles of Healthcare EthicsHealth Management, Ethics and Research Module: 8.\u00a0\u00a0Ethical Dilemmas in Health Service DeliveryHealth Management, Ethics and Research Module: 9.\u00a0\u00a0Rights and Obligations of Health Extension PractitionersHealth Management, Ethics and Research Module: 10.\u00a0\u00a0General Principles of Health Research and Introduction to Community SurveysHealth Management, Ethics and Research Module: 11.\u00a0\u00a0Developing Your Community ProfileHealth Management, Ethics and Research: 12.\u00a0\u00a0Data Collection and Analysis for Your Baseline Community SurveyHealth Management, Ethics and Research Module: 13.\u00a0\u00a0Writing Your Community Profile Report and Moving on to Small-Scale ResearchStudy Session 13\u00a0\u00a0Writing Your Community Profile Report and Moving on to Small-Scale ResearchIntroductionLearning Outcomes for Study Session 1313.1\u00a0\u00a0Writing a report on your community survey13.1.1\u00a0\u00a0Components of a community profile report13.2\u00a0\u00a0Identifying problems for further investigation13.2.1\u00a0\u00a0Clarifying the problem of malaria infection in your community13.2.2\u00a0\u00a0Criteria for choosing health problems to research13.2.3\u00a0\u00a0Poor sanitary conditions: creating a research question13.2.4\u00a0\u00a0Community participation in prioritising health issues13.3\u00a0\u00a0Choosing which topic to research13.4\u00a0\u00a0Clarifying your research question13.4.1\u00a0\u00a0What other sources should you consult?13.4.2\u00a0\u00a0Research objectivesSummary of Study Session 13Self-Assessment Questions (SAQs) for Study Session 13Health Management, Ethics and Research: 14.\u00a0\u00a0Research Strategies and Study Designs for Small-Scale ResearchHealth Management, Ethics and Research Module: 15.\u00a0\u00a0Sampling Methods and Sample Size in Small-Scale ResearchHealth Management, Ethics and Research Module: 16.\u00a0\u00a0Extended Case Study on Health Management, Ethics and ResearchDownload PDF versionHealth Management, Ethics and Research PDF (1.4MB)<Back to\u00a0Ethiopian HEAT Modules<Back to HEAT home pageAbout this course40 hours study1Level 1: IntroductoryCourse descriptionHealth Management, Ethics and Research If you create an account, you can set up a personal learning profile on the site.Create accountSee more courses13.4.2\u00a0\u00a0Research objectivesThe final part of clarifying your research project involves thinking in more detail about your research objectives. Research objectives should be closely related to the statement of the problem and summarise what you hope will be achieved by the study. For example, if the problem identified is low utilisation of antenatal care services, the general objective of the study could be to identify the reasons for this low uptake, in order to find ways of improving it.Writing your research objectives clearly helps to:Define the focus of your studyClearly identify variables to be measuredIndicate the various steps to be involvedEstablish the limits of the studyAvoid collection of any data that is not strictly necessary.What do you think might happen if you started a research project, but hadn\u2019t written any clear research objectives?\nWithout clearly written research objectives, you might be confused about the limits of the study, what data should be collected, or how to conduct the research.Objectives can be general or specific. The general objective of your study states what you expect to achieve in general terms. Specific objectives break down the general objective into smaller, logically connected parts that systematically address the various aspects of the problem. Your specific objectives should specify exactly what you will do in each phase of your study, how, where, when and for what purpose.How should your objectives be stated?Your objectives should be stated using action verbs that are specific enough to be measured, for example: to compare, to calculate, to assess, to determine, to verify, to calculate, to describe, to explain, etc. Avoid the use of vague non-active verbs such as: to appreciate, to understand, to believe, to study, etc., because it is difficult to evaluate whether they have been achieved.Case Study 13.3  General and specific objectives for a counselling projectA research study designed to assess the accessibility and acceptability of the Voluntary Counselling and Testing (VCT) Services for HIV infection in kebele X had the following general and specific objectives: General objective: To identify factors that affects the acceptability of VCT services and to assess community attitudes towards comprehensive care and support for people living with HIV/AIDS.Specific objectives:To assess the knowledge, attitude and practice of the community towards HIV/AIDS and VCT services.To identify barriers and concerns related to VCT and its uptake.To assess the awareness and perception of the study community regarding comprehensive care and support for people living with HIV/AIDS.What is the difference between the specific objectives and the general objective of a research project? You can use the example in Case Study 13.3 to help you answer this question.\nSpecific objectives are detailed objectives that describe what will be researched during the study, whereas the general objective is a much broader statement about what the study aims to achieve overall.In the next study session, we will move on to teach you about research strategies and alternative study designs that you may choose to conduct for a small-scale research project in your community.Back to previous pagePrevious13.4.1\u00a0\u00a0What other sources should you consult?Go to next pageNextSummary of Study Session 13PrintpageFor further information, take a look at our frequently asked questions which may give you the support you need.Have a question?Report a concernBack to top\n\n\n\n\n\n\n\n\n\n            Search OpenLearn Create\n        \n\n\n\n\n\n\nSearch OpenLearn Create\n\nOpenLearn CreateAbout usHelp and SupportCopyrightContact OpenLearn CreateExploreFree CoursesCollectionsPartnersCreate & ManageCourse guideCreate a courseManage coursesCreative commons licenceExcept for third party materials and otherwise stated, content on this site is\n made available under Creative Commons licences. OpenLearn Create is powered by a number\n of software tools released under the GNU GPL.\u00a92017. All rights reserved. The Open University is incorporated by Royal Charter (RC 000391),\n an exempt charity in England & Wales and a charity registered in Scotland (SC 038302). The Open University is authorised\n and regulated by the Financial Conduct Authority in relation to its secondary activity of credit broking.Conditions of usePrivacy and cookiesModern Slavery ActOU CopyrightLink toTwitterLink toFacebookLink toYoutube\n\n\n\n\n\n\n"
  },
  {
    "text": "\n\n\n\n\nSkip to content\n\n\n\n\n\nMenu\n\n\n\nSearch TechSmith.com\n\nSearch TechSmith.com\n\nCancel\n\n\n\nMenu\n\n\n\n\n\n\nProducts\n\n\n\n\n\n\nSnagit\n\n\nScreen Capture & Screen Recorder\n\n\nFree TrialBuy\n\n\n\n\n\nCamtasia\n\n\nScreen Recorder & Video Editor\n\n\nFree TrialBuy\n\n\n\n\n\nSnagit/Camtasia Bundle\n\n\nBuy Together and Save\n\n\nBuy\n\n\n\n\n\nAssets for Snagit\n\nStock Photos and Custom Assets\n\n\nLearn MoreBuy\n\n\n\n\n\nAssets for Camtasia\n\nStock Video and Custom Assets\n\n\nLearn MoreBuy\n\n\n\n\n\nKnowmia\n\nVideo Learning Platform\n\n\nLearn MoreBuy\n\n\n\n\n\nScreencast\n\nVideo & Content Hosting\n\n\nLearn More\n\n\n\n\n\nAudiate\n\n\nVoice Recorder & Audio Editor\n\n\nFree TrialBuy\n\n\n\n\n\nVideo Review\n\nCollaborative Feedback Tool\n\n\nLearn MoreBuy\n\n\nAll Products & Downloads \u203a\n\n\n\n\nSolutions\n\n\n\n\n\n\nCustomer Education\n\nTrain and support your customers\n\n\n\n\n\n\n\nBusiness\n\nCommunicate visually across your company\n\n\n\n\n\n\n\nHigher Education\n\nEnhance your eLearning content\n\n\n\n\n\n\n\nSupport\n\n\n\n\n\n\nFind Software Key\n\nUse our automatic key lookup tool\n\n\n\n\n\n\n\nTutorials\n\nProduct videos, tutorials, and guides\n\n\n\n\n\n\n\nHelp Center\n\nTroubleshooting and help files\n\n\n\n\n\n\n\nCommunity Forums\n\nShare and connect with other users\n\n\n\n\n\n\n\nEmail Preferences\n\nManage your subscription\n\n\n\n\n\n\n\nWebinars\n\nFree \u201cGetting Started\u201d webinars\n\n\n\n\n\n\n\nResources\n\n\n\n\n\n\nBlog\n\nTips, best practices, and expert advice\n\n\n\n\n\n\n\nTechSmith Academy\n\nFree video courses\n\n\n\n\n\n\n\nCustomer Stories\n\nSee how our customers find success\n\n\n\n\n\n\n\nPress Room\n\nOur latest news, updates, and awards\n\n\n\n\n\n\n\nPartners\n\nHow to locate or become a partner\n\n\n\n\n\n\n\nResearch\n\nOur original research and data\n\n\n\n\n\n\n\nAbout\n\n\n\n\n\n\nAbout Us\n\nOur mission, history, and customers\n\n\n\n\n\n\n\nContact Us\n\nWe're here to help\n\n\n\n\n\n\n\nCareers\n\nJoin our team\n\n\n\n\n\n\n\nStore\n\n\n\n\n\n\nSearch TechSmith.com\n\nSearch TechSmith.com\n\nCancel\n\n\n\n\n\n\n\nBrowse Categories \u00a0\n\n\n\nLatest Articles\n \n\nCapture & Recording\n\n\nVideo\n\n\nVisuals\n\n\nBusiness\n\n\nEducation\n\n\nCustomer Stories\n\n\nPodcasts\n\n\n \n \n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9 Ways Screen Capture Will Make Your Life Easier\n\nIt\u2019s happened to all of us. You see something on your computer screen that you want to share with a coworker. Perhaps you... \n\n\n\n\n\n\n \n\n\nIt\u2019s happened to all of us. You see something on your computer screen that you want to share with a coworker. Perhaps you copy the URL and paste it into an email.\nThen, you type out some text like, \u201ccheck out the article found at this link. Scroll about three-quarters of the way down the page\u2026\u201d If screen capture were a person, this is when she (or he) would say, \u201cPut me in, Coach!\u201d\n\nScreen capture is useful when you need to show others something that you see on your computer monitor. Sometimes a still-image screen capture, known as a screenshot, is perfect. If your screen capture requires a lot of explanation though, a screencast might be an even better option.\nUnlike traditional pictures or videos recorded with a camera, a screen capture program is necessary to grab an image or recording of on-screen activity.\nWith a screen capture tool like Snagit, you are able to communicate more clearly than with text alone by using the screen capture and screen recording functionality. You can show someone exactly what you want them to know, rather than relying solely on words. You can even take your screen capture a step further and incorporate a human element with webcam capture, which can be helpful when you are using screencasting to build and strengthen relationships.\nWhen would you use screen capture?\nPerhaps you\u2019re wondering when screen capture could come in handy? The possibilities are endless! Any situation where you need to convey a complex idea and want to prevent confusion is a potential opportunity, but not the only circumstance when it would make sense to use an image or video captured from your screen.\nHere are 9 ways screen capture can make your life easier.\n1. Report an error message to IT and show them exactly what type of problem you\u2019re having.\n\n2.\u00a0Save important things you might like to refer back to later.\n\n3. Provide feedback to a colleague.\n\n4. Send a personalized video to a customer to touch base about an existing account.\n\n5. Support your customers with clear instructions that explain how to complete a task.\n\n6. Share a brief portion of a video.\n\nYou can view full video, My Favorite Outlook Calendar Tips and Tricks, on YouTube.\n7. Make a meme for use in an email, or for your company\u2019s social media channels.\n\n8. Explain a document to a client.\n\n9. Create an on-demand presentation by recording PowerPoint slides.\n\nThat\u2019s my list of most common ways screen capture makes my life easier.\nHave another use case for screen capture? We\u2019d love to hear about it! Send us a message, tweet, or comment on Twitter or Facebook\nRelated Posts:How to Edit Video (With Step-by-Step Video)How to Make a YouTube Video (Beginner\u2019s Guide)The Ultimate Guide to Easily Make Instructional Videos \n\n\n\n\n\nCapture & Recording\n\nBrowse Categories \n\nBusiness\nCapture & Recording\nEducation\nVideo\nVisuals\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAllison Boatman\nAllison Boatman is a member of the Marketing Team at TechSmith.Follow her on Twitter @allisonboats\nShe can often be found aimlessly wandering around local craft stores.\r\nPersonal motto: \"Work hard, stay humble.\"\r\nFavorites: Alaskan Malamutes, Iceland, and 90's pop culture.\n\n\n\n\n\n\n\t\t\t\t\tHow to Make a Split Screen Video (3 Simple Steps)\t\t\t\t\n\n\n\n\t\t\t\t\tHow to Create Visual Process Documentation and Guides\t\t\t\t\n\n\n\n\t\t\t\t\tHow to Always Keep Your Screenshots Up to Date\t\t\t\t\n\n\n\n\nRelated Posts:How to Edit Video (With Step-by-Step Video)How to Make a YouTube Video (Beginner\u2019s Guide)The Ultimate Guide to Easily Make Instructional Videos\n\nPost navigation\nHow I Use Quizzing in VideosHow to Soundproof a Room for Voice Recording\n\n\n\n\n\n\n\n\n\n\nSubscribe to TechSmith\u2019s Newsletter\nJoin over 200,000 people who get actionable tips and expert advice in their inbox every month.\nSubscribe\n\n\n\n\n\n\n\n\n\nProducts\nSnagit\nCamtasia\nAssets for Camtasia\nAssets for Snagit\nKnowmia\nScreencast\nAudiate\nVideo Review\nJing\nScreen Recorders\nSolutions\nCustomer Education\nBusiness\nHigher Education\nSupport\nFind Software Key\nTutorials\nHelp Center\nCommunity Forums\nEmail Preferences\nWebinars\nResources\nBlog\nTechSmith Academy\nCustomer Stories\nPress Room\nPartners\nResearch\nAbout\nAbout Us\nContact Us\nCareers\nStore\nFind a Reseller\nOnline Store FAQ\nPayment Options\nReturn Policy\n \n\n\n\n\n\n\n\n\nYou Should Stay In Touch!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy\nAccessibility\nContact\nSitemap\n\n\n\n\u00a9\u00a01995\u00a0-\u00a02020, TechSmith Corporation, All\u00a0Rights\u00a0Reserved.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
  },
  {
    "text": "\n\n\n\n\nSkip to content\n\n\n\n\n\nMenu\n\n\n\nSearch TechSmith.com\n\nSearch TechSmith.com\n\nCancel\n\n\n\nMenu\n\n\n\n\n\n\nProducts\n\n\n\n\n\n\nSnagit\n\n\nScreen Capture & Screen Recorder\n\n\nFree TrialBuy\n\n\n\n\n\nCamtasia\n\n\nScreen Recorder & Video Editor\n\n\nFree TrialBuy\n\n\n\n\n\nSnagit/Camtasia Bundle\n\n\nBuy Together and Save\n\n\nBuy\n\n\n\n\n\nAssets for Snagit\n\nStock Photos and Custom Assets\n\n\nLearn MoreBuy\n\n\n\n\n\nAssets for Camtasia\n\nStock Video and Custom Assets\n\n\nLearn MoreBuy\n\n\n\n\n\nKnowmia\n\nVideo Learning Platform\n\n\nLearn MoreBuy\n\n\n\n\n\nScreencast\n\nVideo & Content Hosting\n\n\nLearn More\n\n\n\n\n\nAudiate\n\n\nVoice Recorder & Audio Editor\n\n\nFree TrialBuy\n\n\n\n\n\nVideo Review\n\nCollaborative Feedback Tool\n\n\nLearn MoreBuy\n\n\nAll Products & Downloads \u203a\n\n\n\n\nSolutions\n\n\n\n\n\n\nCustomer Education\n\nTrain and support your customers\n\n\n\n\n\n\n\nBusiness\n\nCommunicate visually across your company\n\n\n\n\n\n\n\nHigher Education\n\nEnhance your eLearning content\n\n\n\n\n\n\n\nSupport\n\n\n\n\n\n\nFind Software Key\n\nUse our automatic key lookup tool\n\n\n\n\n\n\n\nTutorials\n\nProduct videos, tutorials, and guides\n\n\n\n\n\n\n\nHelp Center\n\nTroubleshooting and help files\n\n\n\n\n\n\n\nCommunity Forums\n\nShare and connect with other users\n\n\n\n\n\n\n\nEmail Preferences\n\nManage your subscription\n\n\n\n\n\n\n\nWebinars\n\nFree \u201cGetting Started\u201d webinars\n\n\n\n\n\n\n\nResources\n\n\n\n\n\n\nBlog\n\nTips, best practices, and expert advice\n\n\n\n\n\n\n\nTechSmith Academy\n\nFree video courses\n\n\n\n\n\n\n\nCustomer Stories\n\nSee how our customers find success\n\n\n\n\n\n\n\nPress Room\n\nOur latest news, updates, and awards\n\n\n\n\n\n\n\nPartners\n\nHow to locate or become a partner\n\n\n\n\n\n\n\nResearch\n\nOur original research and data\n\n\n\n\n\n\n\nAbout\n\n\n\n\n\n\nAbout Us\n\nOur mission, history, and customers\n\n\n\n\n\n\n\nContact Us\n\nWe're here to help\n\n\n\n\n\n\n\nCareers\n\nJoin our team\n\n\n\n\n\n\n\nStore\n\n\n\n\n\n\nSearch TechSmith.com\n\nSearch TechSmith.com\n\nCancel\n\n\n\n\n\n\n\nBrowse Categories \u00a0\n\n\n\nLatest Articles\n \n\nCapture & Recording\n\n\nVideo\n\n\nVisuals\n\n\nBusiness\n\n\nEducation\n\n\nCustomer Stories\n\n\nPodcasts\n\n\n \n \n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 Kinds of Screenshots You Need to Start Using Immediately\n\nScreenshots have been described as the most important thing on the internet. And if you\u2019ve seen them in tutorials, or even just... \n\n\n\n\n\n\n \n\n\nScreenshots have been described as the most important thing on the internet. And if you\u2019ve seen them in tutorials, or even just used them in everyday communication, you already know how powerful screenshots can be. \u00a0Screenshots are becoming valuable online currency for communicating more effectively. Knowing when and how to use right ones can help set you apart from everyone else. The info below shows why you should know, appreciate, and use all the different kinds of screenshots.\n1. Screenshot\nDefinition: A single picture of a computer, smartphone, or tablet screen captured and saved as an image file. \nIt all starts with a basic screenshot. You don\u2019t need to have any special applications or software to take a simple screenshot. This functionality is baked into virtually all Windows and Mac computers and smartphones at this point.\nExamples:\nBug Reporting\nSupport Troubleshooting\nQuickly Show Data\n\n2. Screen capture\nDefinition: \u00a0The action of getting all or part of the current screen and turning it into an image or video.\nWhile they may seem similar, a screenshot and screen capture are a little different. A screenshot only refers to a static image. A desktop screen capture involves grabbing anything on your screen, including images, animated GIFs, or videos. It sounds a little bit like arguing semantics, we know, but it can make a difference depending on what end result you want.\nSay you want to capture an entire spreadsheet. Now it gets a little trickier.\nNormally, you\u2019d only be able to capture what you see on your screen, but if you want to capture anything beyond that, like wide, horizontal spreadsheets or infinitely long web pages, you\u2019ll need a screen capture tool built for that. Snagit has built-in Scrolling Capture and Panoramic Capture features that make it simple to get all the content you need in one image, rather than piecing together several screenshots. (Even if you don\u2019t have a copy of Snagit, you can get Snagit free for 15 days.)\nExamples:\nCapture a scrolling map\nCapture a large spreadsheet\nCapture a multi-page PDF\n3. Animated GIF\nDefinition: \u00a0A moving picture in GIF format. A series of image frames is displayed in an animated sequence. \nWhile animated GIFs aren\u2019t exclusive to screen content, they can be a handy (and underutilized) way to share your screen.\nInstead of taking individual screenshots to show someone a process, you can just capture a single animated GIF of what\u2019s happening on your screen. Animated GIFs are also a lightweight file size and play automatically so they\u2019re quick and easy to share on sites like Slack, JIRA, and Trello.\nExamples:\nSubmitting Helpdesk Tickets\nShow a Series of Steps in a Process\nOnboarding and Walkthroughs\n\n4. Screencast\nDefinition: Turning screen content into a video to teach an application or to promote a product by demonstrating features. \nIf you want to get more in-depth than just a simple screenshot or even an animated GIF, screencasts might be for you. If you\u2019ve ever gotten help online for a piece of software or an application, chances are that you\u2019ve come across a screencast.\nThese are videos that show your screen and usually include some sort of narration to help walk you through what you\u2019re seeing.\nScreencasts can be polished videos used by professional trainers or quick recordings to show a co-worker how to submit a ticket to IT. The idea is all the same.\nExamples:\nTutorials\nVideo Lessons\nSlideshare Presentations\nWhat\u2019s your favorite type of screenshot?\nAs you can see, there\u2019s a lot more to capturing your screen than just screenshots. All these screenshot types can be created in a few minutes using Snagit. I\u2019d love to hear about what has been most successful for you!\nFree Trial: You can\u00a0try any of our screen recorders for free. Get everything you need to record on your Windows, Mac, and iOS devices.\nWhat types of screenshots do you use and where do you use them most often?\nRelated Posts:How to Edit Video (With Step-by-Step Video)How to Make a YouTube Video (Beginner\u2019s Guide)How to Effectively Shift to Online Teaching: The\u2026 \n\n\n\n\n\nCapture & Recording\n\nBrowse Categories \n\nBusiness\nCapture & Recording\nEducation\nVideo\nVisuals\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJustin Simon\nGlobal Content Strategy Manager at TechSmith. I play a lot of golf and watch a lot of football.\n\n\n\n\n\n\n\t\t\t\t\tHow to Get the Perfect Lighting for Video\t\t\t\t\n\n\n\n\t\t\t\t\tHow to Make a YouTube Video (Beginner's Guide)\t\t\t\t\n\n\n\n\t\t\t\t\tHow to Transform Your Remote Communication with Images and Videos\t\t\t\t\n\n\n\n\nRelated Posts:How to Edit Video (With Step-by-Step Video)How to Make a YouTube Video (Beginner\u2019s Guide)How to Effectively Shift to Online Teaching: The\u2026\n\nPost navigation\nHere\u2019s Why Marketers Are Obsessed with Facebook VideoHow to Resize an Image Correctly\n\n\n\n\n\n\n\n\n\n\nSubscribe to TechSmith\u2019s Newsletter\nJoin over 200,000 people who get actionable tips and expert advice in their inbox every month.\nSubscribe\n\n\n\n\n\n\n\n\n\nProducts\nSnagit\nCamtasia\nAssets for Camtasia\nAssets for Snagit\nKnowmia\nScreencast\nAudiate\nVideo Review\nJing\nScreen Recorders\nSolutions\nCustomer Education\nBusiness\nHigher Education\nSupport\nFind Software Key\nTutorials\nHelp Center\nCommunity Forums\nEmail Preferences\nWebinars\nResources\nBlog\nTechSmith Academy\nCustomer Stories\nPress Room\nPartners\nResearch\nAbout\nAbout Us\nContact Us\nCareers\nStore\nFind a Reseller\nOnline Store FAQ\nPayment Options\nReturn Policy\n \n\n\n\n\n\n\n\n\nYou Should Stay In Touch!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy\nAccessibility\nContact\nSitemap\n\n\n\n\u00a9\u00a01995\u00a0-\u00a02020, TechSmith Corporation, All\u00a0Rights\u00a0Reserved.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
  },
  {
    "text": "\nArticlePDF AvailableAdaptive Learning-Based Compressive Sampling for Low-power Wireless ImplantsJuly 2018Circuits and Systems I: Regular Papers, IEEE Transactions on PP(99):1-13DOI: 10.1109/TCSI.2018.2853983Authors: Cosimo Aprile\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne Kerim Ture\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne Luca Baldassarre Mahsa ShoaranCornell UniversityShow all 9 authorsHide Download full-text PDFRead full-textDownload full-text PDFRead full-textDownload citation Copy link Link copied Read full-text Download citation Copy link Link copiedCitations (7)References (36)Figures (8)Abstract and FiguresImplantable systems are nowadays being used to interface the human brain with external devices, in order to understand and potentially treat neurological disorders. The most predominant design constraints are the system\u2019s area and power. In this paper, we implement and combine advanced compressive sampling algorithms to reduce the power requirements of wireless telemetry. Moreover, we apply variable compression, to dynamically modify the device performance, based on the actual signal need. This paper presents an area-efficient adaptive system for wireless implantable devices, which dynamically reduces the power requirements yielding compression rates from\n$8{\\times}$ \nto\n$64{\\times }$ \n, with a high reconstruction performance, as qualitatively demonstrated on a human data set. Two different versions of the encoder have been designed and tested, one with and the second without the adaptive compression, requiring an area of\n$230{\\times }235\\,\\,\\mu \\text{m}$ \nand\n$200\\times 190\\,\\,\\mu \\text{m}$ \n, respectively, while consuming only 0.47\n$\\mu \\text{W}$ \nat 0.8 V. The system is powered by a 4-coil inductive link with measured power transmission efficiency of 36%, while the distance between the external and internal coils is 10 mm. Wireless data communication is established by an OOK modulated narrowband and an IR-UWB transmitter, while consuming 124.2 pJ/bit and 45.2 pJ/pulse, respectively. Hybrid electrodes grid containing macro and microelectrode arrays (a) for iEEG signal recordings, reprinted from [12]. Signals recorded from micro and macro electrodes in (b), with an highlight on micro electrode 27 that records a seizure onset seconds before the macros.\u2026\u00a0 One channel block diagram showing the LBCS encoder and the matrix sequence generation logic.\u2026\u00a0 Hadamard bit generator block diagram.\u2026\u00a0 Schematic of the LC cross-coupled voltage controlled oscillator.\u2026\u00a0 +3Schematic of the IR-UWB transmitter.\u2026\u00a0Figures - uploaded by Mahsa ShoaranAuthor contentAll figure content in this area was uploaded by Mahsa ShoaranContent may be subject to copyright. Discover the world's research19+ million members135+ million publications700k+ research projectsJoin for freePublic Full-text 1Content uploaded by Mahsa ShoaranAuthor contentAll content in this area was uploaded by Mahsa Shoaran on Nov 28, 2018 Content may be subject to copyright. \n\n\n\n\n\n\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS\u2013I: REGULAR PAPERS 1Adaptive Learning-Based Compressive Samplingfor Low-power Wireless ImplantsCosimo Aprile ,Student Member, IEEE,KerimTure ,Student Member, IEEE, Luca Baldassarre,Mahsa Shoaran ,Member, IEEE, G\u00fcrkan Yilmaz, Franco Maloberti ,Life Fellow, IEEE,Catherine Dehollain, Member, IEEE, Yusuf Leblebici, Fellow, IEEE,and Volkan Cevher, Senior Member, IEEEAbstract\u2014 Implantable systems are nowadays being used tointerface the human brain with external devices, in order tounderstand and potentially treat neurological disorders. The mostpredominant design constraints are the system\u2019s area and power.In this paper, we implement and combine advanced compres-sive sampling algorithms to reduce the power requirements ofwireless telemetry. Moreover, we apply variable compression,to dynamically modify the device performance, based on theactual signal need. This paper presents an area-ef\ufb01cient adap-tive system for wireless implantable devices, which dynamicallyreduces the power requirements yielding compression rates from8\u00d7to 64\u00d7, with a high reconstruction performance, as qual-itatively demonstrated on a human data set. Two differentversions of the encoder have been designed and tested, one withand the second without the adaptive compression, requiring anarea of 230\u00d7235 \u03bcm and 200 \u00d7190 \u03bcm, respectively, whileconsuming only 0.47 \u03bcW at 0.8 V. The system is powered bya 4-coil inductive link with measured power transmission ef\ufb01-ciency of 36%, while the distance between the external and inter-nal coils is 10 mm. Wireless data communication is establishedby an OOK modulated narrowband and an IR-UWB transmitter,while consuming 124.2 pJ/bit and 45.2 pJ/pulse, respectively.Index Terms\u2014Implantable integrated circuit, area-ef\ufb01cient,low-power, compressive sensing, neural signals, learning-baseddigital signal processing, signal recovery.I. INTRODUCTIONIN MOBILE applications, the power budget is de\ufb01ned bythe battery limits, which, unfortunately, does not improvefrom one node to the following one, as the amount of logicgates does in the IC, as de\ufb01ned by the well-known Moor\u2019slaw [1]. Table I gives an overview of battery power budget inManuscript received April 16, 2018; revised June 26, 2018; acceptedJune 29, 2018. This work was supported by the European Research Councilthrough the European Union\u2019s Horizon 2020 Research and InnovationProgramme under Grant 725594 - time-data. This paper was recommendedby Associate Editor X. Zhang. (Corresponding author: Cosimo Aprile.)C. Aprile, K. Ture, G. Yilmaz, C. Dehollain, Y. Leblebici, and V. Cevher arewith the Swiss Federal Institute of Technology, 1015 Lausanne, Switzerland(e-mail: cosimo.aprile@ep\ufb02.ch).L. Baldassarre is with Data Science, Gamaya, EPFL Innovation Park, 1015Lausanne, Switzerland.M. Shoaran is with the School of Electrical and Computer Engineering,Cornell University, Ithaca, NY 14853 USA.F. Maloberti is with the Department of Electrical, Computer, and BiomedicalEngineering, University of Pavia, 27100 Pavia, Italy.Color versions of one or more of the \ufb01gures in this paper are availableonline at http://ieeexplore.ieee.org.Digital Object Identi\ufb01er 10.1109/TCSI.2018.2853983some of the current electronic devices used for general dailylife applications.Among all the autonomous sensing applications, one ofthe most critical and challenging \ufb01eld is medical monitoring,in which various biological signals have to be processed witha relatively high accuracy, in order to extract reliable medicalinformation for disease diagnosis or therapy.For many decades, scientists have tried to understandthe brain activity. Since the 1990s, clinicians have beenable to implant devices capable of monitoring the neuronalactivity [2]. Micro/Nano fabrication of electromechanicalsystems (M(N)EMS) industry is currently improving the capa-bility to interface with the human brain. A multitude ofapplications are related to these systems, from research exper-iments to personal health monitoring and in-house treatments.In particular, electrodes and micro fabricated electrodes haveenabled ef\ufb01cient electrical or optical links, enhancing thefunctionality of the neuronal interfaces. Since 1997, the usageof prostheses has been approved as an alternative treatmentfor some brain diseases, such as Parkinson and Epilepsy, andmore recently, for depression [3]. Over 5% of the populationworldwide experience at least one epileptic seizure duringlifetime and around 50 million people are diagnosed withepilepsy [4], [5]. Moreover, in 30% of the cases, patientssuffer from pharmaco-resistant epilepsy, where medicationsare not suf\ufb01cient to treat seizures. Currently, the only availablesolution (when applicable) requires a long term hospitaliza-tion in order to record and localize the source of epilepticseizures, using a bulky system connected with cables troughthe skull, and placed over the cortex. After localization ofthe epileptic foci an invasive surgery procedure is required,with the aim of physically removing the brain tissue wherethe stroke seizures originate. This would suggest the designof autonomous monitoring devices with minimal invasiveness.According to the vision of Body Area Network (BAN), suchbio-electrical devices attached to the human body can eitherserve to carry out information to a medical host or to providesome feedback as \ufb01rst aid treatment.The goal of this work is to optimize the informationextraction from neural signals, merging new mathematicaltheory and computational methods in hardware, to reducethe power and area, outperforming the current state-of-the-art compression techniques. Our contention is to reduce the1549-8328 \u00a9 2018 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.\n\n\n\n\n\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.2IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS\u2013I: REGULAR PAPERSTAB LE IPOWER BUDGET FOR DIFFERENT APPLICATIONSamount of required data, still allowing high signal recon-struction quality, leveraging both theory and practice throughlearning. As a result, power and time required for edge-datacomputation can be drastically reduced. This paper extendsour previous work [6], by analyzing and implementing thefully integrated system, from the analog to digital conversionof neural signal to the wireless transmission of compresseddata. Furthermore, we provide two different implementationsof the data compression encoding system.The paper is organized as follows. In Section II the sys-tem level choices are described. Compressive Sensing andLearning Based Compressive Subsampling are introduced inSection III. In Section IV the system architecture and circuitsimplementation are described, followed by numerical experi-ments. Section V presents the electrical measurements, whileSection VI provides a discussion on results and concludes thepaper.II. SYSTEM LEVEL ANALYSISA high level view of the System-on-Chip (SoC) integratedon the implanted chip is depicted on the top left side of Fig. 1.The SoC is wirelessly connected to an external base station(on the right side of Fig. 1), where the compressed data isreconstructed for medical monitoring and storage.The implanted SoC is composed by of neural ampli\ufb01er,which collects the neural signals recorded by the electrodes,placed in contact with the brain surface. An Analog to DigitalConverter (ADC), samples and digitises the ampli\ufb01ed neuralsignals; the ADC output is processed by the Digital SignalProcessor (DSP), aiming to reduce the amount of informationsent by the wireless RF transmitter. Indeed, the transmitterpower budget in typical wireless monitoring systems is usuallyone order of magnitude higher than any other system on thechip [7], [8]. In this Section, we discuss the system level designaspects and details of each block in the proposed SoC.A. Macro and Micro-Electrodes for iEEG RecordingBio-compatible electrodes are employed to collect theneural signal and act as an interface between the siliconmicroelectronics and the neurons. The electrode geometry istypically set according to the application; e.g., for measuringthe single neuron activity, the size of electrodes is in the orderof micrometers, while for studying the behaviour of populationof neurons, the size may be larger. The micro electrodes andFig. 1. Block diagram of the implantable integrated system (on the left side),wirelessly linked with an external base station (on the right), where the datais reconstructed for medical monitoring and stored. No battery is used in theimplanted system.their electronic read-out circuits have evolved according tothe implant positioning and target neural activity. Needle-shaped micro electrodes are preferred for high-precision Brain-Computer Interfaces (BCI) [9], while \ufb02at electrodes areemployed for cortical surface recordings [10]. Moreover, activeelectrodes are preferred to increase the quality neural data, and,consequently, power supply for the neural probes is provided.Wireless monitoring of brain activity would allow patients withimplanted cortical system to safely leave the hospital during amonitoring period, that could potentially extend over severalmonths.Recordings from micro-electrodes of diameter less than100\u03bcm in the epileptic human hippocampus and neo-cortex have enabled the identi\ufb01cation of several classesof electrographic activity localized to sub-millimeter-scale\n\n\n\n\n\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.APRILE et al.: ADAPTIVE LEARNING-BASED COMPRESSIVE SAMPLING FOR LOW-POWER WIRELESS IMPLANTS 3Fig. 2. Hybrid electrodes grid containing macro and microelectrodearrays (a) for iEEG signal recordings, reprinted from [12]. Signals recordedfrom micro and macro electrodes in (b), with an highlight on microelectrode 27 that records a seizure onset seconds before the macros.tissue volumes, inaccessible to standard iEEG technology withmacro-electrodes [11]. Moreover, Stead and colleagues [12]have observed that epileptic seizures identi\ufb01ed on the macro-electrodes are often preceded by seizure-like activity on themicro-electrodes, depicted in Fig. 2. In particular, some ofthe micro-electrodes record an ongoing microperiodic epilep-tiform discharge, which starts minutes before the onset ofthe seizure itself [12], as highlighted on micro-electrode27 shown in Fig. 2(b). Furthermore, the same researchershave also found that the signals recorded by adjacent micro-electrodes can be uncorrelated, despite their spatial vicin-ity. Furthermore, the sub-millimeter scale of high frequencyoscillations involved in seizure generation motivate the wide-band recording of iEEG using micro-electrodes for precisemonitoring of epileptic patients.In this work, we consider neural signals collected andprocessed from every micro-electrode node, in order to accu-rately estimate the seizure onset using an implantable monitor-ing device. The focus of this work is on compressive samplingand wireless telemetry, while discussions on seizure detectionalgorithm are beyond the scope of this paper.B. Data ProcessingFor each sampling electrode, the recorded signal is boostedby a Low-Noise Ampli\ufb01er (LNA) (not described in this work).Then, the ADC, samples and digitises the analog neuralsignal. To meet the stringent area and power constraints ofthe proposed SoC, we have designed and implemented aSuccessive Approximation Register (SAR) ADC, which yieldsmedium resolution and low-power data conversion.Before data transmission, the digitized data isprocessed in order to reduce the power requirements ofwireless TX. In many recently proposed implantable systems(e.g., [7], [13]\u2013[15] and references therein), CompressiveSampling (CS) [16], [17] has been exploited to drasticallyreduce the amount of transmitted data, while still allowingrobust, but complex, off-line reconstruction of original signal.CS stems from the fact that often, the information content ofnatural signals is much lower than the raw data content.Given a training set of fully sampled signals, a novel Learn-ing Based Compressive Subsampling (LBCS) [18] algorithmselects, from a representation basis like Wavelet or Hadamard,a \ufb01xed set of coef\ufb01cients that capture, on average, most of thesignals\u2019 energy. Only these coef\ufb01cients will then be processedfor new signals. Moreover, LBCS allows for very ef\ufb01cientlinear encoders and decoders, reducing the time and powercosts both on sampling and reconstruction, thus improvingthe conventional CS, where non-linear decoding (e.g. basispursuit) is required for reliable signal reconstruction.In the proposed work, we implement a fully digital encoderto compress the neural signal, which adaptively chooses thecoef\ufb01cients to sample, depending on the required signal qual-ity during sampling. This process is enabled by a dynamicon-chip generation of the transformation coef\ufb01cients, avoidingthe large memory required to store all the transformationmatrix entries [6]. Subsection IV-A addresses the analogto compressed data conversion, discussing the design andtrade-offs in detail.C. Wireless Data TelemetryIn addition to the neural data acquisition and processing,a communication channel from the implant to an external basestation, namely uplink communication, is required to transmitdigitized neural data to an external device. A downlink commu-nication is needed for data transfer from external base stationto the implant in order to con\ufb01gure sensor and processingparameters, such as sampling coef\ufb01cient selections.The proposed epilepsy monitoring system in this projectimplements both uplink and downlink communications. Sincethe downlink communication is only used for setting thesystem parameters, there is no need for a high data ratecommunication. Thus, it is suf\ufb01cient a downlink receiverat the implanted SoC, which communicates at a data rateof 10 kbps. However, for the uplink communication, veryhigh data rate communication is required, since the number ofmonitoring channels and their sampling rate is high. For theneural monitoring application with tens of electrodes, uplinkcommunication should at least provide a data rate in the orderof 10 Mbps. Accordingly, design of an uplink transmitteris challenging in such applications. The minimum distancefor both communication types is the average human skullthickness of about 10 mm. The wireless data telemetry isfurther addressed in Subsection IV-C.D. Wireless PoweringWhile in several biomedical applications such as hearingaids and pacemakers, batteries can occupy a signi\ufb01cant vol-ume, the area allocated to a neural implant is very small.Moreover, the neural recording systems consume higheramount of power and this would potentially reduce the dura-tion of operation on battery. Considering the power demand ofa neural implant aiming for continuous data transmission andthe estimated power budget, current ambient energy harvestersare insuf\ufb01cient to ful\ufb01ll this task. Wireless power transfer\n\n\n\n\n\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.4IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS\u2013I: REGULAR PAPERSbased on inductive coupling is a proper choice, since thedistance between the implant and external unit can be in theorder of millimeters (human scalp thickness \u224810 mm), andsending the required power to the implant is accessible withcurrent inductive coupling technology.In this work, we propose a near \ufb01eld remote poweringmethod, composed of four coils, an active half-wave recti\ufb01er,and a low drop-out voltage regulator, as further discussedin Subsection IV-D.III. LEARNING-BASED SIGNAL SAMPLINGIn this section, we \ufb01rst introduce the basics of CompressiveSensing, reviewing three recent approaches applied to neuralsignals. We then discuss non-linear structured recovery, beforediscussing Learning-Based Compressive Subsampling.A. Compressive SensingGiven an input signal x\u2208RNwhich has Knon-zerocoef\ufb01cients, Compressive Sensing (CS) states that xcan berobustly recovered from a signal y\u2208RMcontaining fewersamples than dictated by the Shannon-Nyquist theorem, withM=O(Klog NK). The compressed version of the inputsignal xcan be expressed asy=Ax +w,(1)where Ais a linear operator that either satis\ufb01es the RestrictedIsometry Property (RIP) or is incoherent [19], and wrepresentsthe measurement noise. If the input signal xis not sparse in thegiven domain, an ortho-normal basis \ue002hastobeusedtogetasparser representation of the original signal x. Natural signalsare often characterized by sparse and structured representa-tions in time-frequency (or space-frequency) domains, such aswavelets [20]. On the theoretical point of view, the matrix Acan be generated with random coef\ufb01cients, since i.i.d. sub-Gaussian matrices are incoherent and also satisfy the RIPcondition. Moreover, they are universal, i.e., the RIP or theincoherence of A\ue002is the same as of the original A[19],where matrix \ue002is used to form a sparser representation ofthe signal x. However, sub-Gaussian matrices are prohibitivelyexpensive to use in practice, since they require O(MN)space and time. Transmitting the fewer compressed samples yallows to save on-chip storage and telemetry power. However,the reconstruction process needed to recover xfrom yrequiresto solve non-linear optimization problems that increase bothtime and power requirements on the recovery node.Bernoulli (BERN) described in [7], Multi-Channel Sam-pling (MCS) [14] and Structured Hadamard Sampling (SHS)presented in [21] are randomized sampling approachesrecently proposed for the compression of neural signals.These three architectures are very ef\ufb01cient on the samplingside, but require solving non-linear optimization problems toreconstruct the original signals.As described in [22] and references therein, a reducednumber of samples is required for stable recovery, consideringadditional structures in the signal x, such as interdependen-cies between its non-zero coef\ufb01cients or constraints on itssupport during the recovery process. As discussed in [21],the Hierarchical Group Lasso (HGL) approach achieves thebest performance over three different structured-sparsity recov-ery methods. This approach has been used to compare thereconstructed iEEG signals sampled through BERN, MCS andSHS methods.B. Learning-Based Compressive SubsamplingThe compression method used in this work is based onthe LBCS approach [18], which requires both linear encodingand decoding with respect to a given orthonormal basis.Such method allows to simplify both the sampling and signalrestoring steps, compared to standard CS approaches. In anutshell, LBCS can be summarized considering the followingcompression modely=P\ue002\ue003x,(2)where \ue003\u2208RN\u00d7Nis an orthonormal basis and P\ue002\u2208RM\u00d7Nisa subsampling matrix, whose rows are canonical basis vectors.The effect of applying P\ue002to \ue003xis to return a M-dimensionalvector containing only the components of \ue003xindexed by theset \ue002, also known as the subsampling map. The vector y\u2208RMis the compressed version of x, with a nominal compressionrate (CR) of NM. The signal xis then approximately recoveredvia the fast linear decoder\u02c6x=\ue003\u2217PT\ue002y.(3)where \ue003\u2217is the conjugate-transpose of \ue003and PT\ue002yconstructsa N-dimensional vector of zeros, placing the components of yin the positions indexed by \ue002.The learning process is dictated by a training setD={x1,...,xm}of mfully sampled signals of unit norm.The optimal subsampling map \ue002is learnt by choosing theindices that capture most of the average energy in the trans-form domain:\u02c6\ue002=arg max\ue002,|\ue002|=M1mm\ue002j=1\ue002i\u2208\ue002|\ue005\u03c8i,xj\ue006|2,(4)where \u03c8iis the i-th row of \ue003.\u02c6\ue002can be exactly found byselecting the Mindices whose values of 1m\ue003mj=1|\ue005\u03c8i,xj\ue006|2are the largest [18]. The learnt sampling scheme is then usedto directly sample only those transform coef\ufb01cients indexedby \u02c6\ue002for all signals x.Walsh-Hadamard based transformation has been used inrecent publications [6], [23] because of its hardware friendlyimplementation, since each transformation coef\ufb01cient requiresone bit resolution, resulting in simple computations. In par-ticular, Hosseini-Nejad et al. [23] propose a threshold-basedWalsh-Hadamard compression, to sample the Action Poten-tials (AP) for brain machine interfaces. The authors apply abutter\ufb02y scheme to transform the input signal samples intothe Hadamard domain. However, such butter\ufb02y-based methodcan be performed on very few number of consecutive samples(8 samples in [23]), limiting any kind of learning approachdue to the low signal statistic. Therefore, it is used forAP signal detection, with limited application in continuousmedical monitoring for diseases like epilepsy, where the whole\n\n\n\n\n\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.APRILE et al.: ADAPTIVE LEARNING-BASED COMPRESSIVE SAMPLING FOR LOW-POWER WIRELESS IMPLANTS 5signal behavior is required by clinicians. Majidzadeh et al. [24]propose the generation of the full Hadamard matrix \ue003\u2208R16\u00d716 for a parallel neural recording system. However, suchimplementation does not apply any compression mechanism,resulting in a high power consumption. The circuit imple-mentation of LBCS technique with DCT-based transformhas been proposed in [25]. Even though its implementationshows a great signal reconstruction performance, the actualhardware implementation, which requires relatively larger areaand power consumption with respect to its LBCS-Hadamardcounterpart, makes it more suitable for different application,such as image processing. In [6], LBCS is exploited using theHadamard transformation matrix, where the whole Hadamardmatrix is stored in static memories requiring more than 2/3of the actual encoding area.In this work, we propose an LBCS based compressionalgorithm, which performs the transformation from temporalto Hadamard domain, through on-the-\ufb02y generated Hadamardcoef\ufb01cients. In this implementation, only the selected rowsof the Hadamard matrix (de\ufb01ned by \u02c6\ue002) are generated andused for the embedded compression, resulting in a dynamicgeneration of the coef\ufb01cients that are used to apply the LBCSapproach. Such technique drastically reduces the encodermemory requirements needed by previous LBCS-Hadamardimplementation, while the signal reconstruction quality ispreserved within a low power chip implementation.C. Walsh-Hadamard TransformationThe Hadamard transform is particularly suited for hardwareimplementation since each coef\ufb01cient can be computed byperforming only simple additions or subtractions.The reduction of hardware area in the Had-based LBCSdescribed in [6] is possible by replacing the SRAM dedicatedto store the Hadamard coef\ufb01cients, with a direct computationof each matrix entry [24]. Such computation is feasible dueto the intrinsic structure of the Hadamard matrix, which issummarized as follows. The non-normalized Hadamard trans-formation matrix \u02c6Hn\u2208(\u22121,1)N\u00d7Nof size n, with N=2nisexpressed as a recursive Kronecker product of two matrices\u02c6Hn=\u02c6H1\u2297\u02c6Hn\u22121,where \u02c6H1\ue002\ue004111\u22121\ue005.(5)Each matrix coef\ufb01cient indexes kand j, can be expressed inbinary representationk=n\u22121\ue002i=0ki2i,j=n\u22121\ue002i=0ji2iwith, ki,ji\u2208(0,1). (6)Each Hadamard entry hk,jcan then be expressed ashk,j=(\u22121)\ue003n\u22121i=0kiji\u2261(\u22121)mod2(\ue003n\u22121i=0liji).(7)In particular, mapping the (1, -1) to (0, 1), each Hadamardentry can be derived byhk,j=mod2(n\u22121\ue002i=0liji). (8)Such expression can be ef\ufb01ciently implemented in hardware,through logic AND gates to perform liji, while the module-2sum is derived by a logic XOR. Thus, the circuit implementa-tion takes the row and column indexes kand jand computesthe Hadamard coef\ufb01cient in the binary map (0, 1).D. Dataset Details and Experimental ProtocolThe iEEG.org portal contains several datasets of intracranialEEG data which are manually annotated by expert clinicians.The dataset I001-P034-D01 has been used for the developmentof this research [6], [21]. It consists of approximately 1 day,8 hours and 10 minutes of recordings at 5 kHz, or approxi-mately 6 \u00d7108samples of intracranial EEG data. In order toreduce the dataset size, we use samples from the 12th and13th seizures, and an equal number of samples before theseizure onset, for training and testing, respectively. More indetails, we have used 207k samples before and after the seizurefor the training signal, while for the test set we have used153k samples.The training set of the dataset is used to learn the samplingpattern for the LBCS approach and also to tune the variabledensity parameters for the SHS method. Once the samplingpattern is \ufb01xed, LBCS uses it to compress all the signalwindows in the test set. The reconstruction is then performedwith the linear decoder (3). For the randomized methods ofMCS, BERN and SHS, we draw 20 different sampling patternsfrom the relative distributions for each signal window (withlength N =256) in the test and reconstruct using the tree-based HGL norm, which yields the best results [21].IV. IMPLANTABLE ARCHITECTUREThe implantable chip architecture is described in thisSection. The SoC designed in this work consists of the analogto digital converter, followed by the encoder which compressesthe sampled data, implementing the Learning-based CS algo-rithm described in Section III-B. The compressed bit stream isthen serialized and wirelessly sent out by the RF transmitter.The circuit can be powered wirelessly through an inductivelink between the implant and a power delivery unit.A. Analog to Compressed Data StreamThe neural signal digitization is realized by a SuccessiveApproximation Analog to Digital Converter (SAR ADC).In such ADC topology, just one comparator is required andthe design is based on a charge redistribution DAC, thusthis implementation results to be energy ef\ufb01cient. However,the SAR ADC will require N +1 comparison periods toprepare the \ufb01nal decision. Hence, the SAR ADC is expected toallow the lowest power dissipation, but also it is de\ufb01ned by amoderate sampling rate. The ADC design results in a compactand low-power implementation, which matches the stringentarea and power constraints of our implantable SoC. The SARADC has 8 bit resolution and a sampling rate of 45 kHz,in order to match the 5 kS/s rate of the input signal fromiEEG dataset. A compact ADC implementation is achievedby a binary-weighted capacitive array, with attenuation capac-itor [14]. Since the neural signal bandwidth is relatively low,the compression computations are completed at the DSP,\n\n\n\n\n\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.6IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS\u2013I: REGULAR PAPERSFig. 3. One channel block diagram showing the LBCS encoder and thematrix sequence generation logic.with the same frequency de\ufb01ned by the ADC. In particular,the ADC requires 9 cycles to complete the digitization of theinput signal (at 5 kHz), thus running at 45 kHz. The DSPcore frequency runs at the same speed, performing the datacompression.The Hadamard-based LBCS encoder block diagram isdepicted in Fig. 3, where is shown the input data path fromthe Analog to Digital Converter (ADC), through the LBCSDigital Signal Processor (DSP) to the encoded data transmitter.The Finite State Machine (FSM)oftheDSPdrivestheHad-block and the main DSP core, where the encoding process isexecuted. The Had-block generates the Hadamard bit streamsand replaces the SRAM used in previous implementation [6],reducing the encoder area. The Had-block is mainly composedby the Row-Index Look up Table (LuT), and the Hadamardbit generator. The Row-Index LuT is meant to store thelearnt indices of the sub-sampling matrix P\ue002, described insubsection III-B. Assuming that only M rows of the fullHadamard matrix H\u2208RN\u00d7Nhave to be used to applythe LBCS-based compression, then we can de\ufb01ne a mappingfunction w(k)=\u2208 [0N\u22121],wherek\u2208[0M\u22121]is theindex of the output value, and we de\ufb01ne hk,j=hw(k), j. Then,the LuT implements such mapping function w(k).The LuT coef\ufb01cients, driven by the FSM, are sent to theHadamard-bit generator, which produces the transformationentries hk,j, following the description in subsection III-C.Fig. 4 shows the block diagram of the Hadamard bit gen-erator, highlighting the logic gates used to generate the hk,jentries [24]. During a calibration phase, the learnt Hadamardrow indices, de\ufb01ned by the RowIDX input (log(N)bit wide,to code all the possible Hadamard matrix indexes) are loadedin the LuT. As soon as the program enable (Pr_en) is active,the initialization starts and the FSM programs the M indexesinto the LuT, following the RowIDX and the k signals usedto correctly address the register. The FSM also generates andprograms the enable and reset commands sent to the DSP,to correctly synchronize the encoding procedure, and to resetFig. 4. Hadamard bit generator block diagram.the accumulator registers (Accum in Fig. 3) at the end of eachencoding window.The encoder input signal xj, digitized by the ADC withBibit resolution, is summed or subtracted from the previousaccumulator register values, at each sampling instant jin thesampling window of length N. The LBCS-DSP block performsthe embedded compression, de\ufb01ned asyk=N\ue002j=1hk,jxj,k\u2208{1,...,M},(9)where hk,jis the (k,j)-entry of H\ue002=P\ue002H; the Hadamardmatrix H(=\ue003described in subsection III-B), requires a singlebit per entry, minimizing the computation costs in the transfor-mation process. The encoder processing frequency is M timesfaster than the input signal frequency, in order to updateeach of the accumulator registers, where the transformationcoef\ufb01cients are stored. As analysed in [6], a DSP that foreach sampling window performs the full-compression (withno CS or learning-based CS) would require higher power andarea requirements. In particular, the area and power overheadwould be higher than CR\u00d7[6].The previous Hadamard based LBCS implementation shownin [6], has been designed for sampling window of 256 samples(N =256), with a \ufb01xed CR of 16\u00d7. In this work, we proposethe hardware implementation with an on-the-\ufb02y Hadamardgeneration, with a sampling window length of N =64 andcompression rate of CR =8. The same dataset as in [6] hasbeen taken into account, to validate the proposed hardwareimplementation. The N =64 and CR =8 combination allowsto get similar average reconstruction quality, while the LBCSencoder frequency fsis halved, resulting in a lower powerconsumption. Indeed, since Mis de\ufb01ned as N/CR,thelargeris the number of the Hadamard rows M, the higher is thecore LBCS clock frequency, which might become a limitingfactor. On the other hand, a further reduction on the numberof samples N, would degrade the signal statistics over whichthe learning approach is based on.\n\n\n\n\n\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.APRILE et al.: ADAPTIVE LEARNING-BASED COMPRESSIVE SAMPLING FOR LOW-POWER WIRELESS IMPLANTS 7Fig. 5. Variable CR block diagram, de\ufb01ned by the threshold level (Thr).B. Variable Hadamard CompressionThe simulation results shown in Fig. 6-(a), depict theenergy content of the N samples in the Hadamard domain,for a particular sampling window. As described in Sec. III,the Learning-based algorithm allows to de\ufb01ne the coef\ufb01cientsthat, in average, have the most energy contribution. However,depending on the signal evolution in the sampling window,the coef\ufb01cients de\ufb01ned by the learning process might havea low energy content. This analysis is useful to de\ufb01ne thesystem\u2019s trade-off and a variable compression rate, whichadapts from window to window, depending on the energylevels de\ufb01ned by the neural signal evolution in time. On thesystem level implementation, for a window length of N =64,a maximum compression rate of 8 has been de\ufb01ned, in orderto allow relatively high SNR after the signal reconstruction.Since in the NCR =8 Hadamard coef\ufb01cients the energy mightbe below a certain level, a threshold is also de\ufb01ned during thelearning process, in order to transmit only the most relevantcoef\ufb01cients, enabling a dynamic compression. The dynamicdetection of the Hadamard coef\ufb01cients results in an easyhardware implementation, and allows a variable CR fromwindow to window. Fig. 5 shows the block diagram of thevariable CR implementation, depicting how, the energy contentof the coef\ufb01cient value yKis transmitted or substituted withaBObit stream by means of a multiplexer, mathematicallyresumed as:y\ue009k=\ue0060,|yk|<Thresholdyk,otherwise.(10)In such a design implementation, the SoC features a com-pression which varies from CR =8toCR=64, and allowsthe TX to transmit fewer coef\ufb01cients, thus drastically reducingits power consumption. Fig. 6-(b) shows the trade-off betweenthe mean signal reconstruction SNR and the mean CR over thewhole dataset, as the threshold varies. In particular, Fig. 6-(c)and Fig. 6-(d), show respectively the mean signal recoveryquality and the mean window compression rates, with respectto the threshold levels. In particular, it is worth highlightinghow a relatively small threshold (e.g., below 100) allows toreduce the number of coef\ufb01cients transmitted (thus, higher CRlevel), while the SNR is still relatively high (above 28 dB).In particular, it is worth noticing that such SNR value is around18 dB higher than the minimum SNR value that is acceptableto successfully allow the seizure detection [14].Fig. 6. SNR analysis for adaptive approach.C. Wireless Data TransmitterTwo different wireless transmitters are designed and imple-mented with different data rates, operating frequency, andtransmission distance, in order to cover different applications.The narrowband transmitter which operates in the MedRadioband at 416 MHz is designed for low data rate and indoor com-munication. The other transmitter is based on impulse-radioultra-wideband (IR-UWB) in the 3.1-10.6 GHz frequencyrange and utilized for high data rate and very short distancetransmission. The two transmitters provide the \ufb02exibility ofsending compressed or raw data.1) Narrowband Transmitter: The proposed on-off key-ing (OOK) modulated narrowband transmitter is based onthe turning on and off a voltage controlled oscillator (VCO).The VCO which is shown in Fig. 7 is composed of NMOSand PMOS cross-coupled pairs and data is applied to thebias current for modulation. Reuse of the current by PMOSand NMOS pairs provides higher transconductance and highervoltage swing on the inductor. For setting the resonancefrequency of the VCO, a bank of three capacitors are utilizedfor discrete tuning and varactors are used for \ufb01ne tuning.An off-chip loop antenna is connected to the differential outputof the VCO to transmit the signal and create the requiredinductance for LC tank [26].2) Ultra-Wideband Transmitter: IR-UWB is a promisingtechnique based on transmission of short pulses and it isvery ef\ufb01cient for low range applications which requires highdata-rate. In 2002, the Federal Communications Commission(FCC) approved and limited the maximum effective isotropicradiated power (EIRP) to -41.3 dbm/MHz for bandwidthbetween 3.1 and 10.6 GHz [27].In this work, in addition to the narrowband transmitter,we present a high data-rate, energy and area ef\ufb01cient, and lowcomplexity IR-UWB transmitter. Fig. 8 shows the schematicblock diagram of the IR-UWB transmitter. The small num-ber of circuit elements make the design simpler and area\n\n\n\n\n\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.8IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS\u2013I: REGULAR PAPERSFig. 7. Schematic of the LC cross-coupled voltage controlled oscillator.Fig. 8. Schematic of the IR-UWB transmitter.occupation minimal. The core of the transmitter is based onthe current starved ring oscillator (RO) which generates outputin the range of 3.5-4.5 GHz frequency. The control voltageprovides \ufb02exibility in selecting the oscillation frequency ofthe ring oscillator by adjusting the bias current. The pulsegenerator (PG) block creates short pulses at the rising edgesof the data signal. The output of the RO and PG is mixedwith cascode connected transistors. The drain of the transistordriven by the RO is connected to external resonator circuitformed by an inductor and a capacitor. Before the 50 \ue002UWBantenna, a band-pass \ufb01lter (BPF) centered at 4 GHz is usedin order to satisfy the FCC regulation. For the transmissionof the generated IR-UWB pulses, miniaturized, \ufb02exible andpolarization-diverse UWB antenna presented in [28] can beadopted.D. Wireless Power TransferTo design an implantable system, wireless power trans-fer (WPT) method is chosen since batteries increase the totalTAB LE I IDESIGN PARAMETERS OF INDUCTIVE LINK COILSweight and dimensions of device. Considering the requiredpower of the implant and the power transmission distance,which is in the order of millimeters, an inductive link isselected for power transmission. The losses due to remotepowering are a critical concern that can cause a temperatureelevation, which may damage the tissue. Hence, a poweref\ufb01cient transmission link composed of 4-coils, an active half-wave recti\ufb01er, and a low drop-out voltage regulator is designedand represented in Fig. 9.Different approaches are used for various applications, butthe average power consumptions of the implants are consid-ered nearly constant in system parameters. However, in someapplications such as neural monitoring with a variable numberof active electrodes, the power consumption of the implant isnot always the same. Hence, the power ef\ufb01ciency of WPTand the dimensions of the implanted coil become the majorlimitations in designing the coils for remote powering. In thefundamental approach with two coupled coils, there is a directrelation between the delivered power to the load and theef\ufb01ciency. The variation in the load power requires an addi-tional approach for keeping power transfer ef\ufb01ciency (PTE)maximum for different activity rates. A modi\ufb01ed version ofinductive link with 4-coil instead of 2-coil has been introducedfor 2 meters remote powering [29], and the structure wasadapted for implant powering applications [30]. The resultsshow a signi\ufb01cant improvement in the ef\ufb01ciency. The lowcoupling coef\ufb01cient and the low quality factor of the coils in2-coil link are compensated by the introduced two high qualityfactor coils between them [31]. Moreover, the introduced coilstransform different load impedances to the optimal impedanceat the input of the inductive link and ef\ufb01ciency does not signif-icantly change with load power. Therefore, a 4-coil inductivelink is implemented to take the advantage of high PTE andtolerance for variable load power. The selected geometricalparameters for 4-coil inductive link are represented in Table II.The operation frequency of chosen 4-coil inductive link hasa signi\ufb01cant impact on the PTE and safety of the implantedsystem. Absorbed power by the tissue decreases the PTEand creates a temperature increase in the surrounding. Themaximum temperature elevation is limited to 1 oC by the regu-lations for body implants [32]. To comply with the regulations,low MHz range (1-20 MHz) operation frequency is usuallychosen since the absorption of the cortical tissue is minimumin this range [33]. In addition to the absorbed energy, the powerconsumption of the implanted circuitry causes a temperature\n\n\n\n\n\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.APRILE et al.: ADAPTIVE LEARNING-BASED COMPRESSIVE SAMPLING FOR LOW-POWER WIRELESS IMPLANTS 9Fig. 9. Block diagram of the proposed implanted electronics for wireless power transmission.increase in the tissue. Another study shows the limits ofthe maximum allowable power dissipations depending onthe power dissipation level, chip size, and location of theimplant [34]. In this work, the operation frequency of 8 MHzis chosen to minimize the tissue absorption and implantedsystem is designed for the low power consumption to limitthe temperature elevation.The induced AC voltage by the 4-coil inductive link requiresto be recti\ufb01ed to a DC voltage. To achieve high conversionef\ufb01ciency, an active half-wave recti\ufb01er is selected at the priceof the losses in the comparison and decision blocks in Fig. 9.In this study, the half-wave recti\ufb01er is designed based on thework published in [35]. Pass transistor with dynamic bulkbiasing constitutes the core of the recti\ufb01cation. To preventthe leakage from the capacitor to the input, the n-well ofthe two PMOS transistors are dynamically biased. Hence,the transistor conducts current only when the input voltageis higher than the voltage at the accesses of the capacitor. Thecomparator decides the condition of the PMOS pass transistorby comparing the input voltage and the charged voltage onthe capacitance. Timing and control block applies the decisiongiven in the comparator with an optimum switching timesuch that it is fast enough compared to operation frequencyand minimizes the switching power losses. The low drop-out voltage regulator eliminates the ripples at the output ofthe recti\ufb01er and generated clean voltage supply for the othercircuits in the implant. The capacitors at the output of therecti\ufb01er and regulator are implemented externally.V. MEASUREMENT RESULTSThe chip, fabricated in UMC 180 nm 1P6M MM/RFprocess technology, has been packaged and bonded to adedicated PCB. A Xilinx development board, providing aVirtex 5 FPGA [36], is linked to the PCB trough rigid headers,as shown in Fig. 11. The board is used to set and program theSoC blocks with a PC station.A. Sampling and Data CompressionEach block of the SoC has been independently connected todedicated pads on the chip, in order to validate each design.Fig. 10. Layout (on the left) and micrograph (on the right) of the testedchip.Fig. 11. Measurement setup, highlighting the FPGA and PCB link.The analog input of ADC and the DSP digital bit streamsare connected to ESD protection circuits, to reduce anypossible damage due to electrostatic discharges during themeasurements.As shown in Fig. 10-left, the ADC and the two encoderversions (the variable CR on top and the non-variable versionon the right side of the ASIC) do not share the power-grids,in order to separate the analog and digital domains. Thepower-grid has been designed in a very dense manner, withcapacitors that surround the SoC blocks, stabilizing the VDDto ground \ufb02uctuations. Fig. 10-right shows the micrograph ofthe tested chip.\n\n\n\n\n\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.10 IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS\u2013I: REGULAR PAPERSFig. 12. Measured compressed values with low threshold (on the left) andhigh threshold (on the right).The 8 bit resolution SAR-ADC with a sampling rateof 45 kHz requires an area of 230\u03bcm\u00d7150\u03bcm, with a powerconsumption of 0.46 \u03bcW. The low power requirements of theADC is mainly dictated by the medium resolution of 8 bits,and the low sampling frequency of the neural signals.A Verilog code, implemented on Xilinx ISE tool, has beendeveloped to program the encoder registers, to provide theclock at 45 kHz to the SoC, and to send the input bit streamto the encoders through the FPGA. The compressed datasequences at the output of the DSPs are collected as inputto the FPGA, and analyzed with Xilinx ChipScope tool. Themeasurement setup is shown in Fig. 11.The measured compressed bit streams have been plottedby an oscilloscope and are highlighted in Fig. 12. Both plotshave been generated with the variable CR encoder version,in order to show, on the same plot, the dynamic generationof the transformation coef\ufb01cients, and the different outputsdue to low threshold (on Fig. 12 top-left) and high threshold(on Fig. 12 top-right) settings. The reconstructed signal versusthe original data is plotted for 4 sampling windows, at thebottom of Fig. 12.Table III reports the numerical results of the recoveredsignal, for the different compression methods discussed in thiswork, with \ufb01xed compression rates. In particular, this tableshows how the LBCS-based signal recovery (the only methodwhich applies a learning-based compression technique)performs better than Bernoulli [7], Multi-channel [14] orStructured Hadamard Sampling [21]. The comparison ofreconstruction performance has been done consideringN=256 and an ADC resolution Bi=10, for the iEEGdataset described in Subsection III-D. Furthermore, the LBCSTABLE IIIRECOVERY PERFORMANCE COMPARISON WITHPUBLISHED WORK (N =256, Bi=10)TAB LE I VRECOVERY PERFORMANCE SUMMARY FORTHIS WORK (N =64, Bi=8)TAB LE VCOMPRESSIONHARDWARE COMPARISON WITH PUBLISHED WORKsignal recovery requires the linear decoder (3), which yieldsthe reconstructions at a fraction of the computational cost ofthe other methods [6].Since the actual hardware implementation of this work hasbeen developed with N =64 and Bi=8, Table IV summarizesthe recovery performances for the variable encoder design,for different \ufb01xed energy thresholds (the reported CR are inaverage over the whole dataset). For this reason, Table IV givesan energy content based comparison, while Table III reportsaCR-based comparison.The Learning-based compression algorithm with dynamicgeneration of the transformation coef\ufb01cients requires an areaof 230\u03bcm\u00d7330\u03bcm. A comparable area of 230\u03bcm\u00d7365\u03bcmis required for the adaptive DSP design, which only consumes0.47 \u03bcW at 0.8 V. Table V reports the hardware comparisonwith respect to other published works.During the measurement, each subsystem has been testedindependently. The output data stream from the DSP has beenserialized in a shift register of size M\u00d7BO,inaMSB\ufb01rst order. The serialized data is then directly transmitted bythe RF block.B. Wireless Power TransferThe resonance frequency of each LC tank in the 4-coilinductive link is \ufb01xed at 8 MHz. Power transfer ef\ufb01ciencyof 55% is obtained for the inductive link when the separationbetween the coils and the load is 10 mm and 10 mW,respectively. The performance of the recti\ufb01er and the regulator\n\n\n\n\n\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.APRILE et al.: ADAPTIVE LEARNING-BASED COMPRESSIVE SAMPLING FOR LOW-POWER WIRELESS IMPLANTS 11Fig. 13. Spectrum of the LC cross-coupled voltage controlled oscillator.Fig. 14. Transient pulses of the IR-UWB transmitter at 250 Mpps.is also characterized for 10 mW load and their ef\ufb01ciency reachto 82% and 78%, respectively. As a result, wireless powertransmission beginning from the signal generator to implantload is achieved at 36% ef\ufb01ciency.C. Narrowband TransmitterThe VCO is supplied with internally generated 1.8 V andthe measured average power consumption during operationis 248.4 \u03bcW. Thanks to the discrete and \ufb01ne tuning capacitors,VCO covers the two MedRadio bands (401-406 MHz and413-419 MHz). Fig. 13 shows the frequency spectrum of theOOK transmitter with the highest data rate of 2 Mbps. Duringthe measurement of the spectrum, the distance between thetransmitter antenna and the receiver antenna (Taoglas Limited-TI.10.0112), which was directly connected to the spectrumanalyzer, is \ufb01xed to 60 cm. A custom made OOK receiverboard based on discrete components is used to demodulatethe transmitted data.D. Ultra-Wideband TransmitterThe proposed IR-UWB transmitter is fabricated and itoccupies a 60 \u03bcm\u00d730 \u03bcm area. Fig. 14 shows the measuredFig. 15. Power spectral density of the IR-UWB transmitter.output waveform of the implemented IR-UWB transmitterwith 250 MHz pulse repetition rate. The maximum peak-to-peak amplitude of the measured pulse is 111 mV while itsduration is 2.2 ns. Fig. 15 depicts the measured power spectraldensity of the transmitter and FCC regulation. The triangularenvelope of the output waveform suppress the side-lobes andmeasured spectrum fully meets the FCC mask. When thepulse repetition frequency is 250 Mpps, the complete IR-UWBtransmitter consumes 11.3 mW power which corresponds to45.2 pJ/pulse. High throughput of the IR-UWB transmittermakes it possible to buffer the raw data and transmit it inseveral bursts.VI. CONCLUSIONThis work proposes a novel LBCS-based SoC for recordingneural signals in implantable devices. The proposed encodingsolution enables dynamic generation of the transformationcoef\ufb01cients, allowing on-the-\ufb02y compression with faster andimproved off-line signal recovery than Random Bernoulli [7],Multi-channel [14] or Structured Hadamard Sampling [21].Moreover, a variable compression rate is achieved by energybased threshold method. The proposed data compressionreduces the amount of bit stream transmitted wirelessly, thuslowers the TX and implantable system\u2019s power requirements.In the proposed design, the threshold is set during theoff-line learning process. A further development of the currentchip implementation can include an on-chip calibration, whichsets the threshold level of the encoder in the implanted device.Moreover, in the multichannel implementation, the designshould take into account the synchronization of the data fromthe different electrodes.REFERENCES[1] R. R. Schaller, \u201cMoore\u2019s law: Past, present and future,\u201d IEEE Spectr.,vol. 34, no. 6, pp. 52\u201359, Jun. 1997.[2] A. C. Hoogerwerf and K. D. Wise, \u201cA three-dimensional microelectrodearray for chronic neural recording,\u201d IEEE Trans. Biomed. Eng., vol. 41,no. 12, pp. 1136\u20131146, Dec. 1994.[3] C. B. Nemeroff et al., \u201cVNS therapy in treatment-resistant depression:Clinical evidence and putative neurobiological mechanisms,\u201d Neuropsy-chopharmacology, vol. 31, no. 7, pp. 1345\u20131355, 2006.[4] M. Leonardi and T. B. Ustun, \u201cThe global burden of epilepsy,\u201d Epilepsia,vol. 43, no. s6, pp. 21\u201325, 2002.\n\n\n\n\n\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.12 IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS\u2013I: REGULAR PAPERS[5] \u201cEpilepsy-fact sheet,\u201d World Health Org., Geneva, Switzerland, Tech.Rep., Feb. 2017.[6] C. Aprile et al., \u201cLearning-based near-optimal area-power trade-offs inhardware design for neural signal acquisition,\u201d in Proc. Int. Great LakesSymp. VLSI (GLSVLSI), 2016, pp. 433\u2013438.[7] F. Chen, A. P. Chandrakasan, and V. M. Stojanovic, \u201cDesign andanalysis of a hardware-ef\ufb01cient compressed sensing architecture for datacompression in wireless sensors,\u201d IEEE J. Solid-State Circuits, vol. 47,no. 3, pp. 744\u2013756, Mar. 2012.[8] S. Ha et al., \u201cSilicon-integrated high-density electrocortical interfaces,\u201dProc. IEEE, vol. 105, no. 1, pp. 11\u201333, Jan. 2017.[9] E. M. Maynard, C. T. Nordhausen, and R. A. Normann, \u201cThe utahintracortical electrode array: A recording structure for potential brain-computer interfaces,\u201d Electroencephalogr. Clin. Neurophysiol., vol. 102,no. 3, pp. 228\u2013239, Mar. 1997.[10] D. Yoshor, W. H. Bosking, G. M. Ghose, and J. H. R. Maunsell, \u201cRecep-tive \ufb01elds in human visual cortex mapped with surface electrodes,\u201dCerebral Cortex, vol. 17, no. 10, pp. 2293\u20132302, 2006.[11] G. A. Worrell et al., \u201cHigh-frequency oscillations in human temporallobe: Simultaneous microwire and clinical macroelectrode recordings,\u201dBrain, vol. 131, no. 4, pp. 928\u2013937, 2008.[12] M. Stead et al., \u201cMicroseizures and the spatiotemporal scales of humanpartial epilepsy,\u201d Brain, vol. 133, no. 9, pp. 2789\u20132797, 2010.[13] J. N. Laska, S. Kirolos, M. F. Duarte, T. S. Ragheb, R. G. Baraniuk, andY. Massoud, \u201cTheory and implementation of an analog-to-informationconverter using random demodulation,\u201d in Proc. IEEE Int. Symp. CircuitsSyst., May 2007, pp. 1959\u20131962.[14] M. Shoaran, M. H. Kamal, C. Pollo, P. Vandergheynst, and A. Schmid,\u201cCompact low-power cortical recording architecture for compressivemultichannel data acquisition,\u201d IEEE Trans. Biomed. Circuits Syst.,vol. 8, no. 6, pp. 857\u2013870, Dec. 2014.[15] M. Shoaran et al., \u201cA 16-channel 1.1mm2implantable seizure controlSoC with sub-\u03bcW/channel consumption and closed-loop stimulation in0.18\u03bcmCMOS,\u201dinProc. IEEE Symp. VLSI Circuits, Jun. 2016, pp. 1\u20132.[16] E. J. Cand\u00e8s, \u201cCompressive sampling,\u201d in Proc. Int. Congr. Math.,Madrid, Spain, Aug. 2006, pp. 1433\u20131452.[17] D. L. Donoho, \u201cCompressed sensing,\u201d IEEE Trans. Inf. Theory, vol. 52,no. 4, pp. 1289\u20131306, Apr. 2006.[18] L. Baldassarre, Y.-H. Li, J. Scarlett, B. G\u00f6zc\u00fc, I. Bogunovic, andV. Cevher. (2015). \u201cLearning-based compressive subsampling.\u201d [Online].Available: https://arxiv.org/abs/1510.06188[19] S. Foucart and H. Rauhut, A Mathematical Introduction to CompressiveSensing. Basel, Switzerland: Birkh\u00e4user, 2013.[20] S. Mallat, A Wavelet Tour of Signal Processing. New York, NY, USA:Academic, 1999.[21] L. Baldassarre, C. Aprile, M. Shoaran, Y. Leblebici, and V. Cevher,\u201cStructured sampling and recovery of iEEG signals,\u201d in Proc.6th IEEE Int. Workshop Comput. Adv. Multi-Sensor Process. (CAMSAP),Dec. 2015, pp. 269\u2013272.[22] A. Kyrillidis, L. Baldassarre, M. El Halabi, Q. Tran-Dinh, and V. Cevher,\u201cStructured sparsity: Discrete and convex approaches,\u201d in CompressedSensing and Its Applications. Cham, Switzerland: Birkh\u00e4user, 2015.pp. 341\u2013387.[23] H. Hosseini-Nejad, A. Jannesari, and A. M. Sodagar, \u201cData compressionin brain-machine/computer interfaces based on the Walsh\u2013Hadamardtransform,\u201d IEEE Trans. Biomed. Circuits Syst., vol. 8, no. 1,pp. 129\u2013137, Feb. 2014.[24] V. Majidzadeh, A. Schmid, and Y. Leblebici, \u201cA 16-channel, 359 \u03bcW,parallel neural recording system using Walsh-Hadamard coding,\u201d inProc. Custom Integr. Circuits Conf. (CICC), Sep. 2013, pp. 1\u20134.[25] C. Aprile, J. W\u00fcthrich, L. Baldassarre, Y. Leblebici, and V. Cevher,\u201cDCT learning-based hardware design for neural signal acquisitionsystems,\u201d in Proc. Comput. Frontiers Conf., 2017, pp. 391\u2013394.[26] J. L. Bohorquez, A. P. Chandrakasan, and J. L. Dawson, \u201cA 350 \u03bcWCMOS MSK transmitter and 400 \u03bcW OOK super-regenerative receiverfor medical implant communications,\u201d IEEE J. Solid-State Circuits,vol. 44, no. 4, pp. 1248\u20131259, Apr. 2009.[27] Revision of Part 15 of the Commission\u2019s Rules Regarding Ultra-Wideband Transmission Systems, Federal Commun. Commission,Washington, DC, USA, Apr. 2002.[28] H. Bahrami, S. A. Mirbozorgi, R. Ameli, L. A. Rusch, and B. Gosselin,\u201cFlexible, polarization-diverse UWB antennas for implantable neuralrecording systems,\u201d IEEE Trans. Biomed. Circuits Syst., vol. 10, no. 1,pp. 38\u201348, Feb. 2016.[29] A. Kurs, A. Karalis, R. Moffatt, J. D. Joannopoulos, P. Fisher, andM. Solja\u02c7ci\u00b4c, \u201cWireless power transfer via strongly coupled magneticresonances,\u201d Science, vol. 317, no. 5834, pp. 83\u201386, 2007.[30] G. Yilmaz, O. Atasoy, and C. Dehollain, \u201cWireless energy and datatransfer for in-vivo epileptic focus localization,\u201d IEEE Sensors J., vol. 13,no. 11, pp. 4172\u20134179, Nov. 2013.[31] A. K. Ram Rakhyani, S. Mirabbasi, and M. Chiao, \u201cDesign andoptimization of resonance-based ef\ufb01cient wireless power deliverysystems for biomedical implants,\u201d IEEE Trans. Biomed. Circuits Syst.,vol. 5, no. 1, pp. 48\u201363, Feb. 2011.[32] IEEE Standard for Safety Levels with Respect to Human Exposure toRadio Frequency Electromagnetic Fields, 3 KHz to 300 GHz, IEEEStandard C95.1-2005 (Revision IEEE Standard C95.1-1991), Apr. 2006,pp. 1\u2013238.[33] P. Vaillancourt, A. Djemouai, J. F. Harvey, and M. Sawan, \u201cEM radiationbehavior upon biological tissues in a radio-frequency power transfer linkfor a cortical visual implant,\u201d in Proc. 19th Annu. Int. Conf. IEEE Eng.Med. Biol. Soc., vol. 6, Oct./Nov. 1997, pp. 2499\u20132502.[34] K. M. Silay, C. Dehollain, and M. Declercq, \u201cNumerical analysisof temperature elevation in the head due to power dissipation in acortical implant,\u201d in Proc. 30th Annu. Int. Conf. IEEE Eng. Med. Biol.Soc. (EMBS), Aug. 2008, pp. 951\u2013956.[35] K. M. Silay, C. Dehollain, and M. Declercq, \u201cInductive power link fora wireless cortical implant with two-body packaging,\u201d IEEE Sensors J.,vol. 11, no. 11, pp. 2825\u20132833, Nov. 2011.[36] S. J. Xilinx, \u201cVirtex-5 LX FPGA ML501 evaluation platform,\u201dTech. Rep. UG226 (v1.4), Aug. 2009.Cosimo Aprile (S\u201916) received the B.S. degreein electronic engineering from the Politecnico diTorino, Italy, in 2010, and the joint M.S. degree inmicro and nanotechnologies for ICTs from the SwissFederal Institute of Technology, Lausanne (EPFL),Switzerland, the Institut National Polytechnique deGrenoble, and the Politecnico di Torino in 2012.He is currently pursuing the Ph.D. degree in electri-cal engineering with EPFL. Since 2013, he has beenwith the Laboratory for Information and InferenceSystems and the Microelectronic Systems Labora-tory, EPFL. His research interests include high speed analog circuit design,signal processing, and analog/mixed-signal integrated circuits design foroptimized information extraction from signals or data volumes.Kerim Ture received the B.S. degrees in electri-cal and electronics engineering and physics fromBogazici University, Istanbul, Turkey, in 2012, andthe M.Sc. degree in electrical and electronics engi-neering from the Swiss Federal Institute of Tech-nology, Lausanne (EPFL), Lausanne, Switzerland,in 2014, where he is currently pursuing the Ph.D.degree in wireless power transmission and radiofrequency communication with the RFIC ResearchGroup. His research interests include low-poweranalog and RF CMOS integrated circuit design forwireless sensor systems and biomedical applications.Luca Baldassarre received the master\u2019s degree inphysics and the Ph.D. degree in machine learningfrom the University of Genoa, Italy. He was withthe Swiss Federal Institute of Technology underthe supervision of Prof. V. Cevher on new modelsfor compressive sensing and signal processing, andthe development of new optimization algorithms.Here, he \ufb01led a patent on a machine learning-based approach for improving the scan-time andreconstruction quality of several imaging methods.He was also with the Department of ComputerScience, University College London, where he conducted a Post-DoctoralResearch under the supervision of Prof. M. Pontil. He has been leading datascience efforts at Gamaya since 2016, a precision agriculture start-up thatleverages hyper-spectral imagery, drones and satellites, to help farmers betterunderstand their crops. He published papers in machine learning conferencesand journals, with theoretical and computational analyses of new algorithmsand a novel application of brain decoding based on fMRI neuroimaging.\n\n\n\n\n\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.APRILE et al.: ADAPTIVE LEARNING-BASED COMPRESSIVE SAMPLING FOR LOW-POWER WIRELESS IMPLANTS 13Mahsa Shoaran received the B.Sc. and M.Sc.degrees from the Sharif University of Technologyin 2008 and 2010, respectively, and the Ph.D.degree from the Swiss Federal Institute of Technol-ogy (EPFL) in 2015. She was a Post-Doctoral Fellowwith the California Institute of Technology. She iscurrently an Assistant Professor with the Schoolof Electrical and Computer Engineering, CornellUniversity, and the Director of the Cornell Neu-roengineering Laboratory. Her main research inter-ests include low-power circuit and system designfor biomedical applications, brain\u2013computer interfaces, compressive sensing,embedded classi\ufb01cation and machine learning, and neuromodulation therapiesfor neurological disorders. She is a recipient of both Early and AdvancedSwiss National Science Foundation Postdoctoral Fellowships. She was nameda Rising Star in EE/CS by MIT in 2015.G\u00fcrkan Yilmaz received the B.Sc. and M.Sc.degrees from the Electrical and ElectronicsEngineering Department, Middle East TechnicalUniversity, Ankara, Turkey, in 2008 and 2010,respectively. He is currently pursuing the Ph.D.degree in microelectronics and microsystems fromthe Swiss Federal Institute of Technology, Lausanne(EPFL), Lausanne, Switzerland. He continued hisresearch activities as a Post-Doctoral Researcherwith the RFIC Group, EPFL, until 2017. He isalso a Senior R&D Engineer with Medical DeviceTechnologies, CSEM SA, Switzerland.Franco Maloberti (A\u201984\u2013SM\u201987\u2013F\u201996\u2013LF\u201915) iscurrently an Emeritus Professor with the Universityof Pavia, Pavia, Italy. He is also the Chairman ofthe Academic Committee of the MicroelectronicsKey-Lab of Macau. He has authored or co-authoredover 550 published papers in journals or conferenceproceedings and four books. He holds 34 patents.He was a recipient of the XII Pedriali Prize forhis technical and scienti\ufb01c contributions to nationalindustrial production in 1992. He was a co-recipientof the 1996 Institute of Electrical Engineers FlemingPremium, the Best Paper Award at ESSCIRC-2007, and the Best PaperAward at the IEEJ Analog Workshop in 2007 and 2010. He received the1999 IEEE Circuits and Systems (CAS) Society Meritorious Service Award,the 2000 CAS Society Golden Jubilee Medal, the 2000 IEEE MillenniumMedal, and the IEEE CAS Society 2013 Mac Van Valkenburg Award. In 2009,he received the title of Honorary Professor of the University of Macau. He wasthe President of the IEEE Sensor Council from 2002 to 2003, and the VicePresident, Region 8, of the IEEE CAS Society from 1995 to 1997. He is thepast President of the IEEE Circuits and Systems Society. He was an AssociateEditor of the IEEE TCAS-II. He was serving on the VP Publications of theIEEE CAS Society from 2007 to 2008. He was a Distinguished Lecturer ofthe IEEE Solid State Circuits Society from 2009 to 2010 and a DistinguishedLecturer of the Circuits and Systems Society from 2012 to 2013.Catherine Dehollain (M\u201993) received the mas-ter\u2019s degree in electrical engineering and the Ph.D.degree from the Swiss Federal Institute of Tech-nology, Lausanne (EPFL), Switzerland, in 1982and 1995, respectively. From 1982 to 1984, she wasa Research Assistant with the Electronics Laborato-ries, EPFL. In 1984, she joined the Motorola Euro-pean Center for Research and Development, Geneva,Switzerland, where she designed integrated circuitsapplied to telecommunications. In 1990, she joinedEPFL as a Senior Assistant with the Chaire desCircuits et Systemes, where she was involved in impedance broadbandmatching. Since 1995, she has been responsible for the EPFL-RFIC Groupfor RF activities. She has been the technical project manager of the Europeanprojects, Swiss CTI projects, and the Swiss National Science Foundationprojects dedicated to mobile phones, RF wireless micropower sensor networks,and biomedical applications. Since 1998, she has been a Lecturer at EPFLin the area of RF circuits, electric \ufb01lters, and CMOS analog circuits.From 2006 to 2014, she was a Maitre d\u2019Enseignement et de Recherche,EPFL. Since 2014, she has been Adjunct Professor with EPFL. She hasauthored or co-authored \ufb01ve scienti\ufb01c books and 160 scienti\ufb01c publications.Her research interests include low-power analog circuits, biomedical remotelypowered sensors, and electric \ufb01lters.Yusuf Leblebici (M\u201990\u2013SM\u201998\u2013F\u201910) received theB.Sc. and M.Sc. degrees in electrical engineeringfrom Istanbul Technical University, Istanbul, Turkey,in 1984 and 1986, respectively, and the Ph.D. degreein electrical and computer engineering from theUniversity of Illinois at Urbana\u2013Champaign, Cham-paign, IL, USA, in 1990. Since 2002, he has been aChair Professor with the Swiss Federal Institute ofTechnology (EPFL), Lausanne, Switzerland, and theDirector of the Microelectronic Systems Laboratory,Lausanne. He has co-authored six textbooks, andover 300 articles published in various journals and conferences. His researchinterests include the design of high-speed CMOS digital and mixed-signalintegrated circuits, computer-aided design of VLSI systems, intelligent sensorinterfaces, modeling and simulation of semiconductor devices, and VLSIreliability analysis. He has served as an Associate Editor of the IEEETRANSACTIONS ON CIRCUITS AND SYSTEMS and the IEEE TRANSACTIONSON VERY LARGE SCALE INTEGRATED SYSTEMS. He has been elected asa Distinguished Lecturer of the IEEE Circuits and Systems Society from2010 to 2011.Volkan Cevher received the B.Sc. (valedictorian)degree in electrical engineering from Bilkent Univer-sity, Ankara, Turkey, in 1999, and the Ph.D. in elec-trical and computer engineering from the GeorgiaInstitute of Technology, Atlanta, GA, USA, in 2005.He was a Research Scientist with the Universityof Maryland at College Park, College Park, from2006 to 2007, and also with Rice University, Hous-ton, TX, USA, from 2008 to 2009. He is currently anAssociate Professor with the Swiss Federal Instituteof Technology, Lausanne, and a Faculty Fellow withthe Electrical and Computer Engineering Department, Rice University. Hisresearch interests include signal processing theory, machine learning, convexoptimization, and information theory. He was a recipient of the IEEE SignalProcessing Society Best Paper Award in 2016, the Best Paper Award atCAMSAP in 2015, the Best Paper Award at SPARS in 2009, and an ERCCG in 2016 and an ERC StG in 2011.\n\n\n\nCitations (7)References (36)... Recording and decoding high-frequency neural features through intracortical brain-computer interfaces has allowed accurate control of complex actuators [1]. Moving from laboratory demonstrations to widespread use of such systems requires combining signal acquisition and processing in an implantable system on chip [2], [3], under stringent energy and size constraints. Therefore, accommodating the maximum number of electrodes requires the lowest energy-area cost per recording channel.  ...... SUMMARY AND COMPARISON WITH STATE-OF-THE-ART RECORDING ICS Estimated from given data.2 On-chip decimation filter.3 Off-chip decimation filter.  ...An AC-Coupled Wideband Neural Recording Front-End With Sub-1mm2\u00d7fJ/conv-step Efficiency and 0.97 NEFArticleAug 2020Arda UranYusuf LeblebiciAzita EmamiVolkan CevherThis paper presents an energy-and-area-efficient AC-coupled front-end for multichannel recording of wideband neural signals. The proposed unit conditions local field and action potentials using an inverter-based capacitively-coupled low-noise amplifier, followed by a per-channel 10-bit asynchronous SAR ADC. The adaptation of unit-length capacitors minimizes the ADC area and relaxes the amplifier gain so that small coupling capacitors can be integrated. The prototype in 65nm CMOS achieves 4\u00d7 smaller area and 3\u00d7 higher energy-area efficiency compared to the state of the art with 164 m\u00d740 m footprint and 0.78 mm2\u00d7fJ/conv-step energy-area figure of merit. The measured 0.65 W power consumption and 3.1 Vrms input-referred noise within 1Hz-10kHz bandwidth correspond to a noise efficiency factor of 0.97.ViewShow abstract... Neural signals are proven to be sparse in certain domains (or prelearned dictionaries) [4]. Recent studies have successfully demonstrated highly efficient CS-based neural recorders [5][6][7][8][9][10]. Moreover, CS theory also permits its application in data encryption [11].  ...An Energy-efficient Wireless Neural Recording System with Compressed Sensing and EncryptionPreprintFull-text availableSep 2020 Xilin LiuAndrew G. Richardson Jan Van der SpiegelThis paper presents a wireless neural recording system featuring energy-efficient data compression and encryption. An ultra-high efficiency is achieved by leveraging compressed sensing (CS) for simultaneous data compression and encryption. CS enables sub-Nyquist sampling of neural signals by taking advantage of its intrinsic sparsity. It simultaneously encrypts the data with the sampling matrix being the cryptographic key. To share the key over an insecure wireless channel, we implement an elliptic-curve cryptography (ECC) based key exchanging protocol. The CS operation is executed in a custom-designed IC fabricated in 180nm CMOS technology. Mixed-signal circuits are designed to optimize the power efficiency of the matrix-vector multiplication (MVM) of the CS operation. The ECC algorithm is implemented in a low-power Cortex-M0 microcontroller (MCU). To be protected from timing and power analysis attacks, the implementation avoids possible data-dependent branches and also employs a randomized ECC initialization. At a compression ratio of 8x, the average correlated coefficient between the reconstructed signals and the uncompressed signals is 0.973, while the ciphertext-only attacks (CoA) achieve no better than 0.054 over 200,000 attacks. The prototype achieves a 35x power saving compared with conventional implementation in low-power MCUs. This work demonstrates a promising solution for future chronic neural recording systems with requirements in high energy efficiency and security.ViewShow abstract... At the same time, the engineering community has focused on designing more efficient neural interfaces. Recent designs, aimed at reducing the quantity of raw data generated by conventional neural interfaces, Articles NaTUre BIoMeDICal eNgINeerINg use a wide range of techniques, such as on-chip thresholding [30][31][32] , on-chip spike sorting 33 , on-chip compression [34][35][36][37] and compressive sensing 38,39 . Despite these efforts, there is not yet a consensus on the required specifications for iBCI-oriented neural interfaces.  ...Power-saving design opportunities for wireless intracortical brain\u2013computer interfacesArticleFull-text availableOct 2020Nat. Biomed. Eng.Nir Even-ChenDante G. Muratore Sergey D Stavisky Krishna ShenoyThe efficacy of wireless intracortical brain\u2013computer interfaces (iBCIs) is limited in part by the number of recording channels, which is constrained by the power budget of the implantable system. Designing wireless iBCIs that provide the high-quality recordings of today\u2019s wired neural interfaces may lead to inadvertent over-design at the expense of power consumption and scalability. Here, we report analyses of neural signals collected from experimental iBCI measurements in rhesus macaques and from a clinical-trial participant with implanted 96-channel Utah multielectrode arrays to understand the trade-offs between signal quality and decoder performance. Moreover, we propose an efficient hardware design for clinically viable iBCIs, and suggest that the circuit design parameters of current recording iBCIs can be relaxed considerably without loss of performance. The proposed design may allow for an order-of-magnitude power savings and lead to clinically viable iBCIs with a higher channel count.ViewShow abstract... For online data compression, compressed sensing is widely used in implantable/wearable neural interfaces [83][84][85] due to the simplicity of the encoding process. Data selection is another way to reduce the data transfer throughput.  ...Electronic neural interfacesArticleFull-text availableApr 2020 Milin ZhangZijian Tang Xilin Liu Jan Van der SpiegelDevices such as keyboards and touchscreens allow humans to communicate with machines. Neural interfaces, which can provide a direct, electrical bridge between analogue nervous systems and digital man-made systems, could provide a more efficient route to future information exchange. Here we review the development of electronic neural interfaces. The interfaces typically consist of three modules \u2014 a tissue interface, a sensing interface, and a neural signal processing unit \u2014 and based on technical milestones in the development of the electronic sensing interface, we group and analyse the interfaces in four generations: the patch clamp technique, multi-channel neural interfaces, implantable/wearable neural interfaces and integrated neural interfaces. We also consider key circuit and system challenges in the design of neural interfaces and explore the opportunities that arise with the latest technologyViewShow abstractArtificial Retina: A Future Cellular-Resolution Brain-Machine InterfaceChapterJun 2020Dante G. Muratore E.J. ChichilniskyBrain-machine interfaces (BMIs) of the future will be used to treat diverse neurological disorders and augment human capabilities. However, to realize this futuristic promise will require a major leap forward in how electronic devices interact with the nervous system. Current BMIs provide coarse communication with the target neural circuitry, because they fail to respect its cellular and cell-type specificity. Instead, they indiscriminately activate or record many cells at the same time and provide only partial restoration of lost abilities. A future BMI that may pave the path forward is an artificial retina\u2014a device that can restore vision to people blinded by retinal degeneration. Because the retina is relatively well understood and easily accessible, it is an ideal neural circuit in which to develop a BMI that can approach or exceed the performance of the biological circuitry. This chapter summarizes the basic neuroscience of vision, identifies the requirements for an effective retinal interface, and describes some of the necessary circuits and systems. Based on these ideas and the lessons from first-generation retinal prostheses, a novel neuroengineering approach is proposed: the first BMI that will interact with neural circuitry at cellular and cell-type resolution.ViewShow abstractImplantable Monitoring System for EpilepsyChapterMar 2020 Kerim Ture C. Dehollain Franco MalobertiThis chapter provides detailed information about the implantable intracranial monitoring system introduced in the previous chapter. The system overview and block diagram of the system will be presented. This chapter covers each functional block starting from the properties of the interested brain signals for presurgical analysis of epilepsy treatment to the receiver unit in the external base station. The detailed implementation of the blocks in the scope of this book is left for the following chapters.ViewShow abstractA Data-Compressive Wired-OR Readout for Massively Parallel Neural RecordingArticleAug 2019IEEE T BIOMED CIRC SDante Gabriel Muratore Pulkit TandonMary WoottersBoris MurmannNeural interfaces of the future will be used to help restore lost sensory, motor, and other capabilities. However, realizing this futuristic promise requires a major leap forward in how electronic devices interface with the nervous system. Next generation neural interfaces must support parallel recording from tens of thousands of electrodes within the form factor and power budget of a fully implanted device, posing a number of significant engineering challenges. In this paper, we exploit sparsity and diversity of neural signals to achieve simultaneous data compression and channel multiplexing for neural recordings. The architecture uses wired-OR interactions within an array of single-slope A/D converters to obtain massively parallel digitization of neural action potentials. The achieved compression is lossy but effective at retaining the critical samples belonging to action potentials, enabling efficient spike sorting and cell type identification. Simulation results of the architecture using data obtained from primate retina \nex-vivo \nwith a 512-channel electrode array show average compression rates up to \n$\\sim$ \n40\u00d7 while missing less than 5% of cells. In principle, the techniques presented here could be used to design interfaces to other parts of the nervous system.ViewShow abstractA 16-channel 1.1mm^2 implantable seizure control SoC with sub-\u03bcW/channel consumption and closed-loop stimulation in 0.18\u00b5m CMOSConference PaperFull-text availableJun 2016 Mahsa Shoaran Masoud Shahshahani Masoud Farivar Azita EmamiWe present a 16-channel seizure detection system-on-chip (SoC) with 0.92\u00b5W/channel power dissipation in a total area of 1.1mm^2 including a closed-loop neural stimulator. A set of four features are extracted from the spatially filtered neural data to achieve a high detection accuracy at minimal hardware cost. The performance is demonstrated by early detection and termination of kainic acid-induced seizures in freely moving rats and by offline evaluation on human intracranial EEG (iEEG) data. Our design improves upon previous works by over 40\u00d7 reduction in power-area product per channel. This improvement is a key step towards integration of larger arrays with higher spatiotemporal resolution to further boost the detection accuracy.ViewShow abstractStructured Sampling and Recovery of iEEG SignalsConference PaperFull-text availableDec 2015Luca Baldassarre Cosimo Aprile Mahsa ShoaranVolkan CevherWireless implantable devices capable of monitoring the electrical activity of the brain are becoming an important tool for understanding, and potentially treating, mental diseases such as epilepsy and depression. Compressive sensing (CS) is emerging as a promising approach to directly acquire compressed signals, allowing to reduce the power consumption associated with data transmission. To this end, we propose an efficient CS scheme which exploits the structure of the intracranial EEG signals, both in sampling and recovery. Our structure-aware approach is conceptually simple to implement in hardware and yields state-of-the-art compression rates up to 32x with high reconstruction quality, as illustrated on two human iEEG datasets.ViewShow abstractLearning-Based Near-Optimal Area-Power Trade-offs in Hardware Design for Neural Signal AcquisitionConference PaperFull-text availableMay 2016 Cosimo AprileLuca Baldassarre Suleman BhatVolkan CevherWireless implantable devices capable of monitoring the electrical activity of the brain are becoming an important tool for understanding and potentially treating mental diseases such as epilepsy and depression. While such devices exist, it is still necessary to address several challenges to make them more practical in terms of area and power dissipation.In this work, we apply Learning Based Compressive Subsampling (LBCS) to tackle the power and area trade-offs in neural wireless devices. To this end, we propose a lowpower and area-effcient system for neural signal acquisition which yields state-of-art compression rates up to 64x with high reconstruction quality, as demonstrated on two human iEEG datasets. This new fully digital architecture handles one neural acquisition channel, with an area of 210x210\u03bcm in 90nm CMOS technology, and a power dissipation of only 0:9\u03bcW.ViewShow abstractLearning-Based Compressive SubsamplingArticleFull-text availableOct 2015IEEE J-STSPLuca Baldassarre Yen-Huan Li Jonathan ScarlettVolkan CevherThe problem of recovering a structured signal $\\mathbf{x} \\in \\mathbb{C}^p$\nfrom a set of dimensionality-reduced linear measurements $\\mathbf{b} =\n\\mathbf{A}\\mathbf{x}$ arises in a variety of applications, such as medical\nimaging, spectroscopy, Fourier optics, and computerized tomography. Due to\ncomputational and storage complexity or physical constraints imposed by the\nproblem, the measurement matrix $\\mathbf{A} \\in \\mathbb{C}^{n \\times p}$ is\noften of the form $\\mathbf{A} = \\mathbf{P}_{\\Omega}\\mathbf{\\Psi}$ for some\northonormal basis matrix $\\mathbf{\\Psi}\\in \\mathbb{C}^{p \\times p}$ and\nsubsampling operator $\\mathbf{P}_{\\Omega}: \\mathbb{C}^{p} \\rightarrow\n\\mathbb{C}^{n}$ that selects the rows indexed by $\\Omega$. This raises the\nfundamental question of how best to choose the index set $\\Omega$ in order to\noptimize the recovery performance. Previous approaches to addressing this\nquestion rely on non-uniform \\emph{random} subsampling using\napplication-specific knowledge of the structure of $\\mathbf{x}$. In this paper,\nwe instead take a principled learning-based approach in which a \\emph{fixed}\nindex set is chosen based on a set of training signals\n$\\mathbf{x}_1,\\dotsc,\\mathbf{x}_m$. We formulate combinatorial optimization\nproblems seeking to maximize the energy captured in these signals in an\naverage-case or worst-case sense, and we show that these can be efficiently\nsolved either exactly or approximately via the identification of modularity and\nsubmodularity structures. We provide both deterministic and statistical\ntheoretical guarantees showing how the resulting measurement matrices perform\non signals differing from the training signals, and we provide numerical\nexamples showing our approach to be highly effective in a variety of real-world\nsignal processing applications.ViewShow abstractStructured Sparsity: Discrete and Convex ApproachesArticleFull-text availableJul 2015 Anastasios KyrillidisLuca Baldassarre Marwa El HalabiVolkan CevherCompressive sensing (CS) exploits sparsity to recover sparse or compressible\nsignals from dimensionality reducing, non-adaptive sensing mechanisms. Sparsity\nis also used to enhance interpretability in machine learning and statistics\napplications: While the ambient dimension is vast in modern data analysis\nproblems, the relevant information therein typically resides in a much lower\ndimensional space. However, many solutions proposed nowadays do not leverage\nthe true underlying structure. Recent results in CS extend the simple sparsity\nidea to more sophisticated {\\em structured} sparsity models, which describe the\ninterdependency between the nonzero components of a signal, allowing to\nincrease the interpretability of the results and lead to better recovery\nperformance. In order to better understand the impact of structured sparsity,\nin this chapter we analyze the connections between the discrete models and\ntheir convex relaxations, highlighting their relative advantages. We start with\nthe general group sparse model and then elaborate on two important special\ncases: the dispersive and the hierarchical models. For each, we present the\nmodels in their discrete nature, discuss how to solve the ensuing discrete\nproblems and then describe convex relaxations. We also consider more general\nstructures as defined by set functions and present their convex proxies.\nFurther, we discuss efficient optimization solutions for structured sparsity\nproblems and illustrate structured sparsity in action via three applications.ViewShow abstractDCT Learning-Based Hardware Design for Neural Signal Acquisition SystemsConference PaperMay 2017 Cosimo AprileJohannes W\u00fcthrichLuca BaldassarreVolkan CevherThis work presents an area and power efficient encoding system for wireless implantable devices capable of monitoring the electrical activity of the brain. Such devices are becoming an important tool for understanding, real-time monitoring, and potentially treating mental diseases such as epilepsy and depression. Recent advances on compressive sensing (CS) have shown a huge potential for sub-Nyquist sampling of neuronal signals. However, its implementation is still facing critical issues in delivering sufficient performance and in hardware complexity. In this work, we explore the tradeoffs between area and power requirements applying a novel DCT Learning-Based Compressive Subsampling approach on a human iEEG dataset. The proposed method achieves compression rates up to 64x, increasing the reconstruction performance and reducing the wireless transmission costs with respect to recent state-of-art. This new fully digital architecture handles the data compression of each individual neural acquisition channel with an area of 490 x 650/\u03bcm in 0.18 \u03bcm CMOS technology, and a power dissipation of only 2\u03bcW.ViewShow abstractA Wavelet Tour of Signal ProcessingBookJan 2009S. MallatMallat's book is the undisputed reference in this field - it is the only one that covers the essential material in such breadth and depth. - Laurent Demanet, Stanford University The new edition of this classic book gives all the major concepts, techniques and applications of sparse representation, reflecting the key role the subject plays in today's signal processing. The book clearly presents the standard representations with Fourier, wavelet and time-frequency transforms, and the construction of orthogonal bases with fast algorithms. The central concept of sparsity is explained and applied to signal compression, noise reduction, and inverse problems, while coverage is given to sparse representations in redundant dictionaries, super-resolution and compressive sensing applications. Features: * Balances presentation of the mathematics with applications to signal processing * Algorithms and numerical examples are implemented in WaveLab, a MATLAB toolbox * Companion website for instructors and selected solutions and code available for students New in this edition * Sparse signal representations in dictionaries * Compressive sensing, super-resolution and source separation * Geometric image processing with curvelets and bandlets * Wavelets for computer graphics with lifting on surfaces * Time-frequency audio processing and denoising * Image compression with JPEG-2000 * New and updated exercises A Wavelet Tour of Signal Processing: The Sparse Way, third edition, is an invaluable resource for researchers and R&D engineers wishing to apply the theory in fields such as image processing, video processing and compression, bio-sensing, medical imaging, machine vision and communications engineering. Stephane Mallat is Professor in Applied Mathematics at \u00c9cole Polytechnique, Paris, France. From 1986 to 1996 he was a Professor at the Courant Institute of Mathematical Sciences at New York University, and between 2001 and 2007, he co-founded and became CEO of an image processing semiconductor company. Includes all the latest developments since the book was published in 1999, including its application to JPEG 2000 and MPEG-4 Algorithms and numerical examples are implemented in Wavelab, a MATLAB toolbox Balances presentation of the mathematics with applications to signal processing.ViewShow abstractVNS Therapy in Treatment-Resistant Depression: Clinical Evidence and Putative Neurobiological MechanismsArticleOct 2006Charles B. Nemeroff Helen MaybergScott E KrahlS.K. BrannanViewSilicon-Integrated High-Density Electrocortical InterfacesArticleAug 2016P IEEESohmyung Ha Abraham Akinin Jiwoong Park Gert CauwenberghsRecent demand and initiatives in brain research have driven significant interest toward developing chronically implantable neural interface systems with high spatiotemporal resolution and spatial coverage extending to the whole brain. Electroencephalography-based systems are noninvasive and cost efficient in monitoring neural activity across the brain, but suffer from fundamental limitations in spatiotemporal resolution. On the other hand, neural spike and local field potential (LFP) monitoring with penetrating electrodes offer higher resolution, but are highly invasive and inadequate for long-term use in humans due to unreliability in long-term data recording and risk for infection and inflammation. Alternatively, electrocorticography (ECoG) promises a minimally invasive, chronically implantable neural interface with resolution and spatial coverage capabilities that, with future technology scaling, may meet the needs of recently proposed brain initiatives. In this paper, we discuss the challenges and state-of-the-art technologies that are enabling next-generation fully implantable high-density ECoG interfaces, including details on electrodes, data acquisition front-ends, stimulation drivers, and circuits and antennas for wireless communications and power delivery. Along with state-of-the-art implantable ECoG interface systems, we introduce a modular ECoG system concept based on a fully encapsulated neural interfacing acquisition chip (ENIAC). Multiple ENIACs can be placed across the cortical surface, enabling dense coverage over wide area with high spatiotemporal resolution. The circuit and system level details of ENIAC are presented, along with measurement results.ViewShow abstractFlexible, Polarization-Diverse UWB Antennas for Implantable Neural Recording SystemsArticleMar 2015IEEE T BIOMED CIRC SHadi Bahrami Abdollah MirbozorgiReza AmeliBenoit GosselinImplanted antennas for implant-to-air data communications must be composed of material compatible with biological tissues. We design single and dual-polarization antennas for wireless ultra-wideband neural recording systems using an inhomogeneous multi-layer model of the human head. Antennas made from flexible materials are more easily adapted to implantation; we investigate both flexible and rigid materials and examine performance trade-offs. The proposed antennas are designed to operate in a frequency range of 2-11 GHz (having S11 below -10 dB) covering both the 2.45 GHz (ISM) band and the 3.1-10.6 GHz UWB band. Measurements confirm simulation results showing flexible antennas have little performance degradation due to bending effects (in terms of impedance matching). Our miniaturized flexible antennas are 12 mm\u00d712 mm and 10 mm\u00d79 mm for single- and dual-polarizations, respectively. Finally, a comparison is made of four implantable antennas covering the 2-11 GHz range: 1) rigid, single polarization, 2) rigid, dual polarization, 3) flexible, single polarization and 4) flexible, dual polarization. In all cases a rigid antenna is used outside the body, with an appropriate polarization. Several advantages were confirmed for dual polarization antennas: 1) smaller size, 2) lower sensitivity to angular misalignments, and 3) higher fidelity.ViewShow abstractShow moreAdvertisementRecommendationsDiscover moreProjectLBCS encoding for biomedical applications Cosimo AprileView projectProjectAn implantable autonomous closed-loop electrical stimulation system for epilepsy control Reza Ranjandish Alexandre Schmid Franco Maloberti[...] Kerim TureView projectProjectA 16-channel 1.1mm2 implantable seizure control SoC with sub-\u03bcW/channel consumption and closed-loop stimulation in 0.18\u00b5m CMOS Masoud Shahshahani Amirhossein Shahshahani Anatol Bragin[...] Azita EmamiView projectArticleLow RF power harvesting circuit for wireless sensor nodes in industrial plantsJanuary 2014 Issam Chaour Olfa Kanoun A. FakhfakhTechniques and methods of energy harvesting are developed to recuperate energy coming from the ambiance to be transmitted to electronic systems. Energy should be useful in specific applications, to generate a certain voltage level and make capable of delivering a recommended Power to the load. So, the main challenge for energy harvesting is to obtain a significant amount of power efficiently from ... [Show full abstract] the environment. This paper describes an overview of power transfer systems and methods of charging low power sensors in industrial plants using harvested RF signals. It introduces a scheme investigation of the RF harvester consisting of receiver antenna and a rectifier circuit to convert the RF signal to DC voltage. Low power consumption circuits are used to achieve the target of highest conceivable efficiency in order to produce the maximum power transfer.Read moreConference PaperLow-power high-speed wireless transceivers and antennas for large-scale neural implantsJune 2016Benoit Gosselin Masoud RezaeiAdvancement in wireless and microsystems technology have ushered in new devices that can directly interface with the central nervous system for stimulating and/or monitoring neural circuitry. In this paper, we present the design of low-power CMOS integrated transceivers intended for utilization into large-scale multi-channel neural stimulating/monitoring implants. We discuss the design and the ... [Show full abstract] implementation of different modulation schemes and pulse shaping strategies within CMOS circuits, we review the most critical design challenges of this sensitive application, we compare different solutions and circuit topologies in terms of performance and safety, and we introduce a suitable implantable UWB antenna. In particular, we present an integrated transmitter (TX) and a receiver (RX) that are designed to share a single implantable antenna. The TX generates ultra wideband (UWB) impulses based on edge combining, and the RX uses a low-power ISM-2.4-GHz narrow-band OOK receiver topology. The RX can support downlink telemetry of neural stimulation applications with a data rate as high as 100 Mbps within a power budget of 5 mW, while the TX is designed to support uplink back telemetry with a data rate of up to 800 Mbps for power consumption of 5.36 mW for BPSK modulation. Finally, we present measurement results obtained with biological tissues that confirm the full functionality of the fabricated implantable transceiver.Read moreConference PaperA low-power 2.4-GHz receiver for wireless implantable neural stimulatorsJune 2014 \u00b7 Proceedings - IEEE International Symposium on Circuits and Systems Abdollah MirbozorgiHadi Bahrami Leslie A. RuschBenoit GosselinThis paper presents a 2.4 GHz low-power CMOS On-Off Keying receiver front-end which contains a low noise amplifier with a novel down conversion mixer that is designed for wireless forward telemetry link in neural stimulation applications. The transceiver operates between 2.4 and 2.5 GHz to support the full industrial, scientific and medical band. The post-layout simulation results show that the ... [Show full abstract] fully integrated low-noise amplifier exhibits a gain of 15 dB, a noise figure of 1 dB at 2.4 GHz, and the input matching (S11) is -16 dB. The proposed mixer is resistor-less and designed based on current starved delay elements in a Gilbert topology. The transceiver implemented in a TSMC 0.18 \u03bcm CMOS technology uses a supply voltage of 1.2 V, supports a data rate of up to 100 Mbps, and consumes 7 mW. The total size of the proposed receiver front-end equals 0.38 mm2.Read moreConference Paper23.3 A 3nW fully integrated energy harvester based on self-oscillating switched-capacitor DC-DC conv...February 2014 \u00b7 Digest of Technical Papers - IEEE International Solid-State Circuits ConferenceWanyeong Jung Sechang Oh Suyoung Bang[...]David BlaauwRecent advances in low-power circuits have enabled mm-scale wireless systems [1] for wireless sensor networks and implantable devices, among other applications. Energy harvesting is an attractive way to power such systems due to limited energy capacity of batteries at these form factors. However, the same size limitation restricts the amount of harvested power, which can be as low as 10s of nW ... [Show full abstract] for mm-scale photovoltaic cells in indoor conditions. Efficient DC-DC up-conversion at such low power levels (for battery charging) is extremely challenging and has not yet been demonstrated.Read moreConference PaperMicro-power wireless transmitter for high-temperature MEMS sensing and communication applicationsFebruary 2002 \u00b7 Proceedings of the IEEE International Conference on Micro Electro Mechanical Systems (MEMS) Michael A. Suster Darrin YoungWen H. KoA low-power silicon-tunnel-diode-based LC-tuned oscillator\ntransmitter is proposed for high-temperature MEMS sensing and wireless\ndata transmission applications. The prototype sensing and transmitting\nmodule employs a MEMS silicon capacitive pressure sensor performing\npressure to frequency conversion and a miniature on-board coil loop\nserving as the inductor for the LC tank and also a ... [Show full abstract] transmitting antenna.\nThe system achieves telemetry performance up to 290\u00b0C over a\ndistance of 2.5 meters with a total power consumption of 110 \u03bcWRead moreLast Updated: 09 Nov 2020Discover the world's researchJoin ResearchGate to find the people and research you need to help your work.Join for free ResearchGate iOS AppGet it from the App Store now.InstallKeep up with your stats and moreAccess scientific knowledge from anywhere orDiscover by subject areaRecruit researchersJoin for freeLoginEmail Tip: Most researchers use their institutional email address as their ResearchGate loginPasswordForgot password? Keep me logged inLog inorContinue with LinkedInContinue with GoogleWelcome back! Please log in.Email \u00b7 HintTip: Most researchers use their institutional email address as their ResearchGate loginPasswordForgot password? Keep me logged inLog inorContinue with LinkedInContinue with GoogleNo account? Sign upCompanyAbout usNewsCareersSupportHelp CenterBusiness solutionsAdvertisingRecruiting\u00a9 2008-2020 ResearchGate GmbH. All rights reserved.TermsPrivacyCopyrightImprint\n\n\n\n\n\n\n\n\n\n"
  },
  {
    "text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n#Amplify\n\n\n#HolidayGiftGuide\n\n\nReviews \n\n Menu\n Reviews\nReviews\n\n\nComputers & Electronics\nSoftware\nBusiness\nEditors' Choice\nAll Reviews\n\n\n\n\nComputers & Electronics\nCars\nCameras\nDesktops\nDrones\nGaming Gear\nGraphics Cards\nHeadphones\nLaptops\nMedia Streaming Devices\nMonitors\nNetwork Attached Storage\nPhones\nPrinters\nProjectors\nProcessors\nRouters\nScanners\nSmart Home\nSpeakers\nStorage\nTablets\nTVs\nVR\nWearables\n\n\nSoftware\nAntivirus\nBackup\nMacOS\nMobile Apps\nPC Games\nPhoto Editing\nSecurity\nSystem Utilities\nVideo Editing\nVideo Streaming\nVPN\nWindows 10\n\n\nBusiness\nAccounting & Tax\nCRM\nDatabase\nEmail Providers\nProductivity\nProject Management\nVideo Conferencing\nVoIP\nWeb Site Hosting\n\n\n\n\n\n\nBest Products \n\n Menu\n Best Products\nBest Products\n\n\nComputers & Electronics\nSoftware\nBusiness\nAll Best Products\n\n\n\n\nComputers & Electronics\nBest Cameras\nBest Desktops\nBest Graphics Cards\nBest Hard Drives\nBest Headphones\nBest Home Security Cameras\nBest Home Security Systems\nBest Laptops\nBest Monitors\nBest Phones\nBest Printers\nBest Processors\nBest Robot Vacuums\nBest Smart Locks\nBest Smartwatches\nBest Streaming Devices\nBest Tablets\nBest TVs\nBest VR Headsets\nBest Wireless Routers\nBest Wireless Speakers\n\n\nSoftware\nBest Android Apps\nBest Antivirus Apps\nBest DNA Testing Kits\nBest iOS Apps\nBest Online Backup Services\nBest Password Managers\nBest PC Games\nBest Photo Editing Software\nBest Security Suites\nBest Video Editing Software\nBest Video Streaming Services\nBest VPN Services\n\n\nBusiness\nBest Accounting Software\nBest Business Intelligence Tools\nBest CRM Software\nBest E-Commerce Platforms\nBest Email Marketing Services\nBest Help Desk Software\nBest Project Management Apps\nBest Tax Services\nBest Video Conferencing Tools\nBest VoIP Providers\nBest Web Hosting Services\nBest Website Builders\n\n\n\n\n\n\nHow-To \n\n Menu\n How-To\nHow-To\n\n\nComputers & Electronics\nSoftware\nBusiness\nAll How-To\n\n\n\n\nComputers & Electronics\nHow to Block Robocalls\nHow to Boost Your Wi-Fi Signal\nHow to Build a PC\nHow to Build Your Smart Home\nHow to Clone a Hard Drive\nHow to Free Up Space on Your iPhone or iPad\nHow to Increase Laptop Battery Life\nHow to Save Money on Your Cell Phone Bill\nHow to See Who\u2019s on Your Wi-Fi\nHow to Set Up an Amazon Echo\nHow to Set Up Your Wi-Fi Router\nHow to Take Better Photos\nAndroid Battery Tips\nApple TV Tips\niPhone Battery Tips\nGoogle Chromecast Tips\nRoku Tips\nSmartphone Camera Tips\n\n\nSoftware\nHow to Clear Browser Cache\nHow to Download YouTube Videos\nHow to Edit a PDF\nHow to Set Up Two-Factor Authentication\nHow to Set Up and Use a VPN\nHow to Speed Up Windows\nHow to Stay Safe Online\nHow to Take a Screenshot\nAndroid Tips\nFacebook Tips\nGmail Tips\nGoogle Chrome Tips\nGoogle Search Tips\niOS Tips\nWindows Tips\n\n\nBusiness\nHow to Build an E-Commerce Website\nHow to Create a Website\nHow to Choose a Web Host\nHow to Find Free Tools to Optimize Your Small Business\nHow to Get a Job in IT\nHow to Get Started With Project Management\nHow to Master PowerPoint\nHow to Optimize Your VoIP Network\nHow to Start an Online Business\n\n\n\n\n\n\nNews \n\n Menu\n News\nNews\n\n\n\nNews\nThe Why Axis\nRace to 5G\nReaders' Choice\nDeals\nOpinions\nFastest Mobile Networks\nFastest ISPs\nAll News\n\n\n\n\n\n\nShop\n\n\nNewsletters\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWant instant savings on the tech you love? Try RetailMeNot Deal Finder\u2122 \n\n \nPCMag editors select and review products independently. If you buy through affiliate links, we may earn commissions, which help support our testing. Learn more.\n\n\n\n\nHome\n \n\n\nNews\n \n\n\nAndroid\n\n\n\n\n\nHow to Take a Screenshot on Any Device\nHere's everything you need to know about capturing screenshots, no matter the platform\u2014Windows, macOS, Chrome OS, iOS, Android, and even Linux.\n\n\n\n\n\n\n\n\n\nBy\nJason Cohen\n\n\n\n\n\n Updated\nJune 10, 2020\n\n\n\n\n\nfacebook\n\n \n\n\n\n\ntwitter\n\n \n\n\n\n\nflipboard\n\n \n\n\n\n\nsocial share\n\n \n\n\n\n\n\n\n \nFlipboard\n\n\n\n\n\n \nPinterest\n\n\n\n\n\n \nReddit\n\n\n\n\n\n \nLinkedIn\n\n\n\n\n\n \nEmail\n\n\n\n\n\nCopied\n\n\nError!\n\n\n\n\n \nCopy Link\n\n\nhttps://www.pcmag.com/news/how-to-take-a-screenshot-on-any-device\n\n\n\n\n\n \nComments\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf you need to preserve what you're seeing on your phone or computer screen, mobile and desktop operating systems offer robust screen-capture tools. Most tools are built-in, but there are a wealthy of third-party options, as well as browser extensions that also do the job. Here's how to take a screenshot on Android, Chrome OS, iOS/iPadOS, Linux, macOS, and Windows.How to Take a Screenshot on iPhone or iPadIf you own an Apple device that still has a Home button (like the 2020 iPhone SE), hold down the sleep/wake button and press the Home button to take a screenshot. You will hear a camera shutter (if your sound is on) and see a \"flash\" on the screen. The screenshot will then appear in your Camera Roll and in the Screenshots album.For devices without a Home button\u2014the iPhone X and iPhone 11 lines, iPhone XR, and iPad Pro\u2014hold down the side button to the right of the screen (top button for iPad Pro) and the volume up button at the same time. \nScreenshot capture on iPhones with Touch ID and Face ID (Image: Apple)\nIf you're using an Apple Pencil with\u00a0iPadOS, you can take a screen grab with the drawing tool. Simply swipe up from the bottom corner of the screen with the Apple Pencil to capture the image. You can also choose between just your current screen or the entire page, even after the picture has been taken.If you need to annotate a screenshot, tap the small thumbnail that appears at the bottom of the screen once you capture a screenshot. This will open the device's markup tool and allow you to edit the screengrab.Some apps may make it difficult to take screenshots through the normal means. This is where your device's\u00a0built-in Screen Recording tool\u00a0comes in. While its primary purpose is to record video of your screen, you can pause the video and take a screenshot this way.You can also use a third-party tool to capture the screen of your mobile device from a computer. With the\u00a0LonelyScreen\u00a0tool, you share your screen via AirPlay and record or take screenshots of anything on you mobile device's screen from the computer. Apowersoft's iPhone/iPad Recorder can work as long as the PC and mobile device are on the same Wi-Fi network. Activate the AirPlay connection in Control Center, then record video and stills on a computer.How to Take a Screenshot on AndroidAndroid devices are not as uniform as iPhone and iPad, so screenshot commands may be different depending on the phone's manufacturer. Most Android devices should be able to take screen grabs by holding down the power and volume down buttons, though holding the power and home buttons (if your device has a physical button) may also work. Devices running Android 10 can also hold down the power button, then select Screenshot from the menu.Several Android devices also have a screenshot button in the pull-down Quick Settings menu. If your phone has Google Assistant or Bixby (Samsung), you can use a voice command to ask the voice assistant to take a screenshot for you. For Samsung devices with the S Pen stylus, you can take a screen grab from the Air Command menu by tapping Screen Write. You can then write on or crop the image.\nButtons on the Google Pixel 4\nSamsung phones also support gestures to take screenshots. Navigate to the screen image you like, position your hand like you plan to karate chop the phone, then swipe the entire side of your hand along the screen from right to left. Set this up (or turn it off) in\u00a0Settings > Advanced Features > Palm swipe to capture.No matter what device you have, all Android users can download third-party apps to take screen captures. Many apps meant for recording video can also take screenshots. Screenshot Easy\u00a0is a top-rated option that uses the same basic triggers as Android itself; you can also customize it and take a screenshot just by shaking your phone.To take screens of what's transpiring on your Android device on a PC, check out\u00a0Apowersoft's Android Recorder. The app lets you cast your phone or tablet screen to a Windows or macOS machine for easy capture of stills and video. It requires Android 5.0 and above.How to Take a Screenshot on Apple WatchDid you know you can take a screenshot of your Apple Watch screen? First, the feature must be enabled. Open the Watch app on your iPhone or iPad, and navigate to\u00a0My Watch > General > Enable Screenshots\u00a0and toggle it on. \nTake a screenshot on an Apple Watch by pulling up the screen you want to capture. Hold the Side Button and click the Digital Crown simultaneously. Like on iPhone, the screen will \"flash\" white and the camera shutter will go off. The screenshot will then appear on your iPhone Camera Roll, not the watch itself.How to Take a Screenshot on Wear OSIf you have a smartwatch made by Fossil, Huawei, Motorola, or Samsung, it runs on Google's Wear OS. Taking a screenshot on your Wear OS device is now much easier than it used to be because you use an app on your phone to do the work. Open the\u00a0Wear OS app, hit the three-dot menu and choose Take screenshot of watch. You will receive a notification on your phone allowing you to save or share the image via the supported apps.How to Take a Screenshot in Windows 10The simplest way to\u00a0take a screenshot in Windows\u00a0is to use the Print Screen button. You'll find it on the upper-right side of most keyboards. Tap it once and it will seem like nothing happened, but Windows just copied an image of your entire screen to the clipboard. You can then hit Ctrl+V to paste it into a program, be it a Word document or an image-editing program.The problem with this method is it captures everything visible on your monitor, and if you have a multi-monitor setup, it will grab all the displays as if they're one big screen. You can narrow things down with Alt+Print Screen, which will capture just the window you currently have open.\nWindows also has multiple built-in tools that can help you take more precise screen grabs. The Snipping Tool can be found in the Start menu, which will provide a small toolbar to capture multiple types of screenshots. Grab just the area you want with a rectangular capture area, select a specific window to capture, or get the entire screen in one shot. Once a screenshot is taken, it is moved to the Snipping Tool editor, where you can save and edit the image.Another option is Snip & Sketch, which was introduced with the Windows 10 May 2019 update and is expected to eventually replace the Snipping Tool. Launch this program by using the Shift+Windows Key+S keyboard shortcut. This will launch a small toolbar at the top of the screen so you can easily choose what to capture.\nSnip & Sketch toolbar\nOne more built-in option for screen grabs is the Windows Game Bar. Though it is intended to record gaming sessions, it can be used to record any action and capture screen grabs. Open the tool with Windows Key+S and tap the camera button in the Broadcast & capture section to save a screenshot to the Videos/Captures folder under your main user folder.If all that fails, Windows has anarray of third-party screen-capture utilities available. The best option is\u00a0Snagit, which costs a whopping $50. Of course it'll do everything you can imagine, even take video of what's happening on your screen.You can find plenty of screenshot apps for free, though.\u00a0Jing, by the makers of Snagit, also does screencast videos and makes sharing what you capture easy.\u00a0LightShot\u00a0is a nifty and small utility that takes over the PrtScrn key and makes it easy to capture and share.How to Take a Screenshot on MacFollowing the update to Mojave, Mac users now have more control over grabbing screenshots than ever before. The update introduced a screenshot tool that can be triggered by pressing Command+Shift+5, or by navigating to\u00a0Launchpad > Other > Screenshot.The screen capture window allows you to perform different actions. Choose to capture the entire screen, part of the screen, or a specific window. You can also capture video of the entire screen or just a portion of it, and there's also the option to take screenshots on a timer and change where images are saved.\nFor those who prefer keyboard shortcuts, those are still supported. Use Command+Shift+3 to capture the entire screen. If you only want part of the screen captured, Command+Shift+4 will turn the cursor into a cross-hair. Select the section of the screen you want to capture.If you want to capture a specific window, use Command+Shift+5 (the same shortcut to trigger the screenshot tool). You can then hit the Space Bar to switch between capturing a section of screen and a specific window. If you have a Mac with a Touch Bar, you can capture it by pressing Command+Shift+6.If you prefer to capture an image to the clipboard instantly, add Control to any keyboard shortcut you use. For instance, use Command+Shift+Control+3 to capture the entire screen, or Command+Shift+Control+4 for a specific section. The image won't save to the computer, but it can be pasted into an app.\nIf you've got a Mac with Retina display, a screenshot of the entire screen can be\u00a0huge\u00a0in PNG format\u2014as big as 7MB. If you'd rather the Mac save in JPG or some other format, change the settings. You need to open a terminal window on the Mac in question and type:defaults write com.apple.screencapture type jpgEnter your password if asked, then restart the computer and future screenshots should save in the preferred format you specified. You can always change it back by typing the above command with PNG at the end instead.If you prefer a third-party solution, options like\u00a0Snappy\u00a0(which can sync screenshots with the\u00a0SnappyApp for iOS), Jing, Snagit,\u00a0Skitch, LightShot, and others are available.How to Take a Screenshot on LinuxThere are almost as many ways to take a screenshot in Linux as there are flavors of Linux. Focusing on Ubuntu in particular, open the Activities menu and select Screenshot. You can then choose between the whole screen, a single window, or a custom area before snapping an image.Linux also allows you to use the Print Screen button, as well as the Alt+Print Screen shortcut to screenshot a specific window. Use Shift+Print Screen to select a custom area to capture. You can also add the Ctrl key to any shortcut and save the image to the clipboard.The program\u00a0GIMP\u00a0(GNU Image Manipulation Program) allows you to take a screenshot from the same program where you edit the image after it's captured. Open GIMP and go to\u00a0File > Acquire > Screen Shot. You'll get a few options, such as taking the entire screen, a window, or using a time delay. The captured image then opens in GIMP for editing.How to Take a Screenshot on ChromebookIf you own a\u00a0Chromebook, you can take a screenshot with help from the laptop's Window Switch Key. This button is located at the top of the keyboard and has an image of a box with lines next to it. Hit Ctrl+Window Switch Key to take a full-screen snapshot. You will see the notification on the lower right of the screen.Enter Ctrl+Shift+Window Switcher to get just a section of the screen. The cursor becomes cross-hairs you can use to select what you'd like to capture.\nIf you're using a standard keyboard\u2014not a Chromebook keyboard\u2014you won't see a Window Switcher button. You'll need to Ctrl+F5 and Ctrl+Shift+F5 instead. When using your Chromebook in tablet mode, you can take screenshots without the use of the keyboard. Press the power and volume down buttons to snap a picture, though this method can only be used to capture the entire screen.All the images are saved as PNG files on the computer's local Downloads folder. If you wish to preserve these screenshots permanently, you must upload them to Google Photos or back them up in Google Drive.Since 90 percent of what you do on a Chromebook probably takes place in the Chrome web browser, you can also utilize a number of Chrome extensions.Screenshots in Web BrowsersChrome, Firefox, Safari, and Edge all support add-ons that extend browser usability. Here are a few programs you can download that have browser extensions. Use these add-ons to put screen-capture utilities right into the browser.LightShot is free and works on Windows and Mac, but can also be added as\u00a0Chrome and Firefox extensions. FireShot is a paid ($59.95) capture program that works with a browser or email client. It will capture and allow instant edits, sharing via social media, or instant saves to the computer. There are also\u00a0Chrome,\u00a0Firefox,\u00a0and Edge\u00a0extensionsAwesome Screenshot\u00a0is a free program that captures a whole page or a section, and then quickly annotates it (or blurs out the naughty bits) before sharing instantly. There are extensions for\u00a0Chrome,\u00a0Firefox, and Edge.Nimbus Screen Screenshot\u00a0is free and will let you capture the whole screen or just parts of it. You can also use it to draw, make annotations, or mark up those same images. There are\u00a0Chrome\u00a0and\u00a0Firefox\u00a0extensions.Page Screenshot is a paid ($2.99) extension for Safari users that can capture the full length of a website or just a specific section. Once a screen grab is taken, the program opens Preview for easy editing.\n\n\n\n\n\nFurther Reading\n \nMicrosoft Moves to Help Cyberpunk 2077 Xbox Gamers Get Refunds\nTwitter Tests Audio Chat Rooms Called Spaces\nMicrosoft Hit by SolarWinds Breach, Says It 'Isolated and Removed' the Malware\nReport: Major Cyberpunk 2077 Patch Expected Dec. 21\n\nMore in Android\n\n\nMore in Software & Services\n\n\n\nSoftware & Service Reviews\n \nEliteSingles\nWorld of Warcraft: Shadowlands (for PC)\nEncrypt.me VPN\nApple iOS 14\nShutterfly\n\n\nSoftware & Service Best Picks\n \nThe Best Malware Removal and Protection Software for 2021\nThe Best Mac Antivirus Protection for 2021\nThe Best Email Encryption Services for 2021\nThe Best Android Antivirus Apps for 2021\nThe Best Spyware Protection Software for 2021\n\n\n\n\nAbout Jason Cohen\n\n\n\n\n\nJason is PCMag's how to content generator. He believes tech corporations are bad, but you might as well know how to use technology in everyday life. He is a Mac owner, Android user, dark mode advocate, and tech bargain hunter. Before joining PCMag, Jason was a technical writer, copywriter, and all-around freelancer covering baseball, comics, and more at various outlets. When not writing and editing, he is either reading comic books, playing his Nintendo Switch, hanging out with his wife and two cats, or some combination of the three.\n\nRead the latest from Jason Cohen\n\nWhat to Stream This Weekend\nCOVID-19 Has Increased Interest in Cloud Gaming Services\nThe Best Free PC and Console Games to Claim in December 2020\nFCC May Be Significantly Overestimating US Gigabit Home Internet Coverage\nIt Would Take 17 Hours to Read the Terms & Conditions of the 13 Most Popular Apps\nMore from Jason Cohen\n\n\n\n\n\nGet Our Best Stories!\nSign up for What's New Now to get our top stories delivered to your inbox every morning\n\n\n\n\nEmail\n\n\n\n\n \n\n \n\n \nSign Up\n\n\n\n\n\n\n\nThis newsletter may contain advertising, deals, or affiliate links. Subscribing to a newsletter indicates your consent to our Terms of Use and Privacy Policy. You may unsubscribe from the newsletters at any time.\n\n\n\nThanks for signing up!\nYour subscription has been confirmed. Keep an eye on your inbox!\nSign up for other newsletters\n\n\n\n\n\n\nTable of Contents\n\nTable of Contents\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n \n\n\n\n\nAdvertisement\n\n\n\n\n\n\n\n\n\n\n\n\nPC Magazine Digital Edition\nGet 67% Off Newsstand Price \n\n\n\n\nPCMag Newsletters\nOur Best Stories in Your Inbox \n\n\n\n\nFollow PCMag\n\n\n\nfacebook\n \n\n\n\ntwitter\n \n\n\n\nflipboard\n \n\n\n\ngoogle\n \n\n\n\ninstagram\n \n\n\n\npinterest\n \n\n\n\n\n\n\n\nHonest, Objective Reviews\nPCMag.com is a leading authority on technology, delivering Labs-based, independent reviews of the latest products and services. Our expert industry analysis and practical solutions help you make better buying decisions and get more from technology.\nHow We Test\nEditorial Principles\n\n \n\n\n\nReviews\nBest Products\nCategories\nBrands\nEvents\nSeries\nEncyclopedia\nSitemap\n\n\nAbout PCMag\nCareers\nContact Us\nPress Center\n\n\n\n\u00a9 1996-2020 Ziff Davis, LLC. PCMag Digital Group\nPCMag, PCMag.com and PC Magazine are among the federally registered trademarks of Ziff Davis, LLC and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate any affiliation or the endorsement of PCMag. If you click an affiliate link and buy a product or service, we may be paid a fee by that merchant.\n\n\nAbout Ziff Davis\nPrivacy Policy\nTerms of Use\nAdvertise\nAccessibility\n\nDo Not Sell My Personal Information\n\n\n\n\n\nAdChoices\n\n\n\n\ntruste logo\n\n\n\n\n\n\n\n\n\n\n\n\n\nZiffmedia Logo\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nAskmen Logo\nLogo_AskMenFix \n\n\n\nExtremetech Logo\nExtremetech \n\n\n\nING Logo\nLogo_IGN \n\n\n\nMashable Logo\nMashable-logo \n\n\n\nOffers Logo\nOffers_LogoNoTag \n\n\n\nSpeedtest Logo\nSpeedtest_logo \n\n\n\n\nTechBargains_Logo \n\n\n\n\n\n\n\n\n\n\n\n\n\n"
  },
  {
    "text": "\n\n    Menu\n  \n\n    Close\n  \n\n\n\n\n\n\n\n\n\n\nHome Page\n\n\nCOVID-19\n\n\nArts + Culture\n\n\nBusiness + Economy\n\n\nEducation\n\n\nEnvironment + Energy\n\n\nHealth + Medicine\n\n\nPolitics\n\n\nScience + Technology\n\n\nIn French\n\n\n\n\nEdition\n\n\n\n              Africa\n            \n\n              Australia\n            \n\n              Canada\n            \n\n              Canada (fran\u00e7ais)\n            \n\n              Espa\u00f1a\n            \n\n              France\n            \n\n              Global Perspectives\n            \n\n              Indonesia\n            \n\n              New Zealand\n            \n\n              United Kingdom\n            \n\n              United States\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nEdition:\n\n\n\nAvailable editions\n\n\nAfrica\n\n\n\n\n\nAustralia\n\n\nCanada\n\n\nCanada (fran\u00e7ais)\n\n\nEspa\u00f1a\n\n\nFrance\n\n\nGlobal Perspectives\n\n\nIndonesia\n\n\nNew Zealand\n\n\nUnited Kingdom\n\n\nUnited States\n\n\n\n\n\n\n\n        Get newsletter\n \n\n\n\n\n\n\nBecome an author\n\n\nSign up as a reader\n\n\nSign in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSearch\n\n\n\n\n\n\n\n\n\n\n    Academic rigour, journalistic flair\n  \n\n\n\n\nCOVID-19\n\n\nArts + Culture\n\n\nBusiness + Economy\n\n\nEducation\n\n\nEnvironment + Energy\n\n\nHealth + Medicine\n\n\nPolitics\n\n\nScience + Technology\n\n\nIn French\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n            6 ways to establish a productive homework\u00a0routine\n          \n\n\n\nOctober 9, 2019 3.07pm SAST\n\n\n\n\n\n\n\n\n\n\nJanine L. Nieroda-Madden, Syracuse University\n\n\n\nAuthor\n\n\n\n\n\n        Janine L. Nieroda-Madden\n      \n\n\n      Assistant Professor of College Learning Strategies and Instruction, Syracuse University\n    \n\n\n\n\n\nDisclosure statement\nJanine L. Nieroda-Madden does not work for, consult, own shares in or receive funding from any company or organisation that would benefit from this article, and has disclosed no relevant affiliations beyond their academic appointment.\n\n\nPartners\nThe Conversation is funded by the National Research Foundation, eight universities, including the Cape Peninsula University of Technology, Rhodes University, Stellenbosch University and the Universities of Cape Town, Johannesburg, Kwa-Zulu Natal, Pretoria, and South Africa. It is hosted by the Universities of the Witwatersrand and Western Cape, the African Population and Health Research Centre and the Nigerian Academy of Science. The Bill & Melinda Gates Foundation is a Strategic Partner. more\n\n\n\n\n\n\n\n      Breaking homework assignments down into smaller parts makes it easier to complete.\n      Pressmaster/Shutterstock.com\n\n\n\n\n\n\n Email\n\n\n Twitter\n\n\n Facebook\n\n\n LinkedIn\n\n\n WhatsApp\n\n\n Messenger\n\n\n\n\n\nHomework. Whether you\u2019re a fifth-grader or a freshman in college, the mere thought of homework can be overwhelming. And actually doing homework can be quite difficult. But homework doesn\u2019t have to be something a student dreads.\nAs a former high school English teacher and researcher who specializes in what it takes to make it through college \u2013 and a co-author of a forthcoming revised edition of a book about academic success \u2013 I\u2019ve studied homework since 2010. Here are six ways I believe homework can be made more manageable and valuable, whether you\u2019re in elementary school, high school or graduate school. \n1. Set priorities\nEstablish a list of priorities based on the class syllabus or assignment list. This can be helpful for tackling difficult tasks, creating motivation and activating your sense of control and independence when it comes to learning. The priority list helps maintain goals and gives you a sense satisfaction to cross things off the list as they are completed.\n2. Tackle difficult tasks first\nStart with your most difficult assignments first in order to make the most of your energy level and to focus at the beginning of a work session. You can attend to the easier or less time-consuming assignments at the end of a work session.\n3. Break tasks down to smaller steps\nYou may not know how to start a major task, which could trigger procrastination or feelings of defeat. To guard against this, break major tasks into three or four smaller steps. Within one homework session, you can feel a greater sense of accomplishment by completing each small step toward the larger whole. In some cases, you might be able to spread these tasks over the course of a week.\n4. Create evidence of learning\nYou will get more out of the time you spend reading, reviewing notes or otherwise \u201cstudying\u201d if you create something in the process. For example, creating flash cards, a graphic organizer, chart, or notes with bullet points can help you become an active learner rather than a passive one. Organize the tools you create with the homework assignment by date and topic so that you can review those items to prepare for quizzes, tests or projects.\n5. Build a network of support\nIf certain homework problems could not be solved and you\u2019re stuck in a rut, figure out what\u2019s confusing you and write or record your thoughts. Jot questions down and be as specific as possible in order to seek out additional support from teachers or tutors. The more you can identify sources of confusion, the more you can proactively reach out to your support network \u2013 teachers, tutors and others \u2013 in order to get additional help.\n6. Revisit goals and set new ones\nAt the start of each homework session, establish goals for completion of your tasks or assignments. Revisit the goals at the end of the session and acknowledge a sense of completion. This goal-setting process builds confidence over time and helps you realize their potential even when faced with difficulties. A productive homework routine will help you realize that learning is an ongoing journey. The journey may be difficult but getting organized will make it as stress-free as possible.\n[ Like what you\u2019ve read? Want more? Sign up for The Conversation\u2019s daily newsletter. ]\n\n\n\n\n\nHomework\n\n\nSchool\n\n\nUS higher education\n\n\nStudying\n\n\nGood grades\n\n\nK-12 education\n\n\nstudy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvents\n\n\n\n\nUniversity of Cape Town Summer School\n          \u2014\n          Cape Town, Western Cape\n \n\n\n\nMore events\n\n\n\n\nWant to write?\n\n    Write an article and join a growing community of more than 118,400 academics and researchers from 3,810 institutions.\n  \n\nRegister now\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity standards\n\n\nRepublishing guidelines\n\n\nAnalytics\n\n\nJob Board\n\n\nEvents\n\n\nOur feeds\n\n\n\n\n\n\n\n\nWho we are\n\n\nOur charter\n\n\nOur team\n\n\nPartners and funders\n\n\nResource for media\n\n\nContact us\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n \n\n\u200b\n\n\n\n\n\n\n\n\n\nPrivacy policy\nTerms and conditions\nCorrections\n\n\nCopyright \u00a9 2010\u20132020, The Conversation Africa, Inc.\n\n\n\n\n\n\n\n\n\n\n\n"
  },
  {
    "text": "Skip to contentWhy Zapier?How Zapier worksProduct tourCustomer storiesSecurityExplorePopular ways to use ZapierApps that work with ZapierExplore Zapier by job roleResourcesBlogRead the Zapier blog for tips on productivity, automation, and growing your businessExpertsHire a Zapier Expert to help you improve processes and automate workflows.Help centerGet help with Zapier from our tutorials, FAQs, and troubleshooting articles.CommunityAsk questions, share your knowledge, and get inspired by other Zapier users.Teams & CompaniesZapier for TeamsShare and collaborate on work with your team in Zapier.Zapier for CompaniesManage multiple teams with advanced administrative controls in Zapier.PricingSearch apps\u2026Log inSign upHomeApp PicksAll ArticlesBest AppsApp of the dayApp comparisonsAutomation with ZapierAll ArticlesAutomation inspirationZapier tutorialsCustomer storiesProductivityAll ArticlesProductivity tipsApp tipsApp tutorialsGrow your businessAll ArticlesSmall business tipsRemote workAll ArticlesRemote work tipsHow we work at ZapierLearning CenterZapier UpdatesHomeProductivityApp tipsScreenshot Tools, Tips, and Shortcuts: How to Capture Anything on Your ScreenApp tips12 min readScreenshot Tools, Tips, and Shortcuts: How to Capture Anything on Your ScreenThe Best Screenshot Apps and ShortcutsBy Matthew Guay \u00b7 August 8, 2018Screenshots are the simplest way to show off your new program, point out a bug, and save that picture on Facebook to your camera roll. They're the easiest way to save anything on your screen. And they're so integral to the way we work, every operating system comes equipped with a screenshot tool.But screenshots aren't always simple. If you aren't careful, screenshots can accidentally expose private information or obscure the part of a website you need to share. Built-in screen capture tools often hide behind cryptic keyboard shortcuts. And when a picture alone won't cut it, you'll need to make a video or GIF to show what's happening on your screen.Here's the guide you need to take the best screenshots everywhere:Why Take Screenshots?How to Take High-Quality ScreenshotsKeyboard Shortcuts to Take Screenshots: Windows, OS X, Ubuntu, Chrome OS, iOS, Android, The Web, and MoreApps to Take ScreenshotsIntroducing: Zappy by Zapier, a screenshot tool for macOS that helps your team share what you see in a snap. With easy-to-use annotation tools, Zappy can help you collaborate with your teammates fast. Quickly capture and share screenshots, GIFs, and recordings for free. Learn more about Zappy.Why Take Screenshots?Why should you care about taking high-quality screenshots? Because now, more than ever, we speak through pictures.Photography used to be a time-consuming, expensive endeavor. You'd try hard to make each picture count. No one ever took photos of their parking spot to keep from losing their car, or of a price tag in a store just to comparison shop.Smartphones changed that. Now everyone carries a camera, and pictures are for more than special occasions. Sure, we take pictures of sunsets and babies, but also of receipts, our refrigerators, street signs, and ourselves (lots of pictures of ourselves).Screenshots are the perfect way to save a picture of anything on your screen.We're visual communicators. And like your writing, your visual communication needs to be clear, concise, and to-the-point.Screenshot tools let you do that with your digital life. You might photograph something to remember or share it\u2014and you'll screenshot for the same reason. Screenshots are the simplest way to share your screen with anyone, anywhere. Whether it's a cute Facebook photo, a tricky bug, or a quickly-deleted Tweet from a politician, everyone has reasons to take screenshots.But you still need to take quality screenshots\u2014especially if you're using them at work, or for your customers. Here are some quick tips on grabbing superior screenshots. Then, we'll dive into the nuts and bolts.How to Take High-Quality ScreenshotsScreenshots are more than just pictures of software\u2014they're pictures of your workspace, with all the info you might see right now. That's why you shouldn't just snap a random screenshot.Think carefully about what's on your screen and why you're shooting it, to make sure your screenshots are perfect for their intended purpose. Here are a few pointers:Consider what the screenshot is for. Making a software tutorial? You'll want to show the entire app, and perhaps add an arrow to point out features and guide your readers. Bug reports might need to show the broken part of the app. And just-for-fun screenshots should be double-checked to make sure they only have the info you want to share.Never share private info. Our devices brim with private info, from phone numbers and email addresses to more sensitive data including ID and credit card numbers. They're usually secure on your device, but if you take a screenshot and share it, anyone can see whatever was on your device when you took the screenshot. Be sure the app you're screen capturing doesn't show private data\u2014and if it does, either crop or blur that part out.Be careful with auto-upload. Some third-party screenshot tools like Droplr can automatically upload screenshots. That's handy to share a Google Analytics graph with team members quickly, but be careful about sharing sensitive items. When it comes to your privacy, the convenience might not be worth the risk.Don't show too much. Trying to point out a bug in an app? Don't share a full-screen screenshot. Instead, crop the screenshot to show just the app\u2014then perhaps add an arrow to point out the problem.Don't show too little, either. A screenshot of only the bug might not give enough context, though. Typically, it's best to share a screenshot of the full app or at least the main parts of the app.Say I'm writing a blog post about how to edit documents in Google Docs. I'll take a screenshot of my full browser, with an article I'm editing open in Google Docs. Then, I open the screenshot in Apple Preview on my Mac (or perhaps in Microsoft Paint on a PC), delete the email address from the top corner if I hadn't already removed it via Inspect Element, and perhaps add an arrow to point out the New Changes button to show readers how to see previous versions of their work. I'll finally crop the image to show only the essential parts before adding it to our blog post.There's a reason for everyone to take screenshots today\u2014and tools to capture them on almost every device. Here are steps for taking screenshots on most modern computers, smartphones, and more.How to Take Screenshots on WindowsWindows PCs make it so easy to capture screenshots, there's a dedicated key on your keyboard for it: PrtScn (or Print Screen or PrtSc, depending on your keyboard). Tap that key, and Windows will copy a screenshot of your entire screen to your clipboard, which you can then paste into a document or blank Paint canvas to save.For more specific screenshots, Windows has built-in keyboard shortcuts for screenshots:Copy full screen screenshot to clipboard: PrtScnSave full screen screenshot: Windows Key + PrtScn (or Windows Key + Volume Down on a tablet)Copy screenshot of single window: Alt + PrtScnSave screenshot of single window: Windows Key + Alt + PrtScnHave a Microsoft Surface tablet or laptop? Instead of the PrtScn key, here are the keyboard shortcuts to use:Copy full screen screenshot to clipboard: Fn + SpaceCopy screenshot of single window: Fn + Alt + SpaceSave full screen screenshot: Fn + Windows Key + Space\u2192 Find more Windows screenshot tools and shortcuts, including how to capture video and timed screenshots, in our Windows Screenshot Guide.How to Take Screenshots on MacMacs don't come with a screenshot button, but you can still capture anything on your screen with the default Mac screenshot keyboard shortcuts:Save fullscreen screenshot: Command + Shift + 3Save screenshot of single window: Command + Shift + 4, press the Space key, then click on the window you want to captureSave screenshot of selection: Command + Shift + 4, then select the area you want to capture with your mouse cursor.\u2192 Find more macOS screenshot tools and shortcuts, including how to screenshot the Touch Bar, capture video, and include the mouse cursor in your screenshots in our macOS Screenshot Guide.How to Take Screenshots on UbuntuTaking screenshots in Ubuntu\u2014one of the most popular Linux desktop distributions\u2014works almost the same as on a Windows PC. You'll likely use a standard Windows keyboard with Ubuntu, so the PrtScn key is still the easiest way to take a screenshot. The only difference is, on Ubuntu, PrtScn will capture a screenshot, then show a dialog where you can choose to copy the screenshot to the clipboard or save it to your computer.Here are the default Ubuntu screenshot keyboard shortcuts:Full screen screenshot: PrtScnScreenshot of current window: Alt + PrtScnScreenshot of selection: Shift + PrtScnThe selection tool will change your mouse cursor to a crosshair, which you can use to select a rectangle of your screen to capture.Tip: If your keyboard doesn't have a PrtScn key, you can set a custom shortcut to take screenshots in Ubuntu from the Keyboard options in your System Settings.Ubuntu also includes a Screenshot app, which works much like the Snipping Tool in Windows. It can capture a specific window or just a section of the screen\u2014and can also show or hide the mouse cursor and window interface.See all standard Ubuntu keyboard shortcuts in the Ubuntu documentation.How to Take Screenshots on Chrome OSWhen you only need web apps, Chromebooks are a great\u2014and cheap\u2014alternative to traditional laptops. And they, too, let you take keyboard shortcuts, using the window switcher key like the one in the icon above or the F5 key on traditional keyboards.Here are the default Chrome OS screenshot keyboard shortcuts:Full screen screenshot: Ctrl + Window Switcher KeyScreenshot of selection: Ctrl + Shift + Window Switcher Key, then click and drag over the area you want to captureChrome OS saves the screenshot to your download folder by default. Also, it shows a notification after you've captured a screenshot\u2014click it to copy the screenshot to your clipboard.See all standard Chrome OS keyboard shortcuts in the Chromebook documentation.How to Take Screenshots on iOSOne of the reasons screenshots are so popular today is that they're easy to capture and share your phone. On an iPhone or iPad, press the home button and the power button at the same time, and iOS will save a full-screen screenshot to your Photos app. Screenshots are automatically saved to the Screenshots album, so you can see all screenshots in the same place. In newer versions of iOS, you'll see a preview of your screenshot as soon as you take it\u2014tap that to annotate and share the screenshot directly.You can also record a video of your iPhone or iPad screen. Add the Screen Recording widget from your iPhone or iPad's Control Center settings, then tap Record from that new widget in Control Center to save a video to your camera roll. If you have a Mac, you can also record a screencast from your iPhone or iPad with QuickTime. Just connect your phone to your Mac with the USB cable, select New Movie Recording in QuickTime on your Mac, then click the down arrow beside the record button and select your iPhone or iPad. Now click the red record button, use your device to showcase what you want, then save the video in QuickTime.How to Take Screenshots on AndroidFor screenshots, at least, Android and iPhone are pretty similar. On Android, press the power and volume down button at the same time for a moment to save a screenshot to your Photos app under Screenshots.That's the default on Android, and should work on any Google Pixel device and many other Android phones and tablets. But since there are many Android variations out there, your specific device may have customized shortcuts for screenshots; Samsung Galaxy devices, for example, have you press the home and power button to capture screenshots, as on an iPhone.To capture a screencast on Android, use the YouTube Gaming app\u2014much like you'd use the Xbox app on PCs. Install YouTube Gaming, click the Go Live button, tweak the video settings, then use your device as usual and it'll capture a screencast in the background and let you share it on YouTube or save it to your Photos app.How to Take Better Web ScreenshotsNeed to take a screenshot of a webpage? The default screenshot tools on your computer should be plenty in most cases. The only problem is, most web apps show your name or email address in the top right corner, along with other private info you might not like to share.You could blur the sensitive info in Photoshop, but a cleaner, more professional option is to use Inspect Element. Just right-click on a webpage, click Inspect, then click the selector tool and click on the part of the webpage you want to change. You can then replace the text on the web page, perhaps with a generic email address instead of your real address. It's a simple way to hack the web, for a good cause.Need to capture a full-page screenshot of a website? You can do that from Chrome's Developer Tools as well.Just open the Developer Tools by pressing Alt + Command + I on a Mac, or Ctrl + Shift + C on Windows. click the mobile device icon in the far left corner, then click the 3-dot button and select Capture full-size screenshot.Check out this tutorial on how to capture full-page website screenshots in Chrome for more details.Or, if you'd like to annotate a screenshot with arrows and highlights, the Evernote Web Clipper is a handy tool. Click it, then select Screenshot and drag your mouse over the part of the page you want to save. You can then add annotations, and save or share your tweaked screenshot.Tip: Learn more about how to use Inspect Element to tweak websites and learn web design in our Inspect Element guide.How to Take Screenshots on Other DevicesWant to take a screenshot on your eReader, gaming device, watch, or car? Here are some tips on how grabbing the display from almost any smart device you can imagine:Kindle: Tap the upper left and lower right corners of the screen at the same time, and Kindle will save an image of the screen. Connect the Kindle to your computer via USB to copy the image from the Kindle.Nook: Press Nook button and volume down button at the same time.Kobo: Press volume down and power buttons at the same time.Microsoft Surface: Press Fn + Space to copy a screenshot to your clipboard.Apple Watch: Enable screenshots from your Apple Watch settings on your iPhone, then to take a screenshot, press and hold the side button and Digital Crown at the same time, and Apple Watch will save a screenshot to your iPhone's Photos app.Samsung Galaxy Gear: Press the home button and swipe right on screen at the same time. Screenshots will be saved to the watch's Gallery app.Android Wear: Open the Android Wear app on your phone, tap the 3 dot menu button, and select Take wearable screenshot. Either tap the notification to see and share the screenshot, or find them in your standard pictures app.Pebble: Enable Developer Connection in the Pebble iOS or Android app, enter the IP address in the Pebble Command Line Tools to connect to your watch, then enter pebble screenshot to capture a screenshot.Raspberry Pi: Install the Scrot app via Terminal, then to take a screenshot just type scrot in Terminal and it'll save an image to your /home/pi folder.TI-83/89 Calculators: Install the TI-Navigator app, connect the calculator to your computer, then use the Screen Capture tool to save a screenshot.Google Glass: Tap touchpad, then say Make Vignette to take a photo of what you currently see overlaid with a screenshot of the Google Glass UI.Nintendo Switch: Press the Capture button on your left Joy-Con to save a screenshot. To view screenshots, open the Album app from your Home menu.Xbox One: Either say \"Xbox, take a screenshot\", or double-tap the Xbox button then press the Y button. Screenshots are saved to to the Game DVR app.Playstation 4: Press the Share button for a second, and a screenshot will be saved to the Capture Gallery app. Or, press Share button, then select Share to save a screenshot and share it directly.Apple TV: Connect Apple TV to Mac with a USB-C cable, open QuickTime on your Mac, then take a screenshot or record a screencast with QuickTime's Capture Video tool.PlayStation Vita: Press the PS and Start buttons at the same time, and the screenshot will be saved to the Photos app.Nintendo 3DS: Open the game you want to screenshot, then open the Miiverse community for the game you wish to screenshot, and you can share the current image from the game there.Tesla Vehicles: Press both bottom steering wheel buttons for a moment to save a screenshot. Unfortunately, only Tesla service centers can access the screenshots, though you can send them to Tesla by saying Report to report an issue.For everything else\u2014smart fridges, thermostats, TVs and more\u2014you'll likely need to use the old take a photo of the screen trick.12 of the Best Screenshot AppsWant more from your screenshots\u2014perhaps a quick way to share screenshots instantly or add annotations? Here are some of the best tools to take great screenshots on your computer:AppIcon:Best for:PriceSupports:LightscreenFor quickly sharing screenshots, Lightscreen is a great option. Press its shortcut to snap a customizable area, and Lightscreen will instantly upload your shot to Imgur for quick sharing. Just make sure you don't snap anything private.FreeWindows, LinuxSkitchSkitch makes it simple to grab a timed screenshot on your Mac, add quick annotations to the shot on your Mac or iOS device, and share the file just by dragging-and-dropping it. And, with its web sidekick in the Evernote Web Clipper, you can use the same tools to annotate webpages, too.FreeMac, iOS, Web (via Evernote Web Clipper)CloudAppDesigned for quick file sharing from your system tray, CloudApp also includes screenshot tools. Press Shift + Command + 5\u2014or a customized shortcut of your choice\u2014to snap a screenshot, record a video, or make a GIF of anything on your screen and share it instantly with a private link.Free for sharing 25 screenshots and 15 second screen recordings per month; from $10/mo. Pro plan for unlimited screen recordings and custom brandingWeb, iOS, Android, Mac, WindowsDroplrNeed to share more details? Droplr's Draw option can help. Press Alt + Shift + 3, select the area of your screen you want to capture, then mark it up in Droplr's simple editor. Droplr will autoamtically upload the screenshot and copy a link to your clipboard so you can directly share it.Free to share screenshots with watermarks; from $3/mo. Pro plan for unlimited shares with custom branding.Windows, Mac, Chrome, iOS, AndroidJingSnap screenshots or screencasts of up to 5 minutes with Jing, then annotate them with arrows, text, or captions and share them immediately. It's a quick way to point out problems or create tutorials.FreeWindows, MacSnagitThe original professional screenshot tool, Snagit lets you capture anything on your screen easily. Make profiles of the areas you want to snap, capture full-length scrolling screenshots, make detailed screencasts and tutorials, and more. Then annotate screenshots, manage them all in one library, and share them to Google Drive.$49.95Windows, MacPicPickIf you're taking screenshots for development work, PicPick includes a screen ruler, color picker, protractor and more to measure anything on your screen. It can also take any screenshot you need\u2014including scrolling shots\u2014and save them to popular cloud storage services.$24.99WindowsTailorYou can't snap full-length webpages and chat conversations on your iPhone by default, but you could snap pictures of each section. Then, open them in Tailor, and it'll stitch them together into a seamless full-length screenshot in seconds.Free; $2.99 without adsiOSBlipshotBack on your computer, Blipshot is a simple way to snap a full page screenshot of any website. Tap its button, and Blipshot opens a preview image of your screenshot over the page, which you can then drag-and-drop to any other app to quickly share the screenshot.FreeChrome (Windows, Mac, Linux)PinpointA new version of the Bugshot tool, Pinpoint imports your iOS screenshots and lets you mark them up with arrows, boxes, and text to show exactly what you're talking about\u2014with a blur tool to get rid of sensitive info, too.Free; from $0.99 for markup toolsiOSNapkinMaking a tutorial with your screenshots? Napkin lets you pull screenshots together on a virtual sheet of paper, blur sensitive info, add callouts, and export images in a variety of formats.$39.99MacLicecapWant to make a quick GIF of your screen? Licecap is a simple, free way to whip one up. Just run Licecap, select the area to record, pause or stop recording, and share the finished GIF.FreeWindows, MacJumpshareWant a quicker way to share screenshots? Use your computer's standard screenshot tools and keyboard shortcuts, and Jumpshare will automatically upload your screenshots and copy a share link to your clipboard. It can also record a video or GIF of your screen for a quick way to share anything you want.Free for 2GB storage and 30 second screen recordings; from $9.99/month Plus plan for unlimited screen recording and 1TB storageWindows, Mac, iOS, WebHow to Edit ScreenshotsThere are a few tools in common photo editing apps you should keep handy when editing screenshots:Crop: Screenshots can be rather large\u2014especially if you have a device with a retina display, or a 29\" 4K monitor. Crop images to show just what needs shown, and perhaps resize the image to save space.Blur or Delete: Does your screenshot contain sensitive info that you couldn't remove with Inspect Element? Use the Blur tool to make that text unreadable, or just delete it entirely. If you then fill the area with the same color as the app's background, the removed text may not even be noticeable.Annotations: Need to point stuff out in your screenshot? Add an arrow, circle, or other shapes to highlight important areas. And perhaps add text to describe what your screenshot shows\u2014though make sure the text is a different color or size from the text in the app, to make it stand out.Export: Mac screenshots are saved in .png format by default, which makes them clear and readable, but also takes up more space. You might want to save them in .jpg format before adding them to your blog, or use a tool like ImgOptim to compress them.Put Your Screenshots to WorkNow that you can capture professional-grade screenshots, it's time to use them for more than just saving funny images from Facebook. Here are some ideas for putting your screenshots to work, inspired by how we use them at Zapier.Want to show your work-in-progress to a team member? No need to export a full copy; just snap a screenshot, then share it in your team chat app.Keep up with your screenshots in a notes app to reference important data, or to see how an app or site changes over time.Write tutorial blog posts in Markdown, and use your screenshots to showcase each part of the app or workflow.Turn those blog posts into books, using LeanPub and the other tools Zapier uses to publish books.Write effective documentation for your products, using screenshots to show steps and point out specific parts of your tools.Need help using an app? Before you email a support team, take a screenshot and add annotations to point out exactly where you're having trouble. Chances are, you'll get much more effective help\u2014and you won't have to email back and forth to explain your problems.Originally published March 17, 2017; updated September 4, 2017 and August 8, 2018 with updated steps to take screenshots on every device, along with new app pricing and features.Get productivity tips delivered straight to your inboxSubscribeWe\u2019ll email you 1/wk, and never share your information.Matthew GuayMatthew Guay is an editor and writer in Bangkok. When he's not writing, he's likely reading a new book or exploring random streets in a new city. Follow Matthew at @maguay.Related articlesApp tipsHow to merge multiple Gmail, Google Calendar, or Google Contacts accountsHow to merge multiple Gmail, Google...App tipsWhy we write \"Best Mac\" articlesWhy we write \"Best Mac\"...App tipsEase search ad friction with Google lead form extensionsEase search ad friction with Google lead...App tipsHow to force a public Wi-Fi network login page to openHow to force a public Wi-Fi network login...App tipsFind any email address for free with these tips and toolsFind any email address for free with these...Improve your productivity automatically. Use Zapier to get your apps working together.Sign upSee how it worksPricingHelpDeveloper PlatformPressJobsZapier for CompaniesFollow usmakes you happier:)\u00a9 2020 Zapier Inc.LegalPrivacyBrand"
  },
  {
    "text": "\nAll Courses Log inResources Project ManagementAgile and ScrumBig Data and AnalyticsDigital MarketingIT Security ManagementIT Service and ArchitectureProject ManagementSalesforce TrainingVirtualization and Cloud ComputingCareer Fast-trackEnterpriseDigital TransformationOther SegmentsArticlesEbooksVideo TutorialsMoreFree Practice TestsTrending nowWhat Is Project Scope Management and Why It's Important?ArticleTop PMP Exam Questions and Answers for 2020ArticleAn Introduction to Project Management: A Beginner\u2019s GuideEbookTop 36 Project Manager Interview Questions and AnswersArticleA Step-by-Step Guide to Business Process Mapping for Today's Project ManagersArticleWhat is Agile Project Management?Video TutorialPRINCE2 Vs. PMP: Choosing The Best CertificationArticleFinancial Risk and Its TypesArticle7 Major Leadership Theories Every Manager Should MasterArticle11 Project Selection Methods for Project ManagersArticleUnderstanding Types of Feasibility Study, and Its ImportanceBy SimplilearnLast updated on Nov 22, 202019668474 The growth and recognition of project management training have changed significantly over the past few years, and these changes are expected to continue and expand. And with the rise of project management comes the need for a feasibility study.\nWhat is Feasibility Study? \nAs the name implies, a feasibility\u00a0analysis is used to determine the viability of an idea, such as ensuring a project is legally and technically feasible as well as economically justifiable. It tells us whether a project is worth the investment\u2014in some cases, a project may not be doable. There can be many reasons for this, including requiring too many resources, which not only prevents those resources from performing other tasks but also may cost more than an organization would earn back by taking on a project that isn\u2019t profitable.\nA well-designed study should offer a historical background of the business or project, such as a description of the product or service, accounting statements, details of operations and management, marketing research and policies, financial data, legal requirements, and tax obligations. Generally, such studies precede technical development and project implementation.\nLearn the core competencies required for a Project Management professional with the PMP Certification Training Course. Enroll now!\nTypes of Feasibility Study\nA feasibility analysis evaluates the project\u2019s potential for success; therefore, perceived objectivity is an essential factor in the credibility of the study for potential investors and lending institutions. There are five types of feasibility study\u2014separate areas that a feasibility study examines, described below.\n1. Technical Feasibility\nThis assessment focuses on the technical resources available to the organization. It helps organizations determine whether the technical resources meet capacity and whether the technical team is capable of converting the ideas into working systems. Technical feasibility also involves the evaluation of the hardware, software, and other technical requirements of the proposed system. As an exaggerated example, an organization wouldn\u2019t want to try to put Star Trek\u2019s transporters in their building\u2014currently, this project is not technically feasible.\n2. Economic Feasibility\nThis assessment typically involves a cost/ benefits analysis of the project, helping organizations determine the viability, cost, and benefits associated with a project before financial resources are allocated. It also serves as an independent project assessment and enhances project credibility\u2014helping decision-makers determine the positive economic benefits to the organization that the proposed project will provide.\n3. Legal Feasibility\nThis assessment investigates whether any aspect of the proposed project conflicts with legal requirements like zoning laws, data protection acts or social media laws. Let\u2019s say an organization wants to construct a new office building in a specific location. A feasibility study might reveal the organization\u2019s ideal location isn\u2019t zoned for that type of business. That organization has just saved considerable time and effort by learning that their project was not feasible right from the beginning.\n4. Operational Feasibility\nThis assessment involves undertaking a study to analyze and determine whether\u2014and how well\u2014the organization\u2019s needs can be met by completing the project. Operational feasibility studies also examine how a project plan satisfies the requirements identified in the requirements analysis phase of system development.\n5. Scheduling Feasibility\nThis assessment is the most important for project success; after all, a project will fail if not completed on time. In scheduling feasibility, an organization estimates how much time the project will take to complete.\nWhen these areas have all been examined, the feasibility analysis helps identify any constraints the proposed project may face, including:\n\nInternal Project Constraints: Technical, Technology, Budget, Resource, etc.\nInternal Corporate Constraints: Financial, Marketing, Export, etc.\nExternal Constraints: Logistics, Environment, Laws, and Regulations, etc.\n\nProject Management Interview GuideThe Perfect Guide to Help You Ace Your InterviewDownload Now\nImportance of Feasibility Study\nThe importance of a feasibility study is based on organizational desire to \u201cget it right\u201d before committing resources, time, or budget. A feasibility study might uncover new ideas that could completely change a project\u2019s scope. It\u2019s best to make these determinations in advance, rather than to jump in and to learn that the project won\u2019t work. Conducting a feasibility study is always beneficial to the project as it gives you and other stakeholders a clear picture of the proposed project.\u00a0\nBelow are some key benefits of conducting a feasibility study:\n\nImproves project teams\u2019 focus\nIdentifies new opportunities\nProvides valuable information for a \u201cgo/no-go\u201d decision\nNarrows the business alternatives\nIdentifies a valid reason to undertake the project\nEnhances the success rate by evaluating multiple parameters\nAids decision-making on the project\nIdentifies reasons not to proceed\n\nApart from the approaches to feasibility study listed above, some projects also require other constraints to be analyzed -\n\nInternal Project Constraints: Technical, Technology, Budget, Resource, etc.\nInternal Corporate Constraints: Financial, Marketing, Export, etc.\nExternal Constraints: Logistics, Environment, Laws, and Regulations, etc.\n\n\nWe hope this helped you understand the concept of feasibility study better. To learn more about similar project management concepts, explore our library of Project Management articles or check out our PMP Certification\u00a0that covers new trends, emerging practices, tailoring considerations, and core competencies required of a Project Management professional. Happy reading!\nPMP\u00ae and PMI\u00ae have registered trademarks of the Project Management Institute, Inc.Find our PMP Certification Training Online Classroom training classes in top cities:NameDatePlace PMP Certification Training 4 Jan -19 Jan 2021, Weekdays batchYour CityView Details PMP Certification Training 9 Jan -6 Feb 2021, Weekend batchYour CityView Details PMP Certification Training 16 Jan -13 Feb 2021, Weekend batchYour CityView DetailsAbout the AuthorSimplilearnSimplilearn is one of the world\u2019s leading providers of online training for Digital Marketing, Cloud Computing, Project Management, Data Science, IT, Software Development, and many other emerging technologies.View MoreRecommended ProgramsPMP Certification Training 68790 LearnersCBAP\u00ae-Certified Business Analysis Professional 10859 LearnersLifetime Access*PRINCE2\u00ae Foundation and Practitioner 21903 LearnersLifetime Access**Lifetime access to high-quality, self-paced e-learning content.Explore Category Next ArticleBasics of Project ManagementBy Chandana1691Sep 4, 2017Recommended ResourcesAn Introduction to Project Management: A Beginner\u2019s GuideEbookPMP Study: Types of ContractsArticleWhat is Project Management?Video TutorialProject Management Interview GuideEbookThe Basic Principles of Project ManagementArticleWhat is Agile Project Management?Video TutorialprevNext\n\n\u00a9 2009 -2020- Simplilearn SolutionsFollow us!Refer and EarnCompany About us Our team Careers In the media Alumni speakContact usWork with us Become an instructorBlog as guestDiscoverSkillupResourcesTutorialsSimplilearn communityRSS feedSimplilearn Coupons and Discount OffersFor BusinessesCorporate trainingLearn On the Go!Get the Android AppGet the iOS AppTrending CoursesPMP Certification Training Course | Big Data Hadoop Certification Training Course | Data Science with Python Training Course | Machine Learning Certification Course | AWS Solutions Architect Certification Training Course | DevOps Certification Training Course | CISSP Certification Training | Certified ScrumMaster (CSM) Certification Training | ITIL 4 Foundation Certification Training Course | Java Certification CourseTrending Master ProgramsPMP Plus Certification Training Course | Big Data Engineering Training Course | Data Science Course | Data Analytics Certification Training Course | Artificial Intelligence Course | Cloud Architect Certification Training Course | DevOps Engineer Certification Training Course | Advanced Digital Marketing Course | Cyber Security Expert Course | Full Stack Developer CourseTrending ResourcesAWS Tutorial | Data Science Tutorial | Artificial Intelligence Tutorial | Machine Learning Tutorial | Deep Learning Tutorial | DevOps Tutorial | Docker Tutorial | Big Data Tutorial | Hadoop Tutorial | Cyber Security TutorialTerms of UsePrivacy PolicyRefund PolicyReschedule Policy\u00a9 2009-2020 - Simplilearn Solutions. All Rights Reserved. The certification names are the trademarks of their respective owners.smpl_2020-12-19DisclaimerPMP, PMI, PMBOK, CAPM, PgMP, PfMP, ACP, PBA, RMP, SP, and OPM3 are registered marks of the Project Management Institute, Inc.\n\n\n\n\n\n\n"
  },
  {
    "text": "\n\n\nSkip to main content\n\n\n\n\n\n\n\n\n\n\n\n\n\nHome\nMail\nRadio\nContact Us\n\n\n\n\n\n\n\n\n\n\n\n \n\n\nHome\nAbout ParliamentAbout National Assembly\nHistory\nThe Clerk's OfficeThe Clerk\nDepartments\n\nCareers at Parliament\nProcurement\nVisiting parliament\nContact Us\nParliamentary Calendar\n\nMembersPresiding OfficersThe Speaker\nThe First Deputy Speaker\nThe Second Deputy Speaker\n\nMinistersCabinet Ministers\nProvincial Ministers\n\nWhips\nMembers of ParliamentGender Representation\nParty Representation\nMembers List\n\nConstituencies\nImmediate Past MPs\n\nCommitteesCommittee System\nCommittees\nAttendance Guidlines\nCommittee Composition\nCommittee Timetable\nCommittee ReportsMain\nBills\nSelect (Ad Hoc)\nTreaties/ Agreements\n\nSubmission Procedure\nMake Your Submission\n\nPublicationsSpeaker's Rulings\nOrder Paper\nDebates and ProceedingsDebates and Proceedings\nDebates and Proceedings (OLD)\n\nVotes and Proceedings\nBudget Speech\nYellow Book\nPresidential Speeches\nLaws of ZambiaActs\nBills\nBills - Not Presented\nLaws of Zambia\n\nConstitution Amendment Act 2016\nMinisterial Statements\nLibrary E-Resources\nGovernment Agreements\nFramework\n\n \n\n\n\n \n\n\n\nSearch form\n\nSearch \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou are hereHome\n\n\n\n\n\n\n\n\nWednesday, 30th September, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\u00a0\nNATIONAL ASSEMBLY OF ZAMBIA\n\u00a0\nFIFTH SESSION OF THE TWELFTH ASSEMBLY\n\u00a0\nORDER PAPER \u2013 WEDNESDAY, 30TH SEPTEMBER, 2020\n\u00a0\nAT 1430 HOURS\n\u00a0\n\u00a0\nQUESTION FOR ORAL ANSWER (STANDING ORDER 30)\n\u00a0\n39.\u00a0 Mr Chabi (Chipili) \u00a0 -\u00a0 \u00a0to ask the Minister of Housing and Infrastructure Development:\n\u00a0\n(a) when the construction of the following infrastructure in Chipili District will be completed:\n\u00a0\n(i) district administration block;\n\u00a0\n(ii) civic centre; and\n\u00a0\n(iii) post office; and\n\u00a0\n(b) what has caused the delay in completing the projects.\n\u00a0\nNOTICE OF MOTION\n\u00a0\nMs Kabanshi\n\u00a0\nReport of the Parliamentary Select Committee:\u00a0 That this House do adopt the Report of the Parliamentary Select Committee appointed to scrutinise the Presidential appointment of Mrs Emily Joy Sikazwe to serve as Vice-Chairperson and Major-General Vincent Mbaulu Mukanda (Rtd) and Mrs Ndiyoi Muliwana Mutiti to serve as Members of the Electoral Commission of Zambia, for the Fifth Session of the Twelfth National Assembly, laid on the Table of the House on 29th September, 2020.\n\u00a0\nORDERS OF THE DAY\n\u00a0\n1.\u00a0 The Food and Nutrition Bill\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 (N.A.B 2/2020)\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0Committee Stage\n\u00a0\n2.\u00a0 The Patents and Companies Registration Agency Bill\u00a0 \u00a0 (N.A.B 3/2020)\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Third Reading\n\u00a0\n3.\u00a0 The Landlord and Tenant (Business Premises)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 (N.A.B 4/2020)\n\u00a0 \u00a0 \u00a0 (Amendment) Bill\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0Third Reading\n\u00a0\n4.\u00a0 Supply - Motion (25th September)\u00a0 \u00a0-\u00a0 \u00a0Resumption of Debate.\n\u00a0\n\u00a0\n_________________________\n\u00a0\n\u00a0\n \n\n\n\n\n\n\n\n\n\n\n\n\nPublic Financial Management Handbook\n\n\n\n\nDebates and Proceedings\n\n\n\n\n Wednesday, 30th September, 2020  \n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nparliament.gov.zm\n\n\n\n\n\n\n\n\n\n\nHome\nAbout ParliamentAbout National Assembly\nHistory\nThe Clerk's OfficeThe Clerk\nDepartments\n\nCareers at Parliament\nProcurement\nVisiting parliament\nContact Us\nParliamentary Calendar\n\nMembersPresiding OfficersThe Speaker\nThe First Deputy Speaker\nThe Second Deputy Speaker\n\nMinistersCabinet Ministers\nProvincial Ministers\n\nWhips\nMembers of ParliamentGender Representation\nParty Representation\nMembers List\n\nConstituencies\nImmediate Past MPs\n\nCommitteesCommittee System\nCommittees\nAttendance Guidlines\nCommittee Composition\nCommittee Timetable\nCommittee ReportsMain\nBills\nSelect (Ad Hoc)\nTreaties/ Agreements\n\nSubmission Procedure\nMake Your Submission\n\nPublicationsSpeaker's Rulings\nOrder Paper\nDebates and ProceedingsDebates and Proceedings\nDebates and Proceedings (OLD)\n\nVotes and Proceedings\nBudget Speech\nYellow Book\nPresidential Speeches\nLaws of ZambiaActs\nBills\nBills - Not Presented\nLaws of Zambia\n\nConstitution Amendment Act 2016\nMinisterial Statements\nLibrary E-Resources\nGovernment Agreements\nFramework\n\n \n\n\n\n\n\n\n\n\n\n\nUse Policy\nContact Us\nMail\nRadio\n\n\n\u00a9 2020 National Assembly of Zambia.Powered by Drupal\n\n\n\n\n\n\n\n"
  },
  {
    "text": "\nSkip to main content\n\n\n\n\n\n\n\n\n\n\n\nCommons business papers\n\n\n\n\n\n\n\nUK Parliament\n\n\nBusiness\n\n\nCommons business papers\n\nOrder Paper\n\n\n\n\n\nOrder Paper for Wednesday 30 September 2020\n\n\nRead the agenda for business in the House of Commons chamber, Westminster Hall and Commons Committees.\nFind out more about the Order Paper\n\n\n\n\n\n\n\n\n\n\n\nContents\nPart 1: Business TodayPart 2: Future Business\n\n\n\n\n\n\nPart 1: Business TodaySummary Agenda: Chamber\n\n\n\n\n\n\n\n\n11.30am\n\n\nPrayers\n\n\n\n\n\nDeferred divisions will take place in Members\u2019 Library between 11.30am and 3.30pm\n\n\n\n\nAfterwards\n\n\nOral Questions: Northern Ireland \u2020\n\n\n\n\n12 noon\n\n\nOral Questions: Prime Minister \u2020\n\n\n\n\nAt 12.30pm\n\n\nUrgent Questions, including on:\n\n\n\n\n\nGovernment support for professional and amateur sport (Secretary of State for Digital, Culture, Media and Sport) \u2020\n\n\n\n\n\nMinisterial Statements (if any) \u2020\n\n\n\n\nUp to 20 minutes\n\n\nTen Minute Rule Motion: Business Standards (John McDonnell)\n\n\n\n\nUntil 7.00pm\n\n\nNon-Domestic Rating (Lists) (No. 2) Bill: Second Reading\n\n\n\n\nFollowed by\n\n\nMotions without separate debate:\n\n\n\n\n\nProgramme\n\n\n\n\n\nWays and Means\n\n\n\n\nUp to 90 minutes\n\n\nCoronavirus Act 2020 (Review of Temporary Provisions) (Motion)\n\n\n\n\nNo debate\n\n\nSentencing Bill [Lords]: All Stages\n\n\n\n\nUp to 90 minutes\n\n\nStatutory Instruments (Motions)\n\n\n\n\n\nTown and Country Planning (Permitted Development and Miscellaneous Amendments) (England) (Coronavirus) Regulations 2020 (S.I., 2020, No. 632) (Motion to revoke)\nTown and Country Planning (General Permitted Development) (England) (Amendment) (No. 2) Order 2020 (S.I., 2020, No. 755) (Motion to annul)\nTown and Country Planning (General Permitted Development) (England) (Amendment) (No. 3) Order 2020 (S.I., 2020, No. 756) (Motion to annul)\n\n\n\n\nNo debate after 7.00pm\n\n\nBusiness of the House\n\n\n\n\nNo debate\n\n\nPresentation of Public Petitions\n\n\n\n\nUntil 7.30pm or for half an hour\n\n\nAdjournment Debate: Flooding preparedness in Yorkshire (Dan Jarvis)\n\n\n\n\n\u2020 Virtual participation in proceedings\nBusiness Today: Chamber\nVirtual participation in proceedings will commence after Prayers.\n11.30am Prayers\nFollowed by\nQUESTIONS\n1. Northern Ireland\n2. Prime Minister\nThe call list for Members participating is available on the House of Commons business papers pages.\nURGENT QUESTIONS AND STATEMENTS\n12.30pm\nUrgent Question: To ask the Secretary of State for Digital, Culture, Media and Sport if he will make a statement on Government support for professional and amateur sport (Tracey Crouch)\nMinisterial Statements (if any)\nThe call list for Members participating is available on the House of Commons business papers pages.\nVirtual participation in proceedings will conclude after Urgent Questions and Ministerial Statements.\nBUSINESS OF THE DAY\n1. Business Standards: Ten Minute Rule Motion\nNo debate (Standing Order No. 23)\nJohn McDonnell\nThat leave be given to bring in a Bill to establish an accreditation scheme for businesses that meet standards regarding the treatment of workers, the payment of taxes and environmental practices; and for connected purposes.\nNotes:\nThe Member moving and a Member opposing this Motion may each speak for up to 10 minutes.\n2. NON-DOMESTIC RATING (LISTS) (NO. 2) BILL: SECOND READING \nUntil 7.00pm (Standing Order No. 9(3))\nThe call list for Members participating is available on the House of Commons business papers pages.\n3. NON-DOMESTIC RATING (LISTS) (NO. 2) BILL : PROGRAMME\nNo debate (Standing Order No. 83A(7))\nSecretary Robert Jenrick\nThat the following provisions shall apply to the Non-Domestic Rating (Lists) (No. 2) Bill:\nCommittal\n(1) The Bill shall be committed to a Committee of the whole House.\nProceedings in Committee, on Consideration and up to and including Third Reading\n(2) Proceedings in Committee, any proceedings on Consideration and any proceedings in legislative grand committee shall (so far as not previously concluded) be brought to a conclusion two hours after the commencement of proceedings in Committee of the whole House.\n(3) Proceedings on Third Reading shall (so far as not previously concluded) be brought to a conclusion three hours after the commencement of proceedings in Committee of the whole House.\n(4) Standing Order No. 83B (Programming committees) shall not apply to proceedings in Committee of the whole House, to any proceedings on Consideration or to other proceedings up to and including Third Reading.\nOther proceedings\n(5) Any other proceedings on the Bill may be programmed.\n4. NON-DOMESTIC RATING (LISTS) (NO. 2) BILL: WAYS AND MEANS\nNo debate (Standing Order No. 52(1)(a))\nJesse Norman\nThat, for the purposes of any Act resulting from the Non-Domestic Rating (Lists) (No. 2) Bill, it is expedient to authorise provision for, or in connection with, changing the dates on which non-domestic rating lists must be compiled.\n5. CORONAVIRUS ACT 2020 (REVIEW OF TEMPORARY PROVISIONS)\nUp to 90 minutes (Standing Order No. 16(1))\nSecretary Matt Hancock\nThat the temporary provisions of the Coronavirus Act 2020 should not yet expire.\nAmendment (e)\nMs Harriet Harman\nMr David Davis\nDr Philippa Whitford\nStephen Farry\nYvette Cooper\nMs Karen Buck\nChris BryantDebbie AbrahamsClaire HannaTonia AntoniazziAndrew GwynneMr Virendra SharmaKenny MacAskillRosie CooperBarbara KeeleyAndy SlaughterDame Diana JohnsonStella CreasyClive EffordCatherine McKinnellDerek TwiggSteve McCabeJack DromeyMohammad YasinRuth JonesTony LloydDame Margaret HodgeDarren JonesSarah ChampionMeg HillierGraham StringerBarry GardinerRushanara AliLloyd Russell-MoyleClive LewisBell Ribeiro-AddySir Mark HendrickDawn ButlerKate OsborneMs Diane AbbottRichard BurgonIan MearnsJon TrickettIan ByrneRebecca Long BaileyBeth WinterApsana BegumZarah Sultana\nLine 1, leave out from \u201cThat\u201d to end and add \u201cthis House agrees that the temporary provisions of the Coronavirus Act 2020 should not yet expire; urges the Government to introduce primary legislation to make specific provision for Regulations putting in place lockdown restrictions, whether national or local; and considers that such legislation should specify that (a) lockdown Regulations shall lapse seven days from the date when they were laid before Parliament unless they are approved by both Houses of Parliament before that time, (b) fines or fixed penalty notices for breach of such Regulations may only be introduced if the Regulations also provide for an appeal or administrative review mechanism to allow such fines or fixed penalty notices to be challenged, (c) when introducing such Regulations the Minister may produce guidance but that any such guidance must make clear what conduct is unlawful and what conduct is merely being advised, (d) in any such guidance the Minister must ensure consistency between the law and the guidance when explaining what conduct is unlawful, (e) all new lockdown Regulations, including amendment regulations, must be accompanied by a proportionality assessment and (f) the Prime Minister must use best endeavours to seek consistency between the national Regulations put in place in the four nations, unless very different circumstances require such measures to diverge.\u201d.\nAmendment (f)\nEd Davey\nMr Alistair Carmichael\nWendy Chamberlain\nDaisy Cooper\nTim Farron\nWera Hobhouse\nChristine JardineLayla MoranSarah OlneyJamie StoneMunira WilsonBell Ribeiro-AddyMs Diane AbbottDawn ButlerIan ByrneRebecca Long BaileyCaroline LucasApsana Begum\nLine 1, leave out from \u201cThat\u201d to end and add \u201cthe temporary provisions of the Coronavirus Act 2020 relating to local authority care and support (section 15 and Schedule 12) should expire immediately; that all other temporary provisions of the Act should expire on 30 October 2020, except for those specified in an amendable motion passed by both Houses of Parliament before that date; that future lockdown restrictions must be implemented through new regulations; and that no such regulations may be made unless a draft has been laid before, and approved by a resolution of, each House of Parliament.\u201d.\nAmendment (g)\nIan Blackford\nKirsten Oswald\nDr Philippa Whitford\nPatrick Grady\nLine 1, leave out from \u201cThat\u201d to end and insert \u201cthis House agrees that the temporary provisions of the Coronavirus Act 2020 should not yet expire, and believes that the UK Government should continue to support the four nation approach to tackling the Coronavirus pandemic; calls on the Government to reaffirm the commitment made in the statement on COVID-19 from the UK Government, Northern Ireland Executive, Scottish Government and Welsh Government on 25 September 2020 that calls for suppression of the virus to the lowest possible level and keeping it there; recognises the levels of scrutiny of covid legislation adopted in the Scottish Parliament, including Scottish Ministers\u2019 responsibility under section 15 of the Coronavirus (Scotland) Act 2020 to publish two-monthly reports to Scottish Parliament on the use of emergency powers, the Scottish Government\u2019s Statement of Reason protocol providing detail on considerations to seek an extension to Coronavirus (Scotland) Act 2020 and Coronavirus (Scotland) (No. 2) Act 2020 provisions, the recent requirement of the Scottish Parliament to consider regulations to extend the expiry date of Part 1 of both the Scottish Coronavirus Acts from 30 September to 31 March 2021, and the duty on Scottish Ministers to report on all Scottish statutory instruments made for a reason relating to coronavirus; and calls on the UK Government to consider how similar scrutiny and accountability processes can be introduced in this House.\u201d.\nAmendment (c)\nKeir Starmer\nNick Thomas-Symonds\nJonathan Ashworth\nMr Nicholas Brown\nBell Ribeiro-Addy\nDawn Butler\nKate OsborneMs Diane AbbottRichard BurgonIan MearnsJon TrickettIan ByrneRebecca Long BaileyBeth WinterApsana BegumZarah Sultana\nLine 1, leave out from \u201cshould\u201d to end and add \u201cbe renewed for six months; regrets that the Government\u2019s handling of the pandemic so far has stumbled from one crisis to another; calls for a national plan in which the Coronavirus Act powers contribute in a transparent and proportionate way for all citizens towards a coherent strategy, engaging with local authorities and devolved administrations, to support children\u2019s education, to re-start the economy and to support the NHS in facing the unprecedented challenges of covid-19; calls on the Government to publish a monthly review of any disproportionate impact of the Coronavirus Act 2020 on individuals or groups to include the impact of easements in the Care Act 2014, Mental Health Act 1983 and Children and Families Act 2014; and requires the Government to provide both Houses of Parliament with the time to debate and hold votes on regulatory changes.\u201d.\nAmendment (a)\nMr Steve Baker\nRichard Fuller\nDavid Simmonds\nMr William Wragg\nSir Graham Brady\nMr David Davis\nBell Ribeiro-AddyKate OsborneDawn ButlerMs Diane AbbottRichard BurgonJon TrickettIan ByrneRebecca Long BaileyCaroline LucasBeth WinterApsana Begum\nAt end, add \u201cexcept for Schedule 21.\u201d.\nAmendment (b)\nSir Graham Brady\nJohn Cryer\nMr David Davis\nMs Harriet Harman\nSir Iain Duncan Smith\nJohn Spellar\nJohn RedwoodSir Charles WalkerBob BlackmanMr William WraggChris LoderCraig MackinlayHuw MerrimanSir Edward LeighRichard FullerSir Christopher ChopeMr David JonesKarl McCartneyHenry SmithDr Julian LewisDamian GreenDame Cheryl GillanMrs Pauline LathamBob SeelyHarriett BaldwinTom HuntEsther McVeyMr Laurence RobertsonJulian SturdyPhilip DaviesJames GraySir Geoffrey Clifton-BrownIan PaisleyMr Steve BakerMr Philip HolloboneDehenna DavisonTim LoughtonPaul BristowSir Roger GaleSir Robert NeillMr Peter BoneRichard DraxSir Robert SymsJames DalySammy WilsonGiles WatlingSir Bernard JenkinJackie Doyle-PriceGreg SmithStephen McPartlandSir John HayesMr Jonathan DjanoglyCraig TraceyMs Nusrat GhaniTom TugendhatDerek TwiggGeorge FreemanSally-Ann HartGraham StringerGavin RobinsonDawn ButlerLloyd Russell-MoyleClive LewisBell Ribeiro-AddyChristian WakefordAndrew BridgenDavid SimmondsKate OsborneMs Diane AbbottRichard BurgonIan MearnsJon TrickettIan ByrneRebecca Long BaileyCaroline LucasBeth WinterApsana BegumZarah SultanaStephen Metcalfe\nAt end, add \u201cprovided Ministers ensure as far as is reasonably practicable that in the exercise of their powers to tackle the pandemic under the Coronavirus Act 2020 and other primary legislation, including for example Part 2A of the Public Health (Control of Disease) Act 1984, Parliament has an opportunity to debate and to vote upon any secondary legislation with effect in the whole of England or the whole United Kingdom before it comes into effect.\u201d.\nAmendment (d)\nRichard Fuller\nDavid Simmonds\nAt end, add \u201cprovided Ministers publish a full economic and social impact assessment of the national lockdown that commenced 23 March 2020.\u201d.\nAmendment (h)\nDaisy Cooper\nMr Alistair Carmichael\nEd Davey\nSarah Olney\nTim Farron\nWendy Chamberlain\nWera HobhouseChristine JardineJamie StoneLayla MoranMunira WilsonDawn ButlerBell Ribeiro-AddyKate OsborneMs Diane AbbottIan ByrneRebecca Long BaileyApsana Begum\nAt end, add \u201cbut this House requests the Government to (a) place a duty on any schools, and providers of 16 to 18 education, which close because of the coronavirus outbreak, whether because of a temporary closure direction issued under Schedule 16 to the Act or otherwise, to ensure that its pupils continue to receive educational provision, and (b) to indemnify the school or provider of 16 to 18 education for all reasonable purchases of teaching resources for pupils and staff that its head considers necessary to fulfil that duty.\u201d.\nRelevant Documents:\nFirst Report of the Women and Equalities Committee, Unequal Impact? Coronavirus, disability and access to services: interim Report on temporary provisions in the Coronavirus Act (HC 386)\nSeventh Report of the Joint Committee on Human Rights, The Government\u2019s response to COVID-19: human rights implications (HC 265/HL 125)\nThe call list for Members participating is available on the House of Commons business papers pages.\n6. SENTENCING BILL [LORDS]: SECOND READING (Remaining Stages may also be taken)\nNo debate (Standing Order No. 58)\nNotes:\nNo debate is expected on this Bill. No Amendments have been tabled. Standing Order No. 58 (Consolidation Bills) applies. The Question on Second Reading must be put forthwith; a Minister may move without notice a motion that the Bill be not committed, which must be put forthwith; and the Question on Third Reading must be put forthwith. The Joint Committee on Consolidation, &c., Bills has considered the Bill (First Report, HL Paper 108/HC 666). \nBUSINESS TO BE TAKEN AT 7.00PM\nBUSINESS OF THE HOUSE\nNo debate (Standing Order No. 15)\nThe Prime Minister\nThat, at this day\u2019s sitting, proceedings on the Sentencing Bill [Lords] may be entered upon, though opposed, after the moment of interruption.\nDEFERRED DIVISIONS\nNo debate (Standing Order No. 41A)\nThe Prime Minister\nThat at this day\u2019s sitting, Standing Order No. 41A (Deferred divisions) shall not apply to the Motion in the name of Secretary Matt Hancock relating to the Coronavirus Act 2020 (Review of Temporary Provisions).\nBUSINESS OF THE DAY\n7. Statutory Instruments (Motions) \nUp to 90 minutes (Order of 24 September)\nTown and Country Planning\nKeir Starmer\nMike Amesbury\nSteve Reed\nThangam Debbonaire\nKate Hollern\nMr Nicholas Brown\nThat the Town and Country Planning (Permitted Development and Miscellaneous Amendments) (England) (Coronavirus) Regulations 2020 (S.I., 2020, No. 632), dated 23 June 2020, a copy of which was laid before this House on 24 June 2020, be revoked.\nTown and Country Planning\nKeir Starmer\nMike Amesbury\nSteve Reed\nThangam Debbonaire\nKate Hollern\nMr Nicholas Brown\nThat an humble Address be presented to Her Majesty, praying that the Town and Country Planning (General Permitted Development) (England) (Amendment) (No. 2) Order 2020 (S.I., 2020, No. 755), dated 20 July 2020, a copy of which was laid before this House on 21 July 2020, be annulled.\nTown and Country Planning\nKeir Starmer\nMike Amesbury\nSteve Reed\nThangam Debbonaire\nKate Hollern\nMr Nicholas Brown\nThat an humble Address be presented to Her Majesty, praying that the Town and Country Planning (General Permitted Development) (England) (Amendment) (No. 3) Order 2020 (S.I., 2020, No. 756), dated 20 July 2020, a copy of which was laid before this House on 21 July 2020, be annulled.\nThe call list for Members participating is available on the House of Commons business papers pages.\n8. BUSINESS OF THE HOUSE\nNo debate after 7.00pm (Standing Order No. 9(6))\nMr Jacob Rees-Mogg\nThat, in respect of the Social Security (Up-rating of Benefits) Bill, notices of Amendments, new Clauses and new Schedules to be moved in Committee may be accepted by the Clerks at the Table before the Bill has been read a second time.\nPRESENTATION OF PUBLIC PETITIONS\nNo debate or decision (Standing Order No. 153)\nNestl\u00e9\u2019s relationship with Fairtrade: Holly Lynch\nNestl\u00e9\u2019s relationship with Fairtrade: Patrick Grady\nNestl\u00e9\u2019s relationship with Fairtrade: Rachael Maskell\nNestl\u00e9\u2019s relationship with Fairtrade: Jason McCartney\nRestructuring of Warwickshire County Council: Matt Western\nADJOURNMENT DEBATE\nUntil 7.30pm or for half an hour (whichever is later) (Standing Order No. 9(7))\nFlooding preparedness in Yorkshire: Dan Jarvis [R]\nDeferred Divisions\nDEFERRED DIVISIONS TO BE HELD TODAY\nDeferred Divisions will take place in the Members\u2019 Library between 11.30am and 3.30pm\nImmigration\nSecretary Priti Patel\nThat the draft Immigration (Health Charge) (Amendment) Order 2020, which was laid before this House on 21 July, be approved.\nNotes:\nThe division on this Question was deferred from Wednesday 23 September (Standing Order No. 41A).\nEmployment \nSteve Barclay \nThat the draft Restriction of Public Sector Exit Payments Regulations 2020, which were laid before this House on 21 July, be approved. \nNotes:\nThe division on this Question was deferred from Tuesday 29 September (Standing Order No. 41A).\nWritten Statements\nSTATEMENTS TO BE MADE TODAY\nChancellor of the Duchy of Lancaster and Minister for the Cabinet Office\n1.Appointments to the Boundary Commission for Wales\nSecretary of State for Foreign, Commonwealth and Development Affairs\n2.The Sanctions and Anti-Money Laundering Act 2018 \u2013 Failure to Lay a Section 46 Report in respect of the Sanctions (EU Exit) (Miscellaneous Amendments) Regulations 2019 (S.I. 2019/843)\nSecretary of State for Business, Energy and Industrial Strategy\n3.The Health Protection (Coronavirus, Restrictions) (Obligations of Undertakings) (Amendment) (England) Regulations 2020 \n4.Update on Post Office Horizon IT Inquiry\nSecretary of State for the Home Department\n5.Windrush Lessons Learned Review Response\nNotes:\nTexts of Written Statements are available from the Vote Office and on the internet at https://questions-statements.parliament.uk/ .\nCommittees Meeting Today\nBroadcasts of proceedings can be found at https://www.parliamentlive.tv/Commons\nSome committee members and witnesses might now physically attend meetings, however, there is no public access at present.\nSelect Committees\nNorthern Ireland Affairs Committee\nVirtual meeting9.30am (private)\nCommittee on the Future Relationship with the European Union\nSubject: Progress of the negotiations on the UK\u2019s Future Relationship with the EU\nWitnesses: 9.30am: Paul Everitt, Chief Executive, ADS Group Ltd; Neil Hollis, Regulatory Affairs Manager, BASF; Dr Richard Torbett, Chief Executive, Association of the British Pharmaceutical Industry\nVirtual meeting9.00am (private), 9.30am (public)\nHome Affairs Committee\nSubject: Channel crossings, migration and asylum-seeking routes through the EU\nWitnesses: 10.30am: Vincent Cochetel, Special Envoy for the Central Mediterranean Situation, and Rossella Pagliuchi-Lor, Representative to the UK, United Nations High Commissioner for Refugees\nRoom 610.00am (private), 10.30am (public)\nWork and Pensions Committee\nSubject: DWP\u2019s response to the coronavirus outbreak\nWitnesses: 10.15am: Rt Hon Dr Th\u00e9r\u00e8se Coffey MP, Secretary of State, and John Paul Marks, Director General, Work and Health Services, Department for Work and Pensions\nThe Boothroyd Room, Portcullis House9.00am (private), 10.15am (public)\nInternational Trade Committee\nVirtual meeting2.00pm (private)\nTreasury Committee\nSubject: Decarbonisation and Green Finance\nWitnesses: 2.30pm: Sheldon Mills, Interim Executive Director of Strategy and Competition, Financial Conduct Authority; Sarah Breeden, Executive Director for UK Deposit Takers Supervision, Prudential Regulation Authority; Anthony Raymond, General Counsel and Director of Legal Services, Policy and Advisory Directorate, The Pensions Regulator\nVirtual meeting2.00pm (private), 2.30pm (public)\nScience and Technology Committee\nSubject: UK telecommunications infrastructure and the UK\u2019s domestic capability\nWitnesses: 2.30pm: Ciaran Martin, Professor, University of Oxford; Dr Mike Short, Chief Scientific Adviser, Department for International Trade\n3.15pm: Marcus Weldon, President, Bell Labs; Kip Meek, Director, Communications Chambers and the Wireless Infrastructure Group\n4.00pm: Diane Rinaldo, Executive Director, Open RAN Policy Coalition\nThe Thatcher Room, Portcullis House2.05pm (private), 2.30pm (public)\nWork and Pensions Committee\nRoom 62.15pm (private)\nProcedure Committee\nVirtual meeting2.30pm (private)\nWomen and Equalities Committee\nSubject: One off session: The impact of coronavirus on children\u2019s education\nWitnesses: 2.30pm: Dr Angela Donkin, Chief Social Scientist, The National Foundation for Educational Research; Anne Longfield OBE, Children\u2019s Commissioner, Office of the Children\u2019s Commissioner for England; Ruth Davies, President, National Association of Head Teachers; Dr Halima Begum, Director, Runnymede Trust\nRoom 52.30pm (public)\nCommittee of Selection\nRoom 134.30pm (private)\nDelegated Legislation Committees\nFourth Delegated Legislation Committee\nTo consider the Insolvency (Moratorium) (Special Administration for Energy Licensees) Regulations 2020 (SI, 2020, No. 943)\nRoom 10 9.25am (public)\nFifth Delegated Legislation Committee\nTo consider the draft Apprenticeships (Alternative English Completion Conditions and Miscellaneous Provisions) (Amendment) (Coronavirus) Regulations 2020\nRoom 10 2.30pm (public)\nOther\nBritish Library (Power to Borrow) Bill\nSubject: To Consider the Bill\nRoom 149.25am (public)\nSpeaker\u2019s Committee on the Electoral Commission\nVirtual meeting3.00pm (private)\nCommittee Reports Published Today\nEUROPEAN SCRUTINY\n22nd Report: Documents Considered by the Committee 24 September 2020HC 229-xviiiTime of publication: 11.00am\nAnnouncements\nFORTHCOMING END OF DAY ADJOURNMENT DEBATES\nTuesday 6 October to Monday 12 October \nThe deadline for applications for end of day Adjournment debates for Tuesday 6 October to Monday 12 October is Wednesday 30 September.\nApplications should be made in writing to the Table Office by 7.00pm or rise of the House, whichever is the earlier, on Wednesday 30 September. The ballot will take place on Thursday 1 October.\nTuesday 13 October to Monday 19 October \nThe deadline for applications for end of day Adjournment debates for Tuesday 13 October to Monday 19 October is Wednesday 7 October.\nApplications should be made in writing to the Table Office by 7.00pm or rise of the House, whichever is the earlier, on Wednesday 7 October. The ballot will take place on Thursday 8 October.\nFORTHCOMING DEPARTMENTS ANSWERING IN WESTMINSTER HALL\nApplications for 90, 60 and 30-minute debates should be made to the Table Office by 10.00pm or rise of the House, whichever is the earlier, on the deadline dates listed below. Members must submit their application from their own email account. Application forms are available on the Table Office page on the Parliamentary intranet.\nThe ballot takes place on the day following the deadline. Members will be informed of the outcome by the Speaker\u2019s Office.\nTuesday 13 and Wednesday 14 October (deadline 5 October)\nThe following Departments will answer:\nDefence; Health and Social Care; Housing, Communities and Local Government; International Trade; Justice; Scotland; Transport; Treasury; Work and Pensions; Women and Equalities\nTuesday 20 and Wednesday 21 October (deadline 12 October)\nThe following Departments will answer:\nAttorney General; Business, Energy and Industrial Strategy; Cabinet Office; Digital, Culture, Media, Sport; Education; Environment, Food and Rural Affairs; Foreign and Commonwealth and Development Office; Home Office; Northern Ireland; Wales\nPARTICIPATION IN WESTMINSTER HALL\nOn 23 September, the House agreed a motion to resume sittings in Westminster Hall on Monday 5 October.\nApplying to speak \nApplications to speak should be made via email to the Speaker\u2019s Office (speakersoffice@parliament.uk).\nThe Deadlines are as follows:\n1.00 pm on the previous Friday for debates on a Monday; and\n1.00 pm on the previous day for debates on a Tuesday, Wednesday and Thursday.\nCall lists will be published at around 12.30 pm on a Monday for debates that day and 6.30 pm the previous day for debates on a Tuesday, Wednesday and Thursday.\nParticipation\nMembers must be physically present to participate in debate; they will not be able to participate virtually.\nMembers are reminded that if they have a proxy vote in operation they should not participate in physical proceedings and this includes Westminster Hall.\nFor 60-minute and 90-minute debates, only Members who are on the call list are permitted to attend. Members are not permitted to attend only to intervene.\nMembers will be called in the order they appear on the call list.\nFor 30-minute debates, there will not be a call list. Members wishing to contribute should follow existing conventions about contacting the Member in charge of the debate, the Speaker\u2019s Office and the Minister.\nArrangements for social distancing\nOn the horseshoe in the Grand Committee Room there are a maximum of fifteen seats.\nOf these seats, four are reserved for frontbenchers and there are eleven from which backbenchers can speak.\nThere are five additional seats in the public gallery for Members in the latter part of the call list from which they can listen to debates and move onto the horseshoe when spaces become available.\nMembers should clean their microphones before and after they use it using the cleaning materials provided.\nDEADLINE FOR CALL LISTS FOR SUBSTANTIVE PROCEEDINGS \nDeadlines for call lists for substantive proceedings\n\n\n\n\n\n\n\n\n\nDeadline\n\n\nDate of Proceeding\n\n\nProceeding\n\n\n\n\n1.00 pm Wednesday 30 September\n\n\nThursday 1 October\n\n\nSocial Security (Up-rating of Benefits) Bill: Second Reading\n\n\n\n\n1.00 pm Wednesday 30 September\n\n\nThursday 1 October\n\n\nSocial Security (Up-rating of Benefits) Bill: Committee\n\n\n\n\n1.00 pm Wednesday 30 September\n\n\nThursday 1 October\n\n\nSocial Security (Up-rating of Benefits) Bill: Third Reading\n\n\n\n\n1.00 pm Friday 2 October\n\n\nMonday 5 October\n\n\nCovert Human Intelligence Sources (Criminal Conduct) Bill: Second Reading\n\n\n\n\n1.00 pm Monday 5 October\n\n\nTuesday 6 October\n\n\nPrisoners (Disclosure of Information About Victims) Bill: Consideration of a Lords Amendment\n\n\n\n\n1.00 pm Monday 5 October\n\n\nTuesday 6 October\n\n\nPrivate International Law (Implementation of Agreements) Bill [Lords]: Committee\n\n\n\n\n1.00 pm Monday 5 October\n\n\nTuesday 6 October\n\n\nPrivate International Law (Implementation of Agreements) Bill [Lords]: Third Reading\n\n\n\n\n1.00 pm Monday 5 October\n\n\nTuesday 6 October\n\n\nHealth Protection (Cornonavirus, Restrictions) (No. 2) (England) (Amendment) (No. 4) Regulations 2020: motion for approval\n\n\n\n\n1.00 pm Tuesday 6 October\n\n\nWednesday 7 October\n\n\nPension Schemes Bill [Lords] : Second Reading\n\n\n\n\n1.00 pm Wednesday 7 October\n\n\nThursday 8 October\n\n\nPlanning reform and house building targets: debate on a motion\n\n\n\n\n1.00 pm Wednesday 7 October\n\n\nThursday 8 October\n\n\nThe spending of the Department for Digital, Culture, Media and Sport on support measures for the DCMS sectors during and after the covid-19 pandemic: general debate\n\n\n\n\nMembers wishing to speak in substantive proceedings should apply to the Speaker\u2019s Office by emailing speakersoffice@parliament.uk from their parliamentary email address.\nFurther Information\nMembers\u2019 Guide to Chamber proceedings\nThe Members\u2019 Guide to Chamber proceedings are available on the Parliamentary website\nBusiness of the Day\nDocuments and reports relating to the business being held in the Chamber are available on the Commons Business Briefings webpage: www.parliament.uk/business/publications/research/commons-business-briefings/\nWritten Statements\nText of today\u2019s Written Statements: https://questions-statements.parliament.uk/\nSelect Committees\nSelect Committees Webpage: https://committees.parliament.uk/\nRecent Select Committee Reports: https://committees.parliament.uk/\nStanding Orders Relating to Public Business\nText of Standing Orders relating to public business: www.parliament.uk/business/publications.parliament.uk/pa/cm201919/cmstords/341/body.html\nEuropean Business\nEuropean Business Referrals and Motion documents for consideration by European Committees or on the Floor of the House are available on the European Businesswebpage: https://old.parliament.uk/business/publications/business-papers/commons/european-business11/\nDigital Engagement\nInformation about digital engagement opportunities for debates is available on the parliamentary website: www.parliament.uk/digital-engagement-programme.\nAll business papers are available via the HousePapers app on mobile devices\nPart 2: Future BusinessA.\tCALENDAR OF BUSINESS\nBusiness in either Chamber may be changed, and further business added, up to the rising of the House on the day before it is to be taken, and is therefore provisional.\nGovernment items of business in this section have nominally been set down fortoday, but are expected to be taken on the dates stated.\nB.\tREMAINING ORDERS AND NOTICES\nBusiness in this section has not yet been scheduled for a specific date. It has been nominally set down for today but is not expected to be taken today.\nA. Calendar of Business\nBusiness in either Chamber may be changed, and further business added, up to the rising of the House on the day before it is to be taken, and is therefore provisional.\nTHURSDAY 1 OCTOBER\nCHAMBER\nQUESTIONS\n9.30am Questions to the Chancellor of the Duchy of Lancaster and Minister for the Cabinet Office\n10.15am Topical Questions to the Chancellor of the Duchy of Lancaster and Minister for the Cabinet Office\nAfterwards\nCONSIDERATION OF A BUSINESS OF THE HOUSE MOTION\nSocial Security (Up-rating of Benefits) Bill: All Stages\nSocial Security (Up-rating of Benefits) Bill: Money\nJesse Norman\nThat, for the purposes of any Act resulting from the Social Security (Up-rating of Benefits) Bill, it is expedient to authorise the payment out of money provided by Parliament of any increase attributable to the Act in the sums payable under any other Act out of money so provided.\nNotes:\nQueen\u2019s Recommendation signified.\nADJOURNMENT DEBATE\nIncreasing penalties for fly-tipping: Paul Bristow\nMONDAY 5 OCTOBER\nCHAMBER\nQUESTIONS\n2.30pm Questions to the Secretary of State for Housing, Communities and Local Government\n3.15pm Topical Questions to the Secretary of State for Housing, Communities and Local Government\nAfterwards\nCovert Human Intelligence Sources (Criminal Conduct) Bill: Second Reading\nADJOURNMENT DEBATE\nUnduly Lenient Sentence Scheme: Lee Anderson\nWESTMINSTER HALL\n4.30pm \tThat this House has considered e-petition 306691 relating to the impact of Covid-19 on maternity and parental leave: Catherine McKinnell\nNotes:\nThe subject for this debate was determined by the Petitions Committee. The sitting will last for up to three hours. The sitting will be suspended and time added if divisions take place in the main Chamber (Standing Order No. 10(3)).\n6.00pm \tThat this House has considered e-petitions 241848, 250178, 300412 relating to the UK\u2019s departure from the EU: Mike Hill\nNotes:\nThe subject for this debate was determined by the Petitions Committee. The sitting will last for up to three hours. The sitting will be suspended and time added if divisions take place in the main Chamber (Standing Order No. 10(3)).\nTUESDAY 6 OCTOBER\nCHAMBER\nQUESTIONS\n11.30am \tQuestions to the Secretary of State for Health and Social Care\n12.15pm \tTopical Questions to the Secretary of State for Health and Social Care\nAfterwards\nMarriage and Civil Partnership (Minimum Age): Ten Minute Rule Motion\nMrs Pauline Latham\nThat leave be given to bring in a Bill to revoke parental or judicial consent which permits the marriage or civil partnership of a child and to criminalise child marriage or civil partnership under the age of 18; and for connected purposes.\nNotes: \nThe Member moving and a Member opposing this Motion may each speak for up to 10 minutes.\nPrisoners (Disclosure of Information About Victims) Bill: Consideration of Lords Amendments\nNotes:\nThe Lords Amendment does not engage financial privilege.\nPrivate International Law (Implementation of Agreements) Bill [Lords]: Committee and Remaining Stages\nPublic Health\nSecretary Priti Patel\nThat the Health Protection (Coronavirus, Restrictions) (No. 2) (England) (Amendment) (No. 4) Regulations 2020 (S.I., 2020, No. 986), dated 13 September 2020, a copy of which was laid before this House on 14 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nWESTMINSTER HALL\n9.30am \tThat this House has considered gang-associated girls: Florence Eshalomi\n11.00am\tThat this House has considered the right to food in legislation: Ian Byrne\nNotes:\nThe sitting will be suspended from 11.30am to 2.30pm. \n2.30pm\tThat this House has considered the contribution of theatres, live music venues and other cultural attractions to the local economy: Nickie Aiken\n4.00pm \tThat this House has considered the adoption by universities of the IHRA definition of anti-Semitism: Tulip Siddiq\n4.30pm \tThat this House has considered energy provision and alternative-fueled vehicles: Matt Western\nNotes:\nThe second part of the sitting will be suspended and time added if divisions take place in the main Chamber (Standing Order No. 10(3)). The debate at 4.30pm will last for up to an hour. \nWEDNESDAY 7 OCTOBER\nCHAMBER\nQUESTIONS\n11.30am Questions to the Secretary of State for Scotland\n12 noon \tQuestions to the Prime Minister \nAfterwards\nConveyancing Standards: Ten Minute Rule Motion\nMarco Longhi\nThat leave be given to bring in a Bill to establish minimum standards regarding searches and assessments of risk for solicitors and licenced conveyancers acting on behalf of purchasers of residential properties; and for connected purposes.\nNotes:\nThe Member moving and a Member opposing this Motion may each speak for up to 10 minutes.\nPension Schemes Bill [Lords]: Second Reading\nPENSION SCHEMES BILL [LORDS]: MONEY\nJesse Norman\nThat, for the purposes of any Act resulting from the Pension Schemes Bill [Lords], it is expedient to authorise:\n(1) the payment out of money provided by Parliament of any increase attributable to the Act in the sums payable under any other Act out of money so provided; and\n(2) the payment of sums into the Consolidated Fund.\nNotes:\nQueen\u2019s Recommendation signified.\nWESTMINSTER HALL\n9.30am \tThat this House has considered reports of China\u2019s rapid expansion of the labour programme in Tibet co-published by the Inter-Parliamentary Alliance on China: Sir Iain Duncan Smith\n11.00am\tThat this House has considered the rule of law in the UK: Neale Hanvey\nNotes:\nThe sitting will be suspended from 11.30am to 2.30pm. \n2.30pm\tThat this House has considered online harms: Holly Lynch\n4.00pm \tThat this House has considered the financial implications of covid-19 for schools: Gareth Thomas\n4.30pm \tThat this House has considered flooding in Staffordshire: Theo ClarkeT\nNotes:\nThe second part of the sitting will be suspended and time added if divisions take place in the main Chamber (Standing Order No. 10(3)). The debate at 4.30pm will last for up to an hour. \nCHAMBER\nQUESTIONS\n9.30am \tQuestions to the Secretary of State for International Trade\n10.15am \tTopical Questions to the Secretary of State for International Trade\nAfterwards\nBACKBENCH BUSINESS\nPlanning reform and house building targets in relation to the White Paper\nBob Seely\nThat this House welcomes the Government\u2019s levelling up agenda, and supports appropriate housing development and the Government\u2019s overall housing objectives; further welcomes the Government\u2019s consultation, Planning for the Future, updated on 6 August 2020, as a chance to reform housing and land use for the public good; welcomes the Government\u2019s commitment to protect and restore the natural environment and bio-diversity; and calls on the Government to delay any planned implementation of: the changes to the standard method for assessing local housing need proposed by the Government\u2019s consultation, Changes to the Current Planning System, published 6 August 2020, and Proposal 4 of the Government\u2019s consultation, Planning for the Future, on a standard method for establishing housing requirement, until this House has had the opportunity to hold a debate and meaningful vote on their introduction.\nSpending of the Department for Digital, Culture and Media and Sport on support measures for the DCMS sectors during and after the covid-19 pandemic\nJulian Knight\nKevin Brennan\nThat this House has considered the spending of the Department for Digital, Culture, Media and Sport on support measures for the DCMS sectors during and after the covid-19 pandemic.\nRelevant Documents: \ne-petition 320711, Offer more support to the arts (particularly Theatres and Music) amidst covid-19\nNotes:\nThe subjects for these debates were determined by the Backbench Business Committee.\nMONDAY 12 OCTOBER\nCHAMBER\nQUESTIONS\n2.30pm \tQuestions to the Secretary of State for Education\n3.15pm \tTopical Questions to the Secretary of State for Education\nTUESDAY 13 OCTOBER\nCHAMBER\nQUESTIONS\n11.30am \tQuestions to the Secretary of State for Foreign, Commonwealth and Development Affairs\n12.15pm \tTopical Questions to the Secretary of State for Foreign, Commonwealth and Development Affairs\nAfterwards\nSchool Breakfast: Ten Minute Rule Motion\nMrs Emma Lewell-Buck\nThat leave be given to bring in a Bill to require schools to provide breakfast club facilities; and for connected purposes.\nNotes:\nThe Member moving and a Member opposing this Motion may each speak for up to 10 minutes.\nWEDNESDAY 14 OCTOBER\nCHAMBER\nQUESTIONS\n11.30am \tQuestions to the Secretary of State for Wales\n12 noon \tQuestions to the Prime Minister \nAfterwards\nPRESENTATION OF BILLS\nBritish Museum (Transfer of Objects) \nMargaret Ferrier\nBill to amend the British Museum Act 1963 to permit the transfer of objects from the British Museum; to confer powers on the Secretary of State to require the transfer of objects in specified circumstances; and for connected purposes.\nDogs and Domestic Animals (Accommodation and Protection): Ten Minute Rule Motion\nAndrew Rosindell\nThat leave be given to bring in a Bill to establish rights to keep dogs and other animals in domestic accommodation; to make provision about the protection of the welfare of dogs and other domestic animals; and for connected purposes. \nNotes:\nThe Member moving and a Member opposing this Bill may each speak for up to 10 minutes.\nTHURSDAY 15 OCTOBER\nCHAMBER\nQUESTIONS\n9.30am \tQuestions to the Secretary of State for Environment, Food and Rural Affairs \n10.00am \tTopical Questions to the Secretary of State for Environment, Food and Rural Affairs \n10.10am \tQuestions to the Church Commissioners, the House of Commons Commission, the Parliamentary Works Sponsor Body, the Public Accounts Commission and Speaker\u2019s Committee on the Electoral Commission\nFRIDAY 16 OCtober\nCHAMBER\nBotulinum Toxin and Cosmetic Fillers (Children) Bill: Second Reading\nMember in Charge: Laura Trott\nNotes:\nBill not yet printed.\nPrisons (Substance Testing): Second Reading\nMember in Charge: Dame Cheryl Gillan\nNotes:\nBill not yet printed.\nRegisters of Births and Deaths Bill: Second Reading\nMember in Charge: Mr Andrew Mitchell\nNotes:\nBill not yet printed.\nVoter Registration Bill: Second Reading \nMember in Charge: Mr Peter Bone\nNotes:\nBill not yet printed.\nGeneral Election (Leaders\u2019 Debates) Bill: Second Reading \nMember in Charge: Mr Peter Bone\nNotes:\nBill not yet printed.\nEuropean Citizens\u2019 Rights Bill: Second Reading\nMember in Charge: Christine Jardine\nNotes:\nBill not yet printed.\nCompany Transparency (Carbon in Supply Chains) Bill: Second Reading\nMember in Charge: Karen Bradley\nNotes:\nBill not yet printed.\nPregnancy and Maternity (Redundancy Protection) Bill: Second Reading\nMember in Charge: Mrs Maria Miller\nNotes:\nBill not yet printed.\nDeath by Dangerous Driving (Sentencing) Bill: Second Reading\nMember in Charge: Mrs Theresa May\nNotes:\nBill not yet printed.\nEmployment (Reasonable Adjustments for Carers) Bill: Second Reading\nMember in Charge: Ed Davey\nPolice Stop and Search (Repeal) Bill: Second Reading\nMember in Charge: Ed Davey\nCoronavirus Inquiry Bill: Second Reading\nMember in Charge: Ed Davey\nNotes:\nBill not yet printed.\nWhite Goods (Registration) Bill: Second Reading\nMember in Charge: Yvonne Fovargue\nNotes:\nBill not yet printed.\nPublic Advocate (No. 2) Bill: Second Reading\nMember in Charge: Maria Eagle\nNotes:\nA money resolution is required for this Bill to be proceeded with in Committee.\nDigitally Altered Body Images Bill: Second Reading\nMember in Charge: Dr Luke Evans\nNotes:\nBill not yet printed.\nHospitals (Parking Charges and Business Rates) Bill: Second Reading\nMember in Charge: Mr Peter Bone\nParliamentary Constituencies (Amendment) Bill: Second Reading\nMember in Charge: Mr Peter Bone\nNotes:\nA money resolution is required for this Bill to be proceeded with in Committee.\nRemote Participation in House of Commons Proceedings (Motion) Bill: Second Reading\nMember in Charge: Dawn Butler\nNotes:\nBill not yet printed.\nIllegal Immigration (Offences) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nPedicabs (London) Bill: Second Reading\nMember in Charge: Nickie Aiken\nNotes:\nA money resolution and a ways and means resolution are required for this Bill to be proceeded with in Committee.\nMagistrates (Retirement Age) Bill: Second Reading\nMember in Charge: Edward Timpson\nMONDAY 19 OCTOBER\nCHAMBER\nQUESTIONS\n2.30pm \tQuestions to the Secretary of State for Work and Pensions\n3.15pm \tTopical Questions to the Secretary of State for Work and Pensions\nTUESDAY 20 OCTOBER\nCHAMBER\nQUESTIONS\n11.30am \tQuestions to the Chancellor of the Exchequer\n12.15pm \tTopical Questions to the Chancellor of the Exchequer\nTen Minute Rule Motion\nStella Creasy\nThat leave be given to bring in a Bill under SO No. 23 [details to be provided].\nNotes:\nThe Member moving and a Member opposing this Motion may each speak for up to 10 minutes.\nWEDNESDAY 21 OCTOBER\nCHAMBER\nQUESTIONS\n11.30am \tQuestions to the Minister for Women and Equalities\n11.53am \tTopical Questions to the Minister for Women and Equalities\n12 noon \tQuestions to the Prime Minister \nTHURSDAY 22 OCTOBER\nCHAMBER\nQUESTIONS\n9.30am \tQuestions to the Secretary of State for Transport\n10.15am \tTopical Questions to the Secretary of State for Transport\nFRIDAY 23 October\nCHAMBER\nAnimal Welfare (Sentencing) Bill: Second Reading\nMember in Charge: Chris Loder\nNotes:\nBill not yet printed.\nControl of Roadworks Bill: Second Reading\nMember in Charge: Mr Mark Francois\nNotes:\nBill not yet printed.\nMobile Homes Act 1983 (Amendment) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nCaravan Sites Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nNet Zero Carbon Emissions (Audit) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nInternational Payments (Audit) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nLocal Authorities (Borrowing and Investment) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nBenefits and Public Services (Restriction) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nPublic Services (Availability) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nWorking Time and Holiday Pay Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nLocal Roads (Investment) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nElectronic Cigarettes (Regulation) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nHong Kong Bill: Second Reading\nMember in Charge: Mr Alistair Carmichael \nNotes:\nBill not yet printed.\nVagrancy (Repeal) Bill: Second Reading\nMember in Charge: Layla Moran\nVictims of Abuse (Support) Bill: Second Reading\nMember in Charge: Munira Wilson\nNotes:\nBill not yet printed.\nDecarbonisation and Economic Strategy Bill: Second Reading\nMember in Charge: Caroline Lucas\nTree-lined Streets Bill: Second Reading\nMember in Charge: Chris Clarkson\nNotes:\nBill not yet printed.\nSexual Offences (Sports Coaches) Bill: Second Reading\nMember in Charge: Tracey Crouch\nDomestic Properties (Minimum Energy Performance) Bill: Second Reading\nMember in Charge: Sir David Amess\nNotes:\nBill not yet printed.\nFRIDAY 30 OCTOBER\nCHAMBER\nNational Minimum Wage Bill\nMember in Charge: Paula Barker\nNotes:\nBill not yet printed.\nTrade Agreements (Exclusion of National Health Services) Bill: Second Reading\nMember in Charge: Peter Grant\nNotes:\nBill not yet printed.\nPrime Minister (Accountability to the House of Commons) Bill: Second Reading\nMember in Charge: Mr Peter Bone\nNotes:\nBill not yet printed.\nPrime Minister (Temporary Replacement): Second Reading \nMember in Charge: Mr Peter Bone\nNotes:\nBill not yet printed.\nNational Health Service Expenditure Bill: Second Reading\nMember in Charge: Jamie Stone\nNotes:\nBill not yet printed.\nJune Bank Holiday (Creation) Bill: Second Reading \nMember in Charge: Mr Peter Bone\nNotes:\nBill not yet printed. \nProtest (Abortion Clinics) Bill: Second Reading\nMember in Charge: Sarah Olney\nNotes:\nBill not yet printed.\nAutomatic Electoral Registration Bill: Second Reading\nMember in Charge: Judith Cummins\nNotes:\nBill not yet printed.\nImmigration (Health and Social Care Staff) Bill: Second Reading\nMember in Charge: Christine Jardine\nNotes:\nBill  not yet printed.\nEmployment (Dismissal and Re-employment) Bill: Second Reading\nMember in Charge: Gavin Newlands\nInternet Access (Children Eligible for Free School Meals) Bill: Second Reading\nMember in Charge: Siobhain McDonagh\nNotes:\nA money resolution is required for this Bill to be proceeded with in Committee.\nAssaults on Retail Workers (Offences) Bill: Second Reading\nMember in Charge: Alex Norris\nUnpaid Work Experience (Prohibition) (No. 2) Bill: Adjourned debate on Second Reading [11 September]\nMember in Charge: Alex Cunningham\nFRIDAY 13 November\nCHAMBER\nSewage (Inland Waters) Bill: Second Reading\nMember in Charge: Philip Dunne\nNotes:\nBill not yet printed.\nNHS 111 Service (Training and Clinical Oversight) Bill: Second Reading\nMember in Charge: Kate Osamor\nNotes:\nBill not yet printed.\nBBC Licence Fee (Civil Penalty) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nPublic Service Broadcasters (Privatisation) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nStudent Loans (Debt Interest) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nLocal Authorities (Removal of Council Tax Restrictions) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nValue Added Tax Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nSublet Property (Offences) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nStudent Loans (Debt Discharge) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nStamp Duty Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nSpeed Limits (England) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nSentencing (Women) Bill: Second Reading\nMember in Charge: Daisy Cooper\nNotes:\nBill not yet printed.\nHate Crime (Misogyny) Bill: Second Reading\nMember in Charge: Wera Hobhouse\nNotes:\nBill not yet printed.\nHate Crime (Misandry and Misogyny) Bill: Second Reading\nMember in Charge: Mr Philip Hollobone\nNotes:\nBill not yet printed.\nNon-gender-specific Passports Bill: Second Reading\nMember in Charge: Christine Jardine\nNotes:\nBill not yet printed.\nInternational Development (Women\u2019s Sanitary Products) Bill: Second Reading\nMember in Charge: Wendy Chamberlain\nOverseas Development Assistance Committee Bill: Second Reading\nMember in Charge: Wendy Chamberlain\nNotes:\nBill not yet printed.\nDemonstrations (Abortion Clinics) Bill: Second Reading\nMember in Charge: Dr Rupa Huq\nProblem Drug Use Bill: Second Reading\nMember in Charge: Tommy Sheppard\nNotes:\nBill not yet printed.\nFRIDAY 27 NOVEMBER\nCHAMBER\nEducation (Guidance about Costs of School Uniforms) Bill: Remaining Stages\nMember in Charge: Mike Amesbury\nNot amended in Public Bill Committee, to be considered.\nThird Sector Organisations (Impact and Support) Bill: Second Reading\nMember in Charge: Simon Fell\nNotes:\nBill not yet printed.\nBritish Broadcasting Corporation (Oversight) Bill: Second Reading\nMember in Charge: Mr Peter Bone\nNotes:\nBill not yet printed.\nElectoral Candidates (Age) Bill: Second Reading\nMember in Charge: Mr Peter Bone\nNotes:\nBill not yet printed.\nHuman Trafficking (Child Protection) Bill: Second Reading\nMember in Charge: Mr Peter Bone\nNotes:\nBill not yet printed.\nRule of Law (Enforcement by Public Authorities): Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nPublic Sector Exit Payments (Limitation) Bill: adjourned debate on Second Reading (13 March)\nMember in Charge: Sir Christopher Chope\nGreen Belt Protection Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nBat Habitats Regulation Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nWellbeing of Future Generations (No. 2) Bill: Second Reading\nMember in Charge: Caroline Lucas\nNotes:\nBill not yet printed.\nDisabled Facilities Grants (Review) Bill: Second Reading\nMember in Charge: Liz Twist\nNotes:\nBill not yet printed.\nWelfare (Terminal Illness) Bill: Second Reading\nMember in Charge: Jessica Morden\nNotes:\nBill not yet printed.\nCash Machines Bill: Second Reading\nMember in Charge: Margaret Ferrier\nNotes:\nBill not yet printed.\nFRIDAY 15 JANUARY 2021\nCHAMBER\nDecarbonisation of Road Transport (Audit) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nAnxiety (Environmental Concerns) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nHousing Act 2004 (Amendment) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nHealthcare (Local Accountability) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nHuman Rights and Responsibilities Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nSchools Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nMobile Homes and Park Homes Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nJudicial Appointments and Retirements (Age Limits) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nDomestic Energy (Value Added Tax) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nCriminal Fraud (Private Prosecutions) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nSchool Toilets (Access During Lessons) Bill: Second Reading\nMember in Charge: Layla Moran\nRecall of MPs (Change of Party Affiliation) Bill: Second Reading\nMember in Charge: Anthony Mangnall\nNotes:\nBill not yet printed.\nBorder Control Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nForeign Nationals (Criminal Offender and Prisoner Removal) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nNational Health Service (Co-Funding and Co-Payment) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nFRIDAY 29 JANUARY 2021\nCHAMBER\nMental Health Admissions (Data) Bill: Second Reading\nMember in Charge: Dr Ben Spencer\nNotes:\nBill not yet printed.\nLocal Government (Governance) Bill: Second Reading\nMember in Charge: Mr Peter Bone\nNotes:\nBill not yet printed.\nIsham Bypass Bill: Second Reading\nMember in Charge: Mr Peter Bone\nNotes:\nBill not yet printed.\nNorth Northamptonshire (Urgent Care Facilities) Bill: Second Reading\nMember in Charge: Mr Peter Bone\nNotes:\nBill not yet printed.\nLocal Electricity Bill: Second Reading\nMember in Charge: Peter Aldous\nPlanning (Proper Maintenance of Land) Bill: Second Reading\nMember in Charge: Jonathan Gullis\nNotes:\nBill not yet printed.\nPets (Microchips) Bill: Second Reading\nMember in Charge: James Daly\nNotes:\nBill not yet printed.\nFRIDAY 5 FEBRUARY 2021\nCHAMBER\nAsylum Seekers (Permission to Work) Bill: Second Reading\nMember in Charge: Carol Monaghan\nNotes:\nBill not yet printed.\nAsylum Seekers (Accommodation Eviction Procedures) Bill: Second Reading\nMember in Charge: Chris Stephens\nNotes:\nBill not yet printed.\nUniversal Credit Sanctions (Zero Hours Contracts) Bill: Second Reading\nMember in Charge: Chris Stephens\nNotes:\nBill not yet printed.\nEvictions (Universal Credit Claimants) Bill: Second Reading\nMember in Charge: Chris Stephens\nNotes:\nBill not yet printed.\nWorkers (Definition and Rights): Second Reading\nMember in Charge: Chris Stephens\nNotes:\nBill not yet printed.\nGender-based Pricing (Prohibition) Bill: Second Reading\nMember in Charge: Christine Jardine\nNotes:\nBill not yet printed.\nChildren (Access to Treatment) Bill: Second Reading\nMember in Charge: Bambos Charalambous\nNotes:\nBill not yet printed. \nHouses in Multiple Occupation Bill: Second Reading\nMember in Charge: Ian Levy\nNotes:\nBill not yet printed.\nDesecration of War Memorials Bill: Second Reading\nMember in Charge: Jonathan Gullis\nPublic Interest Disclosure (Protection) Bill: Adjourned debate on Second Reading [25 September]\nMember in Charge: Dr Philippa Whitford\nNotes:\nA money resolution is required for this Bill to be proceeded with in Committee.\nFRIDAY 5 MARCH 2021\nCHAMBER\nHomeless People (Current Accounts) Bill: Second Reading\nMember in Charge: Mr Peter Bone\nNotes:\nBill not yet printed.\nChild Safety (Cycle Helmets) Bill: Second Reading\nMember in Charge: Mr Peter Bone\nNotes:\nBill not yet printed.\nAviation Banning Orders (Disruptive Passengers) Bill: Second Reading\nMember in Charge: Gareth Johnson\nNotes:\nBill not yet printed.\nFRIDAY 12 MARCH 2021\nCHAMBER\nMeat (Grading and Labelling) Bill: Second Reading\nMember in Charge: Bill Wiggin\nNotes:\nBill not yet printed.\nAnxiety in Schools (Environmental Concerns) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nTax Rates and Duties (Review) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nDeregulation Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nFree Trade (Education and Reporting) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nInternational Development Assistance (Definition) Bill: Second Reading\nMember in Charge: Sir Christopher Chope\nNotes:\nBill not yet printed.\nNew Homes (New Development Standards) Bill: Second Reading\nMember in Charge: Sir Geoffrey Clifton-Brown\nNotes:\nBill not yet printed.\nTibet (Reciprocal Access) Bill: Second Reading\nMember in Charge: Tim Loughton\nClimate and Ecology Bill: Second Reading\nMember in Charge: Caroline Lucas\nNotes:\nBill not yet printed.\nAbortion (Cleft Lip, Cleft Palate and Clubfoot) Bill: Second Reading\nMember in Charge: Fiona Bruce\nB. Remaining Orders and Notices\nBusiness in this section has not yet been scheduled for a specific date. It has therefore been set down formally to be taken in the Chamber today but is not expected to be taken today.\n1. Exiting the European Union (Sanctions)\nNigel Adams\nThat the Burundi (Sanctions) (EU Exit) Regulations 2019 (S.I., 2019, No. 1142), dated 18 July 2019, a copy of which was laid before this House on 19 July, in the last Parliament, be approved.\n2. Exiting the European Union (Sanctions)\nNigel Adams\nThat the Guinea (Sanctions) (EU Exit) Regulations 2019 (S.I., 2019, No. 1145), dated 18 July 2019, a copy of which was laid before this House on 19 July, in the last Parliament, be approved.\n3. Criminal Law\nSecretary Robert Buckland\nThat the draft Criminal Justice Act 2003 (Early Release on Licence) Order 2020, which was laid before this House on 16 March, be approved.\nNotes: \nThe Speaker has certified that the Instrument relates exclusively to England and Wales and is within devolved legislative competence (Standing Order No. 83P).\n4. Exiting the European Union (Sanctions)\nNigel Adams\nThat the Sanctions (EU Exit) (Miscellaneous Amendments) (No. 2) Regulations 2020 (S.I., 2020, No. 590), dated 11 June 2020, a copy of which was laid before this House on 15 June, be approved.\n5. Exiting the European Union (Sanctions)\nNigel Adams\nThat the Cyber (Sanctions) (EU Exit) Regulations 2020 (S.I., 2020, No. 597), dated 15 June 2020, a copy of which was laid before this House on 17 June, be approved.\n6. Exiting the European Union (Sanctions)\nNigel Adams\nThat the Bosnia and Herzegovina (Sanctions) (EU Exit) Regulations 2020 (S.I., 2020, No. 608), dated 18 June 2020, a copy of which was laid before this House on 22 June, be approved.\n7. Exiting the European Union (Sanctions)\nNigel Adams\nThat the Nicaragua (Sanctions) (EU Exit) Regulations 2020 (S.I., 2020, No. 610), dated 18 June 2020, a copy of which was laid before this House on 22 June, be approved.\n8. Exiting the European Union\nSecretary Alok Sharma\nThat the draft European Structural and Investment Funds Common Provisions and Common Provision Rules etc. (Amendment) (EU Exit) (Revocation) Regulations 2020, which were laid before this House on 7 July, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\n9. Exiting the European Union (Health Care and Associated Professions)\nEdward Argar\nThat the draft European Qualifications (Health and Social Care Professions) (EFTA States) (Amendment etc.) (EU Exit) Regulations 2020, which were laid before this House on 22 July, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\n10. Charities\nSecretary Oliver Dowden\nThat the Charitable Incorporated Organisations (Insolvency and Dissolution) (Amendment) (No. 2) Regulations 2020 (S.I., 2020, No. 856), dated 12 August 2020, a copy of which was laid before this House on 13 August, be approved.\nNotes:\nThe Joint Committee on Statutory Instruments has drawn the special attention of both Houses to the instrument in its 23rd report of 2019-21 (HC 75-xxiii).\nThe Speaker has certified that the Instrument relates exclusively to England and Wales and is within devolved legislative competence (Standing Order No. 83P).\n11. Constitutional Law\nSecretary Brandon Lewis\nThat the draft Adjacent Waters Boundaries (Northern Ireland) (Amendment) Order 2020, which was laid before this House on 7 September, be approved.\nNotes:\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n12. Public Health\nSecretary Matt Hancock\nThat the Health Protection (Coronavirus, Restrictions) (Blackburn with Darwen and Bradford, Leicester, and North of England) (Amendment) Regulations 2020 (S.I., 2020, No. 954), dated 7 September 2020, a copy of which was laid before this House on 7 September, be approved.\nNotes:\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n13. Exiting the European Union (Sanctions)\nNigel Adams\nThat the Sanctions (EU Exit) (Miscellaneous Amendments) (No. 4) Regulations 2020 (S.I., 2020, No. 951), dated 3 September 2020, a copy of which was laid before this House on 8 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n14. Debt Management and Relief\nJohn Glen\nThat the draft Debt Respite Scheme (Breathing Space Moratorium and Mental Health Crisis Moratorium) (England and Wales) Regulations 2020, which were laid before this House on 9 September, be approved.\nNotes: \nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n15. Immigration\nSecretary Priti Patel\nThat the draft Immigration Skills Charge (Amendment) Regulations 2020, which were laid before this House on 10 September, be approved.\nNotes: \nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n16. Public Health\nHelen Whately\nThat the Health Protection (Coronavirus, Restrictions) (Bolton) Regulations 2020 (S.I., 2020, No. 974), dated 10 September 2020, a copy of which was laid before this House on 10 September, be approved.\nNotes: \nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n17. Education\nGillian Keegan\nThat the draft Apprenticeships (Alternative English Completion Conditions and Miscellaneous Provisions) (Amendment) (Coronavirus) Regulations 2020, which were laid before this House on 10 September, be approved.\nNotes: \nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n18. Criminal Law\nSecretary Robert Buckland\nThat the Criminal Procedure and Investigations Act 1996 (Code of Practice) Order 2020, dated 9 September 2020, a copy of which was laid before this House on 10 September, be approved.\nNotes: \nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n19. Public Health\nHelen Whately\nThat the Health Protection (Coronavirus, Restrictions) (Leicester) (No. 2) (Amendment) (No. 2) Regulations 2020 (S.I., 2020, No. 987), dated 14 September 2020, a copy of which was laid before this House on 14 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n20. Public Health\nHelen Whately\nThat the Health Protection (Coronavirus, Restrictions) (Birmingham, Sandwell and Solihull) Regulations 2020 (S.I., 2020, No. 988), dated 14 September 2020, a copy of which was laid before this House on 14 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n21. Exiting the European Union (Consumer Protection)\nSecretary Alok Sharma\nThat the draft Consumer Protection (Enforcement) (Amendment etc.) (EU Exit) Regulations 2020, which were laid before this House on 14 September, be approved.\nNotes:\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n22. Fisheries Bill [Lords]: Remaining Stages\n23. Committee on Standards\nMr Jacob Rees-Mogg\nThat, in accordance with Standing Order No. 149A, Ms Melanie Carter and Professor Michael Maguire CBE be appointed as lay members of the Committee on Standards for a period of six years, with immediate effect.\nRelevant Documents:\nReport of the House of Commons Commission, Lay Members of the Committee on Standards: Nomination of Candidates, HC 437.\n24. Pensions\nGuy Opperman\nThat the Pension Protection Fund (Moratorium and Arrangements and Reconstructions for Companies in Financial Difficulty) (Amendment and Revocation) Regulations (S.I., 2020, No. 990), dated 14 September 2020, a copy of which was laid before this House on 15 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n25.  Public Health\nSecretary Matt Hancock\nThat the Health Protection (Coronavirus, Restrictions) (North East of England) Regulations 2020 (S.I., 2020, No. 1010), dated 17 September 2020, a copy of which was laid before this House on 17 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n26. Public Health\nSecretary Alok Sharma\nThat the Health Protection (Coronavirus, Restrictions) (Obligations of Hospitality Undertakings) (England) Regulations 2020 (S.I., 2020, No. 1008), dated 17 September 2020, a copy of which was laid before this House on 17 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n27. Exiting the European Union (Health Care and Associated Professions)\nEdward Argar\nThat the draft European Qualifications (Health and Social Care Professions) (EFTA States) (Amendment etc.) (EU Exit) Regulations 2020, which were laid before this House on 17 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n28. Insolvency\nKwasi Kwarteng\nThat the Insolvency (Moratorium) (Special Administration for Energy Licensees) Regulations 2020 (S.I., 2020, No. 943), dated 2 September 2020, a copy of which was laid before this House on 4 September, be approved.\nNotes:\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n29. Exiting the European Union (Electricity)\nSecretary Alok Sharma\nThat the draft Electricity (Risk-Preparedness) (Amendment etc.) (EU Exit) Regulations 2020, which were laid before this House on 17 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n30. Public Health\nSecretary Matt Hancock\nThat the Health Protection (Coronavirus, Collection of Contact Details etc and Related Requirements) Regulations 2020 (S.I., 2020, No. 1005), dated 17 September 2020, a copy of which was laid before this House on 17 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n31. Public Health\nMs Nadine Dorries \nThat the Health Protection (Coronavirus, Restrictions) (North East of England) (Amendment) Regulations 2020 (S.I., 2020, No. 1012), dated 17 September 2020, a copy of which was laid before this House on 18 September, be approved.\nNotes: \nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n32. Exiting the European Union (Immigration)\nSecretary Priti Patel \nThat the draft Citizens\u2019 Rights (Restrictions of Rights of Entry and Residence) (EU Exit) Regulations 2020, which were laid before this House on 21 September, be approved.\nNotes: \nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n33. Exiting the European Union (Immigration)\nSecretary Priti Patel \nThat the draft Citizens\u2019 Rights (Application Deadline and Temporary Protection) (EU Exit) Regulations 2020, which were laid before this House on 21 September, be approved\nNotes: \nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n34. Exiting the European Union (Immigration)\nSecretary Priti Patel \nThat the draft Citizens\u2019 Rights (Frontier Workers) (EU Exit) Regulations 2020, which were laid before this House on 21 September, be approved.\nNotes: \nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n35. Exiting the European Union (TRADE)\nSecretary Elizabeth Truss\nThat the draft Common Rules for Exports (EU Exit) Regulations 2020, which were laid before this House on 21 September, be approved.\nNotes: \nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n36. Public Health\nSecretary Grant Shapps \nThat the Health Protection (Coronavirus, Wearing of Face Coverings in a Relevant Place and on Public Transport) (England) (Amendment) (No. 2) Regulations (S.I., 2020, No. 1021), dated 22 September 2020, a copy of which was laid before this House on 22 September, be approved.\nNotes: \nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n37. Public Health\nEdward Argar\nThat the Health Protection (Coronavirus, Restrictions) (Protected Areas and Linked Childcare Households) (Amendment) Regulations (S.I., 2020, No. 1019), dated 21 September 2020, a copy of which was laid before this House on 22 September, be approved.\nNotes: \nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n38. Public Health\nSecretary Matt Hancock\nThat the Health Protection (Coronavirus, Wearing of Face Coverings in a Relevant Place and on Public Transport) (England) (Amendment) (No. 3) Regulations (S.I., 2020, No. 1026), dated 23 September 2020, a copy of which was laid before this House on 23 September, be approved.\nNotes: \nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n39. Armorial Bearings, Ensigns and Flags\nSecretary Brandon Lewis\nThat the draft Flags (Northern Ireland) (Amendment) (No. 2) Regulations 2020, which were laid before this House on 23 September, be approved\nNotes: \nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n40. Exiting the European Union (Electronic Communications)\nMr John Whittingdale\nThat the draft Communications Act (e-Commerce) (EU Exit) Regulations 2020, which were laid before this House on 24 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n41. Public Health\nSecretary Matt Hancock\nThat the Health Protection (Coronavirus, Restrictions) (No. 2) (England) (Amendment) (No. 5) Regulations 2020 (S.I., 2020, No. 1029), dated 24 September 2020, a copy of which was laid before this House on 24 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n42. Public Health\nSecretary Matt Hancock\nThat the Health Protection (Coronavirus, Wearing of Face Coverings in a Relevant Place) (England) (Amendment) (No. 3) Regulations 2020 (S.I., 2020, No. 1028), dated 23 September 2020, a copy of which was laid before this House on 24 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n43. Insolvency\nSecretary Alok Sharma\nThat the Corporate Insolvency and Governance Act 2020 (Coronavirus) (Extension of the Relevant Period) Regulations 2020 (S.I., 2020, No. 1031), dated 23 September 2020, a copy of which was laid before this House on 24 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n44. Exiting the European Union (Criminal Law)\nSecretary Robert Buckland\nThat the draft Taking Account of Convictions (EU Exit) (Amendment) Regulations 2020, which were laid before this House on 24 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n45. FORENSIC SCIENCE REGULATOR AND BIOMETRICS STRATEGY BILL: MONEY\nJesse Norman\nThat, for the purposes of any Act resulting from the Forensic Science Regulator and Biometrics Strategy Bill, it is expedient to authorise the payment out of money provided by Parliament of any expenditure incurred under the Act by the Secretary of State.\nNotes:\nQueen\u2019s Recommendation signified.\n46. Public Health\nSecretary Matt Hancock\nThat the Health Protection (Coronavirus, Restrictions) (Protected Areas and Restriction on Businesses) (Amendment) Regulations 2020 (S.I., 2020, No. 1041), dated 25 September 2020, a copy of which was laid before this House on 28 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n47. Public Health\nSecretary Matt Hancock\nThat the Health Protection (Coronavirus, Restrictions) (Self-Isolation) (England) Regulations 2020 (S.I., 2020, No. 1045), dated 27 September 2020, a copy of which was laid before this House on 28 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n48. Public Health\nSecretary Alok Sharma\nThat the Health Protection (Coronavirus, Restrictions) (Obligations of Undertakings) (England) (Amendment) Regulations 2020 (S.I., 2020, No. 1046), dated 26 September 2020, a copy of which was laid before this House on 28 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n49. Education\nMichelle Donelan\nThat the draft Higher Education (Fee Limits and Student Support) (England) (Coronavirus) (Revocation) Regulations 2020, which were laid before this House on 28 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n50. Financial Services and Markets\nJohn Glen\nThat the draft Bearer Certificates (Collective Investment Schemes) Regulations 2020, which were laid before this House on 28 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n51. Community Infrastructure Levy\nChristopher Pincher\nThat the draft Community Infrastructure Levy (Amendment) (England) (No. 2) Regulations 2020, which were laid before this House on 28 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n52. Exiting the European Union (Consumer Protection)\nEdward Argar\nThat the draft Tobacco Products and Nicotine Inhaling Products (Amendment) (EU Exit) Regulations 2020, which were laid before this House on 28 September, be approved.\nNotes:\nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n53. Exiting the European Union (Competition)\nSecretary Alok Sharma\nThat the draft State Aid (Revocations and Amendments) (EU Exit) Regulations 2020, which were laid before this House on 29 September, be approved.\nNotes: \nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.\nThe Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n54. Exiting the European Union (Food)\nEdward Argar\nThat the draft Nutrition (Amendment etc.) (EU Exit) Regulations 2020, which were laid before this House on 29 September, be approved.\nNotes: \nThe Instrument has not yet been considered by the Joint Committee on Statutory Instruments.The Speaker has not yet considered this instrument for certification (Standing Order No. 83P).\n\n\n\n\n\n\n\n\n\n\n\u00a9 UK Parliament 2020Accessibility statement\n\n\n\n\n"
  },
  {
    "text": "\n\n\nSkip to main content\n\n\n\n\n\n\n\n\n\n\n\n\n\nHome\nMail\nRadio\nContact Us\n\n\n\n\n\n\n\n\n\n\n\n \n\n\nHome\nAbout ParliamentAbout National Assembly\nHistory\nThe Clerk's OfficeThe Clerk\nDepartments\n\nCareers at Parliament\nProcurement\nVisiting parliament\nContact Us\nParliamentary Calendar\n\nMembersPresiding OfficersThe Speaker\nThe First Deputy Speaker\nThe Second Deputy Speaker\n\nMinistersCabinet Ministers\nProvincial Ministers\n\nWhips\nMembers of ParliamentGender Representation\nParty Representation\nMembers List\n\nConstituencies\nImmediate Past MPs\n\nCommitteesCommittee System\nCommittees\nAttendance Guidlines\nCommittee Composition\nCommittee Timetable\nCommittee ReportsMain\nBills\nSelect (Ad Hoc)\nTreaties/ Agreements\n\nSubmission Procedure\nMake Your Submission\n\nPublicationsSpeaker's Rulings\nOrder Paper\nDebates and ProceedingsDebates and Proceedings\nDebates and Proceedings (OLD)\n\nVotes and Proceedings\nBudget Speech\nYellow Book\nPresidential Speeches\nLaws of ZambiaActs\nBills\nBills - Not Presented\nLaws of Zambia\n\nConstitution Amendment Act 2016\nMinisterial Statements\nLibrary E-Resources\nGovernment Agreements\nFramework\n\n \n\n\n\n \n\n\n\nSearch form\n\nSearch \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou are hereHome\n\n\n\n\n\n\n\n\nWednesday, 30th September, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nWednesday, 30th September, 2020\n\u00a0\nThe House met at 1430 hours\n\u00a0\n[MR SPEAKER in the Chair]\nNATIONAL ANTHEM\n\u00a0\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 PRAYER\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0______\n\u00a0\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0MINISTERIAL STATEMENT\n\u00a0\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a02020/2021 RAINY SEASON FORECAST\n\u00a0\nThe Minister of Transport and Communication (Mr Kafwaya): Mr Speaker, I thank you for giving me this opportunity to issue a ministerial statement on the 2020/2021 Rainy Season Forecast. I feel duty-bound to give this statement, as weather and climate conditions affect all sectors of the economy across the country.\n\u00a0\nSir, over time, we have observed that climate change has a severe impact on many socio-economic sectors of our country and the same could be said for the future. Therefore, the importance of weather information for decision-making across relevant sectors is critical. More importantly, it is essential to make reasonably accurate weather and climate forecasts in a timely manner.\n\u00a0\nMr Speaker, accordingly, the Government, under the able leadership of His Excellency the President of the Republic of Zambia, Mr Edgar Chagwa Lungu, has continued to equip the Zambia Meteorological Department (ZMD). This is being done through the procurement and installation of modern automatic data collection equipment to aid the process of weather forecasting. I would like to register my appreciation and that of the Government for the invaluable contribution from co-operating partners in providing equipment and funding for the success of this programme.\n\u00a0\nSir, I wish to remind this august House that when the Patriotic Front (PF) Government came into power in 2011, there were only thirty-nine manual weather stations across the country. Therefore, I am glad to state that we have added over 110 automatic weather stations. Further, we are in the process of procuring 140 additional automatic weather stations under the Transforming Landscapes for Resilience and Development (TRALARD), and Strengthening Climate Change Resilience (SCRALA) in Agro-ecological Regions I and II projects. It is a two in one project. In addition, we have enhanced the capacity for weather and climate modeling through modern technological infrastructure.\n\u00a0\nMr Speaker, the Seventh National Development Plan (7NDP) outlines our aspirations to enhance economic diversification, job creation, poverty and vulnerability reduction as well as the reduction in developmental inequalities. In this regard, weather and climate information is fundamental to ensuring that, we, as a people, realise these aspirations by the timely sharing of information on weather and climate. The use of weather and climate information is a basis for building resilience in sectors and communities as well as adapting to climate variability and climate change. Moreover, weather and climate information is key to the mitigation and fight against agricultural pests and diseases as well as managing water resources and the environment.\n\u00a0\nSir, before I proceed with the 2020/2021 Rainy Season Forecast, allow me to offer a brief reflective view of the actual results of weather during the 2019/2020 Rainy Season.\n\u00a0\nMr Speaker, you will recall that the negative effects of climate variability and climate change were clear across the country. Many areas experienced extreme weather conditions ranging from prolonged dry spells in December 2019, and part of January 2020, especially in the Southern Province and the Western Province. In contrast, floods were experienced in many areas of the country between January and March 2020 with record breaking seasonal rainfall in excess of 2,000 mm in Misamfu, Mpulungu and Samfya districts in the Northern Province and Luapula Province.\n\u00a0\nSir, further, dry conditions were witnessed in some parts of the southern half of the country during the 2019/2020 Rainy Season. This resulted in reduced agricultural production. Moreover, the floods, which were experienced in the northern and eastern parts of the country, led to the loss of lives, livelihoods and disruption in service delivery due to damaged road infrastructure such as the Lumezi Bridge and the Samfya/Mansa Road, among many others.\n\u00a0\nMr Speaker, let me now give the forecast for the 2020/2021 Rainy Season. Generally, a large part of Zambia is likely to receive normal to above normal rainfall. However, prolonged dry spells are likely to occur in some parts of the North-Western Province, Muchinga Province, Luapula Province and the Northern Province. For the period of October, November and December 2020, much of Zambia will have a high chance of receiving normal to above normal rainfall except for some parts of Chavuma, Zambezi, Kabompo, Manyinga, Mwinilunga, Ikeleng\u2019i, Limulunga, Mongu and Kasama districts, which are likely to receive normal to below normal rainfall.\n\u00a0\nSir, during the months of November, December and January, most parts of the country have a likelihood of receiving normal to above normal rainfall. However, Ikeleng\u2019i, Mwinilunga, Kabompo, Senanga, Kabwe, Kapiri Mposhi, Serenje, Chitambo, Lavushi Manda, Mambwe, Petauke, Sinda, Katete, Kasenengwa and surrounding areas have a high chance of receiving normal to below normal rainfall. For December, January and February, much of Zambia has a high chance of receiving normal to above normal rainfall apart from Kasama, Mungwi, Chama, Lundazi, Chasefu, Petauke and Kalabo districts and, indeed, surrounding areas.\n\u00a0\nMr Speaker, in the last part of the rainy season of January, February and March 2021, most parts of Zambia will have a high chance of receiving normal to above normal rainfall. However, parts of Muchinga Province and the Northern Province as well as Mansa, Ndola, Kabompo, Senanga, Livingstone and surrounding areas are likely to receive normal to below normal rainfall.\n\u00a0\nSir, I wish to emphasise that every season has diverse implications across all sectors. During the 2020/2021 Rainy Season, the country is likely to experience the following:\n\u00a0\ndry spells across the country, especially in Luapula Province, Muchinga Province and the Northern Province, including the northern districts of the Eastern Province; and\nincreased chance of floods and flash floods in flood-prone areas.\n\u00a0\nMr Speaker, the 2020/2021 Rainy Season is likely to be fully established by the end of November 2020, although the rains may start earlier in some areas. Areas like the Northern Province, Luapula Province, Copperbelt Province, North-Western Province and parts of the Western Province may experience thunderstorms and showers by October. In this regard, I advise farmers and the public at large to safeguard their harvested crops properly to avoid damage. It is also important to note that dry spells occur in the middle of the rainy season and in certain circumstances, lead to crop loss. Therefore, I urge our farmers and other stakeholders to regularly follow my ministry\u2019s regular meteorological forecasts and updates which will be broadcast on most radio and television stations. They are also welcome to get in touch with the ministry in order to access weather information.\n\u00a0\nSir, similarly, let me state that there are important aspects that come with the rainy season that affect our daily lives and activities. In this regard, I wish to encourage sectors and communities to undertake sensitisation programmes in good sanitation and hygiene practices and clearing of drainage systems well in advance to avoid water pools that may serve as breeding grounds for germs. Likewise, there is a need for institutions to stock relief materials, medicines and pesticides that may be required during the course of the season. To protect our environment and contribute to mitigating the adverse effects of climate change and variability, I wish to encourage the public to plant trees. Trees are a natural measure to improving rainfall performance and reduce impacts of extreme weather conditions such as floods and droughts.\n\u00a0\nMr Speaker, my ministry will continue giving updates to the nation on the actual and expected weather conditions during the 2020/2021 Rainy Season through community radio stations, the Zambia National Broadcasting Corporation (ZNBC), including other communication platforms.\n\u00a0\nSir, as the adage goes, \u201cforewarned is to be forearmed\u201d. Therefore, I encourage all sectors and communities to incorporate the 2020/2021 Rainy Season Forecast information in their plans and decision-making processes by getting meteorological updates on a regular basis.\n\u00a0\nMr Speaker, I thank you.\n\u00a0\nMr Speaker: Hon. Members are now free to ask questions on points of clarification on the statement given by the hon. Minister of Transport and Communication.\n\u00a0\nI would like to advise the House that there are two ways in which you can indicate if you wish speak or intervene, namely by Electronic Chamber (e-Chamber) application or alternatively, the Zoom Video Communications (Zoom) system.\n\u00a0\nHon. Members, it appears that there are no points of clarification. That being the case, we move on. I am advised that there are a few hon. Members who have indicated their intention to ask questions, and we shall start with the hon. Member for Chisamba.\n\u00a0\nMs Kasanda (Chisamba): Mr Speaker, I would like to find out from the hon. Minister \u2013\n\u00a0\nMr Mwiimbu: On a point of order, Sir.\n\u00a0\nMr Speaker: A point of order is raised.\n\u00a0\nMr Mwiimbu: Mr Speaker, I have noted that for the last two days, we have been having challenges with the Electronic Chamber (e-Chamber) system and we cannot access the proceedings using the system.\n\u00a0\nMr Speaker, I just want your advice on this particular matter. Why would we, as hon. Members who are in this House, be advised to use Zoom when the local system which we have been using is still functioning? Why can those of us who are in the Chamber not use the system which we are used to if the other systems are not functioning?\n\u00a0\nSir, I am failing to log in because of what is happening, and so, I need your guidance on this matter.\n\u00a0\nMr Speaker: I reserve my ruling.\n\u00a0\nHon. Kasanda was inaudible. \n\u00a0\nMr Speaker: Hon. Member for Chisamba, I will come back to you later.\n\u00a0\nDr Imakando (Mongu Central): Mr Speaker, from a crop production point of view, is this year\u2019s forecast better than last year\u2019s or is the hon. Minister able to give an indication?\n\u00a0\nMr Kafwaya: Mr Speaker, this year\u2019s forecast is better in the southern half of our country than it was last year, and the opposite is true for the northern half of our country.\n\u00a0\nI thank you, Sir.\n\u00a0\nMs Kasune (Keembe): Mr Speaker, I hope I am audible. The forecast usually comes through the House and very little is done about packaging the information in the languages used in our respective constituencies. Has there been any effort by the ministry to ensure that this message does not just end in this House, but also goes to the people it is mostly intended for? This is especially for us who come from farming and rural areas at which this information is aimed at in order to ensure that people have this information tailored into the language they are familiar with.\n\u00a0\nMr Kafwaya: Mr Speaker, the Zambia National Broadcasting Corporation (ZNBC) is viewed across the country. Further, community radio stations are spread across the country. My bringing of this ministerial statement to the House is aimed at giving an opportunity to my hon. Colleagues to take the message to their constituencies. Therefore, I think that the Government\u2019s effort of trying to share this information is immeasurable. This is because we are using every available platform to ensure that we take the message across the country.\n\u00a0\nI thank you, Sir.\n\u00a0\nMs Katuta (Chienge): Mr Speaker, my question is similar to the one asked by the hon. Member of Parliament for Keembe. My constituency is in a rural area where it is very difficult to access the Zambia National Broadcasting Corporation (ZNBC) signal. The hon. Minister has talked about community radio stations, which are spread across the country, as tools for the dissemination of information. However, he has not indicated how the Government is going to sponsor these programmes through community radio stations or commercial stations that we have in Chienge, for instance. How is that going to be done because our people need to access this information? I would like the hon. Minister to also clarify that.\n\u00a0\nMr Kafwaya: Mr Speaker, I have already been sponsored by the Government to share this information. Obviously, my hon. Colleagues are also sponsored by the Government to share information in their respective constituencies. It is my hope that this information will not end with people like me, but that it will be shared with councillors so that the entire Government system is involved in disseminating the information across the country.\n\u00a0\nI thank you, Sir.\n\u00a0\nMr Speaker: Hon. Member for Chisamba, are you able to come on board now?\n\u00a0\nMs Kasanda: Mr Speaker, in the event that the country experiences dry spells, what measures are being put in place by the Government to come to the aid of such areas since the Disaster Management and Mitigation Unit (DMMU) is usually very selective and political?\n\u00a0\nMr Kafwaya: Mr Speaker, I did not get the question.\n\u00a0\nMs Kasanda: Mr Speaker, the hon. Minister indicated that some parts of the country may experience dry spells. Therefore, my question is: What measures are being put in place by the Government to make sure that it comes to the aid of the people in these places?\n\u00a0\nMr Kafwaya: Mr Speaker, planning for agriculture should be based on information. This is why as a ministry, we have promised to be updating the nation regularly. We have also encouraged members of the public to come to our ministry to get information which will help stakeholders to plan their agricultural activities accordingly. Clearly, that is a significant measure that we are putting in place. Indeed, this information will be made available, as I said, through community radio stations, the ZNBC and many other communication platforms.\n\u00a0\nI thank you, Sir.\n\u00a0\nMr Miyanda (Mapatizya): Mr Speaker, I would like to thank the hon. Minister for the statement. He clearly stated that we are coming from a situation whereby we had thirty-six manual weather stations across the country and we are now at 110 automatic weather stations. I just want to appreciate this development. However, what is the distribution of the 110 automatic weather stations across the country per province?\n\u00a0\nMr Kafwaya: Mr Speaker, I would like to thank my hon. Colleague for appreciating what the Patriotic Front (PF) Government is doing in migrating our weather forecasting from the manual to the automatic system. I said that we are now at over 110 additional automatic weather stations and we are in the process of procuring 140 more automatic weather stations. However, I do not have the distribution, at the moment, but this is information that I am capable of sharing with my hon. Colleague.\n\u00a0\nI thank you, Mr Speaker\n\u00a0\nMr Nanjuwa (Mumbwa): Mr Speaker, considering that the agriculture input distribution last year in the Central Province was done according to the rain or weather pattern, I would like to find out how much of this information he has given us has been utilised in the distribution of inputs throughout the country, considering that the northern part of the country will receive less rainfall than the southern part. Are we going to have a situation whereby we will have the Electronic Voucher (e-Voucher) system in the north while we will have the conventional Farmer Input Support Programme (FISP) in the south so that the farmers in the north can have the privilege to get a variety of inputs that they will be able to utilise?\n\u00a0\nMr Kafwaya: Mr Speaker, I want to appreciate my hon. Colleague for that follow-up question. Indeed, weather information should be used in decision management, and I was equivocal in that respect in my statement. The Ministry of Agriculture is one of the stakeholders that should benefit from the information that we give. Decisions on how the inputs under the FISP should be distributed are arrived at in the Ministry of Agriculture which is completely out of my jurisdiction. As such, I am unable to state how this information has affected or is going to affect the distribution of inputs under FISP.\n\u00a0\nI thank you, Sir.\n\u00a0\nDr Malama (Kanchibiya): Mr Speaker, I would like to join the hon. Minister in appreciating Hon. Miyanda for acknowledging the successes made by the Patriotic Front (PF) Government. The hon. Minister has highlighted that before the PF Government came into power, there were thirty-six weather stations and that there are now over a hundred. Before, we used to hear of variances. Sometimes, we would be told how the weather would be like and then we would be able to get the alternative. With the introduction of digital weather stations, what is the experience now?\n\u00a0\nMr Kafwaya: Mr Speaker, it is abundantly clear that the PF Government has made progress in making life easier for people by providing information that helps. The example I will give of how the automatic weather stations have helped is how accurate our forecast was last year. Make reference to last year and you will see how accurate our forecast was. So, it is abundantly clear that this pro-poor focus on people on behalf the Zambians is bearing fruit.\n\u00a0\nI thank you, Mr Speaker.\n\u00a0\nMr Kundoti (Luena): Mr Speaker, my question to the hon. Minister is relatively opposite to the recent one which he has just answered. Sometimes, the predictability of meteorological weather forecasting, especially the forecast to do with rains, goes amiss. You will find that instead of having probably an abundance of rain, you end up having little rains in areas which are predicated to receive abundant rainfall. In cases where farmers have probably followed the weather forecast and they end up losing their seed, does the Government consider compensating them with seed to replant, especially for village farmers who may not have money to replace their seed?\n\u00a0\nMr Kafwaya: Mr Speaker, I sincerely thank my hon. Colleague, the Member of Parliament for Luena, for that follow-up question. Indeed, predictions can sometimes go amiss. This is why our language is that of the likelihood of something happening. However, the safeguard is that we have promised to give regular updates, meaning that where changes do occur, we will be able to offer alternative information that speaks to the reality of the time.\n\u00a0\nSir, with regard to compensating farmers, I would not be responsible for distributing that seed. Therefore, it follows that I may not be the right person to compensate our farmers. We may not be the right ministry to think of compensation. However, I do know of the activities of the Disaster Management and Mitigation Unit (DMMU) in the assistance of people who suffer the consequences of nature and all these things. In this particular case, the Ministry of Agriculture will be best suited to offer a response.\n\u00a0\nI thank you, Sir.\n\u00a0\nMr Mwila (Chimwemwe): Mr Speaker, my question has been overtaken by the hon. Minister\u2019s response.\n\u00a0\nMr Speaker: I will take the last question from the hon. Member for Kalabo Central.\n\u00a0\nMr Miyutu (Kalabo Central): Mr Speaker, during the previous season, we used to receive updates on our phones on the changes in the weather patterns. Is the hon. Minister of Transport and Communications assuring us that the ministry will be able to reach us in our rural areas through our phones?\n\u00a0\nMr Kafwaya: Mr Speaker, the short message service (SMS) is an alternative means of circulating this information. In my ministerial statement, I indicated that the ZNBC, community radio stations and other forms of communication will be used. Of course, the SMS is part of those alternative methods.\n\u00a0\nMr Speaker, recently, I was in Kalabo with the hon. Member who just posed this supplementary question. We launched a telecommunication tower in his constituency which is one of the seven that have been erected in that district. Therefore, because of that investment, the people of Kalabo will be able to receive information via the SMS as well as through the internet. So, yes, we will be able to exploit that Government investment to circulate this data via alternative methods.\n\u00a0\nMr Speaker, I thank you.\n\u00a0\n_______\n\u00a0\nQUESTIONS FOR ORAL ANSWER\n\u00a0\nINFRASTRUCTURE CONSTRUCTION IN CHIPILI DISTRICT\n\u00a0\n39.\u00a0 Mr Chabi (Chipili)\u00a0asked the Minister of Housing and Infrastructure Development:\n\u00a0\nwhen the construction of the following infrastructure in Chipili District will be completed:\n\u00a0\ndistrict administration block;\ncivic centre; and\npost office; and\n\u00a0 \u00a0 \u00a0 b,what has caused the delay in completing the projects.\n\u00a0\nThe Minister of Housing and Infrastructure Development (Mr Mwale): Mr Speaker, the construction of the district administration block in Chipili District is at 76 per cent completion and the project is expected to be completed by December 2020, subject to the availability of funds.\n\u00a0\nMr Speaker, the construction of the civic centre in Chipili District is at 38 per cent completion and the project is expected to be completed by December 2020, subject to the availability of funds. \u00a0\n\u00a0\nSir, the construction of a post office in Chipili District has reached 90 per cent completion and works are expected to be completed in December 2020, again, subject to the availability of funds. The delay in completion of the projects has been due to financial constraints.\n\u00a0\nI thank you, Sir.\n\u00a0\nMr Chabi: Mr Speaker, the hon. Minister just mentioned that the delay has been because of financial constraints. However, he knows, as well as I do, that these projects were awarded in 2012, eight years ago. At which point during the eight years did the financial problem occur?\u00a0\n\u00a0\nMr Mwale: Mr Speaker, the financial constraints occurred soon after the project started because we launched too many projects ...\n\u00a0\nHon. PF Members: Hear, hear!\n\u00a0\nMr Mwale: \u2026 and encountered a number of unforeseen challenges like drought and power shortages. We had to abruptly budget for the importation of power. There were just so many challenges that put so much pressure on the Treasury because it had to find money to deal with emergencies. That caused the financial constraints that led to the delay in the completion of many projects, including these ones.\n\u00a0\nI thank you, Sir.\n\u00a0\nDr Malama (Kanchibiya): Mr Speaker, I would like to appreciate the Patriotic Front (PF) Government for the introduction of new districts, from which the people of Kanchibiya and Lavushimanda have benefited. Mpika District was large in size. It was the size of the Netherlands. However, the Chipili case is similar to what is obtaining in Kanchibiya and Lavushimanda, which is an initiative of the hard-working PF Government to bring services closer to the people. Could the hon. Minister be able to come to the House at some point and let us know when the district offices, the post offices and the police stations will be built in Kanchibiya and the new districts?\n\u00a0\nMr Mwale: Mr Speaker, the Ministry of Finance has given my ministry Treasury authority to procure for eleven new districts which were created and had not been allowed to construct infrastructure, a package that comes with new districts. This is now being done and, as I speak to you, my ministry is procuring works for all the eleven new districts, which include Kanchibiya and all the other new districts in Muchinga.\n\u00a0\nMr Speaker, I thank you.\n\u00a0\nMr Speaker: Hon. Minister, the question is: Are you in a position to come to the House and narrate your programme of action in due course?\n\u00a0\nMr Mwale: Mr Speaker, I thought what I said was adequate. However, if there is any further information about what we are procuring, at the moment, that I need to narrate here, I am more than ready to come to the House to present a ministerial statement if the Hon. Mr Speaker avails me the time.\n\u00a0\nI thank you, Sir.\n\u00a0\nMr A. C. Mumba (Kantanshi): Mr Speaker, the hon. Minister mentioned the stages at which these projects are. However, you will agree with me that the contracts have by now expired. In the event that the contracts have expired, and they are going to have to be renewed, obviously, there will be variations in the costs of the contracts, and they will be upwards. For certain projects, as the hon. Minister waits for the Ministry of Finance, does he have a fully-fledged engineering and buildings department? Is the hon. Minister telling the nation that his own ministry cannot complete some of these projects? Like I said, these contracts have already expired. Now, this particular challenge that is in Chipili, which we have learnt is also in Kanchibiya, is also here in Chilanga. Will his ministry not look at other new ways of completing these projects? He has to bear in mind that despite the promise to consider projects at 80 per cent completion, which has been the song for the last two years, there is a project that is at 90 per cent completion and is still incomplete in Chipili District.\n\u00a0\nMr Mwale: Mr Speaker, there are so many issues that Hon. A. C. Mumba has raised. However, the main issue is that most of these contracts should have expired by now and what the ministry is doing to renew them.\n\u00a0\nMr Speaker, this has been an on-going process. In fact, some of these projects started in 2011, soon after the Patriotic Front (PF) came into power. We realised that we needed to decentralise, and, therefore, created new districts. Contractors were engaged, but some works have not been completed. Nine or eight years down the line, we still have the same contractors on sites because there has been an on-going process to renew contracts once they expire. At the same time, where there has been a need to revise rates, we have done so, as we have been renewing contracts.\n\u00a0\nSir, I know that even now, we are having a challenge in that the exchange rate has hit many contractors that are on sites and they are presenting their cases to the ministry to ensure that adjustments are made. Formulas that help to resolve these situations between us, the employer, and the contractors are available. These are on-going routine issues that we encounter in project management. As we construct roads, these issues are well taken care of. We do not have a situation where contractors are on site while their contracts have expired. Before contracts expire, presentations are always made to the ministry and processes to have them renewed are always undertaken because we know we are the ones who have not done our part by not paying the contractors. So, we always renew contracts to give the contractors more time.\u00a0\n\u00a0\nI thank you, Mr Speaker.\n\u00a0\nMr Speaker: The hon. Member for Kantanshi would like to find out whether there is a possibility of the Government completing these contracts. Is that tenable?\n\u00a0\nMr Mwale: Mr Speaker, not in this case. It is tenable in other cases, but not in relation to district infrastructure. Most of the projects are above 80 per cent completion. Very few are below 80 per cent. We are almost there. So, we think we can manage with the contractors that we have. Like I said last time, in other cases, such as in contracts for the construction of secondary schools, we are considering the possibility of the Government completing these contracts.\n\u00a0\nI thank you, Mr Speaker.\n\u00a0\nMr Chabi: Mr Speaker, I would like the hon. Minister to confirm to this House and the nation at large that eight years of delay in the completion of projects that were contracted in 2012 has led to their becoming more expensive for the Government because the cost of building materials has gone up. For example, at the time of signing the contracts, a bag of cement cost only K35, but today, the price has almost tripled and is at K120. Can the hon. Minister confirm to the nation that the Government is paying a lot of money for these projects because of the delay which has made them to become more expensive?\n\u00a0\nMr Speaker: Hon. Member for Chipili, is that not a rhetorical question? Does the hon. Minister want to respond?\n\u00a0\nMr Mwale: Mr Speaker, I responded that there are mechanisms that see to it that there are price adjustments as we implement these projects. It is normal in project management that these mechanisms are in place and contractors are not at loss in any way.\n\u00a0\nI thank you, Mr Speaker.\n\u00a0\nMr Chaatila (Moomba): Mr Speaker, the issue of the new districts that were created by the Patriotic Front (PF) Government is a classic example of its failure to complete whatever it starts. From 2008 to 2012, Chipili District Council had employees. So, where are these officers now operating from? Are they operating under trees or in tents, in some cases?\n\u00a0\nMr Mwale: Mr Speaker, firstly, let me dispel the assertion that nothing is completed under the PF. I want to tell you that we have completed the Kazungula Bridge. It is at 100 per cent completion.\n\u00a0\nHon. Government Members: Hear, hear!\n\u00a0\nMr Mwale: More than US$200 million has been spent on that bridge. We have also completed the Mongu/Kalabo Road. I can go on and on. So many projects are being implemented and completed under this Government and that is for everyone to see. Hospitals and schools have been completed.\n\u00a0\nMr Speaker, to answer his question, officers in Chipili are accommodated in various buildings available in Chipili. I know that Chipili may not have very good housing, so some officers commute from Mansa. The officers are all working and there is no office that is lacking in any way. We want the officers to be in a better environment and in better offices. That is why we are in a hurry to complete all these structures. For now, they are all well accommodated in various buildings available in Chipili and Mansa.\n\u00a0\nI thank you, Mr Speaker.\n\u00a0\nMr Kundoti (Luena): Mr Speaker, has there ever been some financial planning for the construction of houses and office blocks in the newly created districts? There is a saying that anyone who wants to embark on building a house must plan and understand how much it will cost and set aside money. Otherwise, if the building stalls along the way, people will laugh at him/her. So, has there ever been some financial planning towards the cost of these projects? If there has been any financial planning, why are we seeing these projects, like the one in Chipili, stalling? This is happening not only in Chipili, but also almost nationwide, including in Limulunga. The construction of our new district offices and houses has stalled. If ever there was financial planning and money set aside for these projects, why have they stalled? If not, where is the ministry going to get the money?\n\u00a0\nMr Speaker: Hon. Members, you are repeating yourselves. That question has already been asked.\n\u00a0\nMr Mwale: Mr Speaker, there has been a plan, definitely. The Government presents a Budget to the House every year, which is a financial plan of what it intends to achieve in a particular year. In fact, we do have a Medium Term Expenditure Framework (MTEF) which gives us room to plan for three years.\n\u00a0\nMr Speaker, we have had many unplanned events that have happened in this country that have affected our plans. We never expected to lose a Head of State and have a national funeral, which then led to an unplanned election. We ended up having two elections in two years, that is, in 2015 and 2016. We also had a drought, which affected our power production and we had to import power at a huge cost. In the last seven years, this country has seen so many unplanned events that have cost us a lot of money. Now, we have the latest issue of the Coronavirus Disease 2019 (COVID-19).\n\u00a0\nHon. PF Members: Na ba makanta.\n\u00a0\nMr Mwale: Mr Speaker, so many things have happened to this country in the last eight years that really affected our plans. That is why we find ourselves in this situation. All things being equal, we should have completed these structures a long time ago and been looking at starting new ones this time around. However, even though we have had this situation, we have seen ourselves achieving a number of things. We have scored a number of successes in as much as we also have issues that we are still dealing with. Not all has been lost. This Government has done its best, and that is why people keep having confidence in it.\n\u00a0\nI thank you, Mr Speaker.\n\u00a0\nMr Kambita (Zambezi East): Mr Speaker, in the hon. Minister\u2019s response to a question raised by one of the hon. Members, he indicated that the process has taken eight years and thus far, the Government has not been able to raise the resources required to complete the projects in Chipili. In the eight years that the Government has embarked on these projects, has it not had some kind of gantt chart which could be used to determine progress made, year after year, so that we know what is really remaining to be done?\n\u00a0\nMr Mwale: Mr Speaker, the Government is tracking progress on all the structures that it is putting up. Four weeks ago, K32 million was disbursed to contractors on these projects. Two months before that, K28 million was given out for the same projects. There is a lot of progress and improvement on most of these projects that we have in the districts. Twelve months ago, some were at 70 per cent completion and are now at 95 per cent and those that were at 30 per cent are at 60 per cent completion.\n\u00a0\nSir, I have given December 2020 as the deadline for the completion of these projects because I am very hopeful that the progress that we are making will see us through. By December, we should have most of these projects handed over to people for use. So, we have been tracking progress year by year and it has been very significant. Very soon, everything will be completed.\n\u00a0\nI thank you, Mr Speaker.\n\u00a0\nMr Speaker: I will take the last three questions from the hon. Member for Manyinga, followed by the hon. Member for Keembe and lastly will be the hon. Member for Milenge.\n\u00a0\nMr Lihefu (Manyinga): Mr Speaker, Chipili is like many other constituencies, as my hon. Colleagues have stated. Manyinga is a newly created district and during the President\u2019s Address on 11th September, 2020, he said that infrastructure development has been delivered countrywide. However, Manyinga has still been left behind like Chipili. Can the hon. Minister confirm that these infrastructure developments that the President said have been delivered countrywide are only delivered in urban areas like Lusaka Province and the Copperbelt Province? I say so because the workers in Manyinga are still operating from the old infrastructure which is in a bad state.\n\u00a0\nMr Mwale: Mr Speaker, the President is right that this Government has delivered quality infrastructure throughout the country. Infrastructure is not just an administration block, post office or civic centre in Manyinga. Infrastructure includes bridges that we are working on throughout the country and there are so many of them. I think my brother can agree with me that we are working on some bridges and roads in Manyinga. Infrastructure includes secondary schools, the universities that we are seeing in this country, primary schools and the 360 rural health centres throughout the country that are under construction. There are so many things that relate to infrastructure and it is not just about a post office or an administration block.\n\u00a0\nSo, the President is right and, I think, Zambians are saying this everyday and everyone agrees with us that the PF Government has delivered quality infrastructure to this country. We will continue doing so as long as we are in power and that is why people still want us to be in power.\n\u00a0\nMr Speaker, we will complete the infrastructure in Manyinga, just like we will complete infrastructure in Chipili. In fact, in the last disbursement that we made, we released some money to Manyinga for one of the structures to be completed. Like in Chipili, trust me, very soon, this will be a thing of the past. If there is any government you can trust on the delivery of infrastructure, that of the PF is such a one and very soon, this will be a thing of the past.\n\u00a0\nI thank you, Sir.\n\u00a0\nInterruptions\n\u00a0\nMs Kasune (Keembe): Mr Speaker, using the Chipili situation, I want to know the criteria being used to assess progress on these projects. Is there a timeframe within which the unfinished projects in the different districts are to be completed so that none of us should come here all the time to tag along one\u2019s question about various projects? Could that information be availed to us if the ministry has it so that the people in the new districts can know when their projects are coming up for completion or when they will be funded, instead of us always having this back and forth conversation? The people on the ground, who are the beneficiaries, would have some kind of assurance and plan around the development of these districts. This goes beyond those who will be working from these structures, but also the development that they may bring to the local people.\n\u00a0\nMr Mwale: Mr Speaker, the criteria we have now is to complete the projects that are at 80 per cent completion. We are focusing on the completion of such buildings and it does not matter where they are in the country as long as they are at 80 per cent completion so that we can begin to utilise them. So, we do not embark on everything at the same pace because it takes us long to complete the projects. However, we want to ensure that projects that are above 80 per cent completion are quickly be completed and handed over and, then, we move to the rest. From the last disbursement, we are actually getting there because some of the projects are almost 100 per cent completed and some are at 98 per cent completion. Therefore, we are beginning to go down to those below 80 per cent completion. That is the criterion we have.\n\u00a0\nNonetheless, if the hon. Member wishes to get the whole matrix of district infrastructure in terms of where we are and when we are likely to complete these projects, we have this information and we can avail it to her at her convenience. We can avail all the information that we have for all the districts, but the criterion is to focus on projects that are at 80 per cent complete and above.\n\u00a0\nI thank you, Sir.\n\u00a0\nMr Mbulakulima (Milenge): Mr Speaker, I am mindful that the question is on Chipili. So I will not talk about the Kasanka/Milenge Road, which has not even been worked on, yet the hon. Minister is boasting about infrastructure that has been delivered throughout the country. I got back from Milenge yesterday. The road is in an extremely bad state.\n\u00a0\nSir, the hon. Minister almost gave hope to the people of Chipili when he mentioned that this infrastructure will be completed by December, but then again attached the condition of the dependence on the availability of money. For us in the accountancy world, funds are about debit and credit or in and out. So, the statement he made amounts to zero or nothing. It dilutes and then kills hope. Can the hon. Minister state to the people of Chipili what tangible action is being taken between tomorrow, for example, which is 1st October, 2020, to December 2020 to mobilise resources specifically to complete the structures in Chipili?\n\u00a0\nMr Mwale: Mr Speaker, we have agreed with the Ministry of Finance that it will give us some finances on a regular basis to complete these structures. That is why four weeks ago, K32 million was disbursed and a month or two before K28 million was released. We have agreed on something that entails that monies will be coming to our ministry almost every month. So, my promise was based on the arrangement we have with the Ministry of Finance. That is why at the end of my response, I said that the projects would be completed subject to the availability of funds which the Ministry of Finance is mobilising.\n\u00a0\nMr Speaker, there is nothing else except that I am promising based on the agreement we have with the Ministry of Finance. That is the step we have taken, but is it not cast in concrete as well because the Ministry of Finance has to find that money. When that money is made available to us, then, we should complete the projects by December 2020.\n\u00a0\nI thank you, Sir.\n\u00a0\n_______\n\u00a0\n\u00a0\nMOTION \n\u00a0\nREPORT OF THE PARLIAMENTARY SELECT COMMITTEE APPOINTED TO SCRUTINISE THE PRESIDENTIAL APPOINTMENTS OF MRS EMILY SIKAZWE TO SERVE AS VICE-CHAIRPERSON, AND MAJOR-GENERAL VINCENT MBAULU MUKANDU (RTD) AND MRS NDIYOI MULIWANA MUTITI TO SERVE AS MEMBERS OF THE ELECTORAL COMMISSION OF ZAMBIA\n\u00a0\nMs Kabanshi (Luapula): Mr Speaker, I beg to move that this House do adopt the Report of the Parliamentary Select Committee appointed to scrutinise the presidential appointments of Mrs Emily Joy Sikazwe to serve as vice-chairperson, and Major-General Vincent Mbaulu Mukanda (Rtd) and Mrs Ndiyoi Muliwana Mutiti to serve as members of the Electoral Commission of Zambia (ECZ).\n\u00a0\nMr Speaker: Is the Motion seconded?\n\u00a0\nMr Muchima (Ikeleng\u2019i): Mr Speaker, I beg to second the Motion.\n\u00a0\nMs Kabanshi Mr Speaker, the appointments of Mrs Emily Joy Sikazwe to serve as vice-chairperson, and Major-General Vincent Mbaulu Mukanda (Rtd) and Mrs Ndiyoi Muliwana Mutiti to serve as members of the ECZ is made pursuant to Article 240 of the Constitution of Zambia, Cap. 1 of the Laws of Zambia and Section 5 of the Electoral Commission of Zambia Act No. 25 of 2016.\n\u00a0\nSir, in scrutinising the appointments, the Committee noted that the ECZ plays an important role in Zambia\u2019s democratic dispensation with the key mandate of organising and conducting elections in Zambia. In view of this, the Committee resolved that only competent persons with unquestionable integrity, diligence, eminence, and sound character should be appointed as members of the ECZ.\n\u00a0\nFurther, the Committee notes that Article 259 of the Constitution of Zambia requires the person making the appointment to a public office to, where possible, ensure, among others, 50 per cent representation of each gender, representation of the youth, and persons with disabilities. The Committee would like to commend the appointing authority for complying with Article 259 in so far as gender is concerned.\nMr Speaker, the Committee also observes that the appointments of the nominees speak to Article 173 of the Constitution of Zambia which promotes equal opportunities for appointments of members of both genders. The Committee would, in this regard, like to commend the appointing authority for appointing a female vice-chairperson considering that the chairperson is male. The Committee, however, urges the appointing authority to consider the youth and persons with disabilities in future appointments.\n\u00a0\nSir, allow me now to briefly outline the findings of the Committee on each of the nominees.\n\u00a0\nMr Speaker, on the first nominee, Mrs Emily Joy Sikazwe, the Committee notes that during the course of her long career as an academician and gender activist, she has contributed immensely in advocating for gender matters, democracy and good governance. The Committee further notes that since her appointment as member of the ECZ, she has made remarkable contributions in advocating for the participation of women in the electoral process and the fulfilment of the constitutional mandate of the ECZ.\n\u00a0\nSir, the second nominee is Major-General Vincent Mbaulu Mukanda (Rtd). The Committee observes that he is an accomplished military person with thirty-seven years of service to the country, having joined the Zambia Army in 1975 and retired as Deputy Army Commander and chief of staff in 2011. The Committee also observes that his vast knowledge and experience in conflict management at international and national levels will assist the ECZ in discharging its mandate, particularly relating to the settlement of minor electoral disputes in line with Article 229, Section 2(d) of the Constitution of Zambia.\n\u00a0\nMr Speaker, the third nominee is Mrs Ndiyoi Muliwana Mutiti. The Committee observes that she has vast experience in the public sector having worked as a chief archivist, chief immigration officer and Permanent Secretary before being transferred into the Diplomatic Service. The Committee also observes that she has vast knowledge and experience in records management systems, governance, and public administration, which will contribute positively to the attainment of the mandate of the ECZ.\n\u00a0\nSir, the Committee, after due and thorough consideration, analysis and evaluation of the written and oral submissions presented to it by witnesses and nominees, is of the view that all the nominees are suitably qualified and possess the requisite competences to serve as vice-chairperson and members of the ECZ.\n\u00a0\nMr Speaker, in view of this, the Committee recommends that this august House ratifies the presidential appointment of Mrs Emily Joy Sikazwe to serve as vice-chairperson and Major-General Vincent Mbaulu Mukanda (Rtd) and Mrs Ndiyoi Muliwana Mutiti to serve as members of the ECZ.\n\u00a0\nSir, finally, the members of the Committee wish to place on record their gratitude to you for appointing them to serve on this select Committee. The Committee is also thankful for the services and advice rendered to it by the Office of the Clerk of the National Assembly during its deliberations.\n\u00a0\nMr Speaker, I thank you.\n\u00a0\nMr Speaker: Does the seconder wish to speak now or later?\n\u00a0\nMr Muchima: Now, Mr Speaker.\n\u00a0\nMr Speaker, I thank you most sincerely for according me this opportunity to second this Motion. I also extend my gratitude to the mover for ably moving the Motion. The mover has ably covered most of the notable points upon which the Committee supports the ratification of Mrs Emily Joy Sikazwe to serve as vice-chairperson and Major-General Vincent Mbaulu Mukanda (Rtd) and Mrs Ndiyoi Muliwana Mutiti to serve as members of the Electoral Commission of Zambia (ECZ).\n\u00a0\nSir, in seconding the Motion, I wish to reiterate the Committee\u2019s observation that all the three nominees are duly qualified and possess the necessary competences to serve as vice- chairperson and members of the ECZ. The Committee notes that this ratification is important as it promotes equal opportunities for the appointment of members of both genders as required by the Constitution of the Republic of Zambia.\n\u00a0\nMr Speaker, I wish to highlight the Committee\u2019s observation that it is a constitutional requirement that a person making appointments must ensure among others the representation of the youths and persons with disabilities. The Committee thus recommends that in future, nominees should be drawn from among the youths and persons with disabilities as there is a need of their representation among the members of the ECZ.\n\u00a0\nSir, as I conclude, allow me to extend my gratitude to the Chairperson of the Committee for the impartial and just manner in which she presided over the meetings and preparations of the Committee. I would also like to extend my sincere gratitude to all members of the Committee for their objectivity, professionalism and unity of purpose during its deliberations. With those few remarks, I beg to second the Motion.\n\u00a0\nMr Speaker, I thank you.\n\u00a0\nMr Kamboni (Kalomo Central): Mr Speaker, times for nominations are really great moments for the country to tap talent from all over the country. This is an opportunity where in any Government, a leader chooses people from all over the country to tap the talent that could really solve Zambia\u2019s problems.\n\u00a0\nSir, quite often, the scenario I have seen in the Patriotic Front (PF) is that the selection of people to do certain duties, which are very noble for the country, will normally be restricted to one or two provinces and that does not give the country the opportunity to get the best men and women to serve it diligently.\n\u00a0\nMr Speaker, I hope these people who have been chosen to go to the Electoral Commission of Zambia (ECZ) will really bring in something because it is a troubled institution. It is troubled to a level whereby sometimes when they come to define excellence from what happens, we feel embarrassed. For example, the ECZ stated that the elections in Mwansabombwe and Lukashya were excellent yet they were marred with violence and that kind of stuff. So, I hope these individuals who have been selected will stand for the country and the truth.\n\u00a0\nSir, Zambia is desperately in need of men and women who can serve it diligently without fear or favour. Even when they have been appointed, I want to remind them that their allegiance should not be to an individual who also takes part in an election. No! Their allegiance should be to the country. As a country, we are tired of men and women who are openly biased and support what is wrong. We want men and women who can defend the country, stand for the truth and stand by the rules that are set.\n\u00a0\nMr Speaker, what we are now seeing is that the ECZ has been dictating what must be done without engaging all the stakeholders. It has been reduced to an institution that has become a property of somebody else and not the whole country, and this is bringing a very uncomfortable silence in the country. So, I hope these individuals who have been appointed will do what the country expects them to do. The money that these individuals will be paid will come from all the Zambians who pay tax and not from an individual or one party. So, these individuals should really fill in the gap that has been missing in the ECZ. They should involve all the stakeholders.\n\u00a0\nSir, holding elections is the oasis and the heart of democracy in any institution. It has a spillover effect, can bring chaos and very good results to the country. Further, it can make the economy better and can also destroy the country. However, I hope the individuals who have been appointed will come in with fresh knowledge and the vigor to serve the country diligently and professionally.\nMr Speaker, with those few words, I commend the Committee for doing what it did. Above all, I insist that those who nominate these people should nominate them from across the country. All the Zambians are able to see; we cannot be having people nominated from only one or two provinces all the time. I think we can tap talent from all over the country so that we see how the problems that we have can be sorted by such individuals.\n\u00a0\nSir, I thank you for allowing me to say a few words.\n\u00a0\nI thank you, Mr Speaker.\n\u00a0\nMr Mwila (Chimwemwe): Mr Speaker, allow me to thank the appointing authority for the careful selection of the nominees in that as observed by your Committee, firstly, there has been a good attempt at gender equity. We have seen two women nominees against three men, which is good. Secondly, there has also been a good attempt at regional balancing, at least for those who are particular about ethnic balancing. The nominees are from the Western Province, the North-Western Province and the Northern Province. So, having three nominees from three provinces is fair enough. Thirdly, all the nominees are eminent citizens of Zambia. They are quite resourceful, and as a country, we stand to benefit from them. Fourthly, all the nominees meet the constitutional and statutory requirements, which is good. In view of that, we expect the Electoral Commission of Zambia (ECZ) to benefit immensely from the two nominees who are joining it, and the one being promoted.\n\u00a0\nMr Speaker, I am particularly happy with the inclusion of one retired military person, the Major-General, at the ECZ. At least, the people of Chimwemwe Parliamentary Constituency are comforted this time around. Unlike what we were seeing in the past, we are not likely to see mayhem being caused at the ECZ where some political party cadres or leaders who were not happy with one or two decisions by the commission decided to invade it. With this inclusion, we are comforted that such people will now have their heads sorted out and some sense will be pumped into them by the nominee who has a military background.\n\u00a0\nMr Speaker, last but not the least, I would like to give general advice to the nominees who are joining the ECZ. Firstly, they should strive to maintain the clean record that our country has in terms of the electoral process. At least, since Independence, we have not seen \u2018tippex\u2019 elections being conducted in Zambia, and that must be maintained.\n\u00a0\nMr Speaker, secondly, the people of Chimwemwe expect the nominees to stay away from battles involving politically exposed people. We do not want the nominees to join battles that they may not understand. We do not want to see situations whereby the ECZ drags a politically exposed person to court, but when asked why it is in court, it fails to answer. So, political battles must be left to politically exposed people.\n\u00a0\nMr Speaker, thirdly, we expect the nominees to work hand in hand with their colleagues to ensure that they secure adequate funding for the institution. We expect them to get adequate funding so that they can fund seminars where they should educate candidates and political party leaders on the importance of conceding defeat, whenever they find themselves on the losing side of political contests. Further, we expect the ECZ to conduct seminars to educate candidates and political party leaders on the importance of using civil language at political party rallies or even during door to door campaign meetings. When leaders do not understand some phrases, idioms or terms in local languages that they may not be familiar with, they should consult the local people so that they do not find themselves being accused of insulting people of a particular area.\n\u00a0\nMr Speaker, lastly, when the ECZ gets funding from the Ministry of Finance, it should educate political parties and their candidates that the huge attendance at political party rallies does not always translate into the votes cast for a candidate or political party. So, people must balance their investment into Facebook or WhatsApp campaigns, opinion polls and door to door campaigns when delivering their messages.\n\u00a0\nMr Speaker, with those few remarks, the people of Chimwemwe fully support the nominees.\n\u00a0\nI thank you, Sir.\n\u00a0\nDr Malama (Kanchibiya): Mr Speaker, I thank you for the opportunity to speak and I should indicate that I was part of the Committee. The selection of the nominees represents the goodwill His Excellency the President has for the Electoral Commission of Zambia (ECZ) and the electoral process in this country.\n\u00a0\nMr Speaker, you will note that high quality citizens have been nominated to serve on the ECZ. The nominee for the vice-chairperson position has vast experience with women organisations and Non-Governmental Organisations (NGOs). She is, indeed, a very experienced commissioner and one of the longest to serve on the commission. Therefore, one notes that she has a lot of experience to share in providing leadership.\n\u00a0\nMr Speaker, one of the nominees is a Major-General. You will note that a lot has been reported particularly regarding violence during election periods, and with the Major-General coming through, things will change. The nominee is a lecturer in the graduate programme in peace and conflict studies at the Copperbelt University, apart from having served as Deputy Army Commander. Therefore, having served as Deputy Army Commander, he brings on board rich experience to the ECZ and will provide leadership in the management of the electoral process in the country.\n\u00a0\nMr Speaker, Ambassador Mutiti has a lot of experience. As we heard, she worked in the Department of Immigration at the Ministry of Home Affairs and before that, she was a chief archivist. For twenty-eight years, she served in the Public Service very well, and ended up as Permanent Secretary in the Ministry of Home Affairs. She too brings on board rich experience to the ECZ from both her local and international experience. I also note that she served as our Ambassador in Zimbabwe and Australia. So, she brings on board not only a regional context, but also international context to the provision of leadership at the ECZ.\n\u00a0\nMr Speaker, as the appointments of the commissioners get ratified, I urge them that the task before them is mammoth because from its founding, Zambia has been a very peaceful nation. Therefore, some people who may want to make political space a place for violence should not be allowed to do that. Therefore, I urge the ECZ to work closely with law enforcement agents and other stakeholders to create a very meaningful space for everyone to participate in the electoral process, especially women, the disabled and, indeed, all those who feel they are able to contribute meaningfully to the political leadership of our country or to support those who stand for election. A lot is expected from the ECZ and we are grateful that it has continued to distinguish itself.\n\u00a0\nMr Speaker, we, therefore, urge the three Commissioners and, indeed, the entire ECZ to work very closely with the young men and women there to ensure that they work as expected. In this time of the Coronavirus Disease-2019 (COVID-19), we expect that they will be able to follow, very closely, practices and procedures as prescribed by the Government through the Ministry of Health in particular, so that the people who will be going to vote are protected.\n\u00a0\nMr Speaker, I suffered from the COVID-19 and I can say that it is a very bad disease. Therefore, I would not want to see anyone getting sick of it.\n\u00a0\nSir, may I take this opportunity to thank you for allowing me to speak on this very important subject.\n\u00a0\nI thank you, Mr Speaker.\n\u00a0\nMr Mwiimbu (Monze Central): Mr Speaker, I want to state that I am not going to comment on the qualifications of the individuals who have been appointed to serve as commissioners on the Electoral Commission of Zambia (ECZ). There is a saying which states that the taste of the pudding is in the eating. I am aware that on several occasions, we have been applauding a number of individuals who have been appointed to serve on various portfolios of the Government of Zambia, who have only come to disappoint us. So, I am not going to comment on whether the individuals are capable or incapable to serve the ECZ.\n\u00a0\nMr Speaker, however, I am going to comment on the institution that they are going to serve. The ECZ is a failed institution that has failed to manage elections in this country.\n\u00a0\nHon. Government Members: Question!\n\u00a0\nMr Mwiimbu: Mr Speaker, it is in public domain that despite the powers that have been endowed on the ECZ, it has failed to manage elections in this country and I will demonstrate what I mean.\n\u00a0\nHon. Government Members: Question!\n\u00a0\nMr Mwiimbu: Mr Speaker, we are aware that there is a code of conduct for all players in the electoral process in this country which is supposed to be managed by the ECZ in collaboration with the Zambia Police Service. Alas, whenever we have elections in this country and in particular by-elections, we have noted with concern as members of the public and players in the political arena the failures of the ECZ. We have noted that the ECZ has failed to ensure that the players in the political arena are given the latitude to campaign freely in the elections. Despite the numerous complaints that have been given to the ECZ, it has proved to be toothless.\n\u00a0\nMr Speaker: Order!\n\u00a0\nHon. Leader of the Opposition, give me a minute. You indicated in your preface that you will not comment on the qualifications, and of course, you are at liberty ...\n\u00a0\nMr Ngulube: You were lying!\n\u00a0\nMr Speaker: \u2026 not to do so. It was your choice and it was in order. However, we are dealing with a specific Motion here. The Motion is for ratification. I am concerned, if your debate will be exclusively devoted to appraising the performance of the Electoral Commission of Zambia (ECZ) because our business this afternoon is the ratification of nominees. That is the focus, but if we are going to seize this opportunity, instead, to review the operations and functions of the ECZ, independent of the Motion before us, then we will not be attending to the Motion. Please, proceed.\n\u00a0\nMr Mwiimbu: Mr Speaker, I have taken note of your guidance and instead of talking about the issues I wanted to raise, I will now talk about the individuals as you have guided.\n\u00a0\nSir, the individuals will not work in a vacuum. These individuals will be guided by the procedures and the laws that are obtaining at the ECZ. If the individuals find an institution that is impotent, the individuals will also be impotent.\n\u00a0\nMr Mwale: Question!\n\u00a0\nMr Mwiimbu: Mr Speaker, I was saying that currently, one of the commissioners whose appointment we are we are trying to ratify as vice-chairperson has been a commissioner and she was in Lukashya during the recent by-elections where hate speech and tribal issues were very prominent.\n\u00a0\nHon. Government Members: Insults!\n\u00a0\nInterruptions\n\u00a0\nMr Mwiimbu: Mr Speaker, \u2013\n\u00a0\nMr Speaker: Give me a minute. I want to put some order here. Hon. Members on the right, there is no need for running commentaries. I have already received a very long list from the right of individuals who would like to debate. I am sure when that time comes, you will speak. I do not think you elected to speak whilst seated. At least, there was no footnote that you will speak while seated.\n\u00a0\nLaughter\n\u00a0\nMr Speaker: So, let him debate in silence and then you respond. Continue hon. Member.\n\u00a0\nMr Mwiimbu: Mr Speaker, I was saying that the nominee for the vice-chairperson of the Commission was the one who was responsible for running the affairs of the ECZ in Lukashya. I did mention that in Lukashya, hate speech and violence were very prominent and there was no comment whatsoever, from the ECZ to ensure that the elections were free and fair. We hope that as she was superintending over the elections in Lukashya, she learnt a lesson to ensure that in future, she will be above board by ensuring that we are going to have free and fair elections in this country since she is already a commissioner.\n\u00a0\nMr Speaker, I do recall that when we had elections in Chilubi, the police had to order the Opposition leaders to leave Chilubi, which is contrary to the law. There is no regulation whatsoever, under the ECZ that when the President is in a particular area, other candidates cannot campaign. The ECZ was quiet and this vice-chairperson, whose appointment we are trying to ratify today, was already a commissioner and she was very loud in her silence in not condemning what had transpired in Chilubi. We have had so many instances of violence in this country and she has been quiet. We are aware that even leaders in this House, hon. Members of this Parliament were making hate speeches in various constituencies where they were campaigning and the ECZ did not take action. We hope that the lessons she is learning now pertaining to what transpired will make her a better commissioner in future. We should not allow impunity to reign in this country when we have commissioners who are supposed to be umpires in the political dispensation of this country.\n\u00a0\nMr Speaker, in its report, your Committee did make a comment pertaining to the roles of the commissioners. According to the report, these commissioners were being requested to be impartial when dealing with matters of elections in this country. As we are discussing this Motion today, there is a crisis pertaining to the registration of voters. The members of the public are crying and wondering why the ECZ is discarding the current voters\u2019 register when there is no law which empowers it to do that. The law requires the ECZ to continuously register voters. That is what the law says. However, without consulting the stakeholders, the ECZ, with impunity, has gone ahead to discard the voters\u2019 register.\n\u00a0\nSir, the hon. Member for Kanchibiya has talked about the Coronavirus Disease-2019 (COVID-19).\u00a0 Under the circumstances we are in, it is not possible for the ECZ to register 9 million voters in thirty days. Why should the ECZ not go back to the drawing board to consult the stakeholders? The major stakeholders are political parties. The political parties are stating that we should continue using the current voters\u2019 register. All we need to do is upgrade it. Otherwise, we are going to disenfranchise many people. It is, therefore, my appeal that those whose appointments are being considered for ratification must listen to what the people of Zambia are saying over the voters\u2019 register.\n\u00a0\n\u00a0I thank you, Sir.\n\u00a0\nMr Kundoti was inaudible.\n\u00a0\nThe Minister of Home Affairs (Mr Kampyongo): Mr Speaker, thank you so much for affording me an opportunity to make some comments on the Motion ably moved by the Chairperson of the Select Committee and seconded by Hon. Muchima. The Motion is seeking to ratify the appointment of Mrs Emily Joy Sikazwe to serve as Vice-Chairperson for the Electoral Commission of Zambia (ECZ) and also Mrs Ndiyoi Muliwana Mutiti and Major-General Vincent Mbaulu Mukanda (Rtd) to serve as members of the commission.\n\u00a0\nSir, I want to first of all, to commend the appointing authority for striking a balance in terms of gender and identifying these eminent citizens to be part of this very important institution. Speaking of Mrs Emily Sikazwe, who is one of the current commissioners of the ECZ, apart from her vast experience in civil society matters, she is a solid lady with an impeccable record. She has the character we need this time around, to deputise the chairperson. The ECZ is an institution which needs people with strong characters because the nature of us politicians is that when the situation does not suit us, we point fingers, like a losing team, at the referee when you are supposed to be polishing your skills. The referee is there to ensure a level playing field. So, we are encouraging Mrs Emily Sikazwe to continue with her strong character to help the chairperson in providing leadership in that very important institution.\n\u00a0\n\u00a0Sir, Mrs Ndiyoi Mutiti, is a seasoned civil servant who equally has vast experience and we expect her to be equal to the task. The Former Deputy Army Commander, since he comes with experience in conflict resolution and also from the security cluster, we are glad that he will bring some elements of security that are required to the ECZ.\n\u00a0\nMr Speaker, we are very grateful for these choices that the appointing authority made. The nominees are going to this institution at a very interesting time. At times, the hypocrisy of us politicians is surprising. In view of the Coronavirus Disease-2019 (COVID-19), which my hon. Colleague spoke about, we have changed the ways of doing business. We are embracing Information and Communication Technology\u00a0(ICT) platforms. I, therefore, do not know why it should be a problem for the ECZ to devise systems that should help citizens at critical times such as this one. If people want information, certainly the institution is there to provide that. We cannot condemn the institution for our own failures as political players. The commission is there to make sure that everyone participates in the processes. I just want to appeal to the commission to ensure that it takes some of the sentiments coming from reckless politicians seriously. Let it bite. As an important institution, it should learn to bite. We cannot allow individuals who cannot even win a ward by-election as councillors to claim rigging which they cannot substantiate.\nMr Speaker, in agreeing with Hon. Jack Mwiimbu, we are saying that we want this institution, working with law enforcement agencies, to be able to flex its muscle. The Zambia Police Service is there to supplement the efforts of the ECZ.\n\u00a0\nSir, in conclusion, I support these appointments and I have got no iota of doubt in my mind that these eminent citizens will be equal to task and that they will add value to this very important institution in our country.\n\u00a0\nI thank you, Sir.\n\u00a0\nThe Minister of Information and Broadcasting (Ms Siliya): Mr Speaker, I am not going to belabour the operations of the Electoral Commission of Zambia (ECZ). I want to begin by congratulating the appointing authority for bringing these names to House because we believe that these are competent individuals who are going to add value to the ECZ.\n\u00a0\nSir, I just want to very quickly make three points on the appointments at this time for an institution whose confidence some people are bent on eroding. The ECZ is the creation of this House, and we have a responsibility as hon. Members and as politicians to ensure that the confidence of this institution is not eroded. That is what the people of Zambia are looking to us for.\n\u00a0\nMr Speaker, next year will not be the first time the ECZ will be holding elections in this country. This country has been having elections for a very long time and yet, at every election, we have seen groups of politicians and political parties, even some misguided Non-Governmental Organisation (NGO) leaders continue on an agenda to erode the confidence of the ECZ. I believe that we should all reflect on the fact that this institution was created by us and it will continue to manage elections in this country.\u00a0\n\u00a0\nMr Speaker, my second point is on online voter registration. The ECZ has responded and refused to remain behind, like every institution in Zambia, for the very points that the Leader of the Opposition in the House raised. This period, during the Coronavirus Disease 2019 (COVID-19), is for redefining and doing work differently.\n\u00a0\nMr Speaker, the ECZ is an institution for the people of Zambia. It has to respond, especially, to the needs of young people, the 6 million Zambians who are thirty-five years and below. It has to find innovative ways to interest young people into coming onto the voters\u2019 register. This is why, just like the Government, through Smart Zambia, and the private sector, the ECZ has gone digital. The Government has invested in Information Communication Technology (ICT) in the whole country with over 90 per cent penetration of the internet, mobile phones, television and radio.\n\u00a0\nMr Speaker, young people want to participate in elections. So, if they are going to participate using online platforms, the ECZ will respond as such. We expect that the people being appointed today will continue to provide leadership to do things differently in this institution.\n\u00a0\nMr Speaker, allow me to address my last point. Again, I want to thank the appointing authority for capturing the spirit of the Constitution by reflecting the sexes in the country, women and men. He has reflected and captured the spirit of the Constitution that when there is a man, as the head, there should be a woman to deputise. His Excellency the President, Mr Edgar Lungu, has led on that agenda and this is why we have Her Honour the Vice-President sitting in this House.\n\u00a0\nHon. PF Members: Hear, hear!\n\u00a0\nMs Siliya: This is not a spirit we must ever forget. This country is made up of men and women.\n\u00a0\nHon. PF Members: Hear, hear!\n\u00a0\nMs Siliya: When there is a man as the head, we expect a woman to deputise and when there is a woman as the head, we expect a man to deputise.\n\u00a0\nSir, we congratulate Ms Emily Sikazwe for being recommended to deputise at the ECZ. In the many elections carried out in this country, there have been times when the women\u2019s agenda has been lost. We want to make sure that women\u2019s issues are captured in elections.\n\u00a0\nDr Malama: Correct!\n\u00a0\nMs Siliya: I am talking about widows who loose property because their husbands have died; women whose children are displaced because their husbands have died and the many issues that are mundane in elections, like issues of water, hospitals and clinics. We want to make sure that women are at the centre of elections. We, the women of Zambia, are saying that we are putting women at the ECZ because they are going to make sure that the woman\u2019s voice is heard in every issue to do with elections. That is a warning from the women to the men of Zambia.\n\u00a0\nI thank you, Mr Speaker.\n\u00a0\nHon. PF Members: Hear, hear!\n\u00a0\nDr Musokotwane (Liuwa): Mr Speaker, from the outset, I must say that I have difficulties with these nominations.\n\u00a0\nMr Speaker, many colleagues have only talked about the fact that the nominees are qualified. They have talked about qualification in terms of gender, academic credentials and regional diversity. However, the truth is that there is one qualification that people here have been silent about. The qualification is that of partisanship. It is this partisanship that Hon. Mwiimbu was talking about, whereby if there is an election, the Patriotic Front (PF) can do anything it wants, whether it is giving money openly, as is happening these days ...\n\u00a0\nHon. PF Members: No!\n\u00a0\nDr Musokotwane: ... or giving mealie meal openly \u2013\n\u00a0\nMr Ngulube: On a point of order, Sir.\n\u00a0\nInterruptions\n\u00a0\nMr Speaker: Take your seats both of you.\n\u00a0\nLet me make it clear that I am not allowing any points of order in this segment. If you want to contest any issue, I will give you an opportunity.\n\u00a0\nMr Ngulube: Hear, hear!\n\u00a0\nMr Speaker: Not personally, but as groupings.\n\u00a0\nLaughter\n\u00a0\nMr Ngulube: I receive, Mr Speaker.\n\u00a0\nMr Speaker: Hon. Member for Liuwa, please continue with your debate.\n\u00a0\nDr Musokotwane: So, we are seeing this partisanship when there are elections and when there is the registration of voters.\n\u00a0\nMr Speaker, I will tell you that, at the moment, National Registration Cards (NRCs) are being issued in Kalabo on a daily basis. However, the progress that is being made is very slow. Why? It is because on one day, there is no paper and the next day, there is no lamination. You can see that all this is just deliberate inefficiency to disenfranchise the people of the Western Province.\n\u00a0\nHon. PF Members: Question!\n\u00a0\nDr Musokotwane: Mr Speaker, for me, I would say that let us come out openly. The truth of the matter is that these commissioners are being appointed on the basis of partisanship. That being the case, I would rather we accept that this is the reality and then do what other countries are doing. In other countries, commissioners are not appointed by one person. The Minister of Home Affairs said that when a team loses, it should not blame the referee. However, in this particular case, the contestant is the one who is choosing referees. How is it expected that a ...\n\u00a0\nHon. UPND Members: Hear, hear!\n\u00a0\nDr Musokotwane: ... referee can be neutral when he/she has been appointed by a partisan person? So, the solution to this, as is happening in other countries, is that people just accept that the commission is going to be a partisan one. So, each political party can nominate a number of people to sit on the commission. That way, we can have a commission that is going to be fair because those partisan people sitting together would be able to judge cases, as they arise. For now, I consider the commission to be a partisan affair and, therefore, anyone going into this commission will conduct affairs on a partisan basis.\n\u00a0\nMr Speaker, I thank you.\n\u00a0\nThe Minister of Fisheries and Livestock (Prof Luo): Mr Speaker, I want to start by thanking His Excellency the President for appointing Mrs Emily Joy Sikazwe to serve as the Deputy Chairperson of the Electoral Commission of Zambia, Mrs Ndiyoi Mutiti and Major-General Vincent Mukanda (Rtd) as commissioners.\n\u00a0\nSir, look at the names that have been presented. Mrs Emily Sikazwe is a woman whose background is that of a scientist. By nature, a scientist interrogates and asks questions and believes in analysis. Therefore, she is going take this strength to the ECZ. Instead of speaking from without and creating stories that are non-existent, she will bring strength to the ECZ. This is a woman who has worked with civil society and has traversed the whole of Zambia. She understands the lives of Zambians, both poor and wealthy. She will bring that strength to the ECZ. There is no way she can make a judgement that can send Zambia into turmoil, which some of us here are trying to suggest. So, she comes with adequate competence and, I think, people must celebrate her.\n\u00a0\nSir, Mrs Ndiyoi Mutiti is a seasoned civil servant and has served as a diplomat. So, she brings this experience to the ECZ. Major-General Mukanga (Rtd) brings discipline not only to the commission, but also to the people that are going to participate in elections.\n\u00a0\nMr Speaker, why would anybody complain about online voter registration? I know some of us were born before the age of computers and I also know that some of us do not understand the benefits of technology. However, look, Zambia is not an island and will not remain behind simply because some of us do not know how to use technology and do not understand its benefits because we were born before the age of computers, especially so for those who are sitting on my right.\n\u00a0\nHon. PF Members: Hear, hear!\n\u00a0\nMr Mwiimbu rose\n\u00a0\nLaughter\n\u00a0\nMr Speaker: Order!\n\u00a0\nHon. Jack Mwiimbu, take your seat.\n\u00a0\nProf. Luo: We are going to use technology so that we can capture more people. I am surprised that somebody said that we cannot register 9 million people within a month. In fact, that is what technology enables us to do. It is going to improve the numbers. Those of you who do not celebrate technology, just watch the space.\n\u00a0\nMr Speaker, these tongues of ours can destroy a country. People create perceptions of hate speech, yet they are the orchestrators of hate speech. They say that there is violence, yet they are the orchestrators. The Mapatizya Formula was created by some people here, they are on my right and they know themselves. However, they want to pin it on people who are not violent. I think we need to engage in introspection. Even if they want to get into power, they should watch their language. The people of Zambia are watching. They know that when some people stand up to debate, the story is the same. The debate is about insults and tribalism. People will not listen to them.\u00a0\n\u00a0\nMr Speaker, I think that it is very important that we support the Motion on the Floor on the appointment of Mrs Emily Joy Sikazwe, as deputy chairperson, because she brings a wealth of experience to the ECZ. Those who know her and have worked with her know that for a fact. Mrs Ndiyoi Muliwana Mutiti brings a wealth of experience to the commission, and so does Major-General Vincent Mbaulu Mukanda (Rtd).\n\u00a0\nSir, I think Zambians should learn to celebrate people who are accomplished when they are alive. Do not wait until they die and pretend to be crying at the graveside. I have said that if people do not celebrate me now, I do not want them near my graveside. I will get up and slap Hon. Mwiimbu and then die again.\n\u00a0\nHon. Government Members: Hear, hear!\n\u00a0\nMr Speaker: Order!\n\u00a0\nThe hon. Minister\u2019s time expired.\n\u00a0\nHon. Members, we need to conclude this Motion before we rise. Therefore, I will begin winding down. I will ask the hon. Minister of Justice to debate.\n\u00a0\nThe Minister of Justice (Mr Lubinda): Mr Speaker, a number of people have spoken before me and have congratulated His Excellency the President for these appointments. As you might be aware, I represented the appointing authority to the Committee.\n\u00a0\nSir, let me start by commending your Committee for a job very well done. When I went to represent His Excellency, I sat before a Committee that had very eminent hon. Members of Parliament, some of whom deserve to be mentioned: Among them were Hon. Muchima, Member of Parliament for Ikeleng\u2019i, Hon. Mweetwa, Member of Parliament for Choma Central, and Hon. Mulyata, Member of Parliament for Rufunsa. Those three sat in that Committee and supported the nominations by His Excellency. Therefore, I would like to congratulate the three nominees on meeting the criteria that satisfied, particularly those three hon. Members whose names I have mentioned.\n\u00a0\nMr Speaker, some people have raised the issue about youths and people with disabilities being appointed. I want to assure the House that the appointing authority was very aware of the provisions of Articles 173 and 259 with regard to the appointment of youths and disabled people. Had he the choice, he would have done that. Unfortunately, for now, the people he found suitable, and the ones who were accepted by the Committee, are those three candidates. I want to also just reflect upon a few other issues that were raised by those who debated before me, particularly, those who rose first to support the nominees and use this opportunity to debate the institution.\nSir, when I stood up to debate a few days ago, I remarked on my anxiety at some of us in Parliament missing the issues of relevance of time, topic and place. Some matters are meant for Parliament and others are not. Today, the issue on the Floor is the ratification of the appointment of the three candidates.\n\u00a0\nMr Speaker, the eighteen years that I have spent in this House have taught me very clearly that if there is a matter that, I think, the nation ought to debate and whose resolution has to be arrived at by Parliament, it ought to be raised as a specific matter. You cannot raise a matter on the running of an institution when you are talking about the ratification of people to run the institution. This is because at the end of this debate, if a vote was to be put, the vote will be on whether we ratify the nominees or not. It will not have anything to do with the composition of the Electoral Commission of Zambia (ECZ). The composition of the ECZ is provided for in the Constitution at Article 229.\n\u00a0\nSir, if there is any hon. Member of Parliament who really wants to prove that he/she knows why he/she is in Parliament and wants to propose a change in the composition of the ECZ, that hon. Member will have to come here and propose an amendment to the Constitution. They have an opportunity to do just that, which we have given to them through the Constitution of Zambia (Amendment) Bill No. 10 of 2019. They should use The Constitution of Zambia (Amendment) Bill No. 10 of 2019 to discuss these matters. They cannot discuss the Constitution at the time when we are discussing the ratification of nominees to serve as commissioners. That is irrelevance of subject, time and place.\n\u00a0\nMr Speaker, to come and use this opportunity when ratifying these three eminently qualified people to talk about the Lukashya By-election just provokes others to remind the whole country that there were people who went to Lukashya to trade insults. Is this the opportunity for us to come and start laying bare those insults? It is not at all. That is not the reason for this Motion.\n\u00a0\nSir, I would like to say that if, indeed, people are concerned about regional balancing, like somebody mentioned, the Constitution provides guidelines on that. There are ten regions or provinces in the country and one would ask how the President is supposed to use three positions to cover ten provinces. What kind of magical formula would that be?\n\u00a0\nMr Speaker, my hon. Colleague from Chimwemwe already illustrated that His Excellency the President, in appointing the three nominees, looked across the country and picked one person from the North-Western Province and another from the Northern Province. By the way, I have mentioned on the Floor of this House that in Zambia today, simply to use a name and ascribe it to a region is a fallacy. This is because some people carry names that do not mean anything to them. What is in a name after all?\n\u00a0\nFor example, we have someone named Ndiyoi Mutiti. The name sounds like it is from the Western Province and the hon. Member for Chimwemwe said she hails from the Western Province. Yes, the name may come from the Western Province, but for the information of the House and for the satisfaction of the hon. Member of Parliament from Kalomo, Madam Ndiyoi Mutiti was actually socialised in Kalomo. She was born in Kalomo, went to school in Kalomo and if you look at her composition and character, she is a representative of Kalomo. However, today, the hon. Member of Parliament for Kalomo Central is disowning her simply because of her name. What a shame.\n\u00a0\nInterruptions\n\u00a0\nMr Lubinda: Mr Speaker, those who come to this House and use it in an attempt to fan tribalism must be condemned. We must not use this House to peddle tribalism. We must look at Zambians for whom they are. This is the reason we, in the Patriotic Front (PF), revived the slogan of \u2018One Zambia, One Nation\u2019 and we shall continue on that trajectory.\n\u00a0\nInterruptions\n\u00a0\nMr Lubinda: Sir, eighteen years of being a Parliamentarian requires one \u2013\n\u00a0\nMr Speaker: I hope the hon. Minister will allow for this Motion to be concluded.\n\u00a0Mr Lubinda: Thank you, Sir.\n\u00a0\nMr Speaker, let me end by saying that eighteen years of parliamentarianism must be seen in how a person articulates issues and guides those who come after him/her and not mislead them.\n\u00a0\nSir, I heard one hon. Member say that the ECZ is partisan. Indeed, if the ECZ was partisan in Kabwata, was it not partisan in Monze and Liuwa? If Mrs Emily Joy Sikazwe was partisan in Liuwa and Kabwata, she is a very good partisan person. She should continue being partisan by ensuring that the people elect those who they want to govern them without fear and intimidation. As a matter of fact, when we were ratifying the appointment of Mrs Emily Joy Sikazwe for the first time in this House, some people on the left started talking about her nationality. However, she has proven beyond doubt that she is even more patriotic than some people who claim to be more Zambian than others.\n\u00a0\nMr Speaker, I would like to end by thanking your Committee for this well-thought-through report and for approving the ratification of the three eminently qualified persons, whom I am sure shall serve this country without reproach.\n\u00a0\nMr Speaker, I thank you.\n\u00a0\nHon. Government Members: Hear, hear!\n\u00a0\nMs Kabanshi: Mr Speaker, let me start by thanking the hon. Minister of Justice, the hon. Minister of Fisheries and Livestock, the hon. Minister of Home Affairs and the hon. Minister of Information and Broadcasting. I also thank the seconder of the Motion, who seconded it ably and professionally, all the members of your Committee who were very professional, as we deliberated on the Motion, and all the hon. Members of Parliament who have contributed to the debate on the Motion.\n\u00a0\nSir, the hon. Ministers and hon. Members who debated this Motion brought up many issues that will be taken note of. The secretariat will take all those issues into consideration.\n\u00a0\nMr Speaker, I thank you.\n\u00a0\nQuestion put and agreed to.\n\u00a0\n______\n\u00a0\nBILLS\n\u00a0\nHOUSE IN COMMITTEE\n\u00a0\n[THE CHAIRPERSON OF COMMITTEES in the \nChair]\n\u00a0\nTHE FOOD AND NUTRITION BILL, 2020\n\u00a0\nClauses 1, 2, 3 and 4 ordered to stand part of the Bill.\nCLAUSE 5 \u2013 (Functions of Commission)\n\u00a0\nThe Minister of Health (Dr Chilufya): Madam Chairperson, I beg to move an amendment in Clause 5, on page 9, in line 18 by the deletion of paragraph (I) and the substitution therefor of the following:\n\u00a0\nin consultation with the Higher Education Authority, co-ordinate food and nutrition training, in national food and nutrition programmes;\n\u00a0\nAmendment agreed to. Clause amended accordingly.\n\u00a0\nClause 5, as amended, ordered to stand part of the Bill.\n\u00a0\nThe Chairperson: Order!\n\u00a0\n_______\n\u00a0\nHOUSE RESUMED\n\u00a0\n[MR SPEAKER in the Chair]\n\u00a0\nThe following Bill was reported to the House as having passed through Committee with amendments:\n\u00a0\nThe Food and Nutrition Bill, 2020\n\u00a0\n_______\n\u00a0\nMr Speaker: Order!\n\u00a0\n(Debate adjourned)\n\u00a0\n_______\n\u00a0\nThe House adjourned at 1658 hours until 1430 hours on Thursday, 1st October, 2020.\n\u00a0\n____________\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n \n\n\n\n\n\n\n\n\n\n\n\n\nPublic Financial Management Handbook\n\n\n\n\nOrder Paper\n\n\n\n\n Wednesday, 30th September, 2020  \n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nparliament.gov.zm\n\n\n\n\n\n\n\n\n\n\nHome\nAbout ParliamentAbout National Assembly\nHistory\nThe Clerk's OfficeThe Clerk\nDepartments\n\nCareers at Parliament\nProcurement\nVisiting parliament\nContact Us\nParliamentary Calendar\n\nMembersPresiding OfficersThe Speaker\nThe First Deputy Speaker\nThe Second Deputy Speaker\n\nMinistersCabinet Ministers\nProvincial Ministers\n\nWhips\nMembers of ParliamentGender Representation\nParty Representation\nMembers List\n\nConstituencies\nImmediate Past MPs\n\nCommitteesCommittee System\nCommittees\nAttendance Guidlines\nCommittee Composition\nCommittee Timetable\nCommittee ReportsMain\nBills\nSelect (Ad Hoc)\nTreaties/ Agreements\n\nSubmission Procedure\nMake Your Submission\n\nPublicationsSpeaker's Rulings\nOrder Paper\nDebates and ProceedingsDebates and Proceedings\nDebates and Proceedings (OLD)\n\nVotes and Proceedings\nBudget Speech\nYellow Book\nPresidential Speeches\nLaws of ZambiaActs\nBills\nBills - Not Presented\nLaws of Zambia\n\nConstitution Amendment Act 2016\nMinisterial Statements\nLibrary E-Resources\nGovernment Agreements\nFramework\n\n \n\n\n\n\n\n\n\n\n\n\nUse Policy\nContact Us\nMail\nRadio\n\n\n\u00a9 2020 National Assembly of Zambia.Powered by Drupal\n\n\n\n\n\n\n\n"
  },
  {
    "text": "\n\n\n\n\n\n\nToggle navigation\n\n\n\n\nTopics by WorldWideScience.org\n\n\n\nHome\nAbout\nNews\nAdvanced Search\nContact Us\nSite Map\nHelp\n\n\n\n\nSample records for backpropagation learning algorithm\n\n\n\n\n\n\u00ab\n1\n2\n3\n4\n5\n\u00bb\n\n\n\n\n\n\n\n\nTAO-robust backpropagation learning algorithm.\nScience.gov (United States)\nPern\u00c3\u00ada-Espinoza, Alpha V; Ordieres-Mer\u00c3\u00a9, Joaqu\u00c3\u00adn B; Mart\u00c3\u00adnez-de-Pis\u00c3\u00b3n, Francisco J; Gonz\u00c3\u00a1lez-Marcos, Ana\n2005-03-01\nIn several fields, as industrial modelling, multilayer feedforward neural networks are often used as universal function approximations. These supervised neural networks are commonly trained by a traditional backpropagation learning format, which minimises the mean squared error (mse) of the training data. However, in the presence of corrupted data (outliers) this training scheme may produce wrong models. We combine the benefits of the non-linear regression model tau-estimates [introduced by Tabatabai, M. A. Argyros, I. K. Robust Estimation and testing for general nonlinear regression models. Applied Mathematics and Computation. 58 (1993) 85-101] with the backpropagation algorithm to produce the TAO-robust learning algorithm, in order to deal with the problems of modelling with outliers. The cost function of this approach has a bounded influence function given by the weighted average of two psi functions, one corresponding to a very robust estimate and the other to a highly efficient estimate. The advantages of the proposed algorithm are studied with an example.\n\n\nQuick fuzzy backpropagation algorithm.\nScience.gov (United States)\nNikov, A; Stoeva, S\n2001-03-01\nA modification of the fuzzy backpropagation (FBP) algorithm called QuickFBP algorithm is proposed, where the computation of the net function is significantly quicker. It is proved that the FBP algorithm is of exponential time complexity, while the QuickFBP algorithm is of polynomial time complexity. Convergence conditions of the QuickFBP, resp. the FBP algorithm are defined and proved for: (1) single output neural networks in case of training patterns with different targets; and (2) multiple output neural networks in case of training patterns with equivalued target vector. They support the automation of the weights training process (quasi-unsupervised learning) establishing the target value(s) depending on the network's input values. In these cases the simulation results confirm the convergence of both algorithms. An example with a large-sized neural network illustrates the significantly greater training speed of the QuickFBP rather than the FBP algorithm. The adaptation of an interactive web system to users on the basis of the QuickFBP algorithm is presented. Since the QuickFBP algorithm ensures quasi-unsupervised learning, this implies its broad applicability in areas of adaptive and adaptable interactive systems, data mining, etc. applications.\n\n\nA new backpropagation learning algorithm for layered neural networks with nondifferentiable units.\nScience.gov (United States)\nOohori, Takahumi; Naganuma, Hidenori; Watanabe, Kazuhisa\n2007-05-01\nWe propose a digital version of the backpropagation algorithm (DBP) for three-layered neural networks with nondifferentiable binary units. This approach feeds teacher signals to both the middle and output layers, whereas with a simple perceptron, they are given only to the output layer. The additional teacher signals enable the DBP to update the coupling weights not only between the middle and output layers but also between the input and middle layers. A neural network based on DBP learning is fast and easy to implement in hardware. Simulation results for several linearly nonseparable problems such as XOR demonstrate that the DBP performs favorably when compared to the conventional approaches. Furthermore, in large-scale networks, simulation results indicate that the DBP provides high performance.\n\n\nAn efficient implementation of a backpropagation learning algorithm on quadrics parallel supercomputer\nInternational Nuclear Information System (INIS) \nTaraglio, S.; Massaioli, F.\n1995-08-01\nA parallel implementation of a library to build and train Multi Layer Perceptrons via the Back Propagation algorithm is presented. The target machine is the SIMD massively parallel supercomputer Quadrics. Performance measures are provided on three different machines with different number of processors, for two network examples. A sample source code is given\n\n\nRandom synaptic feedback weights support error backpropagation for deep learning\nScience.gov (United States)\nLillicrap, Timothy P.; Cownden, Daniel; Tweed, Douglas B.; Akerman, Colin J.\n2016-01-01\nThe brain processes information through multiple layers of neurons. This deep architecture is representationally powerful, but complicates learning because it is difficult to identify the responsible neurons when a mistake is made. In machine learning, the backpropagation algorithm assigns blame by multiplying error signals with all the synaptic weights on each neuron's axon and further downstream. However, this involves a precise, symmetric backward connectivity pattern, which is thought to be impossible in the brain. Here we demonstrate that this strong architectural constraint is not required for effective error propagation. We present a surprisingly simple mechanism that assigns blame by multiplying errors by even random synaptic weights. This mechanism can transmit teaching signals across multiple layers of neurons and performs as effectively as backpropagation on a variety of tasks. Our results help reopen questions about how the brain could use error signals and dispel long-held assumptions about algorithmic constraints on learning. PMID:27824044\n\n\nInvestigating the performance of neural network backpropagation algorithms for TEC estimations using South African GPS data\nScience.gov (United States)\nHabarulema, J. B.; McKinnell, L.-A.\n2012-05-01\nIn this work, results obtained by investigating the application of different neural network backpropagation training algorithms are presented. This was done to assess the performance accuracy of each training algorithm in total electron content (TEC) estimations using identical datasets in models development and verification processes. Investigated training algorithms are standard backpropagation (SBP), backpropagation with weight delay (BPWD), backpropagation with momentum (BPM) term, backpropagation with chunkwise weight update (BPC) and backpropagation for batch (BPB) training. These five algorithms are inbuilt functions within the Stuttgart Neural Network Simulator (SNNS) and the main objective was to find out the training algorithm that generates the minimum error between the TEC derived from Global Positioning System (GPS) observations and the modelled TEC data. Another investigated algorithm is the MatLab based Levenberg-Marquardt backpropagation (L-MBP), which achieves convergence after the least number of iterations during training. In this paper, neural network (NN) models were developed using hourly TEC data (for 8 years: 2000-2007) derived from GPS observations over a receiver station located at Sutherland (SUTH) (32.38\u00c2\u00b0 S, 20.81\u00c2\u00b0 E), South Africa. Verification of the NN models for all algorithms considered was performed on both \"seen\" and \"unseen\" data. Hourly TEC values over SUTH for 2003 formed the \"seen\" dataset. The \"unseen\" dataset consisted of hourly TEC data for 2002 and 2008 over Cape Town (CPTN) (33.95\u00c2\u00b0 S, 18.47\u00c2\u00b0 E) and SUTH, respectively. The models' verification showed that all algorithms investigated provide comparable results statistically, but differ significantly in terms of time required to achieve convergence during input-output data training/learning. This paper therefore provides a guide to neural network users for choosing appropriate algorithms based on the availability of computation capabilities used for research.\n\n\nFast Back-Propagation Learning Using Steep Activation Functions and Automatic Weight\nScience.gov (United States)\nTai-Hoon Cho; Richard W. Conners; Philip A. Araman\n1992-01-01\nIn this paper, several back-propagation (BP) learning speed-up algorithms that employ the \u00c3\u0192\u00c2\u00a3gain\u00c3\u0192\u00c2\u00a4 parameter, i.e., steepness of the activation function, are examined. Simulations will show that increasing the gain seemingly increases the speed of convergence and that these algorithms can converge faster than the standard BP learning algorithm on some problems. However,...\n\n\nAnalysis Resilient Algorithm on Artificial Neural Network Backpropagation\nScience.gov (United States)\nSaputra, Widodo; Tulus; Zarlis, Muhammad; Widia Sembiring, Rahmat; Hartama, Dedy\n2017-12-01\nPrediction required by decision makers to anticipate future planning. Artificial Neural Network (ANN) Backpropagation is one of method. This method however still has weakness, for long training time. This is a reason to improve a method to accelerate the training. One of Artificial Neural Network (ANN) Backpropagation method is a resilient method. Resilient method of changing weights and bias network with direct adaptation process of weighting based on local gradient information from every learning iteration. Predicting data result of Istanbul Stock Exchange training getting better. Mean Square Error (MSE) value is getting smaller and increasing accuracy.\n\n\nConvergence of Batch Split-Complex Backpropagation Algorithm for Complex-Valued Neural Networks\nDirectory of Open Access Journals (Sweden)\nHuisheng Zhang\n2009-01-01\nFull Text Available The batch split-complex backpropagation (BSCBP algorithm for training complex-valued neural networks is considered. For constant learning rate, it is proved that the error function of BSCBP algorithm is monotone during the training iteration process, and the gradient of the error function tends to zero. By adding a moderate condition, the weights sequence itself is also proved to be convergent. A numerical example is given to support the theoretical analysis.\n\n\nEnhanced backpropagation training algorithm for transient event identification\nInternational Nuclear Information System (INIS) \nVitela, J.; Reifman, J.\n1993-01-01\nWe present an enhanced backpropagation (BP) algorithm for training feedforward neural networks that avoids the undesirable premature saturation of the network output nodes and accelerates the training process even in cases where premature saturation is not present. When the standard BP algorithm is applied to train patterns of nuclear power plant (NPP) transients, the network output nodes often become prematurely saturated causing the already slow rate of convergence of the algorithm to become even slower. When premature saturation occurs, the gradient of the prediction error becomes very small, although the prediction error itself is still large, yielding negligible weight updates and hence no significant decrease in the prediction error until the eventual recovery of the output nodes from saturation. By defining the onset of premature saturation and systematically modifying the gradient of the prediction error at saturation, we developed an enhanced BP algorithm that is compared with the standard BP algorithm in training a network to identify NPP transients\n\n\nEvolving Resilient Back-Propagation Algorithm for Energy Efficiency Problem\nDirectory of Open Access Journals (Sweden)\nYang Fei\n2016-01-01\nFull Text Available Energy efficiency is one of our most economical sources of new energy. When it comes to efficient building design, the computation of the heating load (HL and cooling load (CL is required to determine the specifications of the heating and cooling equipment. The objective of this paper is to model heating load and cooling load buildings using neural networks in order to predict HL load and CL load. Rprop with genetic algorithm was proposed to increase the global convergence capability of Rprop by modifying a corresponding weight. Comparison results show that Rprop with GA can successfully improve the global convergence capability of Rprop and achieve lower MSE than other perceptron training algorithms, such as Back-Propagation or original Rprop. In addition, the trained network has better generalization ability and stabilization performance.\n\n\nThe interchangeability of learning rate and gain in backpropagation neural networks\nNARCIS (Netherlands)\nThimm, G.; Moerland, P.; Fiesler, E.\n1996-01-01\nThe backpropagation algorithm is widely used for training multilayer neural networks. In this publication the gain of its activation function(s) is investigated. In specific, it is proven that changing the gain of the activation function is equivalent to changing the learning rate and the weights.\n\n\nA modified backpropagation algorithm for training neural networks on data with error bars\nInternational Nuclear Information System (INIS) \nGernoth, K.A.; Clark, J.W.\n1994-08-01\nA method is proposed for training multilayer feedforward neural networks on data contaminated with noise. Specifically, we consider the case that the artificial neural system is required to learn a physical mapping when the available values of the target variable are subject to experimental uncertainties, but are characterized by error bars. The proposed method, based on maximum likelihood criterion for parameter estimation, involves simple modifications of the on-line backpropagation learning algorithm. These include incorporation of the error-bar assignments in a pattern-specific learning rate, together with epochal updating of a new measure of model accuracy that replaces the usual mean-square error. The extended backpropagation algorithm is successfully tested on two problems relevant to the modelling of atomic-mass systematics by neural networks. Provided the underlying mapping is reasonably smooth, neural nets trained with the new procedure are able to learn the true function to a good approximation even in the presence of high levels of Gaussian noise. (author). 26 refs, 2 figs, 5 tabs\n\n\nRelay Backpropagation for Effective Learning of Deep Convolutional Neural Networks\nOpenAIRE\nShen, Li; Lin, Zhouchen; Huang, Qingming\n2015-01-01\nLearning deeper convolutional neural networks becomes a tendency in recent years. However, many empirical evidences suggest that performance improvement cannot be gained by simply stacking more layers. In this paper, we consider the issue from an information theoretical perspective, and propose a novel method Relay Backpropagation, that encourages the propagation of effective information through the network in training stage. By virtue of the method, we achieved the first place in ILSVRC 2015...\n\n\nNeural network design with combined backpropagation and creeping random search learning algorithms applied to the determination of retained austenite in TRIP steels; Diseno de redes neuronales con aprendizaje combinado de retropropagacion y busqueda aleatoria progresiva aplicado a la determinacion de austenita retenida en aceros TRIP\nEnergy Technology Data Exchange (ETDEWEB)\nToda-Caraballo, I.; Garcia-Mateo, C.; Capdevila, C.\n2010-07-01\nAt the beginning of the decade of the nineties, the industrial interest for TRIP steels leads to a significant increase of the investigation and application in this field. In this work, the flexibility of neural networks for the modelling of complex properties is used to tackle the problem of determining the retained austenite content in TRIP-steel. Applying a combination of two learning algorithms (backpropagation and creeping-random-search) for the neural network, a model has been created that enables the prediction of retained austenite in low-Si / low-Al multiphase steels as a function of processing parameters. (Author). 34 refs.\n\n\nEvent-Driven Random Back-Propagation: Enabling Neuromorphic Deep Learning Machines.\nScience.gov (United States)\nNeftci, Emre O; Augustine, Charles; Paul, Somnath; Detorakis, Georgios\n2017-01-01\nAn ongoing challenge in neuromorphic computing is to devise general and computationally efficient models of inference and learning which are compatible with the spatial and temporal constraints of the brain. One increasingly popular and successful approach is to take inspiration from inference and learning algorithms used in deep neural networks. However, the workhorse of deep learning, the gradient descent Gradient Back Propagation (BP) rule, often relies on the immediate availability of network-wide information stored with high-precision memory during learning, and precise operations that are difficult to realize in neuromorphic hardware. Remarkably, recent work showed that exact backpropagated gradients are not essential for learning deep representations. Building on these results, we demonstrate an event-driven random BP (eRBP) rule that uses an error-modulated synaptic plasticity for learning deep representations. Using a two-compartment Leaky Integrate & Fire (I&F) neuron, the rule requires only one addition and two comparisons for each synaptic weight, making it very suitable for implementation in digital or mixed-signal neuromorphic hardware. Our results show that using eRBP, deep representations are rapidly learned, achieving classification accuracies on permutation invariant datasets comparable to those obtained in artificial neural network simulations on GPUs, while being robust to neural and synaptic state quantizations during learning.\n\n\nEvent-Driven Random Back-Propagation: Enabling Neuromorphic Deep Learning Machines\nDirectory of Open Access Journals (Sweden)\nEmre O. Neftci\n2017-06-01\nFull Text Available An ongoing challenge in neuromorphic computing is to devise general and computationally efficient models of inference and learning which are compatible with the spatial and temporal constraints of the brain. One increasingly popular and successful approach is to take inspiration from inference and learning algorithms used in deep neural networks. However, the workhorse of deep learning, the gradient descent Gradient Back Propagation (BP rule, often relies on the immediate availability of network-wide information stored with high-precision memory during learning, and precise operations that are difficult to realize in neuromorphic hardware. Remarkably, recent work showed that exact backpropagated gradients are not essential for learning deep representations. Building on these results, we demonstrate an event-driven random BP (eRBP rule that uses an error-modulated synaptic plasticity for learning deep representations. Using a two-compartment Leaky Integrate & Fire (I&F neuron, the rule requires only one addition and two comparisons for each synaptic weight, making it very suitable for implementation in digital or mixed-signal neuromorphic hardware. Our results show that using eRBP, deep representations are rapidly learned, achieving classification accuracies on permutation invariant datasets comparable to those obtained in artificial neural network simulations on GPUs, while being robust to neural and synaptic state quantizations during learning.\n\n\nAutonomous path planning solution for industrial robot manipulator using backpropagation algorithm\nDirectory of Open Access Journals (Sweden)\nPeiJiang Yuan\n2015-12-01\nFull Text Available Here, we propose an autonomous path planning solution using backpropagation algorithm. The mechanism of movement used by humans in controlling their arms is analyzed and then applied to control a robot manipulator. Autonomous path planning solution is a numerical method. The model of industrial robot manipulator used in this article is a KUKA KR 210 R2700 EXTRA robot. In order to show the performance of the autonomous path planning solution, an experiment validation of path tracking is provided. Experiment validation consists of implementation of the autonomous path planning solution and the control of physical robot. The process of converging to target solution is provided. The mean absolute error of position for tool center point is also analyzed. Comparison between autonomous path planning solution and the numerical methods based on Newton\u00e2\u20ac\u201cRaphson algorithm is provided to demonstrate the efficiency and accuracy of the autonomous path planning solution.\n\n\nThe performance of the backpropagation algorithm with varying slope of the activation function\nInternational Nuclear Information System (INIS) \nBai Yanping; Zhang Haixia; Hao Yilong\n2009-01-01\nSome adaptations are proposed to the basic BP algorithm in order to provide an efficient method to non-linear data learning and prediction. In this paper, an adopted BP algorithm with varying slope of activation function and different learning rates is put forward. The results of experiment indicated that this algorithm can get very good performance of training. We also test the prediction performance of our adopted BP algorithm on 16 instances. We compared the test results to the ones of the BP algorithm with gradient descent momentum and an adaptive learning rate. The results indicate this adopted BP algorithm gives best performance (100%) for test example, which conclude this adopted BP algorithm produces a smoothed reconstruction that learns better to new prediction function values than the BP algorithm improved with momentum.\n\n\nA Newton-type neural network learning algorithm\nInternational Nuclear Information System (INIS) \nIvanov, V.V.; Puzynin, I.V.; Purehvdorzh, B.\n1993-01-01\nFirst- and second-order learning methods for feed-forward multilayer networks are considered. A Newton-type algorithm is proposed and compared with the common back-propagation algorithm. It is shown that the proposed algorithm provides better learning quality. Some recommendations for their usage are given. 11 refs.; 1 fig.; 1 tab\n\n\n\n\n\u00ab\n1\n2\n3\n4\n5\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n1\n2\n3\n4\n5\n\u00bb\n\n\n\n\n\n\n\n\nHardware-Efficient On-line Learning through Pipelined Truncated-Error Backpropagation in Binary-State Networks\nDirectory of Open Access Journals (Sweden)\nHesham Mostafa\n2017-09-01\nFull Text Available Artificial neural networks (ANNs trained using backpropagation are powerful learning architectures that have achieved state-of-the-art performance in various benchmarks. Significant effort has been devoted to developing custom silicon devices to accelerate inference in ANNs. Accelerating the training phase, however, has attracted relatively little attention. In this paper, we describe a hardware-efficient on-line learning technique for feedforward multi-layer ANNs that is based on pipelined backpropagation. Learning is performed in parallel with inference in the forward pass, removing the need for an explicit backward pass and requiring no extra weight lookup. By using binary state variables in the feedforward network and ternary errors in truncated-error backpropagation, the need for any multiplications in the forward and backward passes is removed, and memory requirements for the pipelining are drastically reduced. Further reduction in addition operations owing to the sparsity in the forward neural and backpropagating error signal paths contributes to highly efficient hardware implementation. For proof-of-concept validation, we demonstrate on-line learning of MNIST handwritten digit classification on a Spartan 6 FPGA interfacing with an external 1Gb DDR2 DRAM, that shows small degradation in test error performance compared to an equivalently sized binary ANN trained off-line using standard back-propagation and exact errors. Our results highlight an attractive synergy between pipelined backpropagation and binary-state networks in substantially reducing computation and memory requirements, making pipelined on-line learning practical in deep networks.\n\n\nHardware-Efficient On-line Learning through Pipelined Truncated-Error Backpropagation in Binary-State Networks.\nScience.gov (United States)\nMostafa, Hesham; Pedroni, Bruno; Sheik, Sadique; Cauwenberghs, Gert\n2017-01-01\nArtificial neural networks (ANNs) trained using backpropagation are powerful learning architectures that have achieved state-of-the-art performance in various benchmarks. Significant effort has been devoted to developing custom silicon devices to accelerate inference in ANNs. Accelerating the training phase, however, has attracted relatively little attention. In this paper, we describe a hardware-efficient on-line learning technique for feedforward multi-layer ANNs that is based on pipelined backpropagation. Learning is performed in parallel with inference in the forward pass, removing the need for an explicit backward pass and requiring no extra weight lookup. By using binary state variables in the feedforward network and ternary errors in truncated-error backpropagation, the need for any multiplications in the forward and backward passes is removed, and memory requirements for the pipelining are drastically reduced. Further reduction in addition operations owing to the sparsity in the forward neural and backpropagating error signal paths contributes to highly efficient hardware implementation. For proof-of-concept validation, we demonstrate on-line learning of MNIST handwritten digit classification on a Spartan 6 FPGA interfacing with an external 1Gb DDR2 DRAM, that shows small degradation in test error performance compared to an equivalently sized binary ANN trained off-line using standard back-propagation and exact errors. Our results highlight an attractive synergy between pipelined backpropagation and binary-state networks in substantially reducing computation and memory requirements, making pipelined on-line learning practical in deep networks.\n\n\nAn Adaptive Filtering Algorithm Based on Genetic Algorithm-Backpropagation Network\nDirectory of Open Access Journals (Sweden)\nKai Hu\n2013-01-01\nFull Text Available A new image filtering algorithm is proposed. GA-BPN algorithm uses genetic algorithm (GA to decide weights in a back propagation neural network (BPN. It has better global optimal characteristics than traditional optimal algorithm. In this paper, we used GA-BPN to do image noise filter researching work. Firstly, this paper uses training samples to train GA-BPN as the noise detector. Then, we utilize the well-trained GA-BPN to recognize noise pixels in target image. And at last, an adaptive weighted average algorithm is used to recover noise pixels recognized by GA-BPN. Experiment data shows that this algorithm has better performance than other filters.\n\n\nAnalysis of Accuracy and Epoch on Back-propagation BFGS Quasi-Newton\nScience.gov (United States)\nSilaban, Herlan; Zarlis, Muhammad; Sawaluddin\n2017-12-01\nBack-propagation is one of the learning algorithms on artificial neural networks that have been widely used to solve various problems, such as pattern recognition, prediction and classification. The Back-propagation architecture will affect the outcome of learning processed. BFGS Quasi-Newton is one of the functions that can be used to change the weight of back-propagation. This research tested some back-propagation architectures using classical back-propagation and back-propagation with BFGS. There are 7 architectures that have been tested on glass dataset with various numbers of neurons, 6 architectures with 1 hidden layer and 1 architecture with 2 hidden layers. BP with BFGS improves the convergence of the learning process. The average improvement convergence is 98.34%. BP with BFGS is more optimal on architectures with smaller number of neurons with decreased epoch number is 94.37% with the increase of accuracy about 0.5%.\n\n\nGradient descent learning algorithm overview: a general dynamical systems perspective.\nScience.gov (United States)\nBaldi, P\n1995-01-01\nGives a unified treatment of gradient descent learning algorithms for neural networks using a general framework of dynamical systems. This general approach organizes and simplifies all the known algorithms and results which have been originally derived for different problems (fixed point/trajectory learning), for different models (discrete/continuous), for different architectures (forward/recurrent), and using different techniques (backpropagation, variational calculus, adjoint methods, etc.). The general approach can also be applied to derive new algorithms. The author then briefly examines some of the complexity issues and limitations intrinsic to gradient descent learning. Throughout the paper, the author focuses on the problem of trajectory learning.\n\n\nALPHABET SIGN LANGUAGE RECOGNITION USING LEAP MOTION TECHNOLOGY AND RULE BASED BACKPROPAGATION-GENETIC ALGORITHM NEURAL NETWORK (RBBPGANN\nDirectory of Open Access Journals (Sweden)\nWijayanti Nurul Khotimah\n2017-01-01\nFull Text Available Sign Language recognition was used to help people with normal hearing communicate effectively with the deaf and hearing-impaired. Based on survey that conducted by Multi-Center Study in Southeast Asia, Indonesia was on the top four position in number of patients with hearing disability (4.6%. Therefore, the existence of Sign Language recognition is important. Some research has been conducted on this field. Many neural network types had been used for recognizing many kinds of sign languages. However, their performance are need to be improved. This work focuses on the ASL (Alphabet Sign Language in SIBI (Sign System of Indonesian Language which uses one hand and 26 gestures. Here, thirty four features were extracted by using Leap Motion. Further, a new method, Rule Based-Backpropagation Genetic Al-gorithm Neural Network (RB-BPGANN, was used to recognize these Sign Languages. This method is combination of Rule and Back Propagation Neural Network (BPGANN. Based on experiment this pro-posed application can recognize Sign Language up to 93.8% accuracy. It was very good to recognize large multiclass instance and can be solution of overfitting problem in Neural Network algorithm.\n\n\nModified multiblock partial least squares path modeling algorithm with backpropagation neural networks approach\nScience.gov (United States)\nYuniarto, Budi; Kurniawan, Robert\n2017-03-01\nPLS Path Modeling (PLS-PM) is different from covariance based SEM, where PLS-PM use an approach based on variance or component, therefore, PLS-PM is also known as a component based SEM. Multiblock Partial Least Squares (MBPLS) is a method in PLS regression which can be used in PLS Path Modeling which known as Multiblock PLS Path Modeling (MBPLS-PM). This method uses an iterative procedure in its algorithm. This research aims to modify MBPLS-PM with Back Propagation Neural Network approach. The result is MBPLS-PM algorithm can be modified using the Back Propagation Neural Network approach to replace the iterative process in backward and forward step to get the matrix t and the matrix u in the algorithm. By modifying the MBPLS-PM algorithm using Back Propagation Neural Network approach, the model parameters obtained are relatively not significantly different compared to model parameters obtained by original MBPLS-PM algorithm.\n\n\nEvent-Driven Random Back-Propagation: Enabling Neuromorphic Deep Learning Machines\nOpenAIRE\nNeftci, Emre O.; Augustine, Charles; Paul, Somnath; Detorakis, Georgios\n2017-01-01\nAn ongoing challenge in neuromorphic computing is to devise general and computationally efficient models of inference and learning which are compatible with the spatial and temporal constraints of the brain. One increasingly popular and successful approach is to take inspiration from inference and learning algorithms used in deep neural networks. However, the workhorse of deep learning, the gradient descent Gradient Back Propagation (BP) rule, often relies on the immediate availability of net...\n\n\nHuman activity recognition based on feature selection in smart home using back-propagation algorithm.\nScience.gov (United States)\nFang, Hongqing; He, Lei; Si, Hao; Liu, Peng; Xie, Xiaolei\n2014-09-01\nIn this paper, Back-propagation(BP) algorithm has been used to train the feed forward neural network for human activity recognition in smart home environments, and inter-class distance method for feature selection of observed motion sensor events is discussed and tested. And then, the human activity recognition performances of neural network using BP algorithm have been evaluated and compared with other probabilistic algorithms: Na\u00c3\u00afve Bayes(NB) classifier and Hidden Markov Model(HMM). The results show that different feature datasets yield different activity recognition accuracy. The selection of unsuitable feature datasets increases the computational complexity and degrades the activity recognition accuracy. Furthermore, neural network using BP algorithm has relatively better human activity recognition performances than NB classifier and HMM. Copyright \u00c2\u00a9 2014 ISA. Published by Elsevier Ltd. All rights reserved.\n\n\nNon-invasive algorithm for bowel motility estimation using a back-propagation neural network model of bowel sounds\nDirectory of Open Access Journals (Sweden)\nSong Chul-Gyu\n2011-08-01\nFull Text Available Abstract Background Radiological scoring methods such as colon transit time (CTT have been widely used for the assessment of bowel motility. However, these radiograph-based methods need cumbersome radiological instruments and their frequent exposure to radiation. Therefore, a non-invasive estimation algorithm of bowel motility, based on a back-propagation neural network (BPNN model of bowel sounds (BS obtained by an auscultation, was devised. Methods Twelve healthy males (age: 24.8 \u00c2\u00b1 2.7 years and 6 patients with spinal cord injury (6 males, age: 55.3 \u00c2\u00b1 7.1 years were examined. BS signals generated during the digestive process were recorded from 3 colonic segments (ascending, descending and sigmoid colon, and then, the acoustical features (jitter and shimmer of the individual BS segment were obtained. Only 6 features (J1, 3, J3, 3, S1, 2, S2, 1, S2, 2, S3, 2, which are highly correlated to the CTTs measured by the conventional method, were used as the features of the input vector for the BPNN. Results As a results, both the jitters and shimmers of the normal subjects were relatively higher than those of the patients, whereas the CTTs of the normal subjects were relatively lower than those of the patients (p k-fold cross validation, the correlation coefficient and mean average error between the CTTs measured by a conventional radiograph and the values estimated by our algorithm were 0.89 and 10.6 hours, respectively. Conclusions The jitter and shimmer of the BS signals generated during the peristalsis could be clinically useful for the discriminative parameters of bowel motility. Also, the devised algorithm showed good potential for the continuous monitoring and estimation of bowel motility, instead of conventional radiography, and thus, it could be used as a complementary tool for the non-invasive measurement of bowel motility.\n\n\nMatching algorithm of missile tail flame based on back-propagation neural network\nScience.gov (United States)\nHuang, Da; Huang, Shucai; Tang, Yidong; Zhao, Wei; Cao, Wenhuan\n2018-02-01\nThis work presents a spectral matching algorithm of missile plume detection that based on neural network. The radiation value of the characteristic spectrum of the missile tail flame is taken as the input of the network. The network's structure including the number of nodes and layers is determined according to the number of characteristic spectral bands and missile types. We can get the network weight matrixes and threshold vectors through training the network using training samples, and we can determine the performance of the network through testing the network using the test samples. A small amount of data cause the network has the advantages of simple structure and practicality. Network structure composed of weight matrix and threshold vector can complete task of spectrum matching without large database support. Network can achieve real-time requirements with a small quantity of data. Experiment results show that the algorithm has the ability to match the precise spectrum and strong robustness.\n\n\nError-backpropagation in temporally encoded networks of spiking neurons\nNARCIS (Netherlands)\nS.M. Bohte (Sander); J.A. La Poutr\u00c3\u00a9 (Han); J.N. Kok (Joost)\n2000-01-01\ntextabstractFor a network of spiking neurons that encodes information in the timing of individual spike-times, we derive a supervised learning rule, emph{SpikeProp, akin to traditional error-backpropagation and show how to overcome the discontinuities introduced by thresholding. With this algorithm,\n\n\nNew backpropagation algorithm with type-2 fuzzy weights for neural networks\nCERN Document Server\nGaxiola, Fernando; Valdez, Fevrier\n2016-01-01\nIn this book a neural network learning method with type-2 fuzzy weight adjustment is proposed. The mathematical analysis of the proposed learning method architecture and the adaptation of type-2 fuzzy weights are presented. The proposed method is based on research of recent methods that handle weight adaptation and especially fuzzy weights. The internal operation of the neuron is changed to work with two internal calculations for the activation function to obtain two results as outputs of the proposed method. Simulation results and a comparative study among monolithic neural networks, neural network with type-1 fuzzy weights and neural network with type-2 fuzzy weights are presented to illustrate the advantages of the proposed method. The proposed approach is based on recent methods that handle adaptation of weights using fuzzy logic of type-1 and type-2. The proposed approach is applied to a cases of prediction for the Mackey-Glass (for \u00c3\u00b4=17) and Dow-Jones time series, and recognition of person with iris bi...\n\n\nAlgorithms for Reinforcement Learning\nCERN Document Server\nSzepesvari, Csaba\n2010-01-01\nReinforcement learning is a learning paradigm concerned with learning to control a system so as to maximize a numerical performance measure that expresses a long-term objective. What distinguishes reinforcement learning from supervised learning is that only partial feedback is given to the learner about the learner's predictions. Further, the predictions may have long term effects through influencing the future state of the controlled system. Thus, time plays a special role. The goal in reinforcement learning is to develop efficient learning algorithms, as well as to understand the algorithms'\n\n\nEquivalence of Equilibrium Propagation and Recurrent Backpropagation\nOpenAIRE\nScellier, Benjamin; Bengio, Yoshua\n2017-01-01\nRecurrent Backpropagation and Equilibrium Propagation are algorithms for fixed point recurrent neural networks which differ in their second phase. In the first phase, both algorithms converge to a fixed point which corresponds to the configuration where the prediction is made. In the second phase, Recurrent Backpropagation computes error derivatives whereas Equilibrium Propagation relaxes to another nearby fixed point. In this work we establish a close connection between these two algorithms....\n\n\nUnsupervised learning algorithms\nCERN Document Server\nAydin, Kemal\n2016-01-01\nThis book summarizes the state-of-the-art in unsupervised learning. The contributors discuss how with\u00c2\u00a0the proliferation of massive amounts of unlabeled data, unsupervised learning algorithms, which can automatically discover interesting and useful patterns in such data, have gained popularity among researchers and practitioners. The authors outline how these algorithms have found numerous applications including pattern recognition, market basket analysis, web mining, social network analysis, information retrieval, recommender systems, market research, intrusion detection, and fraud detection. They present how the difficulty of developing theoretically sound approaches that are amenable to objective evaluation have resulted in the proposal of numerous unsupervised learning algorithms over the past half-century. The intended audience includes researchers and practitioners who are increasingly using unsupervised learning algorithms to analyze their data. Topics of interest include anomaly detection, clustering,...\n\n\nThe Dropout Learning Algorithm\nScience.gov (United States)\nBaldi, Pierre; Sadowski, Peter\n2014-01-01\nDropout is a recently introduced algorithm for training neural network by randomly dropping units during training to prevent their co-adaptation. A mathematical analysis of some of the static and dynamic properties of dropout is provided using Bernoulli gating variables, general enough to accommodate dropout on units or connections, and with variable rates. The framework allows a complete analysis of the ensemble averaging properties of dropout in linear networks, which is useful to understand the non-linear case. The ensemble averaging properties of dropout in non-linear logistic networks result from three fundamental equations: (1) the approximation of the expectations of logistic functions by normalized geometric means, for which bounds and estimates are derived; (2) the algebraic equality between normalized geometric means of logistic functions with the logistic of the means, which mathematically characterizes logistic functions; and (3) the linearity of the means with respect to sums, as well as products of independent variables. The results are also extended to other classes of transfer functions, including rectified linear functions. Approximation errors tend to cancel each other and do not accumulate. Dropout can also be connected to stochastic neurons and used to predict firing rates, and to backpropagation by viewing the backward propagation as ensemble averaging in a dropout linear network. Moreover, the convergence properties of dropout can be understood in terms of stochastic gradient descent. Finally, for the regularization properties of dropout, the expectation of the dropout gradient is the gradient of the corresponding approximation ensemble, regularized by an adaptive weight decay term with a propensity for self-consistent variance minimization and sparse representations. PMID:24771879\n\n\nBackpropagation and ordered derivatives in the time scales calculus.\nScience.gov (United States)\nSeiffertt, John; Wunsch, Donald C\n2010-08-01\nBackpropagation is the most widely used neural network learning technique. It is based on the mathematical notion of an ordered derivative. In this paper, we present a formulation of ordered derivatives and the backpropagation training algorithm using the important emerging area of mathematics known as the time scales calculus. This calculus, with its potential for application to a wide variety of inter-disciplinary problems, is becoming a key area of mathematics. It is capable of unifying continuous and discrete analysis within one coherent theoretical framework. Using this calculus, we present here a generalization of backpropagation which is appropriate for cases beyond the specifically continuous or discrete. We develop a new multivariate chain rule of this calculus, define ordered derivatives on time scales, prove a key theorem about them, and derive the backpropagation weight update equations for a feedforward multilayer neural network architecture. By drawing together the time scales calculus and the area of neural network learning, we present the first connection of two major fields of research.\n\n\nSuperior Generalization Capability of Hardware-Learing Algorithm Developed for Self-Learning Neuron-MOS Neural Networks\nScience.gov (United States)\nKondo, Shuhei; Shibata, Tadashi; Ohmi, Tadahiro\n1995-02-01\nWe have investigated the learning performance of the hardware backpropagation (HBP) algorithm, a hardware-oriented learning algorithm developed for the self-learning architecture of neural networks constructed using neuron MOS (metal-oxide-semiconductor) transistors. The solution to finding a mirror symmetry axis in a 4\u00c3\u20144 binary pixel array was tested by computer simulation based on the HBP algorithm. Despite the inherent restrictions imposed on the hardware-learning algorithm, HBP exhibits equivalent learning performance to that of the original backpropagation (BP) algorithm when all the pertinent parameters are optimized. Very importantly, we have found that HBP has a superior generalization capability over BP; namely, HBP exhibits higher performance in solving problems that the network has not yet learnt.\n\n\nLeukemia and colon tumor detection based on microarray data classification using momentum backpropagation and genetic algorithm as a feature selection method\nScience.gov (United States)\nWisesty, Untari N.; Warastri, Riris S.; Puspitasari, Shinta Y.\n2018-03-01\nCancer is one of the major causes of mordibility and mortality problems in the worldwide. Therefore, the need of a system that can analyze and identify a person suffering from a cancer by using microarray data derived from the patient\u00e2\u20ac\u2122s Deoxyribonucleic Acid (DNA). But on microarray data has thousands of attributes, thus making the challenges in data processing. This is often referred to as the curse of dimensionality. Therefore, in this study built a system capable of detecting a patient whether contracted cancer or not. The algorithm used is Genetic Algorithm as feature selection and Momentum Backpropagation Neural Network as a classification method, with data used from the Kent Ridge Bio-medical Dataset. Based on system testing that has been done, the system can detect Leukemia and Colon Tumor with best accuracy equal to 98.33% for colon tumor data and 100% for leukimia data. Genetic Algorithm as feature selection algorithm can improve system accuracy, which is from 64.52% to 98.33% for colon tumor data and 65.28% to 100% for leukemia data, and the use of momentum parameters can accelerate the convergence of the system in the training process of Neural Network.\n\n\n\n\n\u00ab\n1\n2\n3\n4\n5\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n1\n2\n3\n4\n5\n\u00bb\n\n\n\n\n\n\n\n\nCascade Error Projection Learning Algorithm\nScience.gov (United States)\nDuong, T. A.; Stubberud, A. R.; Daud, T.\n1995-01-01\nA detailed mathematical analysis is presented for a new learning algorithm termed cascade error projection (CEP) and a general learning frame work. This frame work can be used to obtain the cascade correlation learning algorithm by choosing a particular set of parameters.\n\n\nMachine Learning an algorithmic perspective\nCERN Document Server\nMarsland, Stephen\n2009-01-01\nTraditional books on machine learning can be divided into two groups - those aimed at advanced undergraduates or early postgraduates with reasonable mathematical knowledge and those that are primers on how to code algorithms. The field is ready for a text that not only demonstrates how to use the algorithms that make up machine learning methods, but also provides the background needed to understand how and why these algorithms work. Machine Learning: An Algorithmic Perspective is that text.Theory Backed up by Practical ExamplesThe book covers neural networks, graphical models, reinforcement le\n\n\nConjugate descent formulation of backpropagation error in ...\nAfrican Journals Online (AJOL)\n\n\nThe feedforward neural network architecture uses backpropagation learning to determine optimal weights between dierent interconnected layers. This learning procedure uses a gradient descent technique applied to a sum-of-squares error function for the given input-output pattern. It employs an iterative procedure to\u00c2\u00a0...\n\n\nDynamic training algorithm for dynamic neural networks\nInternational Nuclear Information System (INIS) \nTan, Y.; Van Cauwenberghe, A.; Liu, Z.\n1996-01-01\nThe widely used backpropagation algorithm for training neural networks based on the gradient descent has a significant drawback of slow convergence. A Gauss-Newton method based recursive least squares (RLS) type algorithm with dynamic error backpropagation is presented to speed-up the learning procedure of neural networks with local recurrent terms. Finally, simulation examples concerning the applications of the RLS type algorithm to identification of nonlinear processes using a local recurrent neural network are also included in this paper\n\n\nIMPLEMENTASI BACKPROPAGATION NEURAL NETWORK DALAM PRAKIRAAN CUACA DI DAERAH BALI SELATAN\nDirectory of Open Access Journals (Sweden)\nI MADE DWI UDAYANA PUTRA\n2016-11-01\nFull Text Available Weather information has an important role in human life in various fields, such as agriculture, marine, and aviation. The accurate weather forecasts are needed in order to improve the performance of various fields. In this study, use artificial neural network method with backpropagation learning algorithm to create a model of weather forecasting in the area of ??South Bali. The aim of this study is to determine the effect of the number of neurons in the hidden layer and to determine the level of accuracy of the method of artificial neural network with backpropagation learning algorithm in weather forecast models. Weather forecast models in this study use input of the factors that influence the weather, namely air temperature, dew point, wind speed, visibility, and barometric pressure.The results of testing the network with a different number of neurons in the hidden layer of artificial neural network method with backpropagation learning algorithms show that the increase in the number of neurons in the hidden layer is not directly proportional to the value of the accuracy of the weather forecasts, the increase in the number of neurons in the hidden layer does not necessarily increase or decrease value accuracy of weather forecasts we obtain the best accuracy rate of 51.6129% on a network model with three neurons in the hidden layer.\n\n\nEmpirical tests of the Gradual Learning Algorithm\nNARCIS (Netherlands)\nBoersma, P.; Hayes, B.\n1999-01-01\nThe Gradual Learning Algorithm (Boersma 1997) is a constraint ranking algorithm for learning Optimality-theoretic grammars. The purpose of this article is to assess the capabilities of the Gradual Learning Algorithm, particularly in comparison with the Constraint Demotion algorithm of Tesar and\n\n\nEmpirical tests of the Gradual Learning Algorithm\nNARCIS (Netherlands)\nBoersma, P.; Hayes, B.\n2001-01-01\nThe Gradual Learning Algorithm (Boersma 1997) is a constraint-ranking algorithm for learning optimality-theoretic grammars. The purpose of this article is to assess the capabilities of the Gradual Learning Algorithm, particularly in comparison with the Constraint Demotion algorithm of Tesar and\n\n\nAnalysis of Artificial Neural Network Backpropagation Using Conjugate Gradient Fletcher Reeves In The Predicting Process\nScience.gov (United States)\nWanto, Anjar; Zarlis, Muhammad; Sawaluddin; Hartama, Dedy\n2017-12-01\nBackpropagation is a good artificial neural network algorithm used to predict, one of which is to predict the rate of Consumer Price Index (CPI) based on the foodstuff sector. While conjugate gradient fletcher reeves is a suitable optimization method when juxtaposed with backpropagation method, because this method can shorten iteration without reducing the quality of training and testing result. Consumer Price Index (CPI) data that will be predicted to come from the Central Statistics Agency (BPS) Pematangsiantar. The results of this study will be expected to contribute to the government in making policies to improve economic growth. In this study, the data obtained will be processed by conducting training and testing with artificial neural network backpropagation by using parameter learning rate 0,01 and target error minimum that is 0.001-0,09. The training network is built with binary and bipolar sigmoid activation functions. After the results with backpropagation are obtained, it will then be optimized using the conjugate gradient fletcher reeves method by conducting the same training and testing based on 5 predefined network architectures. The result, the method used can increase the speed and accuracy result.\n\n\nStorage capacity of the Tilinglike Learning Algorithm\nInternational Nuclear Information System (INIS) \nBuhot, Arnaud; Gordon, Mirta B.\n2001-01-01\nThe storage capacity of an incremental learning algorithm for the parity machine, the Tilinglike Learning Algorithm, is analytically determined in the limit of a large number of hidden perceptrons. Different learning rules for the simple perceptron are investigated. The usual Gardner-Derrida rule leads to a storage capacity close to the upper bound, which is independent of the learning algorithm considered\n\n\nRainfall prediction with backpropagation method\nScience.gov (United States)\nWahyuni, E. G.; Fauzan, L. M. F.; Abriyani, F.; Muchlis, N. F.; Ulfa, M.\n2018-03-01\nRainfall is an important factor in many fields, such as aviation and agriculture. Although it has been assisted by technology but the accuracy can not reach 100% and there is still the possibility of error. Though current rainfall prediction information is needed in various fields, such as agriculture and aviation fields. In the field of agriculture, to obtain abundant and quality yields, farmers are very dependent on weather conditions, especially rainfall. Rainfall is one of the factors that affect the safety of aircraft. To overcome the problems above, then it\u00e2\u20ac\u2122s required a system that can accurately predict rainfall. In predicting rainfall, artificial neural network modeling is applied in this research. The method used in modeling this artificial neural network is backpropagation method. Backpropagation methods can result in better performance in repetitive exercises. This means that the weight of the ANN interconnection can approach the weight it should be. Another advantage of this method is the ability in the learning process adaptively and multilayer owned on this method there is a process of weight changes so as to minimize error (fault tolerance). Therefore, this method can guarantee good system resilience and consistently work well. The network is designed using 4 input variables, namely air temperature, air humidity, wind speed, and sunshine duration and 3 output variables ie low rainfall, medium rainfall, and high rainfall. Based on the research that has been done, the network can be used properly, as evidenced by the results of the prediction of the system precipitation is the same as the results of manual calculations.\n\n\nCascade Error Projection: A New Learning Algorithm\nScience.gov (United States)\nDuong, T. A.; Stubberud, A. R.; Daud, T.; Thakoor, A. P.\n1995-01-01\nA new neural network architecture and a hardware implementable learning algorithm is proposed. The algorithm, called cascade error projection (CEP), handles lack of precision and circuit noise better than existing algorithms.\n\n\nDynamic gradient descent learning algorithms for enhanced empirical modeling of power plants\nInternational Nuclear Information System (INIS) \nParlos, A.G.; Atiya, Amir; Chong, K.T.\n1991-01-01\nA newly developed dynamic gradient descent-based learning algorithm is used to train a recurrent multilayer perceptron network for use in empirical modeling of power plants. The two main advantages of the proposed learning algorithm are its ability to consider past error gradient information for future use and the two forward passes associated with its implementation, instead of one forward and one backward pass of the backpropagation algorithm. The latter advantage results in computational time saving because both passes can be performed simultaneously. The dynamic learning algorithm is used to train a hybrid feedforward/feedback neural network, a recurrent multilayer perceptron, which was previously found to exhibit good interpolation and extrapolation capabilities in modeling nonlinear dynamic systems. One of the drawbacks, however, of the previously reported work has been the long training times associated with accurate empirical models. The enhanced learning capabilities provided by the dynamic gradient descent-based learning algorithm are demonstrated by a case study of a steam power plant. The number of iterations required for accurate empirical modeling has been reduced from tens of thousands to hundreds, thus significantly expediting the learning process\n\n\nPsycho-acoustic evaluation of the indoor noise in cabins of a naval vessel using a back-propagation neural network algorithm\nDirectory of Open Access Journals (Sweden)\nHyung-Suk Han\n2012-12-01\nFull Text Available The indoor noise of a ship is usually determined using the A-weighted sound pressure level. However, in order to better understand this phenomenon, evaluation parameters that more accurately reflect the human sense of hearing are required. To find the level of the satisfaction index of the noise inside a naval vessel such as \u00e2\u20ac\u0153Loudness\u00e2\u20ac\ufffd and \u00e2\u20ac\u0153Annoyance\u00e2\u20ac\ufffd, psycho-acoustic evaluation of various sound recordings from the naval vessel was performed in a laboratory. The objective of this paper is to develop a single index of \u00e2\u20ac\u0153Loudness\u00e2\u20ac\ufffd and \u00e2\u20ac\u0153Annoyance\u00e2\u20ac\ufffd for noise inside a naval vessel according to a psycho-acoustic evaluation by using psychological responses such as Noise Rating (NR, Noise Criterion (NC, Room Criterion (RC, Preferred Speech Interference Level (PSIL and loudness level. Additionally, in order to determine a single index of satisfaction for noise such as \u00e2\u20ac\u0153Loudness\u00e2\u20ac\ufffd and \u00e2\u20ac\u0153Annoyance\u00e2\u20ac\ufffd, with respect to a human's sense of hearing, a back-propagation neural network is applied.\n\n\nQuantum learning algorithms for quantum measurements\nEnergy Technology Data Exchange (ETDEWEB)\nBisio, Alessandro, E-mail: alessandro.bisio@unipv.it [QUIT Group, Dipartimento di Fisica ' A. Volta' and INFN, via Bassi 6, 27100 Pavia (Italy); D' Ariano, Giacomo Mauro, E-mail: dariano@unipv.it [QUIT Group, Dipartimento di Fisica ' A. Volta' and INFN, via Bassi 6, 27100 Pavia (Italy); Perinotti, Paolo, E-mail: paolo.perinotti@unipv.it [QUIT Group, Dipartimento di Fisica ' A. Volta' and INFN, via Bassi 6, 27100 Pavia (Italy); Sedlak, Michal, E-mail: michal.sedlak@unipv.it [QUIT Group, Dipartimento di Fisica ' A. Volta' and INFN, via Bassi 6, 27100 Pavia (Italy); Institute of Physics, Slovak Academy of Sciences, Dubravska cesta 9, 845 11 Bratislava (Slovakia)\n2011-09-12\nWe study quantum learning algorithms for quantum measurements. The optimal learning algorithm is derived for arbitrary von Neumann measurements in the case of training with one or two examples. The analysis of the case of three examples reveals that, differently from the learning of unitary gates, the optimal algorithm for learning of quantum measurements cannot be parallelized, and requires quantum memories for the storage of information. -- Highlights: \u00e2\u2020\u2019 Optimal learning algorithm for von Neumann measurements. \u00e2\u2020\u2019 From 2 copies to 1 copy: the optimal strategy is parallel. \u00e2\u2020\u2019 From 3 copies to 1 copy: the optimal strategy must be non-parallel.\n\n\nQuantum learning algorithms for quantum measurements\nInternational Nuclear Information System (INIS) \nBisio, Alessandro; D'Ariano, Giacomo Mauro; Perinotti, Paolo; Sedlak, Michal\n2011-01-01\nWe study quantum learning algorithms for quantum measurements. The optimal learning algorithm is derived for arbitrary von Neumann measurements in the case of training with one or two examples. The analysis of the case of three examples reveals that, differently from the learning of unitary gates, the optimal algorithm for learning of quantum measurements cannot be parallelized, and requires quantum memories for the storage of information. -- Highlights: \u00e2\u2020\u2019 Optimal learning algorithm for von Neumann measurements. \u00e2\u2020\u2019 From 2 copies to 1 copy: the optimal strategy is parallel. \u00e2\u2020\u2019 From 3 copies to 1 copy: the optimal strategy must be non-parallel.\n\n\nLearning algorithms and automatic processing of languages\nInternational Nuclear Information System (INIS) \nFluhr, Christian Yves Andre\n1977-01-01\nThis research thesis concerns the field of artificial intelligence. It addresses learning algorithms applied to automatic processing of languages. The author first briefly describes some mechanisms of human intelligence in order to describe how these mechanisms are simulated on a computer. He outlines the specific role of learning in various manifestations of intelligence. Then, based on the Markov's algorithm theory, the author discusses the notion of learning algorithm. Two main types of learning algorithms are then addressed: firstly, an 'algorithm-teacher dialogue' type sanction-based algorithm which aims at learning how to solve grammatical ambiguities in submitted texts; secondly, an algorithm related to a document system which structures semantic data automatically obtained from a set of texts in order to be able to understand by references to any question on the content of these texts\n\n\nUnderstanding the Convolutional Neural Networks with Gradient Descent and Backpropagation\nScience.gov (United States)\nZhou, XueFei\n2018-04-01\nWith the development of computer technology, the applications of machine learning are more and more extensive. And machine learning is providing endless opportunities to develop new applications. One of those applications is image recognition by using Convolutional Neural Networks (CNNs). CNN is one of the most common algorithms in image recognition. It is significant to understand its theory and structure for every scholar who is interested in this field. CNN is mainly used in computer identification, especially in voice, text recognition and other aspects of the application. It utilizes hierarchical structure with different layers to accelerate computing speed. In addition, the greatest features of CNNs are the weight sharing and dimension reduction. And all of these consolidate the high effectiveness and efficiency of CNNs with idea computing speed and error rate. With the help of other learning altruisms, CNNs could be used in several scenarios for machine learning, especially for deep learning. Based on the general introduction to the background and the core solution CNN, this paper is going to focus on summarizing how Gradient Descent and Backpropagation work, and how they contribute to the high performances of CNNs. Also, some practical applications will be discussed in the following parts. The last section exhibits the conclusion and some perspectives of future work.\n\n\nExploitation of linkage learning in evolutionary algorithms\nCERN Document Server\nChen, Ying-ping\n2010-01-01\nThe exploitation of linkage learning is enhancing the performance of evolutionary algorithms. This monograph examines recent progress in linkage learning, with a series of focused technical chapters that cover developments and trends in the field.\n\n\nEquilibrium Propagation: Bridging the Gap between Energy-Based Models and Backpropagation\nDirectory of Open Access Journals (Sweden)\nBenjamin Scellier\n2017-05-01\nFull Text Available We introduce Equilibrium Propagation, a learning framework for energy-based models. It involves only one kind of neural computation, performed in both the first phase (when the prediction is made and the second phase of training (after the target or prediction error is revealed. Although this algorithm computes the gradient of an objective function just like Backpropagation, it does not need a special computation or circuit for the second phase, where errors are implicitly propagated. Equilibrium Propagation shares similarities with Contrastive Hebbian Learning and Contrastive Divergence while solving the theoretical issues of both algorithms: our algorithm computes the gradient of a well-defined objective function. Because the objective function is defined in terms of local perturbations, the second phase of Equilibrium Propagation corresponds to only nudging the prediction (fixed point or stationary distribution toward a configuration that reduces prediction error. In the case of a recurrent multi-layer supervised network, the output units are slightly nudged toward their target in the second phase, and the perturbation introduced at the output layer propagates backward in the hidden layers. We show that the signal \u00e2\u20ac\u0153back-propagated\u00e2\u20ac\ufffd during this second phase corresponds to the propagation of error derivatives and encodes the gradient of the objective function, when the synaptic update corresponds to a standard form of spike-timing dependent plasticity. This work makes it more plausible that a mechanism similar to Backpropagation could be implemented by brains, since leaky integrator neural computation performs both inference and error back-propagation in our model. The only local difference between the two phases is whether synaptic changes are allowed or not. We also show experimentally that multi-layer recurrently connected networks with 1, 2, and 3 hidden layers can be trained by Equilibrium Propagation on the permutation-invariant MNIST\n\n\nLearning Intelligent Genetic Algorithms Using Japanese Nonograms\nScience.gov (United States)\nTsai, Jinn-Tsong; Chou, Ping-Yi; Fang, Jia-Cen\n2012-01-01\nAn intelligent genetic algorithm (IGA) is proposed to solve Japanese nonograms and is used as a method in a university course to learn evolutionary algorithms. The IGA combines the global exploration capabilities of a canonical genetic algorithm (CGA) with effective condensed encoding, improved fitness function, and modified crossover and\u00e2\u20ac\u00a6\n\n\n\n\n\u00ab\n1\n2\n3\n4\n5\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n2\n3\n4\n5\n6\n\u00bb\n\n\n\n\n\n\n\n\nNon-Linear Back-propagation: Doing Back-Propagation withoutDerivatives of the Activation Function\nDEFF Research Database (Denmark)\nHertz, John; Krogh, Anders St\u00c3\u00a6rmose; Lautrup, Benny\n1997-01-01\nThe conventional linear back-propagation algorithm is replaced by a non-linear version, which avoids the necessity for calculating the derivative of the activation function. This may be exploited in hardware realizations of neural processors. In this paper we derive the non-linear back...\n\n\nLearning theory of distributed spectral algorithms\nInternational Nuclear Information System (INIS) \nGuo, Zheng-Chu; Lin, Shao-Bo; Zhou, Ding-Xuan\n2017-01-01\nSpectral algorithms have been widely used and studied in learning theory and inverse problems. This paper is concerned with distributed spectral algorithms, for handling big data, based on a divide-and-conquer approach. We present a learning theory for these distributed kernel-based learning algorithms in a regression framework including nice error bounds and optimal minimax learning rates achieved by means of a novel integral operator approach and a second order decomposition of inverse operators. Our quantitative estimates are given in terms of regularity of the regression function, effective dimension of the reproducing kernel Hilbert space, and qualification of the filter function of the spectral algorithm. They do not need any eigenfunction or noise conditions and are better than the existing results even for the classical family of spectral algorithms. (paper)\n\n\nKernel learning algorithms for face recognition\nCERN Document Server\nLi, Jun-Bao; Pan, Jeng-Shyang\n2013-01-01\nKernel Learning Algorithms for Face Recognition covers the framework of kernel based face recognition. This book discusses the advanced kernel learning algorithms and its application on face recognition. This book also focuses on the theoretical deviation, the system framework and experiments involving kernel based face recognition. Included within are algorithms of kernel based face recognition, and also the feasibility of the kernel based face recognition method. This book provides researchers in pattern recognition and machine learning area with advanced face recognition methods and its new\n\n\nQuantum algorithms and learning theory\nNARCIS (Netherlands)\nArunachalam, S.\n2018-01-01\nThis thesis studies strengths and weaknesses of quantum computers. In the first part we present three contributions to quantum algorithms. 1) consider a search space of N elements. One of these elements is \"marked\" and our goal is to find this. We describe a quantum algorithm to solve this problem\n\n\nParallelization of TMVA Machine Learning Algorithms\nCERN Document Server\nHajili, Mammad\n2017-01-01\nThis report reflects my work on Parallelization of TMVA Machine Learning Algorithms integrated to ROOT Data Analysis Framework during summer internship at CERN. The report consists of 4 impor- tant part - data set used in training and validation, algorithms that multiprocessing applied on them, parallelization techniques and re- sults of execution time changes due to number of workers.\n\n\nTop Tagging by Deep Learning Algorithm\nCERN Document Server\nAkil, Ali\n2015-01-01\nIn this report I will show the application of a deep learning algorithm on a Monte Carlo simulation sample to test its performance in tagging hadronic decays of boosted top quarks and compare what we get with the results of the application of some other algorithms.\n\n\nKlasifikasi Varietas Cabai Berdasarkan Morfologi Daun Menggunakan Backpropagation Neural Network\nDirectory of Open Access Journals (Sweden)\nKharis Syaban\n2016-07-01\nFull Text Available Compared with other methods of classifiers such as cellular and molecular biological methods, using the image of the leaves become the first choice in the classification of plants. The leaves can be characterized by shape, color, and texture; The leaves can have a color that varies depending on the season and geographical location. In addition, the same plant species also can have different leaf shapes. In this study, the morphological features of leaves used to identify varieties of pepper plants. The method used to perform feature extraction is a moment invariant and basic geometric features. For the process of recognition based on the features that have been extracted, used neural network methods with backpropagation learning algorithm. From the neural-network training, the best accuracy in classifying varieties of chili with minimum error 0.001 by providing learning rate 0.1, momentum of 0.7, and 15 neurons in the hidden layer foreach of various feature. To conduct cross-validation testing with k-fold tehcnique, obtained classification accuracy to be range of 80.75%\u00c2\u00b10.09% with k=4.\n\n\nA distributed algorithm for machine learning\nScience.gov (United States)\nChen, Shihong\n2018-04-01\nThis paper considers a distributed learning problem in which a group of machines in a connected network, each learning its own local dataset, aim to reach a consensus at an optimal model, by exchanging information only with their neighbors but without transmitting data. A distributed algorithm is proposed to solve this problem under appropriate assumptions.\n\n\nAlgorithmic learning in a random world\nCERN Document Server\nVovk, Vladimir; Shafer, Glenn\n2005-01-01\nA new scientific monograph developing significant new algorithmic foundations in machine learning theory. Researchers and postgraduates in CS, statistics, and A.I. will find the book an authoritative and formal presentation of some of the most promising theoretical developments in machine learning.\n\n\nOnline Learning Algorithm for Time Series Forecasting Suitable for Low Cost Wireless Sensor Networks Nodes\nDirectory of Open Access Journals (Sweden)\nJuan Pardo\n2015-04-01\nFull Text Available Time series forecasting is an important predictive methodology which can be applied to a wide range of problems. Particularly, forecasting the indoor temperature permits an improved utilization of the HVAC (Heating, Ventilating and Air Conditioning systems in a home and thus a better energy efficiency. With such purpose the paper describes how to implement an Artificial Neural Network (ANN algorithm in a low cost system-on-chip to develop an autonomous intelligent wireless sensor network. The present paper uses a Wireless Sensor Networks (WSN to monitor and forecast the indoor temperature in a smart home, based on low resources and cost microcontroller technology as the 8051MCU. An on-line learning approach, based on Back-Propagation (BP algorithm for ANNs, has been developed for real-time time series learning. It performs the model training with every new data that arrive to the system, without saving enormous quantities of data to create a historical database as usual, i.e., without previous knowledge. Consequently to validate the approach a simulation study through a Bayesian baseline model have been tested in order to compare with a database of a real application aiming to see the performance and accuracy. The core of the paper is a new algorithm, based on the BP one, which has been described in detail, and the challenge was how to implement a computational demanding algorithm in a simple architecture with very few hardware resources.\n\n\nOnline Learning Algorithm for Time Series Forecasting Suitable for Low Cost Wireless Sensor Networks Nodes\nScience.gov (United States)\nPardo, Juan; Zamora-Mart\u00c3\u00adnez, Francisco; Botella-Rocamora, Paloma\n2015-01-01\nTime series forecasting is an important predictive methodology which can be applied to a wide range of problems. Particularly, forecasting the indoor temperature permits an improved utilization of the HVAC (Heating, Ventilating and Air Conditioning) systems in a home and thus a better energy efficiency. With such purpose the paper describes how to implement an Artificial Neural Network (ANN) algorithm in a low cost system-on-chip to develop an autonomous intelligent wireless sensor network. The present paper uses a Wireless Sensor Networks (WSN) to monitor and forecast the indoor temperature in a smart home, based on low resources and cost microcontroller technology as the 8051MCU. An on-line learning approach, based on Back-Propagation (BP) algorithm for ANNs, has been developed for real-time time series learning. It performs the model training with every new data that arrive to the system, without saving enormous quantities of data to create a historical database as usual, i.e., without previous knowledge. Consequently to validate the approach a simulation study through a Bayesian baseline model have been tested in order to compare with a database of a real application aiming to see the performance and accuracy. The core of the paper is a new algorithm, based on the BP one, which has been described in detail, and the challenge was how to implement a computational demanding algorithm in a simple architecture with very few hardware resources. PMID:25905698\n\n\nOnline learning algorithm for time series forecasting suitable for low cost wireless sensor networks nodes.\nScience.gov (United States)\nPardo, Juan; Zamora-Mart\u00c3\u00adnez, Francisco; Botella-Rocamora, Paloma\n2015-04-21\nTime series forecasting is an important predictive methodology which can be applied to a wide range of problems. Particularly, forecasting the indoor temperature permits an improved utilization of the HVAC (Heating, Ventilating and Air Conditioning) systems in a home and thus a better energy efficiency. With such purpose the paper describes how to implement an Artificial Neural Network (ANN) algorithm in a low cost system-on-chip to develop an autonomous intelligent wireless sensor network. The present paper uses a Wireless Sensor Networks (WSN) to monitor and forecast the indoor temperature in a smart home, based on low resources and cost microcontroller technology as the 8051MCU. An on-line learning approach, based on Back-Propagation (BP) algorithm for ANNs, has been developed for real-time time series learning. It performs the model training with every new data that arrive to the system, without saving enormous quantities of data to create a historical database as usual, i.e., without previous knowledge. Consequently to validate the approach a simulation study through a Bayesian baseline model have been tested in order to compare with a database of a real application aiming to see the performance and accuracy. The core of the paper is a new algorithm, based on the BP one, which has been described in detail, and the challenge was how to implement a computational demanding algorithm in a simple architecture with very few hardware resources.\n\n\nA Learning Algorithm for Multimodal Grammar Inference.\nScience.gov (United States)\nD'Ulizia, A; Ferri, F; Grifoni, P\n2011-12-01\nThe high costs of development and maintenance of multimodal grammars in integrating and understanding input in multimodal interfaces lead to the investigation of novel algorithmic solutions in automating grammar generation and in updating processes. Many algorithms for context-free grammar inference have been developed in the natural language processing literature. An extension of these algorithms toward the inference of multimodal grammars is necessary for multimodal input processing. In this paper, we propose a novel grammar inference mechanism that allows us to learn a multimodal grammar from its positive samples of multimodal sentences. The algorithm first generates the multimodal grammar that is able to parse the positive samples of sentences and, afterward, makes use of two learning operators and the minimum description length metrics in improving the grammar description and in avoiding the over-generalization problem. The experimental results highlight the acceptable performances of the algorithm proposed in this paper since it has a very high probability of parsing valid sentences.\n\n\nLearning from nature: Nature-inspired algorithms\nDEFF Research Database (Denmark)\nAlbeanu, Grigore; Madsen, Henrik; Popentiu-Vladicescu, Florin\n2016-01-01\n.), genetic and evolutionary strategies, artificial immune systems etc. Well-known examples of applications include: aircraft wing design, wind turbine design, bionic car, bullet train, optimal decisions related to traffic, appropriate strategies to survive under a well-adapted immune system etc. Based......During last decade, the nature has inspired researchers to develop new algorithms. The largest collection of nature-inspired algorithms is biology-inspired: swarm intelligence (particle swarm optimization, ant colony optimization, cuckoo search, bees' algorithm, bat algorithm, firefly algorithm etc...... on collective social behaviour of organisms, researchers have developed optimization strategies taking into account not only the individuals, but also groups and environment. However, learning from nature, new classes of approaches can be identified, tested and compared against already available algorithms...\n\n\nA novel low-voltage low-power analogue VLSI implementation of neural networks with on-chip back-propagation learning\nScience.gov (United States)\nCarrasco, Manuel; Garde, Andres; Murillo, Pilar; Serrano, Luis\n2005-06-01\nIn this paper a novel design and implementation of a VLSI Analogue Neural Net based on Multi-Layer Perceptron (MLP) with on-chip Back Propagation (BP) learning algorithm suitable for the resolution of classification problems is described. In order to implement a general and programmable analogue architecture, the design has been carried out in a hierarchical way. In this way the net has been divided in synapsis-blocks and neuron-blocks providing an easy method for the analysis. These blocks basically consist on simple cells, which are mainly, the activation functions (NAF), derivatives (DNAF), multipliers and weight update circuits. The analogue design is based on current-mode translinear techniques using MOS transistors working in the weak inversion region in order to reduce both the voltage supply and the power consumption. Moreover, with the purpose of minimizing the noise, offset and distortion of even order, the topologies are fully-differential and balanced. The circuit, named ANNE (Analogue Neural NEt), has been prototyped and characterized as a proof of concept on CMOS AMI-0.5A technology occupying a total area of 2.7mm2. The chip includes two versions of neural nets with on-chip BP learning algorithm, which are respectively a 2-1 and a 2-2-1 implementations. The proposed nets have been experimentally tested using supply voltages from 2.5V to 1.8V, which is suitable for single cell lithium-ion battery supply applications. Experimental results of both implementations included in ANNE exhibit a good performance on solving classification problems. These results have been compared with other proposed Analogue VLSI implementations of Neural Nets published in the literature demonstrating that our proposal is very efficient in terms of occupied area and power consumption.\n\n\nNeural network construction via back-propagation\nInternational Nuclear Information System (INIS) \nBurwick, T.T.\n1994-06-01\nA method is presented that combines back-propagation with multi-layer neural network construction. Back-propagation is used not only to adjust the weights but also the signal functions. Going from one network to an equivalent one that has additional linear units, the non-linearity of these units and thus their effective presence is then introduced via back-propagation (weight-splitting). The back-propagated error causes the network to include new units in order to minimize the error function. We also show how this formalism allows to escape local minima\n\n\nClassifying spatially heterogeneous wetland communities using machine learning algorithms and spectral and textural features.\nScience.gov (United States)\nSzantoi, Zoltan; Escobedo, Francisco J; Abd-Elrahman, Amr; Pearlstine, Leonard; Dewitt, Bon; Smith, Scot\n2015-05-01\nMapping of wetlands (marsh vs. swamp vs. upland) is a common remote sensing application.Yet, discriminating between similar freshwater communities such as graminoid/sedge fromremotely sensed imagery is more difficult. Most of this activity has been performed using medium to low resolution imagery. There are only a few studies using highspatial resolutionimagery and machine learning image classification algorithms for mapping heterogeneouswetland plantcommunities. This study addresses this void by analyzing whether machine learning classifierssuch as decisiontrees (DT) and artificial neural networks (ANN) can accurately classify graminoid/sedgecommunities usinghigh resolution aerial imagery and image texture data in the Everglades National Park, Florida.In addition tospectral bands, the normalized difference vegetation index, and first- and second-order texturefeatures derivedfrom the near-infrared band were analyzed. Classifier accuracies were assessed using confusiontablesand the calculated kappa coefficients of the resulting maps. The results indicated that an ANN(multilayerperceptron based on backpropagation) algorithm produced a statistically significantly higheraccuracy(82.04%) than the DT (QUEST) algorithm (80.48%) or the maximum likelihood (80.56%)classifier (\u00ce\u00b1texture features.\n\n\nUniversal perceptron and DNA-like learning algorithm for binary neural networks: LSBF and PBF implementations.\nScience.gov (United States)\nChen, Fangyue; Chen, Guanrong Ron; He, Guolong; Xu, Xiubin; He, Qinbin\n2009-10-01\nUniversal perceptron (UP), a generalization of Rosenblatt's perceptron, is considered in this paper, which is capable of implementing all Boolean functions (BFs). In the classification of BFs, there are: 1) linearly separable Boolean function (LSBF) class, 2) parity Boolean function (PBF) class, and 3) non-LSBF and non-PBF class. To implement these functions, UP takes different kinds of simple topological structures in which each contains at most one hidden layer along with the smallest possible number of hidden neurons. Inspired by the concept of DNA sequences in biological systems, a novel learning algorithm named DNA-like learning is developed, which is able to quickly train a network with any prescribed BF. The focus is on performing LSBF and PBF by a single-layer perceptron (SLP) with the new algorithm. Two criteria for LSBF and PBF are proposed, respectively, and a new measure for a BF, named nonlinearly separable degree (NLSD), is introduced. In the sense of this measure, the PBF is the most complex one. The new algorithm has many advantages including, in particular, fast running speed, good robustness, and no need of considering the convergence property. For example, the number of iterations and computations in implementing the basic 2-bit logic operations such as AND, OR, and XOR by using the new algorithm is far smaller than the ones needed by using other existing algorithms such as error-correction (EC) and backpropagation (BP) algorithms. Moreover, the synaptic weights and threshold values derived from UP can be directly used in designing of the template of cellular neural networks (CNNs), which has been considered as a new spatial-temporal sensory computing paradigm.\n\n\nSecond-Order Learning Methods for a Multilayer Perceptron\nInternational Nuclear Information System (INIS) \nIvanov, V.V.; Purehvdorzh, B.; Puzynin, I.V.\n1994-01-01\nFirst- and second-order learning methods for feed-forward multilayer neural networks are studied. Newton-type and quasi-Newton algorithms are considered and compared with commonly used back-propagation algorithm. It is shown that, although second-order algorithms require enhanced computer facilities, they provide better convergence and simplicity in usage. 13 refs., 2 figs., 2 tabs\n\n\nA Decomposition Algorithm for Learning Bayesian Network Structures from Data\nDEFF Research Database (Denmark)\nZeng, Yifeng; Cordero Hernandez, Jorge\n2008-01-01\nIt is a challenging task of learning a large Bayesian network from a small data set. Most conventional structural learning approaches run into the computational as well as the statistical problems. We propose a decomposition algorithm for the structure construction without having to learn...... the complete network. The new learning algorithm firstly finds local components from the data, and then recover the complete network by joining the learned components. We show the empirical performance of the decomposition algorithm in several benchmark networks....\n\n\n\n\n\u00ab\n2\n3\n4\n5\n6\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n3\n4\n5\n6\n7\n\u00bb\n\n\n\n\n\n\n\n\nConjugate descent formulation of backpropagation error in ...\nAfrican Journals Online (AJOL)\n\n\nnique of backpropagation was popularized in a paper by Rumelhart, et al. ... the training of a multilayer neural network using a gradient descent approach applied to a .... superior convergence of the conjugate descent method over a standard\u00c2\u00a0...\n\n\nA Learning Algorithm based on High School Teaching Wisdom\nOpenAIRE\nPhilip, Ninan Sajeeth\n2010-01-01\nA learning algorithm based on primary school teaching and learning is presented. The methodology is to continuously evaluate a student and to give them training on the examples for which they repeatedly fail, until, they can correctly answer all types of questions. This incremental learning procedure produces better learning curves by demanding the student to optimally dedicate their learning time on the failed examples. When used in machine learning, the algorithm is found to train a machine...\n\n\n\"Accelerated Perceptron\": A Self-Learning Linear Decision Algorithm\nOpenAIRE\nZuev, Yu. A.\n2003-01-01\nThe class of linear decision rules is studied. A new algorithm for weight correction, called an \"accelerated perceptron\", is proposed. In contrast to classical Rosenblatt's perceptron this algorithm modifies the weight vector at each step. The algorithm may be employed both in learning and in self-learning modes. The theoretical aspects of the behaviour of the algorithm are studied when the algorithm is used for the purpose of increasing the decision reliability by means of weighted voting. I...\n\n\nLearning algorithms and automatic processing of languages; Algorithmes a apprentissage et traitement automatique des langues\nEnergy Technology Data Exchange (ETDEWEB)\nFluhr, Christian Yves Andre\n1977-06-15\nThis research thesis concerns the field of artificial intelligence. It addresses learning algorithms applied to automatic processing of languages. The author first briefly describes some mechanisms of human intelligence in order to describe how these mechanisms are simulated on a computer. He outlines the specific role of learning in various manifestations of intelligence. Then, based on the Markov's algorithm theory, the author discusses the notion of learning algorithm. Two main types of learning algorithms are then addressed: firstly, an 'algorithm-teacher dialogue' type sanction-based algorithm which aims at learning how to solve grammatical ambiguities in submitted texts; secondly, an algorithm related to a document system which structures semantic data automatically obtained from a set of texts in order to be able to understand by references to any question on the content of these texts.\n\n\nOnline learning algorithm for ensemble of decision rules\nKAUST Repository\nChikalov, Igor; Moshkov, Mikhail; Zielosko, Beata\n2011-01-01\nWe describe an online learning algorithm that builds a system of decision rules for a classification problem. Rules are constructed according to the minimum description length principle by a greedy algorithm or using the dynamic programming approach\n\n\nCascade Error Projection: An Efficient Hardware Learning Algorithm\nScience.gov (United States)\nDuong, T. A.\n1995-01-01\nA new learning algorithm termed cascade error projection (CEP) is presented. CEP is an adaption of a constructive architecture from cascade correlation and the dynamical stepsize of A/D conversion from the cascade back propagation algorithm.\n\n\nBoosting Learning Algorithm for Stock Price Forecasting\nScience.gov (United States)\nWang, Chengzhang; Bai, Xiaoming\n2018-03-01\nTo tackle complexity and uncertainty of stock market behavior, more studies have introduced machine learning algorithms to forecast stock price. ANN (artificial neural network) is one of the most successful and promising applications. We propose a boosting-ANN model in this paper to predict the stock close price. On the basis of boosting theory, multiple weak predicting machines, i.e. ANNs, are assembled to build a stronger predictor, i.e. boosting-ANN model. New error criteria of the weak studying machine and rules of weights updating are adopted in this study. We select technical factors from financial markets as forecasting input variables. Final results demonstrate the boosting-ANN model works better than other ones for stock price forecasting.\n\n\nResearch on machine learning framework based on random forest algorithm\nScience.gov (United States)\nRen, Qiong; Cheng, Hui; Han, Hai\n2017-03-01\nWith the continuous development of machine learning, industry and academia have released a lot of machine learning frameworks based on distributed computing platform, and have been widely used. However, the existing framework of machine learning is limited by the limitations of machine learning algorithm itself, such as the choice of parameters and the interference of noises, the high using threshold and so on. This paper introduces the research background of machine learning framework, and combined with the commonly used random forest algorithm in machine learning classification algorithm, puts forward the research objectives and content, proposes an improved adaptive random forest algorithm (referred to as ARF), and on the basis of ARF, designs and implements the machine learning framework.\n\n\nAn algorithm for learning real-time automata\nNARCIS (Netherlands)\nVerwer, S.E.; De Weerdt, M.M.; Witteveen, C.\n2007-01-01\nWe describe an algorithm for learning simple timed automata, known as real-time automata. The transitions of real-time automata can have a temporal constraint on the time of occurrence of the current symbol relative to the previous symbol. The learning algorithm is similar to the redblue fringe\n\n\nRelevance as a metric for evaluating machine learning algorithms\nNARCIS (Netherlands)\nKota Gopalakrishna, A.; Ozcelebi, T.; Liotta, A.; Lukkien, J.J.\n2013-01-01\nIn machine learning, the choice of a learning algorithm that is suitable for the application domain is critical. The performance metric used to compare different algorithms must also reflect the concerns of users in the application domain under consideration. In this work, we propose a novel\n\n\nChallenges in the Verification of Reinforcement Learning Algorithms\nScience.gov (United States)\nVan Wesel, Perry; Goodloe, Alwyn E.\n2017-01-01\nMachine learning (ML) is increasingly being applied to a wide array of domains from search engines to autonomous vehicles. These algorithms, however, are notoriously complex and hard to verify. This work looks at the assumptions underlying machine learning algorithms as well as some of the challenges in trying to verify ML algorithms. Furthermore, we focus on the specific challenges of verifying reinforcement learning algorithms. These are highlighted using a specific example. Ultimately, we do not offer a solution to the complex problem of ML verification, but point out possible approaches for verification and interesting research opportunities.\n\n\nLocation-Aware Mobile Learning of Spatial Algorithms\nScience.gov (United States)\nKaravirta, Ville\n2013-01-01\nLearning an algorithm--a systematic sequence of operations for solving a problem with given input--is often difficult for students due to the abstract nature of the algorithms and the data they process. To help students understand the behavior of algorithms, a subfield in computing education research has focused on algorithm\u00e2\u20ac\u00a6\n\n\nAutomated training for algorithms that learn from genomic data.\nScience.gov (United States)\nCilingir, Gokcen; Broschat, Shira L\n2015-01-01\nSupervised machine learning algorithms are used by life scientists for a variety of objectives. Expert-curated public gene and protein databases are major resources for gathering data to train these algorithms. While these data resources are continuously updated, generally, these updates are not incorporated into published machine learning algorithms which thereby can become outdated soon after their introduction. In this paper, we propose a new model of operation for supervised machine learning algorithms that learn from genomic data. By defining these algorithms in a pipeline in which the training data gathering procedure and the learning process are automated, one can create a system that generates a classifier or predictor using information available from public resources. The proposed model is explained using three case studies on SignalP, MemLoci, and ApicoAP in which existing machine learning models are utilized in pipelines. Given that the vast majority of the procedures described for gathering training data can easily be automated, it is possible to transform valuable machine learning algorithms into self-evolving learners that benefit from the ever-changing data available for gene products and to develop new machine learning algorithms that are similarly capable.\n\n\nSOL: A Library for Scalable Online Learning Algorithms\nOpenAIRE\nWu, Yue; Hoi, Steven C. H.; Liu, Chenghao; Lu, Jing; Sahoo, Doyen; Yu, Nenghai\n2016-01-01\nSOL is an open-source library for scalable online learning algorithms, and is particularly suitable for learning with high-dimensional data. The library provides a family of regular and sparse online learning algorithms for large-scale binary and multi-class classification tasks with high efficiency, scalability, portability, and extensibility. SOL was implemented in C++, and provided with a collection of easy-to-use command-line tools, python wrappers and library calls for users and develope...\n\n\nHuman resource recommendation algorithm based on ensemble learning and Spark\nScience.gov (United States)\nCong, Zihan; Zhang, Xingming; Wang, Haoxiang; Xu, Hongjie\n2017-08-01\nAiming at the problem of \u00e2\u20ac\u0153information overload\u00e2\u20ac\ufffd in the human resources industry, this paper proposes a human resource recommendation algorithm based on Ensemble Learning. The algorithm considers the characteristics and behaviours of both job seeker and job features in the real business circumstance. Firstly, the algorithm uses two ensemble learning methods-Bagging and Boosting. The outputs from both learning methods are then merged to form user interest model. Based on user interest model, job recommendation can be extracted for users. The algorithm is implemented as a parallelized recommendation system on Spark. A set of experiments have been done and analysed. The proposed algorithm achieves significant improvement in accuracy, recall rate and coverage, compared with recommendation algorithms such as UserCF and ItemCF.\n\n\nA strategy for quantum algorithm design assisted by machine learning\nInternational Nuclear Information System (INIS) \nBang, Jeongho; Lee, Jinhyoung; Ryu, Junghee; Yoo, Seokwon; Paw\u00c5\u201aowski, Marcin\n2014-01-01\nWe propose a method for quantum algorithm design assisted by machine learning. The method uses a quantum\u00e2\u20ac\u201cclassical hybrid simulator, where a \u00e2\u20ac\u02dcquantum student\u00e2\u20ac\u2122 is being taught by a \u00e2\u20ac\u02dcclassical teacher\u00e2\u20ac\u2122. In other words, in our method, the learning system is supposed to evolve into a quantum algorithm for a given problem, assisted by a classical main-feedback system. Our method is applicable for designing quantum oracle-based algorithms. We chose, as a case study, an oracle decision problem, called a Deutsch\u00e2\u20ac\u201cJozsa problem. We showed by using Monte Carlo simulations that our simulator can faithfully learn a quantum algorithm for solving the problem for a given oracle. Remarkably, the learning time is proportional to the square root of the total number of parameters, rather than showing the exponential dependence found in the classical machine learning-based method. (paper)\n\n\nA strategy for quantum algorithm design assisted by machine learning\nScience.gov (United States)\nBang, Jeongho; Ryu, Junghee; Yoo, Seokwon; Paw\u00c5\u201aowski, Marcin; Lee, Jinhyoung\n2014-07-01\nWe propose a method for quantum algorithm design assisted by machine learning. The method uses a quantum-classical hybrid simulator, where a \u00e2\u20ac\u02dcquantum student\u00e2\u20ac\u2122 is being taught by a \u00e2\u20ac\u02dcclassical teacher\u00e2\u20ac\u2122. In other words, in our method, the learning system is supposed to evolve into a quantum algorithm for a given problem, assisted by a classical main-feedback system. Our method is applicable for designing quantum oracle-based algorithms. We chose, as a case study, an oracle decision problem, called a Deutsch-Jozsa problem. We showed by using Monte Carlo simulations that our simulator can faithfully learn a quantum algorithm for solving the problem for a given oracle. Remarkably, the learning time is proportional to the square root of the total number of parameters, rather than showing the exponential dependence found in the classical machine learning-based method.\n\n\nPremature saturation in backpropagation networks: Mechanism and necessary conditions\nInternational Nuclear Information System (INIS) \nVitela, J.E.; Reifman, J.\n1997-01-01\nThe mechanism that gives rise to the phenomenon of premature saturation of the output units of feedforward multilayer neural networks during training with the standard backpropagation algorithm is described. The entire process of premature saturation is characterized by three distinct stages and it is concluded that the momentum term plays the leading role in the occurrence of the phenomenon. The necessary conditions for the occurrence of premature saturation are presented and a new method is proposed, based on these conditions, that eliminates the occurrence of the phenomenon. Validity of the conditions and the proposed method are illustrated through simulation results. Three case studies are presented. The first two came from a training session for classification of three component failures in a nuclear power plant. The last case, comes from a training session for classification of welded fuel elements\n\n\nImbalanced learning foundations, algorithms, and applications\nCERN Document Server\nHe, Haibo\n2013-01-01\nThe first book of its kind to review the current status and future direction of the exciting new branch of machine learning/data mining called imbalanced learning Imbalanced learning focuses on how an intelligent system can learn when it is provided with imbalanced data. Solving imbalanced learning problems is critical in numerous data-intensive networked systems, including surveillance, security, Internet, finance, biomedical, defense, and more. Due to the inherent complex characteristics of imbalanced data sets, learning from such data requires new understandings, principles,\n\n\nLeave-two-out stability of ontology learning algorithm\nInternational Nuclear Information System (INIS) \nWu, Jianzhang; Yu, Xiao; Zhu, Linli; Gao, Wei\n2016-01-01\nOntology is a semantic analysis and calculation model, which has been applied to many subjects. Ontology similarity calculation and ontology mapping are employed as machine learning approaches. The purpose of this paper is to study the leave-two-out stability of ontology learning algorithm. Several leave-two-out stabilities are defined in ontology learning setting and the relationship among these stabilities are presented. Furthermore, the results manifested reveal that leave-two-out stability is a sufficient and necessary condition for ontology learning algorithm.\n\n\n\n\n\u00ab\n3\n4\n5\n6\n7\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n4\n5\n6\n7\n8\n\u00bb\n\n\n\n\n\n\n\n\nQUEST : Eliminating online supervised learning for efficient classification algorithms\nNARCIS (Netherlands)\nZwartjes, Ardjan; Havinga, Paul J.M.; Smit, Gerard J.M.; Hurink, Johann L.\n2016-01-01\nIn this work, we introduce QUEST (QUantile Estimation after Supervised Training), an adaptive classification algorithm for Wireless Sensor Networks (WSNs) that eliminates the necessity for online supervised learning. Online processing is important for many sensor network applications. Transmitting\n\n\nTeaching learning based optimization algorithm and its engineering applications\nCERN Document Server\nRao, R Venkata\n2016-01-01\nDescribing a new optimization algorithm, the \u00e2\u20ac\u0153Teaching-Learning-Based Optimization (TLBO),\u00e2\u20ac\ufffd in a clear and lucid style, this book maximizes reader insights into how the TLBO algorithm can be used to solve continuous and discrete optimization problems involving single or multiple objectives. As the algorithm operates on the principle of teaching and learning, where teachers influence the quality of learners\u00e2\u20ac\u2122 results, the elitist version of TLBO algorithm (ETLBO) is described along with applications of the TLBO algorithm in the fields of electrical engineering, mechanical design, thermal engineering, manufacturing engineering, civil engineering, structural engineering, computer engineering, electronics engineering, physics and biotechnology. The book offers a valuable resource for scientists, engineers and practitioners involved in the development and usage of advanced optimization algorithms.\n\n\nExtreme learning machines 2013 algorithms and applications\nCERN Document Server\nToh, Kar-Ann; Romay, Manuel; Mao, Kezhi\n2014-01-01\nIn recent years, ELM has emerged as a revolutionary technique of computational intelligence, and has attracted considerable attentions. An extreme learning machine (ELM) is a single layer feed-forward neural network alike learning system, whose connections from the input layer to the hidden layer are randomly generated, while the connections from the hidden layer to the output layer are learned through linear learning methods. The outstanding merits of extreme learning machine (ELM) are its fast learning speed, trivial human intervene and high scalability. \u00c2\u00a0 This book contains some selected papers from the International Conference on Extreme Learning Machine 2013, which was held in Beijing China, October 15-17, 2013. This conference aims to bring together the researchers and practitioners of extreme learning machine from a variety of fields including artificial intelligence, biomedical engineering and bioinformatics, system modelling and control, and signal and image processing, to promote research and discu...\n\n\nA parallel ILP algorithm that incorporates incremental batch learning\nOpenAIRE\nNuno Fonseca; Rui Camacho; Fernado Silva\n2003-01-01\nIn this paper we tackle the problems of eciency and scala-bility faced by Inductive Logic Programming (ILP) systems. We proposethe use of parallelism to improve eciency and the use of an incrementalbatch learning to address the scalability problem. We describe a novelparallel algorithm that incorporates into ILP the method of incremen-tal batch learning. The theoretical complexity of the algorithm indicatesthat a linear speedup can be achieved.\n\n\nMachine Learning in Production Systems Design Using Genetic Algorithms\nOpenAIRE\nAbu Qudeiri Jaber; Yamamoto Hidehiko Rizauddin Ramli\n2008-01-01\nTo create a solution for a specific problem in machine learning, the solution is constructed from the data or by use a search method. Genetic algorithms are a model of machine learning that can be used to find nearest optimal solution. While the great advantage of genetic algorithms is the fact that they find a solution through evolution, this is also the biggest disadvantage. Evolution is inductive, in nature life does not evolve towards a good solution but it evolves aw...\n\n\nOnline learning algorithm for ensemble of decision rules\nKAUST Repository\nChikalov, Igor\n2011-01-01\nWe describe an online learning algorithm that builds a system of decision rules for a classification problem. Rules are constructed according to the minimum description length principle by a greedy algorithm or using the dynamic programming approach. \u00c2\u00a9 2011 Springer-Verlag.\n\n\nMind the Gaps: Controversies about Algorithms, Learning and Trendy Knowledge\nScience.gov (United States)\nArgenton, Gerald\n2017-01-01\nThis article critically explores the ways by which the Web could become a more learning-oriented medium in the age of, but also in spite of, the newly bred algorithmic cultures. The social dimension of algorithms is reported in literature as being a socio-technological entanglement that has a powerful influence on users' practices and their lived\u00e2\u20ac\u00a6\n\n\nRecommending Learning Activities in Social Network Using Data Mining Algorithms\nScience.gov (United States)\nMahnane, Lamia\n2017-01-01\nIn this paper, we show how data mining algorithms (e.g. Apriori Algorithm (AP) and Collaborative Filtering (CF)) is useful in New Social Network (NSN-AP-CF). \"NSN-AP-CF\" processes the clusters based on different learning styles. Next, it analyzes the habits and the interests of the users through mining the frequent episodes by the\u00e2\u20ac\u00a6\n\n\nMachine learning algorithms for datasets popularity prediction\nCERN Document Server\nKancys, Kipras\n2016-01-01\nThis report represents continued study where ML algorithms were used to predict databases popularity. Three topics were covered. First of all, there was a discrepancy between old and new meta-data collection procedures, so a reason for that had to be found. Secondly, different parameters were analysed and dropped to make algorithms perform better. And third, it was decided to move modelling part on Spark.\n\n\nAssessment of various supervised learning algorithms using different performance metrics\nScience.gov (United States)\nSusheel Kumar, S. M.; Laxkar, Deepak; Adhikari, Sourav; Vijayarajan, V.\n2017-11-01\nOur work brings out comparison based on the performance of supervised machine learning algorithms on a binary classification task. The supervised machine learning algorithms which are taken into consideration in the following work are namely Support Vector Machine(SVM), Decision Tree(DT), K Nearest Neighbour (KNN), Na\u00c3\u00afve Bayes(NB) and Random Forest(RF). This paper mostly focuses on comparing the performance of above mentioned algorithms on one binary classification task by analysing the Metrics such as Accuracy, F-Measure, G-Measure, Precision, Misclassification Rate, False Positive Rate, True Positive Rate, Specificity, Prevalence.\n\n\nConvergence analysis of Chauvin's PCA learning algorithm with a constant learning rate\nInternational Nuclear Information System (INIS) \nLv Jiancheng; Yi Zhang\n2007-01-01\nThe convergence of Chauvin's PCA learning algorithm with a constant learning rate is studied in this paper by using a DDT method (deterministic discrete-time system method). Different from the DCT method (deterministic continuous-time system method), the DDT method does not require that the learning rate converges to zero. An invariant set of Chauvin's algorithm with a constant learning rate is obtained so that the non-divergence of this algorithm can be guaranteed. Rigorous mathematic proofs are provided to prove the local convergence of this algorithm\n\n\nConvergence analysis of Chauvin's PCA learning algorithm with a constant learning rate\nEnergy Technology Data Exchange (ETDEWEB)\nLv Jiancheng [Computational Intelligence Laboratory, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 610054 (China); Yi Zhang [Computational Intelligence Laboratory, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 610054 (China)]. E-mail: zhangyi@uestc.edu.cn\n2007-05-15\nThe convergence of Chauvin's PCA learning algorithm with a constant learning rate is studied in this paper by using a DDT method (deterministic discrete-time system method). Different from the DCT method (deterministic continuous-time system method), the DDT method does not require that the learning rate converges to zero. An invariant set of Chauvin's algorithm with a constant learning rate is obtained so that the non-divergence of this algorithm can be guaranteed. Rigorous mathematic proofs are provided to prove the local convergence of this algorithm.\n\n\nConjugate descent formulation of backpropagation error in feedforward neural networks\nDirectory of Open Access Journals (Sweden)\nNK Sharma\n2009-06-01\nFull Text Available The feedforward neural network architecture uses backpropagation learning to determine optimal weights between different interconnected layers. This learning procedure uses a gradient descent technique applied to a sum-of-squares error function for the given input-output pattern. It employs an iterative procedure to minimise the error function for a given set of patterns, by adjusting the weights of the network. The first derivates of the error with respect to the weights identify the local error surface in the descent direction. Hence the network exhibits a different local error surface for every different pattern presented to it, and weights are iteratively modified in order to minimise the current local error. The determination of an optimal weight vector is possible only when the total minimum error (mean of the minimum local errors for all patterns from the training set may be minimised. In this paper, we present a general mathematical formulation for the second derivative of the error function with respect to the weights (which represents a conjugate descent for arbitrary feedforward neural network topologies, and we use this derivative information to obtain the optimal weight vector. The local error is backpropagated among the units of hidden layers via the second order derivative of the error with respect to the weights of the hidden and output layers independently and also in combination. The new total minimum error point may be evaluated with the help of the current total minimum error and the current minimised local error. The weight modification processes is performed twice: once with respect to the present local error and once more with respect to the current total or mean error. We present some numerical evidence that our proposed method yields better network weights than those determined via a conventional gradient descent approach.\n\n\nLearning motor skills from algorithms to robot experiments\nCERN Document Server\nKober, Jens\n2014-01-01\nThis book presents the state of the art in reinforcement learning applied to robotics both in terms of novel algorithms and applications. It discusses recent approaches that allow robots to learn motor skills and presents tasks that need to take into account the dynamic behavior of the robot and its environment, where a kinematic movement plan is not sufficient. The book illustrates a method that learns to generalize parameterized motor plans which is obtained by imitation or reinforcement learning, by adapting a small set of global parameters, and appropriate kernel-based reinforcement learning algorithms. The presented applications explore highly dynamic tasks and exhibit a very efficient learning process. All proposed approaches have been extensively validated with benchmarks tasks, in simulation, and on real robots. These tasks correspond to sports and games but the presented techniques are also applicable to more mundane household tasks. The book is based on the first author\u00e2\u20ac\u2122s doctoral thesis, which wo...\n\n\nCognitive Radio Transceivers: RF, Spectrum Sensing, and Learning Algorithms Review\nDirectory of Open Access Journals (Sweden)\nLise Safatly\n2014-01-01\nreconfigurable radio frequency (RF parts, enhanced spectrum sensing algorithms, and sophisticated machine learning techniques. In this paper, we present a review of the recent advances in CR transceivers hardware design and algorithms. For the RF part, three types of antennas are presented: UWB antennas, frequency-reconfigurable/tunable antennas, and UWB antennas with reconfigurable band notches. The main challenges faced by the design of the other RF blocks are also discussed. Sophisticated spectrum sensing algorithms that overcome main sensing challenges such as model uncertainty, hardware impairments, and wideband sensing are highlighted. The cognitive engine features are discussed. Moreover, we study unsupervised classification algorithms and a reinforcement learning (RL algorithm that has been proposed to perform decision-making in CR networks.\n\n\nEvolving Stochastic Learning Algorithm based on Tsallis entropic index\nScience.gov (United States)\nAnastasiadis, A. D.; Magoulas, G. D.\n2006-03-01\nIn this paper, inspired from our previous algorithm, which was based on the theory of Tsallis statistical mechanics, we develop a new evolving stochastic learning algorithm for neural networks. The new algorithm combines deterministic and stochastic search steps by employing a different adaptive stepsize for each network weight, and applies a form of noise that is characterized by the nonextensive entropic index q, regulated by a weight decay term. The behavior of the learning algorithm can be made more stochastic or deterministic depending on the trade off between the temperature T and the q values. This is achieved by introducing a formula that defines a time-dependent relationship between these two important learning parameters. Our experimental study verifies that there are indeed improvements in the convergence speed of this new evolving stochastic learning algorithm, which makes learning faster than using the original Hybrid Learning Scheme (HLS). In addition, experiments are conducted to explore the influence of the entropic index q and temperature T on the convergence speed and stability of the proposed method.\n\n\nOptimal quantum sample complexity of learning algorithms\nNARCIS (Netherlands)\nArunachalam, S.; de Wolf, R.\n2017-01-01\nIn learning theory, the VC dimension of a concept class C is the most common way to measure its \"richness.\" A fundamental result says that the number of examples needed to learn an unknown target concept c 2 C under an unknown distribution D, is tightly determined by the VC dimension d of the\n\n\nOptimizing learning path selection through memetic algorithms\nNARCIS (Netherlands)\nAcampora, G.; Gaeta, M.; Loia, V.; Ritrovato, P.; Salerno, S.\n2008-01-01\ne-Learning is a critical support mechanism for industrial and academic organizations to enhance the skills of employees and students and, consequently, the overall competitiveness in the new economy. The remarkable velocity and volatility of modern knowledge require novel learning methods offering\n\n\nInteractive Algorithms for Unsupervised Machine Learning\nScience.gov (United States)\n\n2015-06-01\nin Neural Information Processing Systems, 2013. 14 [3] Louigi Addario-Berry, Nicolas Broutin, Luc Devroye, and Ga\u00cc\ufffdbor Lugosi. On combinato- rial...Myung Jin Choi, Vincent Y F Tan , Animashree Anandkumar, and Alan S Willsky. Learn- ing Latent Tree Graphical Models. Journal of Machine Learning\n\n\nBackpropagation Neural Ensemble for Localizing and Recognizing Non-Standardized Malaysia\u00e2\u20ac\u2122s Car Plates\nOpenAIRE\nChin Kim On; Teo Kein Yau; Rayner Alfred; Jason Teo; Patricia Anthony; Wang Cheng\n2016-01-01\nIn this paper, we describe a research project that autonomously localizes and recognizes non-standardized Malaysian\u00e2\u20ac\u2122s car plates using conventional Backpropagation algorithm (BPP) in combination with Ensemble Neural Network (ENN). We compared the results with the results obtained using simple Feed-Forward Neural Network (FFNN). This research aims to solve four main issues; (1) localization of car plates that has the same colour with the vehicle colour, (2) detection and recognition of car pla...\n\n\n\n\n\u00ab\n4\n5\n6\n7\n8\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n5\n6\n7\n8\n9\n\u00bb\n\n\n\n\n\n\n\n\nQUEST: Eliminating Online Supervised Learning for Efficient Classification Algorithms\nDirectory of Open Access Journals (Sweden)\nArdjan Zwartjes\n2016-10-01\nFull Text Available In this work, we introduce QUEST (QUantile Estimation after Supervised Training, an adaptive classification algorithm for Wireless Sensor Networks (WSNs that eliminates the necessity for online supervised learning. Online processing is important for many sensor network applications. Transmitting raw sensor data puts high demands on the battery, reducing network life time. By merely transmitting partial results or classifications based on the sampled data, the amount of traffic on the network can be significantly reduced. Such classifications can be made by learning based algorithms using sampled data. An important issue, however, is the training phase of these learning based algorithms. Training a deployed sensor network requires a lot of communication and an impractical amount of human involvement. QUEST is a hybrid algorithm that combines supervised learning in a controlled environment with unsupervised learning on the location of deployment. Using the SITEX02 dataset, we demonstrate that the presented solution works with a performance penalty of less than 10% in 90% of the tests. Under some circumstances, it even outperforms a network of classifiers completely trained with supervised learning. As a result, the need for on-site supervised learning and communication for training is completely eliminated by our solution.\n\n\nQUEST: Eliminating Online Supervised Learning for Efficient Classification Algorithms.\nScience.gov (United States)\nZwartjes, Ardjan; Havinga, Paul J M; Smit, Gerard J M; Hurink, Johann L\n2016-10-01\nIn this work, we introduce QUEST (QUantile Estimation after Supervised Training), an adaptive classification algorithm for Wireless Sensor Networks (WSNs) that eliminates the necessity for online supervised learning. Online processing is important for many sensor network applications. Transmitting raw sensor data puts high demands on the battery, reducing network life time. By merely transmitting partial results or classifications based on the sampled data, the amount of traffic on the network can be significantly reduced. Such classifications can be made by learning based algorithms using sampled data. An important issue, however, is the training phase of these learning based algorithms. Training a deployed sensor network requires a lot of communication and an impractical amount of human involvement. QUEST is a hybrid algorithm that combines supervised learning in a controlled environment with unsupervised learning on the location of deployment. Using the SITEX02 dataset, we demonstrate that the presented solution works with a performance penalty of less than 10% in 90% of the tests. Under some circumstances, it even outperforms a network of classifiers completely trained with supervised learning. As a result, the need for on-site supervised learning and communication for training is completely eliminated by our solution.\n\n\nTrans-algorithmic nature of learning in biological systems.\nScience.gov (United States)\nShimansky, Yury P\n2018-05-02\nLearning ability is a vitally important, distinctive property of biological systems, which provides dynamic stability in non-stationary environments. Although several different types of learning have been successfully modeled using a universal computer, in general, learning cannot be described by an algorithm. In other words, algorithmic approach to describing the functioning of biological systems is not sufficient for adequate grasping of what is life. Since biosystems are parts of the physical world, one might hope that adding some physical mechanisms and principles to the concept of algorithm could provide extra possibilities for describing learning in its full generality. However, a straightforward approach to that through the so-called physical hypercomputation so far has not been successful. Here an alternative approach is proposed. Biosystems are described as achieving enumeration of possible physical compositions though random incremental modifications inflicted on them by active operating resources (AORs) in the environment. Biosystems learn through algorithmic regulation of the intensity of the above modifications according to a specific optimality criterion. From the perspective of external observers, biosystems move in the space of different algorithms driven by random modifications imposed by the environmental AORs. A particular algorithm is only a snapshot of that motion, while the motion itself is essentially trans-algorithmic. In this conceptual framework, death of unfit members of a population, for example, is viewed as a trans-algorithmic modification made in the population as a biosystem by environmental AORs. Numerous examples of AOR utilization in biosystems of different complexity, from viruses to multicellular organisms, are provided.\n\n\nSome chaotic behaviors in a MCA learning algorithm with a constant learning rate\nInternational Nuclear Information System (INIS) \nLv Jiancheng; Yi Zhang\n2007-01-01\nDouglas's minor component analysis algorithm with a constant learning rate has both stability and chaotic dynamical behavior under some conditions. The paper explores such dynamical behavior of this algorithm. Certain stability and chaos of this algorithm are derived. Waveform plots, Lyapunov exponents and bifurcation diagrams are presented to illustrate the existence of chaotic behavior\n\n\nGradient Learning Algorithms for Ontology Computing\nScience.gov (United States)\nGao, Wei; Zhu, Linli\n2014-01-01\nThe gradient learning model has been raising great attention in view of its promising perspectives for applications in statistics, data dimensionality reducing, and other specific fields. In this paper, we raise a new gradient learning model for ontology similarity measuring and ontology mapping in multidividing setting. The sample error in this setting is given by virtue of the hypothesis space and the trick of ontology dividing operator. Finally, two experiments presented on plant and humanoid robotics field verify the efficiency of the new computation model for ontology similarity measure and ontology mapping applications in multidividing setting. PMID:25530752\n\n\nGradient Learning Algorithms for Ontology Computing\nDirectory of Open Access Journals (Sweden)\nWei Gao\n2014-01-01\nFull Text Available The gradient learning model has been raising great attention in view of its promising perspectives for applications in statistics, data dimensionality reducing, and other specific fields. In this paper, we raise a new gradient learning model for ontology similarity measuring and ontology mapping in multidividing setting. The sample error in this setting is given by virtue of the hypothesis space and the trick of ontology dividing operator. Finally, two experiments presented on plant and humanoid robotics field verify the efficiency of the new computation model for ontology similarity measure and ontology mapping applications in multidividing setting.\n\n\nMachine-Learning Algorithms to Code Public Health Spending Accounts.\nScience.gov (United States)\nBrady, Eoghan S; Leider, Jonathon P; Resnick, Beth A; Alfonso, Y Natalia; Bishai, David\n\nGovernment public health expenditure data sets require time- and labor-intensive manipulation to summarize results that public health policy makers can use. Our objective was to compare the performances of machine-learning algorithms with manual classification of public health expenditures to determine if machines could provide a faster, cheaper alternative to manual classification. We used machine-learning algorithms to replicate the process of manually classifying state public health expenditures, using the standardized public health spending categories from the Foundational Public Health Services model and a large data set from the US Census Bureau. We obtained a data set of 1.9 million individual expenditure items from 2000 to 2013. We collapsed these data into 147\u00e2\u20ac\u2030280 summary expenditure records, and we followed a standardized method of manually classifying each expenditure record as public health, maybe public health, or not public health. We then trained 9 machine-learning algorithms to replicate the manual process. We calculated recall, precision, and coverage rates to measure the performance of individual and ensembled algorithms. Compared with manual classification, the machine-learning random forests algorithm produced 84% recall and 91% precision. With algorithm ensembling, we achieved our target criterion of 90% recall by using a consensus ensemble of \u00e2\u2030\u00a56 algorithms while still retaining 93% coverage, leaving only 7% of the summary expenditure records unclassified. Machine learning can be a time- and cost-saving tool for estimating public health spending in the United States. It can be used with standardized public health spending categories based on the Foundational Public Health Services model to help parse public health expenditure information from other types of health-related spending, provide data that are more comparable across public health organizations, and evaluate the impact of evidence-based public health resource allocation.\n\n\nLearning Sorting Algorithms through Visualization Construction\nScience.gov (United States)\nCetin, Ibrahim; Andrews-Larson, Christine\n2016-01-01\nRecent increased interest in computational thinking poses an important question to researchers: What are the best ways to teach fundamental computing concepts to students? Visualization is suggested as one way of supporting student learning. This mixed-method study aimed to (i) examine the effect of instruction in which students constructed\u00e2\u20ac\u00a6\n\n\nFast algorithm selection using learning curves\nNARCIS (Netherlands)\nRijn, van J.N.; Abdulrahman, S.M.; Brazdil, P.; Vanschoren, J.; Fromont, E.; De Bie, T.; Leeuwen, van M.\n2015-01-01\nOne of the challenges in Machine Learning to find a classifier and parameter settings that work well on a given dataset. Evaluating all possible combinations typically takes too much time, hence many solutions have been proposed that attempt to predict which classifiers are most promising to try. As\n\n\nEvolutionary Pseudo-Relaxation Learning Algorithm for Bidirectional Associative Memory\nInstitute of Scientific and Technical Information of China (English)\nSheng-Zhi Du; Zeng-Qiang Chen; Zhu-Zhi Yuan\n2005-01-01\nThis paper analyzes the sensitivity to noise in BAM (Bidirectional Associative Memory), and then proves the noise immunity of BAM relates not only to the minimum absolute value of net inputs (MAV) but also to the variance of weights associated with synapse connections. In fact, it is a positive monotonically increasing function of the quotient of MAV divided by the variance of weights. Besides, the performance of pseudo-relaxation method depends on learning parameters (\u00ce\u00bb and \u00ce\u00b6), but the relation of them is not linear. So it is hard to find a best combination of \u00ce\u00bb and \u00ce\u00b6 which leads to the best BAM performance. And it is obvious that pseudo-relaxation is a kind of local optimization method, so it cannot guarantee to get the global optimal solution. In this paper, a novel learning algorithm EPRBAM (evolutionary psendo-relaxation learning algorithm for bidirectional association memory) employing genetic algorithm and pseudo-relaxation method is proposed to get feasible solution of BAM weight matrix. This algorithm uses the quotient as the fitness of each individual and employs pseudo-relaxation method to adjust individual solution when it does not satisfy constraining condition any more after genetic operation. Experimental results show this algorithm improves noise immunity of BAM greatly. At the same time, EPRBAM does not depend on learning parameters and can get global optimal solution.\n\n\nAlgorithm-Dependent Generalization Bounds for Multi-Task Learning.\nScience.gov (United States)\nLiu, Tongliang; Tao, Dacheng; Song, Mingli; Maybank, Stephen J\n2017-02-01\nOften, tasks are collected for multi-task learning (MTL) because they share similar feature structures. Based on this observation, in this paper, we present novel algorithm-dependent generalization bounds for MTL by exploiting the notion of algorithmic stability. We focus on the performance of one particular task and the average performance over multiple tasks by analyzing the generalization ability of a common parameter that is shared in MTL. When focusing on one particular task, with the help of a mild assumption on the feature structures, we interpret the function of the other tasks as a regularizer that produces a specific inductive bias. The algorithm for learning the common parameter, as well as the predictor, is thereby uniformly stable with respect to the domain of the particular task and has a generalization bound with a fast convergence rate of order O(1/n), where n is the sample size of the particular task. When focusing on the average performance over multiple tasks, we prove that a similar inductive bias exists under certain conditions on the feature structures. Thus, the corresponding algorithm for learning the common parameter is also uniformly stable with respect to the domains of the multiple tasks, and its generalization bound is of the order O(1/T), where T is the number of tasks. These theoretical analyses naturally show that the similarity of feature structures in MTL will lead to specific regularizations for predicting, which enables the learning algorithms to generalize fast and correctly from a few examples.\n\n\nA globally convergent MC algorithm with an adaptive learning rate.\nScience.gov (United States)\nPeng, Dezhong; Yi, Zhang; Xiang, Yong; Zhang, Haixian\n2012-02-01\nThis brief deals with the problem of minor component analysis (MCA). Artificial neural networks can be exploited to achieve the task of MCA. Recent research works show that convergence of neural networks based MCA algorithms can be guaranteed if the learning rates are less than certain thresholds. However, the computation of these thresholds needs information about the eigenvalues of the autocorrelation matrix of data set, which is unavailable in online extraction of minor component from input data stream. In this correspondence, we introduce an adaptive learning rate into the OJAn MCA algorithm, such that its convergence condition does not depend on any unobtainable information, and can be easily satisfied in practical applications.\n\n\nMINING ON CAR DATABASE EMPLOYING LEARNING AND CLUSTERING ALGORITHMS\nOpenAIRE\nMuhammad Rukunuddin Ghalib; Shivam Vohra; Sunish Vohra; Akash Juneja\n2013-01-01\nIn data mining, classification is a form of data analysis that can be used to extract models describing important data classes. Two of the known learning algorithms used are Na\u00c3\u00afve Bayesian (NB) and SMO (Self-Minimal-Optimisation) .Thus the following two learning algorithms are used on a Car review database and thus a model is hence created which predicts the characteristic of a review comment after getting trained. It was found that model successfully predicted correctly about the review comm...\n\n\nLearning Search Algorithms: An Educational View\nDirectory of Open Access Journals (Sweden)\nAles Janota\n2014-12-01\nFull Text Available Artificial intelligence methods find their practical usage in many applications including maritime industry. The paper concentrates on the methods of uninformed and informed search, potentially usable in solving of complex problems based on the state space representation. The problem of introducing the search algorithms to newcomers has its technical and psychological dimensions. The authors show how it is possible to cope with both of them through design and use of specialized authoring systems. A typical example of searching a path through the maze is used to demonstrate how to test, observe and compare properties of various search strategies. Performance of search methods is evaluated based on the common criteria.\n\n\nLearning behavior and temporary minima of two-layer neural networks\nNARCIS (Netherlands)\nAnnema, Anne J.; Hoen, Klaas; Hoen, Klaas; Wallinga, Hans\n1994-01-01\nThis paper presents a mathematical analysis of the occurrence of temporary minima during training of a single-output, two-layer neural network, with learning according to the back-propagation algorithm. A new vector decomposition method is introduced, which simplifies the mathematical analysis of\n\n\nRandomized Algorithms for Scalable Machine Learning\nOpenAIRE\nKleiner, Ariel Jacob\n2012-01-01\nMany existing procedures in machine learning and statistics are computationally intractable in the setting of large-scale data. As a result, the advent of rapidly increasing dataset sizes, which should be a boon yielding improved statistical performance, instead severely blunts the usefulness of a variety of existing inferential methods. In this work, we use randomness to ameliorate this lack of scalability by reducing complex, computationally difficult inferential problems to larger sets o...\n\n\nReinforcement Learning for Online Control of Evolutionary Algorithms\nNARCIS (Netherlands)\nEiben, A.; Horvath, Mark; Kowalczyk, Wojtek; Schut, Martijn\n2007-01-01\nThe research reported in this paper is concerned with assessing the usefulness of reinforcment learning (RL) for on-line calibration of parameters in evolutionary algorithms (EA). We are running an RL procedure and the EA simultaneously and the RL is changing the EA parameters on-the-fly. We\n\n\nFour Machine Learning Algorithms for Biometrics Fusion: A Comparative Study\nDirectory of Open Access Journals (Sweden)\nI. G. Damousis\n2012-01-01\nFull Text Available We examine the efficiency of four machine learning algorithms for the fusion of several biometrics modalities to create a multimodal biometrics security system. The algorithms examined are Gaussian Mixture Models (GMMs, Artificial Neural Networks (ANNs, Fuzzy Expert Systems (FESs, and Support Vector Machines (SVMs. The fusion of biometrics leads to security systems that exhibit higher recognition rates and lower false alarms compared to unimodal biometric security systems. Supervised learning was carried out using a number of patterns from a well-known benchmark biometrics database, and the validation/testing took place with patterns from the same database which were not included in the training dataset. The comparison of the algorithms reveals that the biometrics fusion system is superior to the original unimodal systems and also other fusion schemes found in the literature.\n\n\nAn Efficient Inductive Genetic Learning Algorithm for Fuzzy Relational Rules\nDirectory of Open Access Journals (Sweden)\nAntonio\n2012-04-01\nFull Text Available Fuzzy modelling research has traditionally focused on certain types of fuzzy rules. However, the use of alternative rule models could improve the ability of fuzzy systems to represent a specific problem. In this proposal, an extended fuzzy rule model, that can include relations between variables in the antecedent of rules is presented. Furthermore, a learning algorithm based on the iterative genetic approach which is able to represent the knowledge using this model is proposed as well. On the other hand, potential relations among initial variables imply an exponential growth in the feasible rule search space. Consequently, two filters for detecting relevant potential relations are added to the learning algorithm. These filters allows to decrease the search space complexity and increase the algorithm efficiency. Finally, we also present an experimental study to demonstrate the benefits of using fuzzy relational rules.\n\n\nLearning sorting algorithms through visualization construction\nScience.gov (United States)\nCetin, Ibrahim; Andrews-Larson, Christine\n2016-01-01\nRecent increased interest in computational thinking poses an important question to researchers: What are the best ways to teach fundamental computing concepts to students? Visualization is suggested as one way of supporting student learning. This mixed-method study aimed to (i) examine the effect of instruction in which students constructed visualizations on students' programming achievement and students' attitudes toward computer programming, and (ii) explore how this kind of instruction supports students' learning according to their self-reported experiences in the course. The study was conducted with 58 pre-service teachers who were enrolled in their second programming class. They expect to teach information technology and computing-related courses at the primary and secondary levels. An embedded experimental model was utilized as a research design. Students in the experimental group were given instruction that required students to construct visualizations related to sorting, whereas students in the control group viewed pre-made visualizations. After the instructional intervention, eight students from each group were selected for semi-structured interviews. The results showed that the intervention based on visualization construction resulted in significantly better acquisition of sorting concepts. However, there was no significant difference between the groups with respect to students' attitudes toward computer programming. Qualitative data analysis indicated that students in the experimental group constructed necessary abstractions through their engagement in visualization construction activities. The authors of this study argue that the students' active engagement in the visualization construction activities explains only one side of students' success. The other side can be explained through the instructional approach, constructionism in this case, used to design instruction. The conclusions and implications of this study can be used by researchers and\n\n\n\n\n\u00ab\n5\n6\n7\n8\n9\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n6\n7\n8\n9\n10\n\u00bb\n\n\n\n\n\n\n\n\nGeneralized SMO algorithm for SVM-based multitask learning.\nScience.gov (United States)\nCai, Feng; Cherkassky, Vladimir\n2012-06-01\nExploiting additional information to improve traditional inductive learning is an active research area in machine learning. In many supervised-learning applications, training data can be naturally separated into several groups, and incorporating this group information into learning may improve generalization. Recently, Vapnik proposed a general approach to formalizing such problems, known as \"learning with structured data\" and its support vector machine (SVM) based optimization formulation called SVM+. Liang and Cherkassky showed the connection between SVM+ and multitask learning (MTL) approaches in machine learning, and proposed an SVM-based formulation for MTL called SVM+MTL for classification. Training the SVM+MTL classifier requires the solution of a large quadratic programming optimization problem which scales as O(n(3)) with sample size n. So there is a need to develop computationally efficient algorithms for implementing SVM+MTL. This brief generalizes Platt's sequential minimal optimization (SMO) algorithm to the SVM+MTL setting. Empirical results show that, for typical SVM+MTL problems, the proposed generalized SMO achieves over 100 times speed-up, in comparison with general-purpose optimization routines.\n\n\nInverse Problems in Geodynamics Using Machine Learning Algorithms\nScience.gov (United States)\nShahnas, M. H.; Yuen, D. A.; Pysklywec, R. N.\n2018-01-01\nDuring the past few decades numerical studies have been widely employed to explore the style of circulation and mixing in the mantle of Earth and other planets. However, in geodynamical studies there are many properties from mineral physics, geochemistry, and petrology in these numerical models. Machine learning, as a computational statistic-related technique and a subfield of artificial intelligence, has rapidly emerged recently in many fields of sciences and engineering. We focus here on the application of supervised machine learning (SML) algorithms in predictions of mantle flow processes. Specifically, we emphasize on estimating mantle properties by employing machine learning techniques in solving an inverse problem. Using snapshots of numerical convection models as training samples, we enable machine learning models to determine the magnitude of the spin transition-induced density anomalies that can cause flow stagnation at midmantle depths. Employing support vector machine algorithms, we show that SML techniques can successfully predict the magnitude of mantle density anomalies and can also be used in characterizing mantle flow patterns. The technique can be extended to more complex geodynamic problems in mantle dynamics by employing deep learning algorithms for putting constraints on properties such as viscosity, elastic parameters, and the nature of thermal and chemical anomalies.\n\n\nComponent Pin Recognition Using Algorithms Based on Machine Learning\nScience.gov (United States)\nXiao, Yang; Hu, Hong; Liu, Ze; Xu, Jiangchang\n2018-04-01\nThe purpose of machine vision for a plug-in machine is to improve the machine\u00e2\u20ac\u2122s stability and accuracy, and recognition of the component pin is an important part of the vision. This paper focuses on component pin recognition using three different techniques. The first technique involves traditional image processing using the core algorithm for binary large object (BLOB) analysis. The second technique uses the histogram of oriented gradients (HOG), to experimentally compare the effect of the support vector machine (SVM) and the adaptive boosting machine (AdaBoost) learning meta-algorithm classifiers. The third technique is the use of an in-depth learning method known as convolution neural network (CNN), which involves identifying the pin by comparing a sample to its training. The main purpose of the research presented in this paper is to increase the knowledge of learning methods used in the plug-in machine industry in order to achieve better results.\n\n\nAutomated Essay Grading using Machine Learning Algorithm\nScience.gov (United States)\nRamalingam, V. V.; Pandian, A.; Chetry, Prateek; Nigam, Himanshu\n2018-04-01\nEssays are paramount for of assessing the academic excellence along with linking the different ideas with the ability to recall but are notably time consuming when they are assessed manually. Manual grading takes significant amount of evaluator\u00e2\u20ac\u2122s time and hence it is an expensive process. Automated grading if proven effective will not only reduce the time for assessment but comparing it with human scores will also make the score realistic. The project aims to develop an automated essay assessment system by use of machine learning techniques by classifying a corpus of textual entities into small number of discrete categories, corresponding to possible grades. Linear regression technique will be utilized for training the model along with making the use of various other classifications and clustering techniques. We intend to train classifiers on the training set, make it go through the downloaded dataset, and then measure performance our dataset by comparing the obtained values with the dataset values. We have implemented our model using java.\n\n\nDNA Cryptography and Deep Learning using Genetic Algorithm with NW algorithm for Key Generation.\nScience.gov (United States)\nKalsi, Shruti; Kaur, Harleen; Chang, Victor\n2017-12-05\nCryptography is not only a science of applying complex mathematics and logic to design strong methods to hide data called as encryption, but also to retrieve the original data back, called decryption. The purpose of cryptography is to transmit a message between a sender and receiver such that an eavesdropper is unable to comprehend it. To accomplish this, not only we need a strong algorithm, but a strong key and a strong concept for encryption and decryption process. We have introduced a concept of DNA Deep Learning Cryptography which is defined as a technique of concealing data in terms of DNA sequence and deep learning. In the cryptographic technique, each alphabet of a letter is converted into a different combination of the four bases, namely; Adenine (A), Cytosine (C), Guanine (G) and Thymine (T), which make up the human deoxyribonucleic acid (DNA). Actual implementations with the DNA don't exceed laboratory level and are expensive. To bring DNA computing on a digital level, easy and effective algorithms are proposed in this paper. In proposed work we have introduced firstly, a method and its implementation for key generation based on the theory of natural selection using Genetic Algorithm with Needleman-Wunsch (NW) algorithm and Secondly, a method for implementation of encryption and decryption based on DNA computing using biological operations Transcription, Translation, DNA Sequencing and Deep Learning.\n\n\nPrediction of benzo[a]pyrene content of smoked sausage using back-propagation artificial neural network.\nScience.gov (United States)\nChen, Yan; Cai, Kezhou; Tu, Zehui; Nie, Wen; Ji, Tuo; Hu, Bing; Chen, Conggui; Jiang, Shaotong\n2017-11-29\nBenzo[a]pyrene (BaP), a potent mutagen and carcinogen, is reported to be present in processed meat products and, in particular, in smoked meat. However, few methods exist for predictive determination of the BaP content of smoked meats such as sausage. In this study, an artificial neural network (ANN) model based on the back-propagation (BP) algorithm was used to predict the BaP content of smoked sausage. The results showed that the BP network based on the Levenberg-Marquardt algorithm was the best suited for creating a nonlinear map between the input and output parameters. The optimal network structure was 3-7-1 and the learning rate was 0.6. This BP-ANN model allowed for accurate predictions, with the correlation coefficients (R) for the experimentally determined training, validation, test and global data sets being 0.94, 0.96, 0.95 and 0.95 respectively. The validation performance was 0.013, suggesting that the proposed BP-ANN may be used to predictively detect the BaP content of smoked meat products. An effective predictive model was constructed for estimation of the BaP content of smoked sausage using ANN modeling techniques, which shows potential to predict the BaP content in smoked sausage. \u00c2\u00a9 2017 Society of Chemical Industry. \u00c2\u00a9 2017 Society of Chemical Industry.\n\n\nDenoising of gravitational wave signals via dictionary learning algorithms\nScience.gov (United States)\nTorres-Forn\u00c3\u00a9, Alejandro; Marquina, Antonio; Font, Jos\u00c3\u00a9 A.; Ib\u00c3\u00a1\u00c3\u00b1ez, Jos\u00c3\u00a9 M.\n2016-12-01\nGravitational wave astronomy has become a reality after the historical detections accomplished during the first observing run of the two advanced LIGO detectors. In the following years, the number of detections is expected to increase significantly with the full commissioning of the advanced LIGO, advanced Virgo and KAGRA detectors. The development of sophisticated data analysis techniques to improve the opportunities of detection for low signal-to-noise-ratio events is, hence, a most crucial effort. In this paper, we present one such technique, dictionary-learning algorithms, which have been extensively developed in the last few years and successfully applied mostly in the context of image processing. However, to the best of our knowledge, such algorithms have not yet been employed to denoise gravitational wave signals. By building dictionaries from numerical relativity templates of both binary black holes mergers and bursts of rotational core collapse, we show how machine-learning algorithms based on dictionaries can also be successfully applied for gravitational wave denoising. We use a subset of signals from both catalogs, embedded in nonwhite Gaussian noise, to assess our techniques with a large sample of tests and to find the best model parameters. The application of our method to the actual signal GW150914 shows promising results. Dictionary-learning algorithms could be a complementary addition to the gravitational wave data analysis toolkit. They may be used to extract signals from noise and to infer physical parameters if the data are in good enough agreement with the morphology of the dictionary atoms.\n\n\nGenetic algorithm enhanced by machine learning in dynamic aperture optimization\nScience.gov (United States)\nLi, Yongjun; Cheng, Weixing; Yu, Li Hua; Rainer, Robert\n2018-05-01\nWith the aid of machine learning techniques, the genetic algorithm has been enhanced and applied to the multi-objective optimization problem presented by the dynamic aperture of the National Synchrotron Light Source II (NSLS-II) Storage Ring. During the evolution processes employed by the genetic algorithm, the population is classified into different clusters in the search space. The clusters with top average fitness are given \"elite\" status. Intervention on the population is implemented by repopulating some potentially competitive candidates based on the experience learned from the accumulated data. These candidates replace randomly selected candidates among the original data pool. The average fitness of the population is therefore improved while diversity is not lost. Maintaining diversity ensures that the optimization is global rather than local. The quality of the population increases and produces more competitive descendants accelerating the evolution process significantly. When identifying the distribution of optimal candidates, they appear to be located in isolated islands within the search space. Some of these optimal candidates have been experimentally confirmed at the NSLS-II storage ring. The machine learning techniques that exploit the genetic algorithm can also be used in other population-based optimization problems such as particle swarm algorithm.\n\n\nDynamics of the evolution of learning algorithms by selection\nInternational Nuclear Information System (INIS) \nNeirotti, Juan Pablo; Caticha, Nestor\n2003-01-01\nWe study the evolution of artificial learning systems by means of selection. Genetic programming is used to generate populations of programs that implement algorithms used by neural network classifiers to learn a rule in a supervised learning scenario. In contrast to concentrating on final results, which would be the natural aim while designing good learning algorithms, we study the evolution process. Phenotypic and genotypic entropies, which describe the distribution of fitness and of symbols, respectively, are used to monitor the dynamics. We identify significant functional structures responsible for the improvements in the learning process. In particular, some combinations of variables and operators are useful in assessing performance in rule extraction and can thus implement annealing of the learning schedule. We also find combinations that can signal surprise, measured on a single example, by the difference between predicted and correct classification. When such favorable structures appear, they are disseminated on very short time scales throughout the population. Due to such abruptness they can be thought of as dynamical transitions. But foremost, we find a strict temporal order of such discoveries. Structures that measure performance are never useful before those for measuring surprise. Invasions of the population by such structures in the reverse order were never observed. Asymptotically, the generalization ability approaches Bayesian results\n\n\nPredicting Smoking Status Using Machine Learning Algorithms and Statistical Analysis\nDirectory of Open Access Journals (Sweden)\nCharles Frank\n2018-03-01\nFull Text Available Smoking has been proven to negatively affect health in a multitude of ways. As of 2009, smoking has been considered the leading cause of preventable morbidity and mortality in the United States, continuing to plague the country\u00e2\u20ac\u2122s overall health. This study aims to investigate the viability and effectiveness of some machine learning algorithms for predicting the smoking status of patients based on their blood tests and vital readings results. The analysis of this study is divided into two parts: In part 1, we use One-way ANOVA analysis with SAS tool to show the statistically significant difference in blood test readings between smokers and non-smokers. The results show that the difference in INR, which measures the effectiveness of anticoagulants, was significant in favor of non-smokers which further confirms the health risks associated with smoking. In part 2, we use five machine learning algorithms: Na\u00c3\u00afve Bayes, MLP, Logistic regression classifier, J48 and Decision Table to predict the smoking status of patients. To compare the effectiveness of these algorithms we use: Precision, Recall, F-measure and Accuracy measures. The results show that the Logistic algorithm outperformed the four other algorithms with Precision, Recall, F-Measure, and Accuracy of 83%, 83.4%, 83.2%, 83.44%, respectively.\n\n\nComparison of machine learning algorithms for detecting coral reef\nDirectory of Open Access Journals (Sweden)\nEduardo Tusa\n2014-09-01\nFull Text Available (Received: 2014/07/31 - Accepted: 2014/09/23This work focuses on developing a fast coral reef detector, which is used for an autonomous underwater vehicle, AUV. A fast detection secures the AUV stabilization respect to an area of reef as fast as possible, and prevents devastating collisions. We use the algorithm of Purser et al. (2009 because of its precision. This detector has two parts: feature extraction that uses Gabor Wavelet filters, and feature classification that uses machine learning based on Neural Networks. Due to the extensive time of the Neural Networks, we exchange for a classification algorithm based on Decision Trees. We use a database of 621 images of coral reef in Belize (110 images for training and 511 images for testing. We implement the bank of Gabor Wavelets filters using C++ and the OpenCV library. We compare the accuracy and running time of 9 machine learning algorithms, whose result was the selection of the Decision Trees algorithm. Our coral detector performs 70ms of running time in comparison to 22s executed by the algorithm of Purser et al. (2009.\n\n\nVideo game for learning and metaphorization of recursive algorithms\nDirectory of Open Access Journals (Sweden)\nRicardo Inacio Alvares Silva\n2013-09-01\nFull Text Available The learning of recursive algorithms in computer programming is problematic, because its execution and resolution is not natural to the thinking way people are trained and used to since young. As with other topics in algorithms, we use metaphors to make parallels between the abstract and the concrete to help in understanding the operation of recursive algorithms. However, the classic metaphors employed in this area, such as calculating factorial recursively and Towers of Hanoi game, may just confuse more or be insufficient. In this work, we produced a computer game to assist students in computer courses in learning recursive algorithms. It was designed to have regular video game characteristics, with narrative and classical gameplay elements, commonly found in this kind of product. Aiding to education occurs through metaphorization, or in other words, through experiences provided by game situations that refer to recursive algorithms. To this end, we designed and imbued in the game four valid metaphors related to the theory, and other minor references to the subject.\n\n\nAdvanced Machine learning Algorithm Application for Rotating Machine Health Monitoring\nEnergy Technology Data Exchange (ETDEWEB)\nKanemoto, Shigeru; Watanabe, Masaya [The University of Aizu, Aizuwakamatsu (Japan); Yusa, Noritaka [Tohoku University, Sendai (Japan)\n2014-08-15\nThe present paper tries to evaluate the applicability of conventional sound analysis techniques and modern machine learning algorithms to rotating machine health monitoring. These techniques include support vector machine, deep leaning neural network, etc. The inner ring defect and misalignment anomaly sound data measured by a rotating machine mockup test facility are used to verify the above various kinds of algorithms. Although we cannot find remarkable difference of anomaly discrimination performance, some methods give us the very interesting eigen patterns corresponding to normal and abnormal states. These results will be useful for future more sensitive and robust anomaly monitoring technology.\n\n\nAdvanced Machine learning Algorithm Application for Rotating Machine Health Monitoring\nInternational Nuclear Information System (INIS) \nKanemoto, Shigeru; Watanabe, Masaya; Yusa, Noritaka\n2014-01-01\nThe present paper tries to evaluate the applicability of conventional sound analysis techniques and modern machine learning algorithms to rotating machine health monitoring. These techniques include support vector machine, deep leaning neural network, etc. The inner ring defect and misalignment anomaly sound data measured by a rotating machine mockup test facility are used to verify the above various kinds of algorithms. Although we cannot find remarkable difference of anomaly discrimination performance, some methods give us the very interesting eigen patterns corresponding to normal and abnormal states. These results will be useful for future more sensitive and robust anomaly monitoring technology\n\n\nGeneral asymmetric neutral networks and structure design by genetic algorithms: A learning rule for temporal patterns\nEnergy Technology Data Exchange (ETDEWEB)\nBornholdt, S. [Heidelberg Univ., (Germany). Inst., fuer Theoretische Physik; Graudenz, D. [Lawrence Berkeley Lab., CA (United States)\n1993-07-01\nA learning algorithm based on genetic algorithms for asymmetric neural networks with an arbitrary structure is presented. It is suited for the learning of temporal patterns and leads to stable neural networks with feedback.\n\n\nGeneral asymmetric neutral networks and structure design by genetic algorithms: A learning rule for temporal patterns\nInternational Nuclear Information System (INIS) \nBornholdt, S.\n1993-07-01\nA learning algorithm based on genetic algorithms for asymmetric neural networks with an arbitrary structure is presented. It is suited for the learning of temporal patterns and leads to stable neural networks with feedback\n\n\nPrediction of tides using back-propagation neural networks\nDigital Repository Service at National Institute of Oceanography (India)\nMandal, S.\n\nPrediction of tides is very much essential for human activities and to reduce the construction cost in marine environment. This paper presents an application of the artificial neural network with back-propagation procedures for accurate prediction...\n\n\nImage Denoising Algorithm Combined with SGK Dictionary Learning and Principal Component Analysis Noise Estimation\nDirectory of Open Access Journals (Sweden)\nWenjing Zhao\n2018-01-01\nFull Text Available SGK (sequential generalization of K-means dictionary learning denoising algorithm has the characteristics of fast denoising speed and excellent denoising performance. However, the noise standard deviation must be known in advance when using SGK algorithm to process the image. This paper presents a denoising algorithm combined with SGK dictionary learning and the principal component analysis (PCA noise estimation. At first, the noise standard deviation of the image is estimated by using the PCA noise estimation algorithm. And then it is used for SGK dictionary learning algorithm. Experimental results show the following: (1 The SGK algorithm has the best denoising performance compared with the other three dictionary learning algorithms. (2 The SGK algorithm combined with PCA is superior to the SGK algorithm combined with other noise estimation algorithms. (3 Compared with the original SGK algorithm, the proposed algorithm has higher PSNR and better denoising performance.\n\n\nFast, Simple and Accurate Handwritten Digit Classification by Training Shallow Neural Network Classifiers with the 'Extreme Learning Machine' Algorithm.\nDirectory of Open Access Journals (Sweden)\nMark D McDonnell\n\nFull Text Available Recent advances in training deep (multi-layer architectures have inspired a renaissance in neural network use. For example, deep convolutional networks are becoming the default option for difficult tasks on large datasets, such as image and speech recognition. However, here we show that error rates below 1% on the MNIST handwritten digit benchmark can be replicated with shallow non-convolutional neural networks. This is achieved by training such networks using the 'Extreme Learning Machine' (ELM approach, which also enables a very rapid training time (\u00e2\u02c6\u00bc 10 minutes. Adding distortions, as is common practise for MNIST, reduces error rates even further. Our methods are also shown to be capable of achieving less than 5.5% error rates on the NORB image database. To achieve these results, we introduce several enhancements to the standard ELM algorithm, which individually and in combination can significantly improve performance. The main innovation is to ensure each hidden-unit operates only on a randomly sized and positioned patch of each image. This form of random 'receptive field' sampling of the input ensures the input weight matrix is sparse, with about 90% of weights equal to zero. Furthermore, combining our methods with a small number of iterations of a single-batch backpropagation method can significantly reduce the number of hidden-units required to achieve a particular performance. Our close to state-of-the-art results for MNIST and NORB suggest that the ease of use and accuracy of the ELM algorithm for designing a single-hidden-layer neural network classifier should cause it to be given greater consideration either as a standalone method for simpler problems, or as the final classification stage in deep neural networks applied to more difficult problems.\n\n\nNeural Network Back-Propagation Algorithm for Sensing Hypergols\nScience.gov (United States)\nPerotti, Jose; Lewis, Mark; Medelius, Pedro; Bastin, Gary\n2013-01-01\nFast, continuous detection of a wide range of hazardous substances simultaneously is needed to achieve improved safety for personnel working with hypergolic fuels and oxidizers, as well as other hazardous substances, with a requirement for such detection systems to warn personnel immediately upon the sudden advent of hazardous conditions, with a high probability of detection and a low false alarm rate. The primary purpose of this software is to read the voltage outputs from voltage dividers containing carbon nano - tube sensors as a variable resistance leg, and to recognize quickly when a leak has occurred through recognizing that a generalized pattern change in resistivity of a carbon nanotube sensor has occurred upon exposure to dangerous substances, and, further, to identify quickly just what substance is present through detailed pattern recognition of the shape of the response provided by the carbon nanotube sensor.\n\n\n\n\n\u00ab\n6\n7\n8\n9\n10\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n7\n8\n9\n10\n11\n\u00bb\n\n\n\n\n\n\n\n\nClassification of underground pipe scanned images using feature extraction and neuro-fuzzy algorithm.\nScience.gov (United States)\nSinha, S K; Karray, F\n2002-01-01\nPipeline surface defects such as holes and cracks cause major problems for utility managers, particularly when the pipeline is buried under the ground. Manual inspection for surface defects in the pipeline has a number of drawbacks, including subjectivity, varying standards, and high costs. Automatic inspection system using image processing and artificial intelligence techniques can overcome many of these disadvantages and offer utility managers an opportunity to significantly improve quality and reduce costs. A recognition and classification of pipe cracks using images analysis and neuro-fuzzy algorithm is proposed. In the preprocessing step the scanned images of pipe are analyzed and crack features are extracted. In the classification step the neuro-fuzzy algorithm is developed that employs a fuzzy membership function and error backpropagation algorithm. The idea behind the proposed approach is that the fuzzy membership function will absorb variation of feature values and the backpropagation network, with its learning ability, will show good classification efficiency.\n\n\nTraining Deep Spiking Neural Networks Using Backpropagation.\nScience.gov (United States)\nLee, Jun Haeng; Delbruck, Tobi; Pfeiffer, Michael\n2016-01-01\nDeep spiking neural networks (SNNs) hold the potential for improving the latency and energy efficiency of deep neural networks through data-driven event-based computation. However, training such networks is difficult due to the non-differentiable nature of spike events. In this paper, we introduce a novel technique, which treats the membrane potentials of spiking neurons as differentiable signals, where discontinuities at spike times are considered as noise. This enables an error backpropagation mechanism for deep SNNs that follows the same principles as in conventional deep networks, but works directly on spike signals and membrane potentials. Compared with previous methods relying on indirect training and conversion, our technique has the potential to capture the statistics of spikes more precisely. We evaluate the proposed framework on artificially generated events from the original MNIST handwritten digit benchmark, and also on the N-MNIST benchmark recorded with an event-based dynamic vision sensor, in which the proposed method reduces the error rate by a factor of more than three compared to the best previous SNN, and also achieves a higher accuracy than a conventional convolutional neural network (CNN) trained and tested on the same data. We demonstrate in the context of the MNIST task that thanks to their event-driven operation, deep SNNs (both fully connected and convolutional) trained with our method achieve accuracy equivalent with conventional neural networks. In the N-MNIST example, equivalent accuracy is achieved with about five times fewer computational operations.\n\n\nAn Educational System for Learning Search Algorithms and Automatically Assessing Student Performance\nScience.gov (United States)\nGrivokostopoulou, Foteini; Perikos, Isidoros; Hatzilygeroudis, Ioannis\n2017-01-01\nIn this paper, first we present an educational system that assists students in learning and tutors in teaching search algorithms, an artificial intelligence topic. Learning is achieved through a wide range of learning activities. Algorithm visualizations demonstrate the operational functionality of algorithms according to the principles of active\u00e2\u20ac\u00a6\n\n\nAlignment of Custom Standards by Machine Learning Algorithms\nDirectory of Open Access Journals (Sweden)\nAdela Sirbu\n2010-09-01\nFull Text Available Building an efficient model for automatic alignment of terminologies would bring a significant improvement to the information retrieval process. We have developed and compared two machine learning based algorithms whose aim is to align 2 custom standards built on a 3 level taxonomy, using kNN and SVM classifiers that work on a vector representation consisting of several similarity measures. The weights utilized by the kNN were optimized with an evolutionary algorithm, while the SVM classifier's hyper-parameters were optimized with a grid search algorithm. The database used for train was semi automatically obtained by using the Coma++ tool. The performance of our aligners is shown by the results obtained on the test set.\n\n\nImplementation of dictionary pair learning algorithm for image quality improvement\nScience.gov (United States)\nVimala, C.; Aruna Priya, P.\n2018-04-01\nThis paper proposes an image denoising on dictionary pair learning algorithm. Visual information is transmitted in the form of digital images is becoming a major method of communication in the modern age, but the image obtained after transmissions is often corrupted with noise. The received image needs processing before it can be used in applications. Image denoising involves the manipulation of the image data to produce a visually high quality image.\n\n\nTowards the compression of parton densities through machine learning algorithms\nCERN Document Server\nCarrazza, Stefano\n2016-01-01\nOne of the most fascinating challenges in the context of parton density function (PDF) is the determination of the best combined PDF uncertainty from individual PDF sets. Since 2014 multiple methodologies have been developed to achieve this goal. In this proceedings we first summarize the strategy adopted by the PDF4LHC15 recommendation and then, we discuss about a new approach to Monte Carlo PDF compression based on clustering through machine learning algorithms.\n\n\nOptimization in Quaternion Dynamic Systems: Gradient, Hessian, and Learning Algorithms.\nScience.gov (United States)\nXu, Dongpo; Xia, Yili; Mandic, Danilo P\n2016-02-01\nThe optimization of real scalar functions of quaternion variables, such as the mean square error or array output power, underpins many practical applications. Solutions typically require the calculation of the gradient and Hessian. However, real functions of quaternion variables are essentially nonanalytic, which are prohibitive to the development of quaternion-valued learning systems. To address this issue, we propose new definitions of quaternion gradient and Hessian, based on the novel generalized Hamilton-real (GHR) calculus, thus making a possible efficient derivation of general optimization algorithms directly in the quaternion field, rather than using the isomorphism with the real domain, as is current practice. In addition, unlike the existing quaternion gradients, the GHR calculus allows for the product and chain rule, and for a one-to-one correspondence of the novel quaternion gradient and Hessian with their real counterparts. Properties of the quaternion gradient and Hessian relevant to numerical applications are also introduced, opening a new avenue of research in quaternion optimization and greatly simplified the derivations of learning algorithms. The proposed GHR calculus is shown to yield the same generic algorithm forms as the corresponding real- and complex-valued algorithms. Advantages of the proposed framework are illuminated over illustrative simulations in quaternion signal processing and neural networks.\n\n\nLearning-based meta-algorithm for MRI brain extraction.\nScience.gov (United States)\nShi, Feng; Wang, Li; Gilmore, John H; Lin, Weili; Shen, Dinggang\n2011-01-01\nMultiple-segmentation-and-fusion method has been widely used for brain extraction, tissue segmentation, and region of interest (ROI) localization. However, such studies are hindered in practice by their computational complexity, mainly coming from the steps of template selection and template-to-subject nonlinear registration. In this study, we address these two issues and propose a novel learning-based meta-algorithm for MRI brain extraction. Specifically, we first use exemplars to represent the entire template library, and assign the most similar exemplar to the test subject. Second, a meta-algorithm combining two existing brain extraction algorithms (BET and BSE) is proposed to conduct multiple extractions directly on test subject. Effective parameter settings for the meta-algorithm are learned from the training data and propagated to subject through exemplars. We further develop a level-set based fusion method to combine multiple candidate extractions together with a closed smooth surface, for obtaining the final result. Experimental results show that, with only a small portion of subjects for training, the proposed method is able to produce more accurate and robust brain extraction results, at Jaccard Index of 0.956 +/- 0.010 on total 340 subjects under 6-fold cross validation, compared to those by the BET and BSE even using their best parameter combinations.\n\n\nMACHINE LEARNING METHODS IN DIGITAL AGRICULTURE: ALGORITHMS AND CASES\nDirectory of Open Access Journals (Sweden)\nAleksandr Vasilyevich Koshkarov\n2018-05-01\nFull Text Available Ensuring food security is a major challenge in many countries. With a growing global population, the issues of improving the efficiency of agriculture have become most relevant. Farmers are looking for new ways to increase yields, and governments of different countries are developing new programs to support agriculture. This contributes to a more active implementation of digital technologies in agriculture, helping farmers to make better decisions, increase yields and take care of the environment. The central point is the collection and analysis of data. In the industry of agriculture, data can be collected from different sources and may contain useful patterns that identify potential problems or opportunities. Data should be analyzed using machine learning algorithms to extract useful insights. Such methods of precision farming allow the farmer to monitor individual parts of the field, optimize the consumption of water and chemicals, and identify problems quickly. Purpose: to make an overview of the machine learning algorithms used for data analysis in agriculture. Methodology: an overview of the relevant literature; a survey of farmers. Results: relevant algorithms of machine learning for the analysis of data in agriculture at various levels were identified: soil analysis (soil assessment, soil classification, soil fertility predictions, weather forecast (simulation of climate change, temperature and precipitation prediction, and analysis of vegetation (weed identification, vegetation classification, plant disease identification, crop forecasting. Practical implications: agriculture, crop production.\n\n\nInference algorithms and learning theory for Bayesian sparse factor analysis\nInternational Nuclear Information System (INIS) \nRattray, Magnus; Sharp, Kevin; Stegle, Oliver; Winn, John\n2009-01-01\nBayesian sparse factor analysis has many applications; for example, it has been applied to the problem of inferring a sparse regulatory network from gene expression data. We describe a number of inference algorithms for Bayesian sparse factor analysis using a slab and spike mixture prior. These include well-established Markov chain Monte Carlo (MCMC) and variational Bayes (VB) algorithms as well as a novel hybrid of VB and Expectation Propagation (EP). For the case of a single latent factor we derive a theory for learning performance using the replica method. We compare the MCMC and VB/EP algorithm results with simulated data to the theoretical prediction. The results for MCMC agree closely with the theory as expected. Results for VB/EP are slightly sub-optimal but show that the new algorithm is effective for sparse inference. In large-scale problems MCMC is infeasible due to computational limitations and the VB/EP algorithm then provides a very useful computationally efficient alternative.\n\n\nInference algorithms and learning theory for Bayesian sparse factor analysis\nEnergy Technology Data Exchange (ETDEWEB)\nRattray, Magnus; Sharp, Kevin [School of Computer Science, University of Manchester, Manchester M13 9PL (United Kingdom); Stegle, Oliver [Max-Planck-Institute for Biological Cybernetics, Tuebingen (Germany); Winn, John, E-mail: magnus.rattray@manchester.ac.u [Microsoft Research Cambridge, Roger Needham Building, Cambridge, CB3 0FB (United Kingdom)\n2009-12-01\nBayesian sparse factor analysis has many applications; for example, it has been applied to the problem of inferring a sparse regulatory network from gene expression data. We describe a number of inference algorithms for Bayesian sparse factor analysis using a slab and spike mixture prior. These include well-established Markov chain Monte Carlo (MCMC) and variational Bayes (VB) algorithms as well as a novel hybrid of VB and Expectation Propagation (EP). For the case of a single latent factor we derive a theory for learning performance using the replica method. We compare the MCMC and VB/EP algorithm results with simulated data to the theoretical prediction. The results for MCMC agree closely with the theory as expected. Results for VB/EP are slightly sub-optimal but show that the new algorithm is effective for sparse inference. In large-scale problems MCMC is infeasible due to computational limitations and the VB/EP algorithm then provides a very useful computationally efficient alternative.\n\n\nExploration Of Deep Learning Algorithms Using Openacc Parallel Programming Model\nKAUST Repository\nHamam, Alwaleed A.\n2017-03-13\nDeep learning is based on a set of algorithms that attempt to model high level abstractions in data. Specifically, RBM is a deep learning algorithm that used in the project to increase it\\\\'s time performance using some efficient parallel implementation by OpenACC tool with best possible optimizations on RBM to harness the massively parallel power of NVIDIA GPUs. GPUs development in the last few years has contributed to growing the concept of deep learning. OpenACC is a directive based ap-proach for computing where directives provide compiler hints to accelerate code. The traditional Restricted Boltzmann Ma-chine is a stochastic neural network that essentially perform a binary version of factor analysis. RBM is a useful neural net-work basis for larger modern deep learning model, such as Deep Belief Network. RBM parameters are estimated using an efficient training method that called Contrastive Divergence. Parallel implementation of RBM is available using different models such as OpenMP, and CUDA. But this project has been the first attempt to apply OpenACC model on RBM.\n\n\nRobust Semi-Supervised Manifold Learning Algorithm for Classification\nDirectory of Open Access Journals (Sweden)\nMingxia Chen\n2018-01-01\nFull Text Available In the recent years, manifold learning methods have been widely used in data classification to tackle the curse of dimensionality problem, since they can discover the potential intrinsic low-dimensional structures of the high-dimensional data. Given partially labeled data, the semi-supervised manifold learning algorithms are proposed to predict the labels of the unlabeled points, taking into account label information. However, these semi-supervised manifold learning algorithms are not robust against noisy points, especially when the labeled data contain noise. In this paper, we propose a framework for robust semi-supervised manifold learning (RSSML to address this problem. The noisy levels of the labeled points are firstly predicted, and then a regularization term is constructed to reduce the impact of labeled points containing noise. A new robust semi-supervised optimization model is proposed by adding the regularization term to the traditional semi-supervised optimization model. Numerical experiments are given to show the improvement and efficiency of RSSML on noisy data sets.\n\n\nExploration Of Deep Learning Algorithms Using Openacc Parallel Programming Model\nKAUST Repository\nHamam, Alwaleed A.; Khan, Ayaz H.\n2017-01-01\nDeep learning is based on a set of algorithms that attempt to model high level abstractions in data. Specifically, RBM is a deep learning algorithm that used in the project to increase it's time performance using some efficient parallel implementation by OpenACC tool with best possible optimizations on RBM to harness the massively parallel power of NVIDIA GPUs. GPUs development in the last few years has contributed to growing the concept of deep learning. OpenACC is a directive based ap-proach for computing where directives provide compiler hints to accelerate code. The traditional Restricted Boltzmann Ma-chine is a stochastic neural network that essentially perform a binary version of factor analysis. RBM is a useful neural net-work basis for larger modern deep learning model, such as Deep Belief Network. RBM parameters are estimated using an efficient training method that called Contrastive Divergence. Parallel implementation of RBM is available using different models such as OpenMP, and CUDA. But this project has been the first attempt to apply OpenACC model on RBM.\n\n\nAn augmented Lagrangian multi-scale dictionary learning algorithm\nDirectory of Open Access Journals (Sweden)\nYe Meng\n2011-01-01\nFull Text Available Abstract Learning overcomplete dictionaries for sparse signal representation has become a hot topic fascinated by many researchers in the recent years, while most of the existing approaches have a serious problem that they always lead to local minima. In this article, we present a novel augmented Lagrangian multi-scale dictionary learning algorithm (ALM-DL, which is achieved by first recasting the constrained dictionary learning problem into an AL scheme, and then updating the dictionary after each inner iteration of the scheme during which majorization-minimization technique is employed for solving the inner subproblem. Refining the dictionary from low scale to high makes the proposed method less dependent on the initial dictionary hence avoiding local optima. Numerical tests for synthetic data and denoising applications on real images demonstrate the superior performance of the proposed approach.\n\n\nHead pose estimation algorithm based on deep learning\nScience.gov (United States)\nCao, Yuanming; Liu, Yijun\n2017-05-01\nHead pose estimation has been widely used in the field of artificial intelligence, pattern recognition and intelligent human-computer interaction and so on. Good head pose estimation algorithm should deal with light, noise, identity, shelter and other factors robustly, but so far how to improve the accuracy and robustness of attitude estimation remains a major challenge in the field of computer vision. A method based on deep learning for pose estimation is presented. Deep learning with a strong learning ability, it can extract high-level image features of the input image by through a series of non-linear operation, then classifying the input image using the extracted feature. Such characteristics have greater differences in pose, while they are robust of light, identity, occlusion and other factors. The proposed head pose estimation is evaluated on the CAS-PEAL data set. Experimental results show that this method is effective to improve the accuracy of pose estimation.\n\n\nPenerapan Fitur Warna Untuk Identifikasi Plasmodium Falciparum pada Sediaan Apus Darah Menggunakan MK-Means dan Jaringan Backpropagation\nDirectory of Open Access Journals (Sweden)\nmustamin hamid\n2016-09-01\nFull Text Available Abstract - This research proposed a system to identify Plasmodium falciparum on blood smear \u00c2\u00a0using the neural network \u00c2\u00a0backpropagation. Modified K-Means (MK-Means is used to separate between the object with the background image because that method was able to equalize the value of fitness at all Center cluster so there is no dead center and can also cope with the local minimum value. The extraction of the features used in this study consists of color features i.e. calculation of the mean, standard deviation, skewness, curtosis and entropy of co-occurent matrix with the purpose to get the values of all the trait value image, obtained are then used to train a neural network with the backpropagation training algorithm. Method of backpropagation networks capable of acquiring knowledge even though there is no certainty, able to perform a generalization and extraction of a specific data pattern. \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0 The image of\u00c2\u00a0 the preparations\u00c2\u00a0 blood smear\u00c2\u00a0 are classified using the method of\u00c2\u00a0 neural network Backpropagation. The test results obtained from Tropozoit with the accuracy 100%, scizon 80% and gametocytes 80%. Identification is then obtained outcomes the introduction with an average accuracy of 86,66%.\n\n\nApplication of artificial neural networks with backpropagation technique in the financial data\nScience.gov (United States)\nJaiswal, Jitendra Kumar; Das, Raja\n2017-11-01\nThe propensity of applying neural networks has been proliferated in multiple disciplines for research activities since the past recent decades because of its powerful control with regulatory parameters for pattern recognition and classification. It is also being widely applied for forecasting in the numerous divisions. Since financial data have been readily available due to the involvement of computers and computing systems in the stock market premises throughout the world, researchers have also developed numerous techniques and algorithms to analyze the data from this sector. In this paper we have applied neural network with backpropagation technique to find the data pattern from finance section and prediction for stock values as well.\n\n\nBehavioral Modeling for Mental Health using Machine Learning Algorithms.\nScience.gov (United States)\nSrividya, M; Mohanavalli, S; Bhalaji, N\n2018-04-03\nMental health is an indicator of emotional, psychological and social well-being of an individual. It determines how an individual thinks, feels and handle situations. Positive mental health helps one to work productively and realize their full potential. Mental health is important at every stage of life, from childhood and adolescence through adulthood. Many factors contribute to mental health problems which lead to mental illness like stress, social anxiety, depression, obsessive compulsive disorder, drug addiction, and personality disorders. It is becoming increasingly important to determine the onset of the mental illness to maintain proper life balance. The nature of machine learning algorithms and Artificial Intelligence (AI) can be fully harnessed for predicting the onset of mental illness. Such applications when implemented in real time will benefit the society by serving as a monitoring tool for individuals with deviant behavior. This research work proposes to apply various machine learning algorithms such as support vector machines, decision trees, na\u00c3\u00afve bayes classifier, K-nearest neighbor classifier and logistic regression to identify state of mental health in a target group. The responses obtained from the target group for the designed questionnaire were first subject to unsupervised learning techniques. The labels obtained as a result of clustering were validated by computing the Mean Opinion Score. These cluster labels were then used to build classifiers to predict the mental health of an individual. Population from various groups like high school students, college students and working professionals were considered as target groups. The research presents an analysis of applying the aforementioned machine learning algorithms on the target groups and also suggests directions for future work.\n\n\nA Learning Method for Neural Networks Based on a Pseudoinverse Technique\nDirectory of Open Access Journals (Sweden)\nChinmoy Pal\n1996-01-01\nFull Text Available A theoretical formulation of a fast learning method based on a pseudoinverse technique is presented. The efficiency and robustness of the method are verified with the help of an Exclusive OR problem and a dynamic system identification of a linear single degree of freedom mass\u00e2\u20ac\u201cspring problem. It is observed that, compared with the conventional backpropagation method, the proposed method has a better convergence rate and a higher degree of learning accuracy with a lower equivalent learning coefficient. It is also found that unlike the steepest descent method, the learning capability of which is dependent on the value of the learning coefficient \u00ce\u00bd, the proposed pseudoinverse based backpropagation algorithm is comparatively robust with respect to its equivalent variable learning coefficient. A combination of the pseudoinverse method and the steepest descent method is proposed for a faster, more accurate learning capability.\n\n\n\n\n\u00ab\n7\n8\n9\n10\n11\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n8\n9\n10\n11\n12\n\u00bb\n\n\n\n\n\n\n\n\nValidating module network learning algorithms using simulated data.\nScience.gov (United States)\nMichoel, Tom; Maere, Steven; Bonnet, Eric; Joshi, Anagha; Saeys, Yvan; Van den Bulcke, Tim; Van Leemput, Koenraad; van Remortel, Piet; Kuiper, Martin; Marchal, Kathleen; Van de Peer, Yves\n2007-05-03\nIn recent years, several authors have used probabilistic graphical models to learn expression modules and their regulatory programs from gene expression data. Despite the demonstrated success of such algorithms in uncovering biologically relevant regulatory relations, further developments in the area are hampered by a lack of tools to compare the performance of alternative module network learning strategies. Here, we demonstrate the use of the synthetic data generator SynTReN for the purpose of testing and comparing module network learning algorithms. We introduce a software package for learning module networks, called LeMoNe, which incorporates a novel strategy for learning regulatory programs. Novelties include the use of a bottom-up Bayesian hierarchical clustering to construct the regulatory programs, and the use of a conditional entropy measure to assign regulators to the regulation program nodes. Using SynTReN data, we test the performance of LeMoNe in a completely controlled situation and assess the effect of the methodological changes we made with respect to an existing software package, namely Genomica. Additionally, we assess the effect of various parameters, such as the size of the data set and the amount of noise, on the inference performance. Overall, application of Genomica and LeMoNe to simulated data sets gave comparable results. However, LeMoNe offers some advantages, one of them being that the learning process is considerably faster for larger data sets. Additionally, we show that the location of the regulators in the LeMoNe regulation programs and their conditional entropy may be used to prioritize regulators for functional validation, and that the combination of the bottom-up clustering strategy with the conditional entropy-based assignment of regulators improves the handling of missing or hidden regulators. We show that data simulators such as SynTReN are very well suited for the purpose of developing, testing and improving module network\n\n\nA Comparison of the Effects of K-Anonymity on Machine Learning Algorithms\nOpenAIRE\nHayden Wimmer; Loreen Powell\n2014-01-01\nWhile research has been conducted in machine learning algorithms and in privacy preserving in data mining (PPDM), a gap in the literature exists which combines the aforementioned areas to determine how PPDM affects common machine learning algorithms. The aim of this research is to narrow this literature gap by investigating how a common PPDM algorithm, K-Anonymity, affects common machine learning and data mining algorithms, namely neural networks, logistic regression, decision trees, and Baye...\n\n\nA numeric comparison of variable selection algorithms for supervised learning\nInternational Nuclear Information System (INIS) \nPalombo, G.; Narsky, I.\n2009-01-01\nDatasets in modern High Energy Physics (HEP) experiments are often described by dozens or even hundreds of input variables. Reducing a full variable set to a subset that most completely represents information about data is therefore an important task in analysis of HEP data. We compare various variable selection algorithms for supervised learning using several datasets such as, for instance, imaging gamma-ray Cherenkov telescope (MAGIC) data found at the UCI repository. We use classifiers and variable selection methods implemented in the statistical package StatPatternRecognition (SPR), a free open-source C++ package developed in the HEP community ( (http://sourceforge.net/projects/statpatrec/)). For each dataset, we select a powerful classifier and estimate its learning accuracy on variable subsets obtained by various selection algorithms. When possible, we also estimate the CPU time needed for the variable subset selection. The results of this analysis are compared with those published previously for these datasets using other statistical packages such as R and Weka. We show that the most accurate, yet slowest, method is a wrapper algorithm known as generalized sequential forward selection ('Add N Remove R') implemented in SPR.\n\n\nA Dynamic Neighborhood Learning-Based Gravitational Search Algorithm.\nScience.gov (United States)\nZhang, Aizhu; Sun, Genyun; Ren, Jinchang; Li, Xiaodong; Wang, Zhenjie; Jia, Xiuping\n2018-01-01\nBalancing exploration and exploitation according to evolutionary states is crucial to meta-heuristic search (M-HS) algorithms. Owing to its simplicity in theory and effectiveness in global optimization, gravitational search algorithm (GSA) has attracted increasing attention in recent years. However, the tradeoff between exploration and exploitation in GSA is achieved mainly by adjusting the size of an archive, named , which stores those superior agents after fitness sorting in each iteration. Since the global property of remains unchanged in the whole evolutionary process, GSA emphasizes exploitation over exploration and suffers from rapid loss of diversity and premature convergence. To address these problems, in this paper, we propose a dynamic neighborhood learning (DNL) strategy to replace the model and thereby present a DNL-based GSA (DNLGSA). The method incorporates the local and global neighborhood topologies for enhancing the exploration and obtaining adaptive balance between exploration and exploitation. The local neighborhoods are dynamically formed based on evolutionary states. To delineate the evolutionary states, two convergence criteria named limit value and population diversity, are introduced. Moreover, a mutation operator is designed for escaping from the local optima on the basis of evolutionary states. The proposed algorithm was evaluated on 27 benchmark problems with different characteristic and various difficulties. The results reveal that DNLGSA exhibits competitive performances when compared with a variety of state-of-the-art M-HS algorithms. Moreover, the incorporation of local neighborhood topology reduces the numbers of calculations of gravitational force and thus alleviates the high computational cost of GSA.\n\n\nFall detection using supervised machine learning algorithms: A comparative study\nKAUST Repository\nZerrouki, Nabil; Harrou, Fouzi; Houacine, Amrane; Sun, Ying\n2017-01-01\nFall incidents are considered as the leading cause of disability and even mortality among older adults. To address this problem, fall detection and prevention fields receive a lot of intention over the past years and attracted many researcher efforts. We present in the current study an overall performance comparison between fall detection systems using the most popular machine learning approaches which are: Na\u00c3\u00afve Bayes, K nearest neighbor, neural network, and support vector machine. The analysis of the classification power associated to these most widely utilized algorithms is conducted on two fall detection databases namely FDD and URFD. Since the performance of the classification algorithm is inherently dependent on the features, we extracted and used the same features for all classifiers. The classification evaluation is conducted using different state of the art statistical measures such as the overall accuracy, the F-measure coefficient, and the area under ROC curve (AUC) value.\n\n\nFall detection using supervised machine learning algorithms: A comparative study\nKAUST Repository\nZerrouki, Nabil\n2017-01-05\nFall incidents are considered as the leading cause of disability and even mortality among older adults. To address this problem, fall detection and prevention fields receive a lot of intention over the past years and attracted many researcher efforts. We present in the current study an overall performance comparison between fall detection systems using the most popular machine learning approaches which are: Na\u00c3\u00afve Bayes, K nearest neighbor, neural network, and support vector machine. The analysis of the classification power associated to these most widely utilized algorithms is conducted on two fall detection databases namely FDD and URFD. Since the performance of the classification algorithm is inherently dependent on the features, we extracted and used the same features for all classifiers. The classification evaluation is conducted using different state of the art statistical measures such as the overall accuracy, the F-measure coefficient, and the area under ROC curve (AUC) value.\n\n\nMachine learning based global particle indentification algorithms at LHCb experiment\nCERN Multimedia\nDerkach, Denis; Likhomanenko, Tatiana; Rogozhnikov, Aleksei; Ratnikov, Fedor\n2017-01-01\nOne of the most important aspects of data processing at LHC experiments is the particle identification (PID) algorithm. In LHCb, several different sub-detector systems provide PID information: the Ring Imaging CHerenkov (RICH) detector, the hadronic and electromagnetic calorimeters, and the muon chambers. To improve charged particle identification, several neural networks including a deep architecture and gradient boosting have been applied to data. These new approaches provide higher identification efficiencies than existing implementations for all charged particle types. It is also necessary to achieve a flat dependency between efficiencies and spectator variables such as particle momentum, in order to reduce systematic uncertainties during later stages of data analysis. For this purpose, \"flat\u00e2\u20ac\ufffd algorithms that guarantee the flatness property for efficiencies have also been developed. This talk presents this new approach based on machine learning and its performance.\n\n\nQ-learning-based adjustable fixed-phase quantum Grover search algorithm\nInternational Nuclear Information System (INIS) \nGuo Ying; Shi Wensha; Wang Yijun; Hu, Jiankun\n2017-01-01\nWe demonstrate that the rotation phase can be suitably chosen to increase the efficiency of the phase-based quantum search algorithm, leading to a dynamic balance between iterations and success probabilities of the fixed-phase quantum Grover search algorithm with Q-learning for a given number of solutions. In this search algorithm, the proposed Q-learning algorithm, which is a model-free reinforcement learning strategy in essence, is used for performing a matching algorithm based on the fraction of marked items \u00ce\u00bb and the rotation phase \u00ce\u00b1. After establishing the policy function \u00ce\u00b1 = \u00cf\u20ac(\u00ce\u00bb), we complete the fixed-phase Grover algorithm, where the phase parameter is selected via the learned policy. Simulation results show that the Q-learning-based Grover search algorithm (QLGA) enables fewer iterations and gives birth to higher success probabilities. Compared with the conventional Grover algorithms, it avoids the optimal local situations, thereby enabling success probabilities to approach one. (author)\n\n\nA self-learning algorithm for biased molecular dynamics\nScience.gov (United States)\nTribello, Gareth A.; Ceriotti, Michele; Parrinello, Michele\n2010-01-01\nA new self-learning algorithm for accelerated dynamics, reconnaissance metadynamics, is proposed that is able to work with a very large number of collective coordinates. Acceleration of the dynamics is achieved by constructing a bias potential in terms of a patchwork of one-dimensional, locally valid collective coordinates. These collective coordinates are obtained from trajectory analyses so that they adapt to any new features encountered during the simulation. We show how this methodology can be used to enhance sampling in real chemical systems citing examples both from the physics of clusters and from the biological sciences. PMID:20876135\n\n\nAn elitist teaching-learning-based optimization algorithm for solving complex constrained optimization problems\nDirectory of Open Access Journals (Sweden)\nVivek Patel\n2012-08-01\nFull Text Available Nature inspired population based algorithms is a research field which simulates different natural phenomena to solve a wide range of problems. Researchers have proposed several algorithms considering different natural phenomena. Teaching-Learning-based optimization (TLBO is one of the recently proposed population based algorithm which simulates the teaching-learning process of the class room. This algorithm does not require any algorithm-specific control parameters. In this paper, elitism concept is introduced in the TLBO algorithm and its effect on the performance of the algorithm is investigated. The effects of common controlling parameters such as the population size and the number of generations on the performance of the algorithm are also investigated. The proposed algorithm is tested on 35 constrained benchmark functions with different characteristics and the performance of the algorithm is compared with that of other well known optimization algorithms. The proposed algorithm can be applied to various optimization problems of the industrial environment.\n\n\nMODIS Science Algorithms and Data Systems Lessons Learned\nScience.gov (United States)\nWolfe, Robert E.; Ridgway, Bill L.; Patt, Fred S.; Masuoka, Edward J.\n2009-01-01\nFor almost 10 years, standard global products from NASA's Earth Observing System s (EOS) two Moderate Resolution Imaging Spectroradiometer (MODIS) sensors are being used world-wide for earth science research and applications. This paper discusses the lessons learned in developing the science algorithms and the data systems needed to produce these high quality data products for the earth sciences community. Strong science team leadership and communication, an evolvable and scalable data system, and central coordination of QA and validation activities enabled the data system to grow by two orders of magnitude from the initial at-launch system to the current system able to reprocess data from both the Terra and Aqua missions in less than a year. Many of the lessons learned from MODIS are already being applied to follow-on missions.\n\n\nPrediction of Baseflow Index of Catchments using Machine Learning Algorithms\nScience.gov (United States)\nYadav, B.; Hatfield, K.\n2017-12-01\nWe present the results of eight machine learning techniques for predicting the baseflow index (BFI) of ungauged basins using a surrogate of catchment scale climate and physiographic data. The tested algorithms include ordinary least squares, ridge regression, least absolute shrinkage and selection operator (lasso), elasticnet, support vector machine, gradient boosted regression trees, random forests, and extremely randomized trees. Our work seeks to identify the dominant controls of BFI that can be readily obtained from ancillary geospatial databases and remote sensing measurements, such that the developed techniques can be extended to ungauged catchments. More than 800 gauged catchments spanning the continental United States were selected to develop the general methodology. The BFI calculation was based on the baseflow separated from daily streamflow hydrograph using HYSEP filter. The surrogate catchment attributes were compiled from multiple sources including digital elevation model, soil, landuse, climate data, other publicly available ancillary and geospatial data. 80% catchments were used to train the ML algorithms, and the remaining 20% of the catchments were used as an independent test set to measure the generalization performance of fitted models. A k-fold cross-validation using exhaustive grid search was used to fit the hyperparameters of each model. Initial model development was based on 19 independent variables, but after variable selection and feature ranking, we generated revised sparse models of BFI prediction that are based on only six catchment attributes. These key predictive variables selected after the careful evaluation of bias-variance tradeoff include average catchment elevation, slope, fraction of sand, permeability, temperature, and precipitation. The most promising algorithms exceeding an accuracy score (r-square) of 0.7 on test data include support vector machine, gradient boosted regression trees, random forests, and extremely randomized\n\n\nNeuromorphic implementations of neurobiological learning algorithms for spiking neural networks.\nScience.gov (United States)\nWalter, Florian; R\u00c3\u00b6hrbein, Florian; Knoll, Alois\n2015-12-01\nThe application of biologically inspired methods in design and control has a long tradition in robotics. Unlike previous approaches in this direction, the emerging field of neurorobotics not only mimics biological mechanisms at a relatively high level of abstraction but employs highly realistic simulations of actual biological nervous systems. Even today, carrying out these simulations efficiently at appropriate timescales is challenging. Neuromorphic chip designs specially tailored to this task therefore offer an interesting perspective for neurorobotics. Unlike Von Neumann CPUs, these chips cannot be simply programmed with a standard programming language. Like real brains, their functionality is determined by the structure of neural connectivity and synaptic efficacies. Enabling higher cognitive functions for neurorobotics consequently requires the application of neurobiological learning algorithms to adjust synaptic weights in a biologically plausible way. In this paper, we therefore investigate how to program neuromorphic chips by means of learning. First, we provide an overview over selected neuromorphic chip designs and analyze them in terms of neural computation, communication systems and software infrastructure. On the theoretical side, we review neurobiological learning techniques. Based on this overview, we then examine on-die implementations of these learning algorithms on the considered neuromorphic chips. A final discussion puts the findings of this work into context and highlights how neuromorphic hardware can potentially advance the field of autonomous robot systems. The paper thus gives an in-depth overview of neuromorphic implementations of basic mechanisms of synaptic plasticity which are required to realize advanced cognitive capabilities with spiking neural networks. Copyright \u00c2\u00a9 2015 Elsevier Ltd. All rights reserved.\n\n\nFrom the social learning theory to a social learning algorithm for global optimization\nOpenAIRE\nGong, Yue-Jiao; Zhang, Jun; Li, Yun\n2014-01-01\nTraditionally, the Evolutionary Computation (EC) paradigm is inspired by Darwinian evolution or the swarm intelligence of animals. Bandura's Social Learning Theory pointed out that the social learning behavior of humans indicates a high level of intelligence in nature. We found that such intelligence of human society can be implemented by numerical computing and be utilized in computational algorithms for solving optimization problems. In this paper, we design a novel and generic optimization...\n\n\nAdaptive Learning Rule for Hardware-based Deep Neural Networks Using Electronic Synapse Devices\nOpenAIRE\nLim, Suhwan; Bae, Jong-Ho; Eum, Jai-Ho; Lee, Sungtae; Kim, Chul-Heung; Kwon, Dongseok; Park, Byung-Gook; Lee, Jong-Ho\n2017-01-01\nIn this paper, we propose a learning rule based on a back-propagation (BP) algorithm that can be applied to a hardware-based deep neural network (HW-DNN) using electronic devices that exhibit discrete and limited conductance characteristics. This adaptive learning rule, which enables forward, backward propagation, as well as weight updates in hardware, is helpful during the implementation of power-efficient and high-speed deep neural networks. In simulations using a three-layer perceptron net...\n\n\nSpike sorting based upon machine learning algorithms (SOMA).\nScience.gov (United States)\nHorton, P M; Nicol, A U; Kendrick, K M; Feng, J F\n2007-02-15\nWe have developed a spike sorting method, using a combination of various machine learning algorithms, to analyse electrophysiological data and automatically determine the number of sampled neurons from an individual electrode, and discriminate their activities. We discuss extensions to a standard unsupervised learning algorithm (Kohonen), as using a simple application of this technique would only identify a known number of clusters. Our extra techniques automatically identify the number of clusters within the dataset, and their sizes, thereby reducing the chance of misclassification. We also discuss a new pre-processing technique, which transforms the data into a higher dimensional feature space revealing separable clusters. Using principal component analysis (PCA) alone may not achieve this. Our new approach appends the features acquired using PCA with features describing the geometric shapes that constitute a spike waveform. To validate our new spike sorting approach, we have applied it to multi-electrode array datasets acquired from the rat olfactory bulb, and from the sheep infero-temporal cortex, and using simulated data. The SOMA sofware is available at http://www.sussex.ac.uk/Users/pmh20/spikes.\n\n\nStochastic sensitivity analysis and Langevin simulation for neural network learning\nInternational Nuclear Information System (INIS) \nKoda, Masato\n1997-01-01\nA comprehensive theoretical framework is proposed for the learning of a class of gradient-type neural networks with an additive Gaussian white noise process. The study is based on stochastic sensitivity analysis techniques, and formal expressions are obtained for stochastic learning laws in terms of functional derivative sensitivity coefficients. The present method, based on Langevin simulation techniques, uses only the internal states of the network and ubiquitous noise to compute the learning information inherent in the stochastic correlation between noise signals and the performance functional. In particular, the method does not require the solution of adjoint equations of the back-propagation type. Thus, the present algorithm has the potential for efficiently learning network weights with significantly fewer computations. Application to an unfolded multi-layered network is described, and the results are compared with those obtained by using a back-propagation method\n\n\nApplication of structured support vector machine backpropagation to a convolutional neural network for human pose estimation.\nScience.gov (United States)\nWitoonchart, Peerajak; Chongstitvatana, Prabhas\n2017-08-01\nIn this study, for the first time, we show how to formulate a structured support vector machine (SSVM) as two layers in a convolutional neural network, where the top layer is a loss augmented inference layer and the bottom layer is the normal convolutional layer. We show that a deformable part model can be learned with the proposed structured SVM neural network by backpropagating the error of the deformable part model to the convolutional neural network. The forward propagation calculates the loss augmented inference and the backpropagation calculates the gradient from the loss augmented inference layer to the convolutional layer. Thus, we obtain a new type of convolutional neural network called an Structured SVM convolutional neural network, which we applied to the human pose estimation problem. This new neural network can be used as the final layers in deep learning. Our method jointly learns the structural model parameters and the appearance model parameters. We implemented our method as a new layer in the existing Caffe library. Copyright \u00c2\u00a9 2017 Elsevier Ltd. All rights reserved.\n\n\nTwo Algorithms for Learning the Parameters of Stochastic Context-Free Grammars\nNational Research Council Canada - National Science Library\nHeeringa, Brent; Oates, Tim\n2001-01-01\n.... Most algorithms for learning them require storage and repeated processing of a sentence corpus. The memory and computational demands of such algorithms are illsuited for embedded agents such as a mobile robot...\n\n\nMultifactor-influenced energy consumption forecasting using enhanced back-propagation neural network\nInternational Nuclear Information System (INIS) \nZeng, Yu-Rong; Zeng, Yi; Choi, Beomjin; Wang, Lin\n2017-01-01\nReliable energy consumption forecasting can provide effective decision-making support for planning development strategies to energy enterprises and for establishing national energy policies. Accordingly, the present study aims to apply a hybrid intelligent approach named ADE\u00e2\u20ac\u201cBPNN, the back-propagation neural network (BPNN) model supported by an adaptive differential evolution algorithm, to estimate energy consumption. Most often, energy consumption is influenced by socioeconomic factors. The proposed hybrid model incorporates gross domestic product, population, import, and export data as inputs. An improved differential evolution with adaptive mutation and crossover is utilized to find appropriate global initial connection weights and thresholds to enhance the forecasting performance of the BPNN. A comparative example and two extended examples are utilized to validate the applicability and accuracy of the proposed ADE\u00e2\u20ac\u201cBPNN model. Errors of the test data sets indicate that the ADE\u00e2\u20ac\u201cBPNN model can effectively predict energy consumption compared with the traditional back-propagation neural network model and other popular existing models. Moreover, mean impact value based analysis is conducted for electrical energy consumption in U.S. and total energy consumption forecasting in China to quantitatively explore the relative importance of each input variable for the improvement of effective energy consumption prediction. - Highlights: \u00e2\u20ac\u00a2 Enhanced back-propagation neural network (ADE-BPNN) for energy consumption forecasting. \u00e2\u20ac\u00a2 ADE-BPNN outperforms the current best models for two comparative cases. \u00e2\u20ac\u00a2 Mean impact value approach explores socio-economic factors' relative importance. \u00e2\u20ac\u00a2 ADE-BPNN's adjusted goodness-of-fit is 99.2% for China's energy consumption forecasting.\n\n\n\n\n\u00ab\n8\n9\n10\n11\n12\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n9\n10\n11\n12\n13\n\u00bb\n\n\n\n\n\n\n\n\nGenetic algorithm learning in a New Keynesian macroeconomic setup.\nScience.gov (United States)\nHommes, Cars; Makarewicz, Tomasz; Massaro, Domenico; Smits, Tom\n2017-01-01\nIn order to understand heterogeneous behavior amongst agents, empirical data from Learning-to-Forecast (LtF) experiments can be used to construct learning models. This paper follows up on Assenza et al. (2013) by using a Genetic Algorithms (GA) model to replicate the results from their LtF experiment. In this GA model, individuals optimize an adaptive, a trend following and an anchor coefficient in a population of general prediction heuristics. We replicate experimental treatments in a New-Keynesian environment with increasing complexity and use Monte Carlo simulations to investigate how well the model explains the experimental data. We find that the evolutionary learning model is able to replicate the three different types of behavior, i.e. convergence to steady state, stable oscillations and dampened oscillations in the treatments using one GA model. Heterogeneous behavior can thus be explained by an adaptive, anchor and trend extrapolating component and the GA model can be used to explain heterogeneous behavior in LtF experiments with different types of complexity.\n\n\nImpairment mitigation in superchannels with digital backpropagation and MLSD\nDEFF Research Database (Denmark)\nPorto da Silva, Edson; Larsen, Knud J.; Zibar, Darko\n2015-01-01\nWe assess numerically the performance of single-carrier digital backpropagation (SC-DBP) and maximum-likelihood sequence detection (MLSD) for DP-QPSK and DP-16QAM superchannel transmission over dispersion uncompensated links for three different cases of spectral shaping: optical pre-filtering of ...\n\n\nAdaptive digital back-propagation for optical communication systems\nNARCIS (Netherlands)\nLin, C.-Y.; Napoli, A.; Spinnler, B.; Sleiffer, V.A.J.M.; Rafique, D.; Kuschnerov, M.; Bohn, M.; Schmauss, B.\n2014-01-01\nWe propose an adaptive digital back-propagation method (A-DBP) to selfdetermine unknown fiber nonlinear coefficient gamma. Performance is experimentally verified with 10224-Gb/s POLMUX-16QAM over 656km. Optimal DBP performance, without knowledge of gamma, is obtained by A-DBP.\n\n\nSingle-step digital backpropagation for nonlinearity mitigation\nDEFF Research Database (Denmark)\nSecondini, Marco; Rommel, Simon; Meloni, Gianluca\n2015-01-01\nNonlinearity mitigation based on the enhanced split-step Fourier method (ESSFM) for the implementation of low-complexity digital backpropagation (DBP) is investigated and experimentally demonstrated. After reviewing the main computational aspects of DBP and of the conventional split-step Fourier...... in the computational complexity, power consumption, and latency with respect to a simple feed-forward equalizer for bulk dispersion compensation....\n\n\nComparative performance of an elitist teaching-learning-based optimization algorithm for solving unconstrained optimization problems\nDirectory of Open Access Journals (Sweden)\nR. Venkata Rao\n2013-01-01\nFull Text Available Teaching-Learning-based optimization (TLBO is a recently proposed population based algorithm, which simulates the teaching-learning process of the class room. This algorithm requires only the common control parameters and does not require any algorithm-specific control parameters. In this paper, the effect of elitism on the performance of the TLBO algorithm is investigated while solving unconstrained benchmark problems. The effects of common control parameters such as the population size and the number of generations on the performance of the algorithm are also investigated. The proposed algorithm is tested on 76 unconstrained benchmark functions with different characteristics and the performance of the algorithm is compared with that of other well known optimization algorithms. A statistical test is also performed to investigate the results obtained using different algorithms. The results have proved the effectiveness of the proposed elitist TLBO algorithm.\n\n\nKnowledge Mining from Clinical Datasets Using Rough Sets and Backpropagation Neural Network\nDirectory of Open Access Journals (Sweden)\nKindie Biredagn Nahato\n2015-01-01\nFull Text Available The availability of clinical datasets and knowledge mining methodologies encourages the researchers to pursue research in extracting knowledge from clinical datasets. Different data mining techniques have been used for mining rules, and mathematical models have been developed to assist the clinician in decision making. The objective of this research is to build a classifier that will predict the presence or absence of a disease by learning from the minimal set of attributes that has been extracted from the clinical dataset. In this work rough set indiscernibility relation method with backpropagation neural network (RS-BPNN is used. This work has two stages. The first stage is handling of missing values to obtain a smooth data set and selection of appropriate attributes from the clinical dataset by indiscernibility relation method. The second stage is classification using backpropagation neural network on the selected reducts of the dataset. The classifier has been tested with hepatitis, Wisconsin breast cancer, and Statlog heart disease datasets obtained from the University of California at Irvine (UCI machine learning repository. The accuracy obtained from the proposed method is 97.3%, 98.6%, and 90.4% for hepatitis, breast cancer, and heart disease, respectively. The proposed system provides an effective classification model for clinical datasets.\n\n\nTwo-Stage Electricity Demand Modeling Using Machine Learning Algorithms\nDirectory of Open Access Journals (Sweden)\nKrzysztof Gajowniczek\n2017-10-01\nFull Text Available Forecasting of electricity demand has become one of the most important areas of research in the electric power industry, as it is a critical component of cost-efficient power system management and planning. In this context, accurate and robust load forecasting is supposed to play a key role in reducing generation costs, and deals with the reliability of the power system. However, due to demand peaks in the power system, forecasts are inaccurate and prone to high numbers of errors. In this paper, our contributions comprise a proposed data-mining scheme for demand modeling through peak detection, as well as the use of this information to feed the forecasting system. For this purpose, we have taken a different approach from that of time series forecasting, representing it as a two-stage pattern recognition problem. We have developed a peak classification model followed by a forecasting model to estimate an aggregated demand volume. We have utilized a set of machine learning algorithms to benefit from both accurate detection of the peaks and precise forecasts, as applied to the Polish power system. The key finding is that the algorithms can detect 96.3% of electricity peaks (load value equal to or above the 99th percentile of the load distribution and deliver accurate forecasts, with mean absolute percentage error (MAPE of 3.10% and resistant mean absolute percentage error (r-MAPE of 2.70% for the 24 h forecasting horizon.\n\n\nExperiments on Supervised Learning Algorithms for Text Categorization\nScience.gov (United States)\nNamburu, Setu Madhavi; Tu, Haiying; Luo, Jianhui; Pattipati, Krishna R.\n2005-01-01\nModern information society is facing the challenge of handling massive volume of online documents, news, intelligence reports, and so on. How to use the information accurately and in a timely manner becomes a major concern in many areas. While the general information may also include images and voice, we focus on the categorization of text data in this paper. We provide a brief overview of the information processing flow for text categorization, and discuss two supervised learning algorithms, viz., support vector machines (SVM) and partial least squares (PLS), which have been successfully applied in other domains, e.g., fault diagnosis [9]. While SVM has been well explored for binary classification and was reported as an efficient algorithm for text categorization, PLS has not yet been applied to text categorization. Our experiments are conducted on three data sets: Reuter's- 21578 dataset about corporate mergers and data acquisitions (ACQ), WebKB and the 20-Newsgroups. Results show that the performance of PLS is comparable to SVM in text categorization. A major drawback of SVM for multi-class categorization is that it requires a voting scheme based on the results of pair-wise classification. PLS does not have this drawback and could be a better candidate for multi-class text categorization.\n\n\nHardware implementation of on -chip learning using re configurable FPGAS\nInternational Nuclear Information System (INIS) \nKelash, H.M.; Sorour, H.S; Mahmoud, I.I.; Zaki, M; Haggag, S.S.\n2009-01-01\nThe multilayer perceptron (MLP) is a neural network model that is being widely applied in the solving of diverse problems. A supervised training is necessary before the use of the neural network.A highly popular learning algorithm called back-propagation is used to train this neural network model. Once trained, the MLP can be used to solve classification problems. An interesting method to increase the performance of the model is by using hardware implementations. The hardware can do the arithmetical operations much faster than software. In this paper, a design and implementation of the sequential mode (stochastic mode) of backpropagation algorithm with on-chip learning using field programmable gate arrays (FPGA) is presented, a pipelined adaptation of the on-line back propagation algorithm (BP) is shown.The hardware implementation of forward stage, backward stage and update weight of backpropagation algorithm is also presented. This implementation is based on a SIMD parallel architecture of the forward propagation the diagnosis of the multi-purpose research reactor of Egypt accidents is used to test the proposed system\n\n\nOverlay improvements using a real time machine learning algorithm\nScience.gov (United States)\nSchmitt-Weaver, Emil; Kubis, Michael; Henke, Wolfgang; Slotboom, Daan; Hoogenboom, Tom; Mulkens, Jan; Coogans, Martyn; ten Berge, Peter; Verkleij, Dick; van de Mast, Frank\n2014-04-01\nWhile semiconductor manufacturing is moving towards the 14nm node using immersion lithography, the overlay requirements are tightened to below 5nm. Next to improvements in the immersion scanner platform, enhancements in the overlay optimization and process control are needed to enable these low overlay numbers. Whereas conventional overlay control methods address wafer and lot variation autonomously with wafer pre exposure alignment metrology and post exposure overlay metrology, we see a need to reduce these variations by correlating more of the TWINSCAN system's sensor data directly to the post exposure YieldStar metrology in time. In this paper we will present the results of a study on applying a real time control algorithm based on machine learning technology. Machine learning methods use context and TWINSCAN system sensor data paired with post exposure YieldStar metrology to recognize generic behavior and train the control system to anticipate on this generic behavior. Specific for this study, the data concerns immersion scanner context, sensor data and on-wafer measured overlay data. By making the link between the scanner data and the wafer data we are able to establish a real time relationship. The result is an inline controller that accounts for small changes in scanner hardware performance in time while picking up subtle lot to lot and wafer to wafer deviations introduced by wafer processing.\n\n\nEffective and efficient optics inspection approach using machine learning algorithms\nInternational Nuclear Information System (INIS) \nAbdulla, G.; Kegelmeyer, L.; Liao, Z.; Carr, W.\n2010-01-01\nThe Final Optics Damage Inspection (FODI) system automatically acquires and utilizes the Optics Inspection (OI) system to analyze images of the final optics at the National Ignition Facility (NIF). During each inspection cycle up to 1000 images acquired by FODI are examined by OI to identify and track damage sites on the optics. The process of tracking growing damage sites on the surface of an optic can be made more effective by identifying and removing signals associated with debris or reflections. The manual process to filter these false sites is daunting and time consuming. In this paper we discuss the use of machine learning tools and data mining techniques to help with this task. We describe the process to prepare a data set that can be used for training and identifying hardware reflections in the image data. In order to collect training data, the images are first automatically acquired and analyzed with existing software and then relevant features such as spatial, physical and luminosity measures are extracted for each site. A subset of these sites is 'truthed' or manually assigned a class to create training data. A supervised classification algorithm is used to test if the features can predict the class membership of new sites. A suite of self-configuring machine learning tools called 'Avatar Tools' is applied to classify all sites. To verify, we used 10-fold cross correlation and found the accuracy was above 99%. This substantially reduces the number of false alarms that would otherwise be sent for more extensive investigation.\n\n\nThe Prediction of Bandwidth On Need Computer Network Through Artificial Neural Network Method of Backpropagation\nDirectory of Open Access Journals (Sweden)\nIkhthison Mekongga\n2014-02-01\nFull Text Available The need for bandwidth has been increasing recently. This is because the development of internet infrastructure is also increasing so that\u00c2\u00a0we need an economic and efficient provider system. This can be achieved through good planning and a proper system. The prediction of\u00c2\u00a0the bandwidth consumption is one of the factors that support the planning for an efficient internet service provider system. Bandwidth\u00c2\u00a0consumption is predicted using ANN. ANN is an information processing system which has similar characteristics as the biologic al neural\u00c2\u00a0network. \u00c2\u00a0ANN \u00c2\u00a0is \u00c2\u00a0chosen \u00c2\u00a0to \u00c2\u00a0predict \u00c2\u00a0the \u00c2\u00a0consumption \u00c2\u00a0of \u00c2\u00a0the \u00c2\u00a0bandwidth \u00c2\u00a0because \u00c2\u00a0ANN \u00c2\u00a0has \u00c2\u00a0good \u00c2\u00a0approachability \u00c2\u00a0to \u00c2\u00a0non-linearity. \u00c2\u00a0The\u00c2\u00a0variable used in ANN is the historical load data. A bandwidth consumption information system was built using neural networks \u00c2\u00a0with a\u00c2\u00a0backpropagation algorithm to make the use of bandwidth more efficient in the future both in the rental rate of the bandwidth and in the\u00c2\u00a0usage of the bandwidth.Keywords: Forecasting, Bandwidth, Backpropagation\n\n\nCreating Engaging Online Learning Material with the JSAV JavaScript Algorithm Visualization Library\nScience.gov (United States)\nKaravirta, Ville; Shaffer, Clifford A.\n2016-01-01\nData Structures and Algorithms are a central part of Computer Science. Due to their abstract and dynamic nature, they are a difficult topic to learn for many students. To alleviate these learning difficulties, instructors have turned to algorithm visualizations (AV) and AV systems. Research has shown that especially engaging AVs can have an impact\u00e2\u20ac\u00a6\n\n\nKontrol Kecepatan Motor Induksi menggunakan Algoritma Backpropagation Neural Network\nDirectory of Open Access Journals (Sweden)\nMUHAMMAD RUSWANDI DJALAL\n2017-07-01\nFull Text Available ABSTRAKBanyak strategi kontrol berbasis kecerdasan buatan telah diusulkan dalam penelitian seperti Fuzzy Logic dan Artificial Neural Network (ANN. Tujuan dari penelitian ini adalah untuk mendesain sebuah kontrol agar kecepatan motor induksi dapat diatur sesuai kebutuhan serta membandingkan kinerja motor induksi tanpa kontrol dan dengan kontrol. Dalam penelitian ini diusulkan sebuah metode artificial neural network untuk mengontrol kecepatan motor induksi tiga fasa. Kecepatan referensi motor diatur pada kecepatan 140 rad/s, 150 rad/s, dan 130 rad/s. Perubahan kecepatan diatur pada setiap interval 0.3 detik dan waktu simulasi maksimum adalah 0,9 detik. Kasus 1 tanpa kontrol, menunjukkan respon torka dan kecepatan dari motor induksi tiga fasa tanpa kontrol. Meskipun kecepatan motor induksi tiga fasa diatur berubah pada setiap 0,3 detik tidak akan mempengaruhi torka. Selain itu, motor induksi tiga fasa tanpa kontrol memiliki kinerja yang buruk dikarenakan kecepatan motor induksi tidak dapat diatur sesuai dengan kebutuhan. Kasus 2 dengan control backpropagation neural network, meskipun kecepatan motor induksi tiga fasa berubah pada setiap 0.3 detik tidak akan mempengaruhi torsi. Selain itu, kontrol backpropagation neural network memiliki kinerja yang baik dikarenakan kecepatan motor induksi dapat diatur sesuai dengan kebutuhan.Kata kunci: Backpropagation Neural Network (BPNN, NN Training, NN Testing, Motor.ABSTRACTMany artificial intelligence-based control strategies have been proposed in research such as Fuzzy Logic and Artificial Neural Network (ANN. The purpose of this research was design a control for the induction motor speed that could be adjusted as needed and compare the performance of induction motor without control and with control. In this research, it was proposed an artificial neural network method to control the speed of three-phase induction motors. The reference speed of motor was set at the rate of 140 rad / s, 150 rad / s, and 130\n\n\nFuzzy gain scheduling of velocity PI controller with intelligent learning algorithm for reactor control\nInternational Nuclear Information System (INIS) \nDong Yun Kim; Poong Hyun Seong; .\n1997-01-01\nIn this research, we propose a fuzzy gain scheduler (FGS) with an intelligent learning algorithm for a reactor control. In the proposed algorithm, the gradient descent method is used in order to generate the rule bases of a fuzzy algorithm by learning. These rule bases are obtained by minimizing an objective function, which is called a performance cost function. The objective of the FGS with an intelligent learning algorithm is to generate gains, which minimize the error of system. The proposed algorithm can reduce the time and effort required for obtaining the fuzzy rules through the intelligent learning function. It is applied to reactor control of nuclear power plant (NPP), and the results are compared with those of a conventional PI controller with fixed gains. As a result, it is shown that the proposed algorithm is superior to the conventional PI controller. (author)\n\n\nStability and chaos of LMSER PCA learning algorithm\nInternational Nuclear Information System (INIS) \nLv Jiancheng; Y, Zhang\n2007-01-01\nLMSER PCA algorithm is a principal components analysis algorithm. It is used to extract principal components on-line from input data. The algorithm has both stability and chaotic dynamic behavior under some conditions. This paper studies the local stability of the LMSER PCA algorithm via a corresponding deterministic discrete time system. Conditions for local stability are derived. The paper also explores the chaotic behavior of this algorithm. It shows that the LMSER PCA algorithm can produce chaos. Waveform plots, Lyapunov exponents and bifurcation diagrams are presented to illustrate the existence of chaotic behavior of this algorithm\n\n\nPerturbation of convex risk minimization and its application in differential private learning algorithms\nDirectory of Open Access Journals (Sweden)\nWeilin Nie\n2017-01-01\nFull Text Available Abstract Convex risk minimization is a commonly used setting in learning theory. In this paper, we firstly give a perturbation analysis for such algorithms, and then we apply this result to differential private learning algorithms. Our analysis needs the objective functions to be strongly convex. This leads to an extension of our previous analysis to the non-differentiable loss functions, when constructing differential private algorithms. Finally, an error analysis is then provided to show the selection for the parameters.\n\n\nModeling the Swift Bat Trigger Algorithm with Machine Learning\nScience.gov (United States)\nGraff, Philip B.; Lien, Amy Y.; Baker, John G.; Sakamoto, Takanori\n2016-01-01\nTo draw inferences about gamma-ray burst (GRB) source populations based on Swift observations, it is essential to understand the detection efficiency of the Swift burst alert telescope (BAT). This study considers the problem of modeling the Swift / BAT triggering algorithm for long GRBs, a computationally expensive procedure, and models it using machine learning algorithms. A large sample of simulated GRBs from Lien et al. is used to train various models: random forests, boosted decision trees (with AdaBoost), support vector machines, and artificial neural networks. The best models have accuracies of greater than or equal to 97 percent (less than or equal to 3 percent error), which is a significant improvement on a cut in GRB flux, which has an accuracy of 89.6 percent (10.4 percent error). These models are then used to measure the detection efficiency of Swift as a function of redshift z, which is used to perform Bayesian parameter estimation on the GRB rate distribution. We find a local GRB rate density of n (sub 0) approaching 0.48 (sup plus 0.41) (sub minus 0.23) per cubic gigaparsecs per year with power-law indices of n (sub 1) approaching 1.7 (sup plus 0.6) (sub minus 0.5) and n (sub 2) approaching minus 5.9 (sup plus 5.7) (sub minus 0.1) for GRBs above and below a break point of z (redshift) (sub 1) approaching 6.8 (sup plus 2.8) (sub minus 3.2). This methodology is able to improve upon earlier studies by more accurately modeling Swift detection and using this for fully Bayesian model fitting.\n\n\nEfficient generation of image chips for training deep learning algorithms\nScience.gov (United States)\nHan, Sanghui; Fafard, Alex; Kerekes, John; Gartley, Michael; Ientilucci, Emmett; Savakis, Andreas; Law, Charles; Parhan, Jason; Turek, Matt; Fieldhouse, Keith; Rovito, Todd\n2017-05-01\nTraining deep convolutional networks for satellite or aerial image analysis often requires a large amount of training data. For a more robust algorithm, training data need to have variations not only in the background and target, but also radiometric variations in the image such as shadowing, illumination changes, atmospheric conditions, and imaging platforms with different collection geometry. Data augmentation is a commonly used approach to generating additional training data. However, this approach is often insufficient in accounting for real world changes in lighting, location or viewpoint outside of the collection geometry. Alternatively, image simulation can be an efficient way to augment training data that incorporates all these variations, such as changing backgrounds, that may be encountered in real data. The Digital Imaging and Remote Sensing Image Image Generation (DIRSIG) model is a tool that produces synthetic imagery using a suite of physics-based radiation propagation modules. DIRSIG can simulate images taken from different sensors with variation in collection geometry, spectral response, solar elevation and angle, atmospheric models, target, and background. Simulation of Urban Mobility (SUMO) is a multi-modal traffic simulation tool that explicitly models vehicles that move through a given road network. The output of the SUMO model was incorporated into DIRSIG to generate scenes with moving vehicles. The same approach was used when using helicopters as targets, but with slight modifications. Using the combination of DIRSIG and SUMO, we quickly generated many small images, with the target at the center with different backgrounds. The simulations generated images with vehicles and helicopters as targets, and corresponding images without targets. Using parallel computing, 120,000 training images were generated in about an hour. Some preliminary results show an improvement in the deep learning algorithm when real image training data are augmented with\n\n\nModeling the Swift BAT Trigger Algorithm with Machine Learning\nScience.gov (United States)\nGraff, Philip B.; Lien, Amy Y.; Baker, John G.; Sakamoto, Takanori\n2015-01-01\nTo draw inferences about gamma-ray burst (GRB) source populations based on Swift observations, it is essential to understand the detection efficiency of the Swift burst alert telescope (BAT). This study considers the problem of modeling the Swift BAT triggering algorithm for long GRBs, a computationally expensive procedure, and models it using machine learning algorithms. A large sample of simulated GRBs from Lien et al. (2014) is used to train various models: random forests, boosted decision trees (with AdaBoost), support vector machines, and artificial neural networks. The best models have accuracies of approximately greater than 97% (approximately less than 3% error), which is a significant improvement on a cut in GRB flux which has an accuracy of 89:6% (10:4% error). These models are then used to measure the detection efficiency of Swift as a function of redshift z, which is used to perform Bayesian parameter estimation on the GRB rate distribution. We find a local GRB rate density of eta(sub 0) approximately 0.48(+0.41/-0.23) Gpc(exp -3) yr(exp -1) with power-law indices of eta(sub 1) approximately 1.7(+0.6/-0.5) and eta(sub 2) approximately -5.9(+5.7/-0.1) for GRBs above and below a break point of z(sub 1) approximately 6.8(+2.8/-3.2). This methodology is able to improve upon earlier studies by more accurately modeling Swift detection and using this for fully Bayesian model fitting. The code used in this is analysis is publicly available online.\n\n\n\n\n\u00ab\n9\n10\n11\n12\n13\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n10\n11\n12\n13\n14\n\u00bb\n\n\n\n\n\n\n\n\nAlgorithms\nIndian Academy of Sciences (India)\n\n\npolynomial) division have been found in Vedic Mathematics which are dated much before Euclid's algorithm. A programming language Is used to describe an algorithm for execution on a computer. An algorithm expressed using a programming.\n\n\nThe parallel implementation of a backpropagation neural network and its applicability to SPECT image reconstruction\nEnergy Technology Data Exchange (ETDEWEB)\nKerr, John Patrick [Iowa State Univ., Ames, IA (United States)\n1992-01-01\nThe objective of this study was to determine the feasibility of using an Artificial Neural Network (ANN), in particular a backpropagation ANN, to improve the speed and quality of the reconstruction of three-dimensional SPECT (single photon emission computed tomography) images. In addition, since the processing elements (PE)s in each layer of an ANN are independent of each other, the speed and efficiency of the neural network architecture could be better optimized by implementing the ANN on a massively parallel computer. The specific goals of this research were: to implement a fully interconnected backpropagation neural network on a serial computer and a SIMD parallel computer, to identify any reduction in the time required to train these networks on the parallel machine versus the serial machine, to determine if these neural networks can learn to recognize SPECT data by training them on a section of an actual SPECT image, and to determine from the knowledge obtained in this research if full SPECT image reconstruction by an ANN implemented on a parallel computer is feasible both in time required to train the network, and in quality of the images reconstructed.\n\n\nDesain Sistem Pendeteksi untuk Citra Base Sub-assembly dengan Algoritma Backpropagation\nDirectory of Open Access Journals (Sweden)\nKasdianto Kasdianto\n2017-04-01\nFull Text Available Object identification technique using machine vision has been implemented in industrial of electronic manufacturers for years. This technique is commonly used for reject detection (for disqualified product based on existing standard or defect detection. This research aims to build a reject detector of sub-assembly condition which is differed by two conditions that are missing screw and wrong position screw using neural network backpropagation. The image taken using camera will be converted into grayscale before it is processed in backpropagation methods to generate a weight value. The experiment result shows that the network architecture with two layers has the most excellent accuracy level. Using learning rate of 0.5, target error 0.015%, and the number of node 1 of 100 and node 2 of 50, the successive rate for sub-assembly detection in right condition reached 99.02% while no error occurs in detecting the wrong condition of Sub-assembly (missing screw and wrong position screw.\n\n\nEthnomathematics elements in Batik Bali using backpropagation method\nScience.gov (United States)\nLestari, Mei; Irawan, Ari; Rahayu, Wanti; Wayan Parwati, Ni\n2018-05-01\nBatik is one of traditional arts that has been established by the UNESCO as Indonesia\u00e2\u20ac\u2122s cultural heritage. Batik has varieties and motifs, and each motifs has its own uniqueness but seems similar, that makes it difficult to identify. This study aims to develop an application that can identify typical batik Bali with etnomatematics elements on it. Etnomatematics is a study that shows relation between culture and mathematics concepts. Etnomatematics in Batik Bali is more to geometrical concept in line of strong Balinese culture element. The identification process is use backpropagation method. Steps of backpropagation methods are image processing (including scalling and tresholding image process). Next step is insert the processed image to an artificial neural network. This study resulted an accuracy of identification of batik Bali that has Etnomatematics elements on it.\n\n\nUsing an improved association rules mining optimization algorithm in web-based mobile-learning system\nScience.gov (United States)\nHuang, Yin; Chen, Jianhua; Xiong, Shaojun\n2009-07-01\nMobile-Learning (M-learning) makes many learners get the advantages of both traditional learning and E-learning. Currently, Web-based Mobile-Learning Systems have created many new ways and defined new relationships between educators and learners. Association rule mining is one of the most important fields in data mining and knowledge discovery in databases. Rules explosion is a serious problem which causes great concerns, as conventional mining algorithms often produce too many rules for decision makers to digest. Since Web-based Mobile-Learning System collects vast amounts of student profile data, data mining and knowledge discovery techniques can be applied to find interesting relationships between attributes of learners, assessments, the solution strategies adopted by learners and so on. Therefore ,this paper focus on a new data-mining algorithm, combined with the advantages of genetic algorithm and simulated annealing algorithm , called ARGSA(Association rules based on an improved Genetic Simulated Annealing Algorithm), to mine the association rules. This paper first takes advantage of the Parallel Genetic Algorithm and Simulated Algorithm designed specifically for discovering association rules. Moreover, the analysis and experiment are also made to show the proposed method is superior to the Apriori algorithm in this Mobile-Learning system.\n\n\nSupervised learning of probability distributions by neural networks\nScience.gov (United States)\nBaum, Eric B.; Wilczek, Frank\n1988-01-01\nSupervised learning algorithms for feedforward neural networks are investigated analytically. The back-propagation algorithm described by Werbos (1974), Parker (1985), and Rumelhart et al. (1986) is generalized by redefining the values of the input and output neurons as probabilities. The synaptic weights are then varied to follow gradients in the logarithm of likelihood rather than in the error. This modification is shown to provide a more rigorous theoretical basis for the algorithm and to permit more accurate predictions. A typical application involving a medical-diagnosis expert system is discussed.\n\n\nPredicting breast screening attendance using machine learning techniques.\nScience.gov (United States)\nBaskaran, Vikraman; Guergachi, Aziz; Bali, Rajeev K; Naguib, Raouf N G\n2011-03-01\nMachine learning-based prediction has been effectively applied for many healthcare applications. Predicting breast screening attendance using machine learning (prior to the actual mammogram) is a new field. This paper presents new predictor attributes for such an algorithm. It describes a new hybrid algorithm that relies on back-propagation and radial basis function-based neural networks for prediction. The algorithm has been developed in an open source-based environment. The algorithm was tested on a 13-year dataset (1995-2008). This paper compares the algorithm and validates its accuracy and efficiency with different platforms. Nearly 80% accuracy and 88% positive predictive value and sensitivity were recorded for the algorithm. The results were encouraging; 40-50% of negative predictive value and specificity warrant further work. Preliminary results were promising and provided ample amount of reasons for testing the algorithm on a larger scale.\n\n\nA rank-based Prediction Algorithm of Learning User's Intention\nScience.gov (United States)\nShen, Jie; Gao, Ying; Chen, Cang; Gong, HaiPing\n\nInternet search has become an important part in people's daily life. People can find many types of information to meet different needs through search engines on the Internet. There are two issues for the current search engines: first, the users should predetermine the types of information they want and then change to the appropriate types of search engine interfaces. Second, most search engines can support multiple kinds of search functions, each function has its own separate search interface. While users need different types of information, they must switch between different interfaces. In practice, most queries are corresponding to various types of information results. These queries can search the relevant results in various search engines, such as query \"Palace\" contains the websites about the introduction of the National Palace Museum, blog, Wikipedia, some pictures and video information. This paper presents a new aggregative algorithm for all kinds of search results. It can filter and sort the search results by learning three aspects about the query words, search results and search history logs to achieve the purpose of detecting user's intention. Experiments demonstrate that this rank-based method for multi-types of search results is effective. It can meet the user's search needs well, enhance user's satisfaction, provide an effective and rational model for optimizing search engines and improve user's search experience.\n\n\nSelf-learning health monitoring algorithm in composite structures\nScience.gov (United States)\nGrassia, Luigi; Iannone, Michele; Califano, America; D'Amore, Alberto\n2018-02-01\nThe paper describes a system that it is able of monitoring the health state of a composite structure in real time. The hardware of the system consists of a wire of strain sensors connected to a control unit. The software of the system elaborates the strain data and in real time is able to detect the presence of an eventual damage of the structures monitored with the strain sensors. The algorithm requires as input only the strains of the monitored structured measured on real time, i.e. those strains coming from the deformations of the composite structure due to the working loads. The health monitoring system does not require any additional device to interrogate the structure as often used in the literature, instead it is based on a self-learning procedure. The strain data acquired when the structure is healthy are used to set up the correlations between the strain in different positions of structure by means of neural network. Once the correlations between the strains in different position have been set up, these correlations act as a fingerprint of the healthy structure. In case of damage the correlation between the strains in the position of the structure near the damage will change due to the change of the stiffness of the structure caused by the damage. The developed software is able to recognize the change of the transfer function between the strains and consequently is able to detect the damage.\n\n\nDiagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer\nNARCIS (Netherlands)\nBejnordi, Babak Ehteshami; Veta, Mitko; van Diest, Paul Johannes; Van Ginneken, Bram; Karssemeijer, Nico; Litjens, Geert; van der Laak, Jeroen A.W.M.; Hermsen, Meyke; Manson, Quirine F.; Balkenhol, Maschenka; Geessink, Oscar; Stathonikos, Nikolaos; Van Dijk, Marcory C.R.F.; Bult, Peter; Beca, Francisco; Beck, Andrew H.; Wang, Dayong; Khosla, Aditya; Gargeya, Rishab; Irshad, Humayun; Zhong, Aoxiao; Dou, Qi; Li, Quanzheng; Chen, Hao; Lin, Huang Jing; Heng, Pheng Ann; Ha\u00c3\u0178, Christian; Bruni, Elia; Wong, Quincy; Halici, Ugur; \u00c3\u2013ner, Mustafa \u00c3\u0153mit; Cetin-Atalay, Rengul; Berseth, Matt; Khvatkov, Vitali; Vylegzhanin, Alexei; Kraus, Oren; Shaban, Muhammad; Rajpoot, Nasir; Awan, Ruqayya; Sirinukunwattana, Korsuk; Qaiser, Talha; Tsang, Yee Wah; Tellez, David; Annuscheit, Jonas; Hufnagl, Peter; Valkonen, Mira; Kartasalo, Kimmo; Latonen, Leena; Ruusuvuori, Pekka; Liimatainen, Kaisa\n2017-01-01\nIMPORTANCE: Application of deep learning algorithms to whole-slide pathology imagescan potentially improve diagnostic accuracy and efficiency. OBJECTIVE: Assess the performance of automated deep learning algorithms at detecting metastases in hematoxylin and eosin-stained tissue sections of lymph\n\n\nMaximum power point tracking-based control algorithm for PMSG wind generation system without mechanical sensors\nInternational Nuclear Information System (INIS) \nHong, Chih-Ming; Chen, Chiung-Hsing; Tu, Chia-Sheng\n2013-01-01\nHighlights: \u00e2\u2013\u00ba This paper presents MPPT based control for optimal wind energy capture using RBFN. \u00e2\u2013\u00ba MPSO is adopted to adjust the learning rates to improve the learning capability. \u00e2\u2013\u00ba This technique can maintain the system stability and reach the desired performance. \u00e2\u2013\u00ba The EMF in the rotating reference frame is utilized in order to estimate speed. - Abstract: This paper presents maximum-power-point-tracking (MPPT) based control algorithms for optimal wind energy capture using radial basis function network (RBFN) and a proposed torque observer MPPT algorithm. The design of a high-performance on-line training RBFN using back-propagation learning algorithm with modified particle swarm optimization (MPSO) regulating controller for the sensorless control of a permanent magnet synchronous generator (PMSG). The MPSO is adopted in this study to adapt the learning rates in the back-propagation process of the RBFN to improve the learning capability. The PMSG is controlled by the loss-minimization control with MPPT below the base speed, which corresponds to low and high wind speed, and the maximum energy can be captured from the wind. Then the observed disturbance torque is feed-forward to increase the robustness of the PMSG system\n\n\nFidelity-Based Ant Colony Algorithm with Q-learning of Quantum System\nScience.gov (United States)\nLiao, Qin; Guo, Ying; Tu, Yifeng; Zhang, Hang\n2018-03-01\nQuantum ant colony algorithm (ACA) has potential applications in quantum information processing, such as solutions of traveling salesman problem, zero-one knapsack problem, robot route planning problem, and so on. To shorten the search time of the ACA, we suggest the fidelity-based ant colony algorithm (FACA) for the control of quantum system. Motivated by structure of the Q-learning algorithm, we demonstrate the combination of a FACA with the Q-learning algorithm and suggest the design of a fidelity-based ant colony algorithm with the Q-learning to improve the performance of the FACA in a spin-1/2 quantum system. The numeric simulation results show that the FACA with the Q-learning can efficiently avoid trapping into local optimal policies and increase the speed of convergence process of quantum system.\n\n\nA Coupled User Clustering Algorithm Based on Mixed Data for Web-Based Learning Systems\nDirectory of Open Access Journals (Sweden)\nKe Niu\n2015-01-01\nFull Text Available In traditional Web-based learning systems, due to insufficient learning behaviors analysis and personalized study guides, a few user clustering algorithms are introduced. While analyzing the behaviors with these algorithms, researchers generally focus on continuous data but easily neglect discrete data, each of which is generated from online learning actions. Moreover, there are implicit coupled interactions among the data but are frequently ignored in the introduced algorithms. Therefore, a mass of significant information which can positively affect clustering accuracy is neglected. To solve the above issues, we proposed a coupled user clustering algorithm for Wed-based learning systems by taking into account both discrete and continuous data, as well as intracoupled and intercoupled interactions of the data. The experiment result in this paper demonstrates the outperformance of the proposed algorithm.\n\n\nInductive learning of thyroid functional states using the ID3 algorithm. The effect of poor examples on the learning result.\nScience.gov (United States)\nForsstr\u00c3\u00b6m, J\n1992-01-01\nThe ID3 algorithm for inductive learning was tested using preclassified material for patients suspected to have a thyroid illness. Classification followed a rule-based expert system for the diagnosis of thyroid function. Thus, the knowledge to be learned was limited to the rules existing in the knowledge base of that expert system. The learning capability of the ID3 algorithm was tested with an unselected learning material (with some inherent missing data) and with a selected learning material (no missing data). The selected learning material was a subgroup which formed a part of the unselected learning material. When the number of learning cases was increased, the accuracy of the program improved. When the learning material was large enough, an increase in the learning material did not improve the results further. A better learning result was achieved with the selected learning material not including missing data as compared to unselected learning material. With this material we demonstrate a weakness in the ID3 algorithm: it can not find available information from good example cases if we add poor examples to the data.\n\n\nNew Dandelion Algorithm Optimizes Extreme Learning Machine for Biomedical Classification Problems\nDirectory of Open Access Journals (Sweden)\nXiguang Li\n2017-01-01\nFull Text Available Inspired by the behavior of dandelion sowing, a new novel swarm intelligence algorithm, namely, dandelion algorithm (DA, is proposed for global optimization of complex functions in this paper. In DA, the dandelion population will be divided into two subpopulations, and different subpopulations will undergo different sowing behaviors. Moreover, another sowing method is designed to jump out of local optimum. In order to demonstrate the validation of DA, we compare the proposed algorithm with other existing algorithms, including bat algorithm, particle swarm optimization, and enhanced fireworks algorithm. Simulations show that the proposed algorithm seems much superior to other algorithms. At the same time, the proposed algorithm can be applied to optimize extreme learning machine (ELM for biomedical classification problems, and the effect is considerable. At last, we use different fusion methods to form different fusion classifiers, and the fusion classifiers can achieve higher accuracy and better stability to some extent.\n\n\nResearch on B Cell Algorithm for Learning to Rank Method Based on Parallel Strategy.\nScience.gov (United States)\nTian, Yuling; Zhang, Hongxian\n2016-01-01\nFor the purposes of information retrieval, users must find highly relevant documents from within a system (and often a quite large one comprised of many individual documents) based on input query. Ranking the documents according to their relevance within the system to meet user needs is a challenging endeavor, and a hot research topic-there already exist several rank-learning methods based on machine learning techniques which can generate ranking functions automatically. This paper proposes a parallel B cell algorithm, RankBCA, for rank learning which utilizes a clonal selection mechanism based on biological immunity. The novel algorithm is compared with traditional rank-learning algorithms through experimentation and shown to outperform the others in respect to accuracy, learning time, and convergence rate; taken together, the experimental results show that the proposed algorithm indeed effectively and rapidly identifies optimal ranking functions.\n\n\nDeveloping robust arsenic awareness prediction models using machine learning algorithms.\nScience.gov (United States)\nSingh, Sushant K; Taylor, Robert W; Rahman, Mohammad Mahmudur; Pradhan, Biswajeet\n2018-04-01\nArsenic awareness plays a vital role in ensuring the sustainability of arsenic mitigation technologies. Thus far, however, few studies have dealt with the sustainability of such technologies and its associated socioeconomic dimensions. As a result, arsenic awareness prediction has not yet been fully conceptualized. Accordingly, this study evaluated arsenic awareness among arsenic-affected communities in rural India, using a structured questionnaire to record socioeconomic, demographic, and other sociobehavioral factors with an eye to assessing their association with and influence on arsenic awareness. First a logistic regression model was applied and its results compared with those produced by six state-of-the-art machine-learning algorithms (Support Vector Machine [SVM], Kernel-SVM, Decision Tree [DT], k-Nearest Neighbor [k-NN], Na\u00c3\u00afve Bayes [NB], and Random Forests [RF]) as measured by their accuracy at predicting arsenic awareness. Most (63%) of the surveyed population was found to be arsenic-aware. Significant arsenic awareness predictors were divided into three types: (1) socioeconomic factors: caste, education level, and occupation; (2) water and sanitation behavior factors: number of family members involved in water collection, distance traveled and time spent for water collection, places for defecation, and materials used for handwashing after defecation; and (3) social capital and trust factors: presence of anganwadi and people's trust in other community members, NGOs, and private agencies. Moreover, individuals' having higher social network positively contributed to arsenic awareness in the communities. Results indicated that both the SVM and the RF algorithms outperformed at overall prediction of arsenic awareness-a nonlinear classification problem. Lower-caste, less educated, and unemployed members of the population were found to be the most vulnerable, requiring immediate arsenic mitigation. To this end, local social institutions and NGOs could play a\n\n\nLearning Path Recommendation Based on Modified Variable Length Genetic Algorithm\nScience.gov (United States)\nDwivedi, Pragya; Kant, Vibhor; Bharadwaj, Kamal K.\n2018-01-01\nWith the rapid advancement of information and communication technologies, e-learning has gained a considerable attention in recent years. Many researchers have attempted to develop various e-learning systems with personalized learning mechanisms for assisting learners so that they can learn more efficiently. In this context, curriculum sequencing\u00e2\u20ac\u00a6\n\n\nA controllable sensor management algorithm capable of learning\nScience.gov (United States)\nOsadciw, Lisa A.; Veeramacheneni, Kalyan K.\n2005-03-01\nSensor management technology progress is challenged by the geographic space it spans, the heterogeneity of the sensors, and the real-time timeframes within which plans controlling the assets are executed. This paper presents a new sensor management paradigm and demonstrates its application in a sensor management algorithm designed for a biometric access control system. This approach consists of an artificial intelligence (AI) algorithm focused on uncertainty measures, which makes the high level decisions to reduce uncertainties and interfaces with the user, integrated cohesively with a bottom up evolutionary algorithm, which optimizes the sensor network\"s operation as determined by the AI algorithm. The sensor management algorithm presented is composed of a Bayesian network, the AI algorithm component, and a swarm optimization algorithm, the evolutionary algorithm. Thus, the algorithm can change its own performance goals in real-time and will modify its own decisions based on observed measures within the sensor network. The definition of the measures as well as the Bayesian network determine the robustness of the algorithm and its utility in reacting dynamically to changes in the global system.\n\n\nThe efficiency of the RULES-4 classification learning algorithm in predicting the density of agents\nDirectory of Open Access Journals (Sweden)\nZiad Salem\n2014-12-01\nFull Text Available Learning is the act of obtaining new or modifying existing knowledge, behaviours, skills or preferences. The ability to learn is found in humans, other organisms and some\u00c2\u00a0machines. Learning is always based on some sort of observations or data such as examples, direct experience or instruction. This paper presents a classification algorithm to learn the density of agents in an arena based on the measurements of six proximity sensors of a combined actuator sensor units (CASUs. Rules are presented that were induced by the learning algorithm that was trained with data-sets based on the CASU\u00e2\u20ac\u2122s sensor data streams collected during a number of experiments with \u00e2\u20ac\u0153Bristlebots (agents in the arena (environment\u00e2\u20ac\ufffd. It was found that a set of rules generated by the learning algorithm is able to predict the number of bristlebots in the arena based on the CASU\u00e2\u20ac\u2122s sensor readings with satisfying accuracy.\n\n\n\n\n\u00ab\n10\n11\n12\n13\n14\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n11\n12\n13\n14\n15\n\u00bb\n\n\n\n\n\n\n\n\nAlgorithms\nIndian Academy of Sciences (India)\n\n\nto as 'divide-and-conquer'. Although there has been a large effort in realizing efficient algorithms, there are not many universally accepted algorithm design paradigms. In this article, we illustrate algorithm design techniques such as balancing, greedy strategy, dynamic programming strategy, and backtracking or traversal of\u00c2\u00a0...\n\n\nValidating Machine Learning Algorithms for Twitter Data Against Established Measures of Suicidality.\nScience.gov (United States)\nBraithwaite, Scott R; Giraud-Carrier, Christophe; West, Josh; Barnes, Michael D; Hanson, Carl Lee\n2016-05-16\nOne of the leading causes of death in the United States (US) is suicide and new methods of assessment are needed to track its risk in real time. Our objective is to validate the use of machine learning algorithms for Twitter data against empirically validated measures of suicidality in the US population. Using a machine learning algorithm, the Twitter feeds of 135 Mechanical Turk (MTurk) participants were compared with validated, self-report measures of suicide risk. Our findings show that people who are at high suicidal risk can be easily differentiated from those who are not by machine learning algorithms, which accurately identify the clinically significant suicidal rate in 92% of cases (sensitivity: 53%, specificity: 97%, positive predictive value: 75%, negative predictive value: 93%). Machine learning algorithms are efficient in differentiating people who are at a suicidal risk from those who are not. Evidence for suicidality can be measured in nonclinical populations using social media data.\n\n\nElements of Causal Inference: Foundations and Learning Algorithms\nDEFF Research Database (Denmark)\nPeters, Jonas Martin; Janzing, Dominik; Sch\u00c3\u00b6lkopf, Bernhard\n\nA concise and self-contained introduction to causal inference, increasingly important in data science and machine learning......A concise and self-contained introduction to causal inference, increasingly important in data science and machine learning...\n\n\nExperimental analysis of the performance of machine learning algorithms in the classification of navigation accident records\nDirectory of Open Access Journals (Sweden)\nREIS, M V. S. de A.\n2017-06-01\nFull Text Available This paper aims to evaluate the use of machine learning techniques in a database of marine accidents. We analyzed and evaluated the main causes and types of marine accidents in the Northern Fluminense region. For this, machine learning techniques were used. The study showed that the modeling can be done in a satisfactory manner using different configurations of classification algorithms, varying the activation functions and training parameters. The SMO (Sequential Minimal Optimization algorithm showed the best performance result.\n\n\nAn analysis dictionary learning algorithm under a noisy data model with orthogonality constraint.\nScience.gov (United States)\nZhang, Ye; Yu, Tenglong; Wang, Wenwu\n2014-01-01\nTwo common problems are often encountered in analysis dictionary learning (ADL) algorithms. The first one is that the original clean signals for learning the dictionary are assumed to be known, which otherwise need to be estimated from noisy measurements. This, however, renders a computationally slow optimization process and potentially unreliable estimation (if the noise level is high), as represented by the Analysis K-SVD (AK-SVD) algorithm. The other problem is the trivial solution to the dictionary, for example, the null dictionary matrix that may be given by a dictionary learning algorithm, as discussed in the learning overcomplete sparsifying transform (LOST) algorithm. Here we propose a novel optimization model and an iterative algorithm to learn the analysis dictionary, where we directly employ the observed data to compute the approximate analysis sparse representation of the original signals (leading to a fast optimization procedure) and enforce an orthogonality constraint on the optimization criterion to avoid the trivial solutions. Experiments demonstrate the competitive performance of the proposed algorithm as compared with three baselines, namely, the AK-SVD, LOST, and NAAOLA algorithms.\n\n\nApplication of a fuzzy control algorithm with improved learning speed to nuclear steam generator level control\nInternational Nuclear Information System (INIS) \nPark, Gee Yong; Seong, Poong Hyun\n1994-01-01\nIn order to reduce the load of tuning works by trial-and-error for obtaining the best control performance of conventional fuzzy control algorithm, a fuzzy control algorithm with learning function is investigated in this work. This fuzzy control algorithm can make its rule base and tune the membership functions automatically by use of learning function which needs the data from the control actions of the plant operator or other controllers. Learning process in fuzzy control algorithm is to find the optimal values of parameters, which consist of the membership functions and the rule base, by gradient descent method. Learning speed of gradient descent is significantly improved in this work with the addition of modified momentum. This control algorithm is applied to the steam generator level control by computer simulations. The simulation results confirm the good performance of this control algorithm for level control and show that the fuzzy learning algorithm has the generalization capability for the relation of inputs and outputs and it also has the excellent capability of disturbance rejection\n\n\nAn Analysis Dictionary Learning Algorithm under a Noisy Data Model with Orthogonality Constraint\nDirectory of Open Access Journals (Sweden)\nYe Zhang\n2014-01-01\nFull Text Available Two common problems are often encountered in analysis dictionary learning (ADL algorithms. The first one is that the original clean signals for learning the dictionary are assumed to be known, which otherwise need to be estimated from noisy measurements. This, however, renders a computationally slow optimization process and potentially unreliable estimation (if the noise level is high, as represented by the Analysis K-SVD (AK-SVD algorithm. The other problem is the trivial solution to the dictionary, for example, the null dictionary matrix that may be given by a dictionary learning algorithm, as discussed in the learning overcomplete sparsifying transform (LOST algorithm. Here we propose a novel optimization model and an iterative algorithm to learn the analysis dictionary, where we directly employ the observed data to compute the approximate analysis sparse representation of the original signals (leading to a fast optimization procedure and enforce an orthogonality constraint on the optimization criterion to avoid the trivial solutions. Experiments demonstrate the competitive performance of the proposed algorithm as compared with three baselines, namely, the AK-SVD, LOST, and NAAOLA algorithms.\n\n\nFuzzy gain scheduling of velocity PI controller with intelligent learning algorithm for reactor control\nInternational Nuclear Information System (INIS) \nKim, Dong Yun\n1997-02-01\nIn this research, we propose a fuzzy gain scheduler (FGS) with an intelligent learning algorithm for a reactor control. In the proposed algorithm, the gradient descent method is used in order to generate the rule bases of a fuzzy algorithm by learning. These rule bases are obtained by minimizing an objective function, which is called a performance cost function. The objective of the FGS with an intelligent learning algorithm is to generate adequate gains, which minimize the error of system. The proposed algorithm can reduce the time and efforts required for obtaining the fuzzy rules through the intelligent learning function. The evolutionary programming algorithm is modified and adopted as the method in order to find the optimal gains which are used as the initial gains of FGS with learning function. It is applied to reactor control of nuclear power plant (NPP), and the results are compared with those of a conventional PI controller with fixed gains. As a result, it is shown that the proposed algorithm is superior to the conventional PI controller\n\n\nIdentification of chaotic systems by neural network with hybrid learning algorithm\nInternational Nuclear Information System (INIS) \nPan, S.-T.; Lai, C.-C.\n2008-01-01\nBased on the genetic algorithm (GA) and steepest descent method (SDM), this paper proposes a hybrid algorithm for the learning of neural networks to identify chaotic systems. The systems in question are the logistic map and the Duffing equation. Different identification schemes are used to identify both the logistic map and the Duffing equation, respectively. Simulation results show that our hybrid algorithm is more efficient than that of other methods\n\n\nA new supervised learning algorithm for spiking neurons.\nScience.gov (United States)\nXu, Yan; Zeng, Xiaoqin; Zhong, Shuiming\n2013-06-01\nThe purpose of supervised learning with temporal encoding for spiking neurons is to make the neurons emit a specific spike train encoded by the precise firing times of spikes. If only running time is considered, the supervised learning for a spiking neuron is equivalent to distinguishing the times of desired output spikes and the other time during the running process of the neuron through adjusting synaptic weights, which can be regarded as a classification problem. Based on this idea, this letter proposes a new supervised learning method for spiking neurons with temporal encoding; it first transforms the supervised learning into a classification problem and then solves the problem by using the perceptron learning rule. The experiment results show that the proposed method has higher learning accuracy and efficiency over the existing learning methods, so it is more powerful for solving complex and real-time problems.\n\n\nTime series classification using k-Nearest neighbours, Multilayer Perceptron and Learning Vector Quantization algorithms\nDirectory of Open Access Journals (Sweden)\nJi\u00c5\u2122\u00c3\u00ad Fejfar\n2012-01-01\nFull Text Available We are presenting results comparison of three artificial intelligence algorithms in a classification of time series derived from musical excerpts in this paper. Algorithms were chosen to represent different principles of classification \u00e2\u20ac\u201c statistic approach, neural networks and competitive learning. The first algorithm is a classical k-Nearest neighbours algorithm, the second algorithm is Multilayer Perceptron (MPL, an example of artificial neural network and the third one is a Learning Vector Quantization (LVQ algorithm representing supervised counterpart to unsupervised Self Organizing Map (SOM.After our own former experiments with unlabelled data we moved forward to the data labels utilization, which generally led to a better accuracy of classification results. As we need huge data set of labelled time series (a priori knowledge of correct class which each time series instance belongs to, we used, with a good experience in former studies, musical excerpts as a source of real-world time series. We are using standard deviation of the sound signal as a descriptor of a musical excerpts volume level.We are describing principle of each algorithm as well as its implementation briefly, giving links for further research. Classification results of each algorithm are presented in a confusion matrix showing numbers of misclassifications and allowing to evaluate overall accuracy of the algorithm. Results are compared and particular misclassifications are discussed for each algorithm. Finally the best solution is chosen and further research goals are given.\n\n\nAn improved clustering algorithm based on reverse learning in intelligent transportation\nScience.gov (United States)\nQiu, Guoqing; Kou, Qianqian; Niu, Ting\n2017-05-01\nWith the development of artificial intelligence and data mining technology, big data has gradually entered people's field of vision. In the process of dealing with large data, clustering is an important processing method. By introducing the reverse learning method in the clustering process of PAM clustering algorithm, to further improve the limitations of one-time clustering in unsupervised clustering learning, and increase the diversity of clustering clusters, so as to improve the quality of clustering. The algorithm analysis and experimental results show that the algorithm is feasible.\n\n\nA Computer Environment for Beginners' Learning of Sorting Algorithms: Design and Pilot Evaluation\nScience.gov (United States)\nKordaki, M.; Miatidis, M.; Kapsampelis, G.\n2008-01-01\nThis paper presents the design, features and pilot evaluation study of a web-based environment--the SORTING environment--for the learning of sorting algorithms by secondary level education students. The design of this environment is based on modeling methodology, taking into account modern constructivist and social theories of learning while at\u00e2\u20ac\u00a6\n\n\nInteractive Learning Environment for Bio-Inspired Optimization Algorithms for UAV Path Planning\nScience.gov (United States)\nDuan, Haibin; Li, Pei; Shi, Yuhui; Zhang, Xiangyin; Sun, Changhao\n2015-01-01\nThis paper describes the development of BOLE, a MATLAB-based interactive learning environment, that facilitates the process of learning bio-inspired optimization algorithms, and that is dedicated exclusively to unmanned aerial vehicle path planning. As a complement to conventional teaching methods, BOLE is designed to help students consolidate the\u00e2\u20ac\u00a6\n\n\nClassification and learning using genetic algorithms applications in Bioinformatics and Web Intelligence\nCERN Document Server\nBandyopadhyay, Sanghamitra\n2007-01-01\nThis book provides a unified framework that describes how genetic learning can be used to design pattern recognition and learning systems. It examines how a search technique, the genetic algorithm, can be used for pattern classification mainly through approximating decision boundaries. Coverage also demonstrates the effectiveness of the genetic classifiers vis-\u00c3\u00a0-vis several widely used classifiers, including neural networks.\n\n\nForecasting spot electricity prices : Deep learning approaches and empirical comparison of traditional algorithms\nNARCIS (Netherlands)\nLago Garcia, J.; De Ridder, Fjo; De Schutter, B.H.K.\n2018-01-01\nIn this paper, a novel modeling framework for forecasting electricity prices is proposed. While many predictive models have been already proposed to perform this task, the area of deep learning algorithms remains yet unexplored. To fill this scientific gap, we propose four different deep learning\n\n\nBeyond the \"c\" and the \"x\": Learning with Algorithms in Massive Open Online Courses (MOOCs)\nScience.gov (United States)\nKnox, Jeremy\n2018-01-01\nThis article examines how algorithms are shaping student learning in massive open online courses (MOOCs). Following the dramatic rise of MOOC platform organisations in 2012, over 4,500 MOOCs have been offered to date, in increasingly diverse languages, and with a growing requirement for fees. However, discussions of \"learning\" in MOOCs\u00e2\u20ac\u00a6\n\n\nUpper-Lower Bounds Candidate Sets Searching Algorithm for Bayesian Network Structure Learning\nDirectory of Open Access Journals (Sweden)\nGuangyi Liu\n2014-01-01\nFull Text Available Bayesian network is an important theoretical model in artificial intelligence field and also a powerful tool for processing uncertainty issues. Considering the slow convergence speed of current Bayesian network structure learning algorithms, a fast hybrid learning method is proposed in this paper. We start with further analysis of information provided by low-order conditional independence testing, and then two methods are given for constructing graph model of network, which is theoretically proved to be upper and lower bounds of the structure space of target network, so that candidate sets are given as a result; after that a search and scoring algorithm is operated based on the candidate sets to find the final structure of the network. Simulation results show that the algorithm proposed in this paper is more efficient than similar algorithms with the same learning precision.\n\n\nEstimation of biogas and methane yields in an UASB treating potato starch processing wastewater with backpropagation artificial neural network.\nScience.gov (United States)\nAntwi, Philip; Li, Jianzheng; Boadi, Portia Opoku; Meng, Jia; Shi, En; Deng, Kaiwen; Bondinuba, Francis Kwesi\n2017-03-01\nThree-layered feedforward backpropagation (BP) artificial neural networks (ANN) and multiple nonlinear regression (MnLR) models were developed to estimate biogas and methane yield in an upflow anaerobic sludge blanket (UASB) reactor treating potato starch processing wastewater (PSPW). Anaerobic process parameters were optimized to identify their importance on methanation. pH, total chemical oxygen demand, ammonium, alkalinity, total Kjeldahl nitrogen, total phosphorus, volatile fatty acids and hydraulic retention time selected based on principal component analysis were used as input variables, whiles biogas and methane yield were employed as target variables. Quasi-Newton method and conjugate gradient backpropagation algorithms were best among eleven training algorithms. Coefficient of determination (R 2 ) of the BP-ANN reached 98.72% and 97.93% whiles MnLR model attained 93.9% and 91.08% for biogas and methane yield, respectively. Compared with the MnLR model, BP-ANN model demonstrated significant performance, suggesting possible control of the anaerobic digestion process with the BP-ANN model. Copyright \u00c2\u00a9 2016 Elsevier Ltd. All rights reserved.\n\n\nLEARNING ALGORITHM EFFECT ON MULTILAYER FEED FORWARD ARTIFICIAL NEURAL NETWORK PERFORMANCE IN IMAGE CODING\nDirectory of Open Access Journals (Sweden)\nOMER MAHMOUD\n2007-08-01\nFull Text Available One of the essential factors that affect the performance of Artificial Neural Networks is the learning algorithm. The performance of Multilayer Feed Forward Artificial Neural Network performance in image compression using different learning algorithms is examined in this paper. Based on Gradient Descent, Conjugate Gradient, Quasi-Newton techniques three different error back propagation algorithms have been developed for use in training two types of neural networks, a single hidden layer network and three hidden layers network. The essence of this study is to investigate the most efficient and effective training methods for use in image compression and its subsequent applications. The obtained results show that the Quasi-Newton based algorithm has better performance as compared to the other two algorithms.\n\n\n\n\n\u00ab\n11\n12\n13\n14\n15\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n12\n13\n14\n15\n16\n\u00bb\n\n\n\n\n\n\n\n\nMachine Learning Algorithms Outperform Conventional Regression Models in Predicting Development of Hepatocellular Carcinoma\nScience.gov (United States)\nSingal, Amit G.; Mukherjee, Ashin; Elmunzer, B. Joseph; Higgins, Peter DR; Lok, Anna S.; Zhu, Ji; Marrero, Jorge A; Waljee, Akbar K\n2015-01-01\nBackground Predictive models for hepatocellular carcinoma (HCC) have been limited by modest accuracy and lack of validation. Machine learning algorithms offer a novel methodology, which may improve HCC risk prognostication among patients with cirrhosis. Our study's aim was to develop and compare predictive models for HCC development among cirrhotic patients, using conventional regression analysis and machine learning algorithms. Methods We enrolled 442 patients with Child A or B cirrhosis at the University of Michigan between January 2004 and September 2006 (UM cohort) and prospectively followed them until HCC development, liver transplantation, death, or study termination. Regression analysis and machine learning algorithms were used to construct predictive models for HCC development, which were tested on an independent validation cohort from the Hepatitis C Antiviral Long-term Treatment against Cirrhosis (HALT-C) Trial. Both models were also compared to the previously published HALT-C model. Discrimination was assessed using receiver operating characteristic curve analysis and diagnostic accuracy was assessed with net reclassification improvement and integrated discrimination improvement statistics. Results After a median follow-up of 3.5 years, 41 patients developed HCC. The UM regression model had a c-statistic of 0.61 (95%CI 0.56-0.67), whereas the machine learning algorithm had a c-statistic of 0.64 (95%CI 0.60\u00e2\u20ac\u201c0.69) in the validation cohort. The machine learning algorithm had significantly better diagnostic accuracy as assessed by net reclassification improvement (pmachine learning algorithm (p=0.047). Conclusion Machine learning algorithms improve the accuracy of risk stratifying patients with cirrhosis and can be used to accurately identify patients at high-risk for developing HCC. PMID:24169273\n\n\nOptimal design of the heat pipe using TLBO (teaching\u00e2\u20ac\u201clearning-based optimization) algorithm\nInternational Nuclear Information System (INIS) \nRao, R.V.; More, K.C.\n2015-01-01\nHeat pipe is a highly efficient and reliable heat transfer component. It is a closed container designed to transfer a large amount of heat in system. Since the heat pipe operates on a closed two-phase cycle, the heat transfer capacity is greater than for solid conductors. Also, the thermal response time is less than with solid conductors. The three major elemental parts of the rotating heat pipe are: a cylindrical evaporator, a truncated cone condenser, and a fixed amount of working fluid. In this paper, a recently proposed new stochastic advanced optimization algorithm called TLBO (Teaching\u00e2\u20ac\u201cLearning-Based Optimization) algorithm is used for single objective as well as multi-objective design optimization of heat pipe. It is easy to implement, does not make use of derivatives and it can be applied to unconstrained or constrained problems. Two examples of heat pipe are presented in this paper. The results of application of TLBO algorithm for the design optimization of heat pipe are compared with the NPGA (Niched Pareto Genetic Algorithm), GEM (Grenade Explosion Method) and GEO (Generalized External optimization). It is found that the TLBO algorithm has produced better results as compared to those obtained by using NPGA, GEM and GEO algorithms. - Highlights: \u00e2\u20ac\u00a2 The TLBO (Teaching\u00e2\u20ac\u201cLearning-Based Optimization) algorithm is used for the design and optimization of a heat pipe. \u00e2\u20ac\u00a2 Two examples of heat pipe design and optimization are presented. \u00e2\u20ac\u00a2 The TLBO algorithm is proved better than the other optimization algorithms in terms of results and the convergence\n\n\nAn Adaptive Bacterial Foraging Optimization Algorithm with Lifecycle and Social Learning\nDirectory of Open Access Journals (Sweden)\nXiaohui Yan\n2012-01-01\nFull Text Available Bacterial Foraging Algorithm (BFO is a recently proposed swarm intelligence algorithm inspired by the foraging and chemotactic phenomenon of bacteria. However, its optimization ability is not so good compared with other classic algorithms as it has several shortages. This paper presents an improved BFO Algorithm. In the new algorithm, a lifecycle model of bacteria is founded. The bacteria could split, die, or migrate dynamically in the foraging processes, and population size varies as the algorithm runs. Social learning is also introduced so that the bacteria will tumble towards better directions in the chemotactic steps. Besides, adaptive step lengths are employed in chemotaxis. The new algorithm is named BFOLS and it is tested on a set of benchmark functions with dimensions of 2 and 20. Canonical BFO, PSO, and GA algorithms are employed for comparison. Experiment results and statistic analysis show that the BFOLS algorithm offers significant improvements than original BFO algorithm. Particulary with dimension of 20, it has the best performance among the four algorithms.\n\n\nAlgorithms\nIndian Academy of Sciences (India)\n\n\nticians but also forms the foundation of computer science. Two ... with methods of developing algorithms for solving a variety of problems but ... applications of computers in science and engineer- ... numerical calculus are as important. We will\u00c2\u00a0...\n\n\nJavascript Library for Developing Interactive Micro-Level Animations for Teaching and Learning Algorithms on One-Dimensional Arrays\nScience.gov (United States)\nV\u00c3\u00a9gh, Ladislav\n2016-01-01\nThe first data structure that first-year undergraduate students learn during the programming and algorithms courses is the one-dimensional array. For novice programmers, it might be hard to understand different algorithms on arrays (e.g. searching, mirroring, sorting algorithms), because the algorithms dynamically change the values of elements. In\u00e2\u20ac\u00a6\n\n\nAlgorithms that Defy the Gravity of Learning Curve\nScience.gov (United States)\n\n2017-04-28\nyield the best perform- ing 1NN ensembles There is no magic to the gravity-defiant algorithms such as aNNE and iNNE which mani- fest that small data...isolation using nearest neighbour en- semble. Proceedings of the 2014 IEEE international conference on data mining, work- shop on incremental\n\n\nSpectral Regularization Algorithms for Learning Large Incomplete Matrices.\nScience.gov (United States)\nMazumder, Rahul; Hastie, Trevor; Tibshirani, Robert\n2010-03-01\nWe use convex relaxation techniques to provide a sequence of regularized low-rank solutions for large-scale matrix completion problems. Using the nuclear norm as a regularizer, we provide a simple and very efficient convex algorithm for minimizing the reconstruction error subject to a bound on the nuclear norm. Our algorithm Soft-Impute iteratively replaces the missing elements with those obtained from a soft-thresholded SVD. With warm starts this allows us to efficiently compute an entire regularization path of solutions on a grid of values of the regularization parameter. The computationally intensive part of our algorithm is in computing a low-rank SVD of a dense matrix. Exploiting the problem structure, we show that the task can be performed with a complexity linear in the matrix dimensions. Our semidefinite-programming algorithm is readily scalable to large matrices: for example it can obtain a rank-80 approximation of a 10(6) \u00c3\u2014 10(6) incomplete matrix with 10(5) observed entries in 2.5 hours, and can fit a rank 40 approximation to the full Netflix training set in 6.6 hours. Our methods show very good performance both in training and test error when compared to other competitive state-of-the art techniques.\n\n\nVariants of Learning Algorithm Based on Kolmogorov Theorem\nCzech Academy of Sciences Publication Activity Database\nNeruda, Roman; \u00c5\u00a0t\u00c4\u203adr\u00c3\u00bd, Arno\u00c5\u00a1t; Drko\u00c5\u00a1ov\u00c3\u00a1, Jitka\n2002-01-01\nRo\u00c4\ufffd. 12, \u00c4\ufffd. 6 (2002), s. 587-597 ISSN 1210-0552 R&D Projects: GA AV \u00c4\u0152R IAB1030006 Institutional research plan: AV0Z1030915 Keywords : Kolmogorov networks * approximation theory * parallel algorithms Subject RIV: BA - General Mathematics\n\n\nLearning JavaScript data structures and algorithms\nCERN Document Server\nGroner, Loiane\n2014-01-01\nIf you are a JavaScript developer or someone who has basic knowledge of JavaScript, and want to explore its optimum ability, this fast-paced book is definitely for you. Programming logic is the only thing you need to know to start having fun with algorithms.\n\n\nInteractive algorithms for teaching and learning acute medicine in the network of medical faculties MEFANET.\nScience.gov (United States)\nSchwarz, Daniel; \u00c5\u00a0toura\u00c4\ufffd, Petr; Komenda, Martin; Harazim, Hana; Kosinov\u00c3\u00a1, Martina; Gregor, Jakub; H\u00c5\u00aflek, Richard; Sm\u00c3\u00a9kalov\u00c3\u00a1, Olga; K\u00c5\u2122ikava, Ivo; \u00c5\u00a0toudek, Roman; Du\u00c5\u00a1ek, Ladislav\n2013-07-08\nMedical Faculties Network (MEFANET) has established itself as the authority for setting standards for medical educators in the Czech Republic and Slovakia, 2 independent countries with similar languages that once comprised a federation and that still retain the same curricular structure for medical education. One of the basic goals of the network is to advance medical teaching and learning with the use of modern information and communication technologies. We present the education portal AKUTNE.CZ as an important part of the MEFANET's content. Our focus is primarily on simulation-based tools for teaching and learning acute medicine issues. Three fundamental elements of the MEFANET e-publishing system are described: (1) medical disciplines linker, (2) authentication/authorization framework, and (3) multidimensional quality assessment. A new set of tools for technology-enhanced learning have been introduced recently: Sandbox (works in progress), WikiLectures (collaborative content authoring), Moodle-MEFANET (central learning management system), and Serious Games (virtual casuistics and interactive algorithms). The latest development in MEFANET is designed for indexing metadata about simulation-based learning objects, also known as electronic virtual patients or virtual clinical cases. The simulations assume the form of interactive algorithms for teaching and learning acute medicine. An anonymous questionnaire of 10 items was used to explore students' attitudes and interests in using the interactive algorithms as part of their medical or health care studies. Data collection was conducted over 10 days in February 2013. In total, 25 interactive algorithms in the Czech and English languages have been developed and published on the AKUTNE.CZ education portal to allow the users to test and improve their knowledge and skills in the field of acute medicine. In the feedback survey, 62 participants completed the online questionnaire (13.5%) from the total 460 addressed\n\n\nEmpirical Studies On Machine Learning Based Text Classification Algorithms\nOpenAIRE\nShweta C. Dharmadhikari; Maya Ingle; Parag Kulkarni\n2011-01-01\nAutomatic classification of text documents has become an important research issue now days. Properclassification of text documents requires information retrieval, machine learning and Natural languageprocessing (NLP) techniques. Our aim is to focus on important approaches to automatic textclassification based on machine learning techniques viz. supervised, unsupervised and semi supervised.In this paper we present a review of various text classification approaches under machine learningparadig...\n\n\nA Weighted Block Dictionary Learning Algorithm for Classification\nOpenAIRE\nShi, Zhongrong\n2016-01-01\nDiscriminative dictionary learning, playing a critical role in sparse representation based classification, has led to state-of-the-art classification results. Among the existing discriminative dictionary learning methods, two different approaches, shared dictionary and class-specific dictionary, which associate each dictionary atom to all classes or a single class, have been studied. The shared dictionary is a compact method but with lack of discriminative information; the class-specific dict...\n\n\nA Parallel Adaboost-Backpropagation Neural Network for Massive Image Dataset Classification\nScience.gov (United States)\nCao, Jianfang; Chen, Lichao; Wang, Min; Shi, Hao; Tian, Yun\n2016-01-01\nImage classification uses computers to simulate human understanding and cognition of images by automatically categorizing images. This study proposes a faster image classification approach that parallelizes the traditional Adaboost-Backpropagation (BP) neural network using the MapReduce parallel programming model. First, we construct a strong classifier by assembling the outputs of 15\u00e2\u20ac\u2030BP neural networks (which are individually regarded as weak classifiers) based on the Adaboost algorithm. Second, we design Map and Reduce tasks for both the parallel Adaboost-BP neural network and the feature extraction algorithm. Finally, we establish an automated classification model by building a Hadoop cluster. We use the Pascal VOC2007 and Caltech256 datasets to train and test the classification model. The results are superior to those obtained using traditional Adaboost-BP neural network or parallel BP neural network approaches. Our approach increased the average classification accuracy rate by approximately 14.5% and 26.0% compared to the traditional Adaboost-BP neural network and parallel BP neural network, respectively. Furthermore, the proposed approach requires less computation time and scales very well as evaluated by speedup, sizeup and scaleup. The proposed approach may provide a foundation for automated large-scale image classification and demonstrates practical value. PMID:27905520\n\n\nAutomatic learning algorithm for the MD-logic artificial pancreas system.\nScience.gov (United States)\nMiller, Shahar; Nimri, Revital; Atlas, Eran; Grunberg, Eli A; Phillip, Moshe\n2011-10-01\nApplying real-time learning into an artificial pancreas system could effectively track the unpredictable behavior of glucose-insulin dynamics and adjust insulin treatment accordingly. We describe a novel learning algorithm and its performance when integrated into the MD-Logic Artificial Pancreas (MDLAP) system developed by the Diabetes Technology Center, Schneider Children's Medical Center of Israel, Petah Tikva, Israel. The algorithm was designed to establish an initial patient profile using open-loop data (Initial Learning Algorithm component) and then make periodic adjustments during closed-loop operation (Runtime Learning Algorithm component). The MDLAP system, integrated with the learning algorithm, was tested in seven different experiments using the University of Virginia/Padova simulator, comprising adults, adolescents, and children. The experiments included simulations using the open-loop and closed-loop control strategy under nominal and varying insulin sensitivity conditions. The learning algorithm was automatically activated at the end of the open-loop segment and after every day of the closed-loop operation. Metabolic control parameters achieved at selected time points were compared. The percentage of time glucose levels were maintained within 70-180 mg/dL for children and adolescents significantly improved when open-loop was compared with day 6 of closed-loop control (Psignificantly reduced by approximately sevenfold (Psignificant reduction in the Low Blood Glucose Index (P<0.001). The new algorithm was effective in characterizing the patient profiles from open-loop data and in adjusting treatment to provide better glycemic control during closed-loop control in both conditions. These findings warrant corroboratory clinical trials.\n\n\nBeyond the \"c\" and the \"x\": Learning with algorithms in massive open online courses (MOOCs)\nScience.gov (United States)\nKnox, Jeremy\n2018-02-01\nThis article examines how algorithms are shaping student learning in massive open online courses (MOOCs). Following the dramatic rise of MOOC platform organisations in 2012, over 4,500 MOOCs have been offered to date, in increasingly diverse languages, and with a growing requirement for fees. However, discussions of learning in MOOCs remain polarised around the \"xMOOC\" and \"cMOOC\" designations. In this narrative, the more recent extended or platform MOOC (\"xMOOC\") adopts a broadcast pedagogy, assuming a direct transmission of information to its largely passive audience (i.e. a teacher-centred approach), while the slightly older connectivist model (\"cMOOC\") offers only a simplistic reversal of the hierarchy, posing students as highly motivated, self-directed and collaborative learners (i.e. a learner-centred approach). The online nature of both models generates data (e.g. on how many times a particular resource was viewed, or the ways in which participants communicated with each other) which MOOC providers use for analysis, albeit only after these data have been selectively processed. Central to many learning analytics approaches is the desire to predict students' future behaviour. Educators need to be aware that MOOC learning is not just about teachers and students, but that it also involves algorithms: instructions which perform automated calculations on data. Education is becoming embroiled in an \"algorithmic culture\" that defines educational roles, forecasts attainment, and influences pedagogy. Established theories of learning appear wholly inadequate in addressing the agential role of algorithms in the educational domain of the MOOC. This article identifies and examines four key areas where algorithms influence the activities of the MOOC: (1) data capture and discrimination; (2) calculated learners; (3) feedback and entanglement; and (4) learning with algorithms. The article concludes with a call for further research in these areas to surface a critical\n\n\nA fast and accurate online sequential learning algorithm for feedforward networks.\nScience.gov (United States)\nLiang, Nan-Ying; Huang, Guang-Bin; Saratchandran, P; Sundararajan, N\n2006-11-01\nIn this paper, we develop an online sequential learning algorithm for single hidden layer feedforward networks (SLFNs) with additive or radial basis function (RBF) hidden nodes in a unified framework. The algorithm is referred to as online sequential extreme learning machine (OS-ELM) and can learn data one-by-one or chunk-by-chunk (a block of data) with fixed or varying chunk size. The activation functions for additive nodes in OS-ELM can be any bounded nonconstant piecewise continuous functions and the activation functions for RBF nodes can be any integrable piecewise continuous functions. In OS-ELM, the parameters of hidden nodes (the input weights and biases of additive nodes or the centers and impact factors of RBF nodes) are randomly selected and the output weights are analytically determined based on the sequentially arriving data. The algorithm uses the ideas of ELM of Huang et al. developed for batch learning which has been shown to be extremely fast with generalization performance better than other batch training methods. Apart from selecting the number of hidden nodes, no other control parameters have to be manually chosen. Detailed performance comparison of OS-ELM is done with other popular sequential learning algorithms on benchmark problems drawn from the regression, classification and time series prediction areas. The results show that the OS-ELM is faster than the other sequential algorithms and produces better generalization performance.\n\n\nSuper-resolution reconstruction of MR image with a novel residual learning network algorithm\nScience.gov (United States)\nShi, Jun; Liu, Qingping; Wang, Chaofeng; Zhang, Qi; Ying, Shihui; Xu, Haoyu\n2018-04-01\nSpatial resolution is one of the key parameters of magnetic resonance imaging (MRI). The image super-resolution (SR) technique offers an alternative approach to improve the spatial resolution of MRI due to its simplicity. Convolutional neural networks (CNN)-based SR algorithms have achieved state-of-the-art performance, in which the global residual learning (GRL) strategy is now commonly used due to its effectiveness for learning image details for SR. However, the partial loss of image details usually happens in a very deep network due to the degradation problem. In this work, we propose a novel residual learning-based SR algorithm for MRI, which combines both multi-scale GRL and shallow network block-based local residual learning (LRL). The proposed LRL module works effectively in capturing high-frequency details by learning local residuals. One simulated MRI dataset and two real MRI datasets have been used to evaluate our algorithm. The experimental results show that the proposed SR algorithm achieves superior performance to all of the other compared CNN-based SR algorithms in this work.\n\n\nDeep Learning with Dynamic Spiking Neurons and Fixed Feedback Weights.\nScience.gov (United States)\nSamadi, Arash; Lillicrap, Timothy P; Tweed, Douglas B\n2017-03-01\nRecent work in computer science has shown the power of deep learning driven by the backpropagation algorithm in networks of artificial neurons. But real neurons in the brain are different from most of these artificial ones in at least three crucial ways: they emit spikes rather than graded outputs, their inputs and outputs are related dynamically rather than by piecewise-smooth functions, and they have no known way to coordinate arrays of synapses in separate forward and feedback pathways so that they change simultaneously and identically, as they do in backpropagation. Given these differences, it is unlikely that current deep learning algorithms can operate in the brain, but we that show these problems can be solved by two simple devices: learning rules can approximate dynamic input-output relations with piecewise-smooth functions, and a variation on the feedback alignment algorithm can train deep networks without having to coordinate forward and feedback synapses. Our results also show that deep spiking networks learn much better if each neuron computes an intracellular teaching signal that reflects that cell's nonlinearity. With this mechanism, networks of spiking neurons show useful learning in synapses at least nine layers upstream from the output cells and perform well compared to other spiking networks in the literature on the MNIST digit recognition task.\n\n\nBehavioral Profiling of Scada Network Traffic Using Machine Learning Algorithms\nScience.gov (United States)\n\n2014-03-27\nAcquisition ( SCADA ) System Overview SCADA systems control and monitor processes for water distribution, oil and natural gas pipelines , electrical...the desire for remote control and monitoring of industrial processes. The ability to identify SCADA devices on a mixed traffic network with zero...optimal attribute subset, while maintaining the desired TPR of .99 for SCADA network traffic. The attributes and ML algorithms chosen for\n\n\nAsymmetric Variate Generation via a Parameterless Dual Neural Learning Algorithm\nDirectory of Open Access Journals (Sweden)\nSimone Fiori\n2008-01-01\nFull Text Available In a previous work (S. Fiori, 2006, we proposed a random number generator based on a tunable non-linear neural system, whose learning rule is designed on the basis of a cardinal equation from statistics and whose implementation is based on look-up tables (LUTs. The aim of the present manuscript is to improve the above-mentioned random number generation method by changing the learning principle, while retaining the efficient LUT-based implementation. The new method proposed here proves easier to implement and relaxes some previous limitations.\n\n\n\n\n\u00ab\n12\n13\n14\n15\n16\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n13\n14\n15\n16\n17\n\u00bb\n\n\n\n\n\n\n\n\nFour wind speed multi-step forecasting models using extreme learning machines and signal decomposing algorithms\nInternational Nuclear Information System (INIS) \nLiu, Hui; Tian, Hong-qi; Li, Yan-fei\n2015-01-01\nHighlights: \u00e2\u20ac\u00a2 A hybrid architecture is proposed for the wind speed forecasting. \u00e2\u20ac\u00a2 Four algorithms are used for the wind speed multi-scale decomposition. \u00e2\u20ac\u00a2 The extreme learning machines are employed for the wind speed forecasting. \u00e2\u20ac\u00a2 All the proposed hybrid models can generate the accurate results. - Abstract: Realization of accurate wind speed forecasting is important to guarantee the safety of wind power utilization. In this paper, a new hybrid forecasting architecture is proposed to realize the wind speed accurate forecasting. In this architecture, four different hybrid models are presented by combining four signal decomposing algorithms (e.g., Wavelet Decomposition/Wavelet Packet Decomposition/Empirical Mode Decomposition/Fast Ensemble Empirical Mode Decomposition) and Extreme Learning Machines. The originality of the study is to investigate the promoted percentages of the Extreme Learning Machines by those mainstream signal decomposing algorithms in the multiple step wind speed forecasting. The results of two forecasting experiments indicate that: (1) the method of Extreme Learning Machines is suitable for the wind speed forecasting; (2) by utilizing the decomposing algorithms, all the proposed hybrid algorithms have better performance than the single Extreme Learning Machines; (3) in the comparisons of the decomposing algorithms in the proposed hybrid architecture, the Fast Ensemble Empirical Mode Decomposition has the best performance in the three-step forecasting results while the Wavelet Packet Decomposition has the best performance in the one and two step forecasting results. At the same time, the Wavelet Packet Decomposition and the Fast Ensemble Empirical Mode Decomposition are better than the Wavelet Decomposition and the Empirical Mode Decomposition in all the step predictions, respectively; and (4) the proposed algorithms are effective in the wind speed accurate predictions\n\n\nA New Fuzzy Cognitive Map Learning Algorithm for Speech Emotion Recognition\nOpenAIRE\nZhang, Wei; Zhang, Xueying; Sun, Ying\n2017-01-01\nSelecting an appropriate recognition method is crucial in speech emotion recognition applications. However, the current methods do not consider the relationship between emotions. Thus, in this study, a speech emotion recognition system based on the fuzzy cognitive map (FCM) approach is constructed. Moreover, a new FCM learning algorithm for speech emotion recognition is proposed. This algorithm includes the use of the pleasure-arousal-dominance emotion scale to calculate the weights between e...\n\n\nCAT-PUMA: CME Arrival Time Prediction Using Machine learning Algorithms\nScience.gov (United States)\nLiu, Jiajia; Ye, Yudong; Shen, Chenglong; Wang, Yuming; Erd\u00c3\u00a9lyi, Robert\n2018-04-01\nCAT-PUMA (CME Arrival Time Prediction Using Machine learning Algorithms) quickly and accurately predicts the arrival of Coronal Mass Ejections (CMEs) of CME arrival time. The software was trained via detailed analysis of CME features and solar wind parameters using 182 previously observed geo-effective partial-/full-halo CMEs and uses algorithms of the Support Vector Machine (SVM) to make its predictions, which can be made within minutes of providing the necessary input parameters of a CME.\n\n\nFuzzy gain scheduling of velocity PI controller with intelligent learning algorithm for reactor control\nInternational Nuclear Information System (INIS) \nKim, Dong Yun; Seong, Poong Hyun\n1996-01-01\nIn this study, we proposed a fuzzy gain scheduler with intelligent learning algorithm for a reactor control. In the proposed algorithm, we used the gradient descent method to learn the rule bases of a fuzzy algorithm. These rule bases are learned toward minimizing an objective function, which is called a performance cost function. The objective of fuzzy gain scheduler with intelligent learning algorithm is the generation of adequate gains, which minimize the error of system. The condition of every plant is generally changed as time gose. That is, the initial gains obtained through the analysis of system are no longer suitable for the changed plant. And we need to set new gains, which minimize the error stemmed from changing the condition of a plant. In this paper, we applied this strategy for reactor control of nuclear power plant (NPP), and the results were compared with those of a simple PI controller, which has fixed gains. As a result, it was shown that the proposed algorithm was superior to the simple PI controller\n\n\nOptimisation of a machine learning algorithm in human locomotion using principal component and discriminant function analyses.\nScience.gov (United States)\nBisele, Maria; Bencsik, Martin; Lewis, Martin G C; Barnett, Cleveland T\n2017-01-01\nAssessment methods in human locomotion often involve the description of normalised graphical profiles and/or the extraction of discrete variables. Whilst useful, these approaches may not represent the full complexity of gait data. Multivariate statistical methods, such as Principal Component Analysis (PCA) and Discriminant Function Analysis (DFA), have been adopted since they have the potential to overcome these data handling issues. The aim of the current study was to develop and optimise a specific machine learning algorithm for processing human locomotion data. Twenty participants ran at a self-selected speed across a 15m runway in barefoot and shod conditions. Ground reaction forces (BW) and kinematics were measured at 1000 Hz and 100 Hz, respectively from which joint angles (\u00c2\u00b0), joint moments (N.m.kg-1) and joint powers (W.kg-1) for the hip, knee and ankle joints were calculated in all three anatomical planes. Using PCA and DFA, power spectra of the kinematic and kinetic variables were used as a training database for the development of a machine learning algorithm. All possible combinations of 10 out of 20 participants were explored to find the iteration of individuals that would optimise the machine learning algorithm. The results showed that the algorithm was able to successfully predict whether a participant ran shod or barefoot in 93.5% of cases. To the authors' knowledge, this is the first study to optimise the development of a machine learning algorithm.\n\n\nAn Improved Brain-Inspired Emotional Learning Algorithm for Fast Classification\nDirectory of Open Access Journals (Sweden)\nYing Mei\n2017-06-01\nFull Text Available Classification is an important task of machine intelligence in the field of information. The artificial neural network (ANN is widely used for classification. However, the traditional ANN shows slow training speed, and it is hard to meet the real-time requirement for large-scale applications. In this paper, an improved brain-inspired emotional learning (BEL algorithm is proposed for fast classification. The BEL algorithm was put forward to mimic the high speed of the emotional learning mechanism in mammalian brain, which has the superior features of fast learning and low computational complexity. To improve the accuracy of BEL in classification, the genetic algorithm (GA is adopted for optimally tuning the weights and biases of amygdala and orbitofrontal cortex in the BEL neural network. The combinational algorithm named as GA-BEL has been tested on eight University of California at Irvine (UCI datasets and two well-known databases (Japanese Female Facial Expression, Cohn\u00e2\u20ac\u201cKanade. The comparisons of experiments indicate that the proposed GA-BEL is more accurate than the original BEL algorithm, and it is much faster than the traditional algorithm.\n\n\nSVC control enhancement applying self-learning fuzzy algorithm for islanded microgrid\nDirectory of Open Access Journals (Sweden)\nHossam Gabbar\n2016-03-01\nFull Text Available Maintaining voltage stability, within acceptable levels, for islanded Microgrids (MGs is a challenge due to limited exchange power between generation and loads. This paper proposes an algorithm to enhance the dynamic performance of islanded MGs in presence of load disturbance using Static VAR Compensator (SVC with Fuzzy Model Reference Learning Controller (FMRLC. The proposed algorithm compensates MG nonlinearity via fuzzy membership functions and inference mechanism imbedded in both controller and inverse model. Hence, MG keeps the desired performance as required at any operating condition. Furthermore, the self-learning capability of the proposed control algorithm compensates for grid parameter\u00e2\u20ac\u2122s variation even with inadequate information about load dynamics. A reference model was designed to reject bus voltage disturbance with achievable performance by the proposed fuzzy controller. Three simulations scenarios have been presented to investigate effectiveness of proposed control algorithm in improving steady-state and transient performance of islanded MGs. The first scenario conducted without SVC, second conducted with SVC using PID controller and third conducted using FMRLC algorithm. A comparison for results shows ability of proposed control algorithm to enhance disturbance rejection due to learning process.\n\n\nAlgorithms\nIndian Academy of Sciences (India)\n\n\nalgorithm design technique called 'divide-and-conquer'. One of ... Turtle graphics, September. 1996. 5. ... whole list named 'PO' is a pointer to the first element of the list; ..... Program for computing matrices X and Y and placing the result in C *).\n\n\nAlgorithms\nIndian Academy of Sciences (India)\n\n\nalgorithm that it is implicitly understood that we know how to generate the next natural ..... Explicit comparisons are made in line (1) where maximum and minimum is ... It can be shown that the function T(n) = 3/2n -2 is the solution to the above\u00c2\u00a0...\n\n\nExtracting quantum dynamics from genetic learning algorithms through principal control analysis\nInternational Nuclear Information System (INIS) \nWhite, J L; Pearson, B J; Bucksbaum, P H\n2004-01-01\nGenetic learning algorithms are widely used to control ultrafast optical pulse shapes for photo-induced quantum control of atoms and molecules. An unresolved issue is how to use the solutions found by these algorithms to learn about the system's quantum dynamics. We propose a simple method based on covariance analysis of the control space, which can reveal the degrees of freedom in the effective control Hamiltonian. We have applied this technique to stimulated Raman scattering in liquid methanol. A simple model of two-mode stimulated Raman scattering is consistent with the results. (letter to the editor)\n\n\nForecasting with Universal Approximators and a Learning Algorithm\nDEFF Research Database (Denmark)\nKock, Anders Bredahl\n2011-01-01\nto the performance of the best single model in the set of models combined from. The use of universal approximators along with a combination scheme for which explicit loss bounds exist should give a solid theoretical foundation to the way the forecasts are performed. The practical performance will be investigated...... combination has a long history in econometrics focus has not been on proving loss bounds for the combination rules applied. We apply the Weighted Average Algorithm (WAA) of Kivinen & Warmuth (1999) for which such loss bounds exist. Specifically, one can bound the worst case performance of the WAA compared...\n\n\nForecasting with Universal Approximators and a Learning Algorithm\nDEFF Research Database (Denmark)\nKock, Anders Bredahl\n\nbounds for the combination rules applied. We apply the Weighted Average Algorithm (WAA) of Kivinen and Warmuth (1999) for which such loss bounds exist. Specifically, one can bound the worst case performance of the WAA compared to the performance of the best single model in the set of models combined from....... The use of universal approximators along with a combination scheme for which explicit loss bounds exist should give a solid theoretical foundation to the way the forecasts are performed. The practical performance will be investigated by considering various monthly postwar macroeconomic data sets for the G...\n\n\nEvaluation of Multiple Kernel Learning Algorithms for Crop Mapping Using Satellite Image Time-Series Data\nScience.gov (United States)\nNiazmardi, S.; Safari, A.; Homayouni, S.\n2017-09-01\nCrop mapping through classification of Satellite Image Time-Series (SITS) data can provide very valuable information for several agricultural applications, such as crop monitoring, yield estimation, and crop inventory. However, the SITS data classification is not straightforward. Because different images of a SITS data have different levels of information regarding the classification problems. Moreover, the SITS data is a four-dimensional data that cannot be classified using the conventional classification algorithms. To address these issues in this paper, we presented a classification strategy based on Multiple Kernel Learning (MKL) algorithms for SITS data classification. In this strategy, initially different kernels are constructed from different images of the SITS data and then they are combined into a composite kernel using the MKL algorithms. The composite kernel, once constructed, can be used for the classification of the data using the kernel-based classification algorithms. We compared the computational time and the classification performances of the proposed classification strategy using different MKL algorithms for the purpose of crop mapping. The considered MKL algorithms are: MKL-Sum, SimpleMKL, LPMKL and Group-Lasso MKL algorithms. The experimental tests of the proposed strategy on two SITS data sets, acquired by SPOT satellite sensors, showed that this strategy was able to provide better performances when compared to the standard classification algorithm. The results also showed that the optimization method of the used MKL algorithms affects both the computational time and classification accuracy of this strategy.\n\n\nPrediction of Negative Conversion Days of Childhood Nephrotic Syndrome Based on the Improved Backpropagation Neural Network with Momentum\nDirectory of Open Access Journals (Sweden)\nYi-jun Liu\n2015-12-01\nFull Text Available Childhood nephrotic syndrome is a chronic disease harmful to growth of children. Scientific and accurate prediction of negative conversion days for children with nephrotic syndrome offers potential benefits for treatment of patients and helps achieve better cure effect. In this study, the improved backpropagation neural network with momentum is used for prediction. Momentum speeds up convergence and maintains the generalization performance of the neural network, and therefore overcomes weaknesses of the standard backpropagation algorithm. The three-tier network structure is constructed. Eight indicators including age, lgG, lgA and lgM, etc. are selected for network inputs. The scientific computing software of MATLAB and its neural network tools are used to create model and predict. The training sample of twenty-eight cases is used to train the neural network. The test sample of six typical cases belonging to six different age groups respectively is used to test the predictive model. The low mean absolute error of predictive results is achieved at 0.83. The experimental results of the small-size sample show that the proposed approach is to some degree applicable for the prediction of negative conversion days of childhood nephrotic syndrome.\n\n\nPrediction model of ammonium uranyl carbonate calcination by microwave heating using incremental improved Back-Propagation neural network\nEnergy Technology Data Exchange (ETDEWEB)\nLi Yingwei [Faculty of Metallurgical and Energy Engineering, Kunming University of Science and Technology, Kunming, Yunnan Province 650093 (China); Key Laboratory of Unconventional Metallurgy, Ministry of Education, Kunming University of Science and Technology, Kunming, Yunnan Province 650093 (China); Peng Jinhui, E-mail: jhpeng@kmust.edu.c [Faculty of Metallurgical and Energy Engineering, Kunming University of Science and Technology, Kunming, Yunnan Province 650093 (China); Key Laboratory of Unconventional Metallurgy, Ministry of Education, Kunming University of Science and Technology, Kunming, Yunnan Province 650093 (China); Liu Bingguo [Faculty of Metallurgical and Energy Engineering, Kunming University of Science and Technology, Kunming, Yunnan Province 650093 (China); Key Laboratory of Unconventional Metallurgy, Ministry of Education, Kunming University of Science and Technology, Kunming, Yunnan Province 650093 (China); Li Wei [Key Laboratory of Unconventional Metallurgy, Ministry of Education, Kunming University of Science and Technology, Kunming, Yunnan Province 650093 (China); Huang Daifu [No. 272 Nuclear Industry Factory, China National Nuclear Corporation, Hengyang, Hunan Province 421002 (China); Zhang Libo [Faculty of Metallurgical and Energy Engineering, Kunming University of Science and Technology, Kunming, Yunnan Province 650093 (China); Key Laboratory of Unconventional Metallurgy, Ministry of Education, Kunming University of Science and Technology, Kunming, Yunnan Province 650093 (China)\n2011-05-15\nResearch highlights: The incremental improved Back-Propagation neural network prediction model using the Levenberg-Marquardt algorithm based on optimizing theory is put forward. The prediction model of the nonlinear system is built, which can effectively predict the experiment of microwave calcining of ammonium uranyl carbonate (AUC). AUC can accept the microwave energy and microwave heating can quickly decompose AUC. In the experiment of microwave calcining of AUC, the contents of U and U{sup 4+} increased with increasing of microwave power and irradiation time, and decreased with increasing of the material average depth. - Abstract: The incremental improved Back-Propagation (BP) neural network prediction model was put forward, which was very useful in overcoming the problems, such as long testing cycle, high testing quantity, difficulty of optimization for process parameters, many training data probably were offered by the way of increment batch and the limitation of the system memory could make the training data infeasible, which existed in the process of calcinations for ammonium uranyl carbonate (AUC) by microwave heating. The prediction model of the nonlinear system was built, which could effectively predict the experiment of microwave calcining of AUC. The predicted results indicated that the contents of U and U{sup 4+} were increased with increasing of microwave power and irradiation time, and decreased with increasing of the material average depth.\n\n\nPrediction model of ammonium uranyl carbonate calcination by microwave heating using incremental improved Back-Propagation neural network\nInternational Nuclear Information System (INIS) \nLi Yingwei; Peng Jinhui; Liu Bingguo; Li Wei; Huang Daifu; Zhang Libo\n2011-01-01\nResearch highlights: \u00e2\u2020\u2019 The incremental improved Back-Propagation neural network prediction model using the Levenberg-Marquardt algorithm based on optimizing theory is put forward. \u00e2\u2020\u2019 The prediction model of the nonlinear system is built, which can effectively predict the experiment of microwave calcining of ammonium uranyl carbonate (AUC). \u00e2\u2020\u2019 AUC can accept the microwave energy and microwave heating can quickly decompose AUC. \u00e2\u2020\u2019 In the experiment of microwave calcining of AUC, the contents of U and U 4+ increased with increasing of microwave power and irradiation time, and decreased with increasing of the material average depth. - Abstract: The incremental improved Back-Propagation (BP) neural network prediction model was put forward, which was very useful in overcoming the problems, such as long testing cycle, high testing quantity, difficulty of optimization for process parameters, many training data probably were offered by the way of increment batch and the limitation of the system memory could make the training data infeasible, which existed in the process of calcinations for ammonium uranyl carbonate (AUC) by microwave heating. The prediction model of the nonlinear system was built, which could effectively predict the experiment of microwave calcining of AUC. The predicted results indicated that the contents of U and U 4+ were increased with increasing of microwave power and irradiation time, and decreased with increasing of the material average depth.\n\n\nEnergy-efficient algorithm for classification of states of wireless sensor network using machine learning methods\nScience.gov (United States)\nYuldashev, M. N.; Vlasov, A. I.; Novikov, A. N.\n2018-05-01\nThis paper focuses on the development of an energy-efficient algorithm for classification of states of a wireless sensor network using machine learning methods. The proposed algorithm reduces energy consumption by: 1) elimination of monitoring of parameters that do not affect the state of the sensor network, 2) reduction of communication sessions over the network (the data are transmitted only if their values can affect the state of the sensor network). The studies of the proposed algorithm have shown that at classification accuracy close to 100%, the number of communication sessions can be reduced by 80%.\n\n\nA method for classification of network traffic based on C5.0 Machine Learning Algorithm\nDEFF Research Database (Denmark)\nBujlow, Tomasz; Riaz, M. Tahir; Pedersen, Jens Myrup\n2012-01-01\ncurrent network traffic. To overcome the drawbacks of existing methods for traffic classification, usage of C5.0 Machine Learning Algorithm (MLA) was proposed. On the basis of statistical traffic information received from volunteers and C5.0 algorithm we constructed a boosted classifier, which was shown...... and classification, an algorithm for recognizing flow direction and the C5.0 itself. Classified applications include Skype, FTP, torrent, web browser traffic, web radio, interactive gaming and SSH. We performed subsequent tries using different sets of parameters and both training and classification options...\n\n\nA new evolutionary algorithm with LQV learning for combinatorial problems optimization\nInternational Nuclear Information System (INIS) \nMachado, Marcelo Dornellas; Schirru, Roberto\n2000-01-01\nGenetic algorithms are biologically motivated adaptive systems which have been used, with good results, for combinatorial problems optimization. In this work, a new learning mode, to be used by the population-based incremental learning algorithm, has the aim to build a new evolutionary algorithm to be used in optimization of numerical problems and combinatorial problems. This new learning mode uses a variable learning rate during the optimization process, constituting a process known as proportional reward. The development of this new algorithm aims its application in the optimization of reload problem of PWR nuclear reactors, in order to increase the useful life of the nuclear fuel. For the test, two classes of problems are used: numerical problems and combinatorial problems. Due to the fact that the reload problem is a combinatorial problem, the major interest relies on the last class. The results achieved with the tests indicate the applicability of the new learning mode, showing its potential as a developing tool in the solution of reload problem. (author)\n\n\nA Probability-based Evolutionary Algorithm with Mutations to Learn Bayesian Networks\nDirectory of Open Access Journals (Sweden)\nSho Fukuda\n2014-12-01\nFull Text Available Bayesian networks are regarded as one of the essential tools to analyze causal relationship between events from data. To learn the structure of highly-reliable Bayesian networks from data as quickly as possible is one of the important problems that several studies have been tried to achieve. In recent years, probability-based evolutionary algorithms have been proposed as a new efficient approach to learn Bayesian networks. In this paper, we target on one of the probability-based evolutionary algorithms called PBIL (Probability-Based Incremental Learning, and propose a new mutation operator. Through performance evaluation, we found that the proposed mutation operator has a good performance in learning Bayesian networks\n\n\n\n\n\u00ab\n13\n14\n15\n16\n17\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n14\n15\n16\n17\n18\n\u00bb\n\n\n\n\n\n\n\n\nThe Design and Analysis of Efficient Learning Algorithms\nScience.gov (United States)\n\n1991-01-01\n31] describe in detail how this can be done efficiently; see also Duda and Hart [22]. Let a&,..., &d be the resulting solution, and let h0 = Fd=1 af...Measure. Wiley, second edition, 1986. [13] Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. Warmuth. Occam\u2019s razor. Information...Processing Letters, 24(6):377-380, April 1987. [14] Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. Warmuth. Learn- ability and the\n\n\nPrediction of Employee Turnover in Organizations using Machine Learning Algorithms\nOpenAIRE\nRohit Punnoose; Pankaj Ajit\n2016-01-01\nEmployee turnover has been identified as a key issue for organizations because of its adverse impact on work place productivity and long term growth strategies. To solve this problem, organizations use machine learning techniques to predict employee turnover. Accurate predictions enable organizations to take action for retention or succession planning of employees. However, the data for this modeling problem comes from HR Information Systems (HRIS); these are typically under-funded compared t...\n\n\nLearning Activity Predictors from Sensor Data: Algorithms, Evaluation, and Applications.\nScience.gov (United States)\nMinor, Bryan; Doppa, Janardhan Rao; Cook, Diane J\n2017-12-01\nRecent progress in Internet of Things (IoT) platforms has allowed us to collect large amounts of sensing data. However, there are significant challenges in converting this large-scale sensing data into decisions for real-world applications. Motivated by applications like health monitoring and intervention and home automation we consider a novel problem called Activity Prediction , where the goal is to predict future activity occurrence times from sensor data. In this paper, we make three main contributions. First, we formulate and solve the activity prediction problem in the framework of imitation learning and reduce it to a simple regression learning problem. This approach allows us to leverage powerful regression learners that can reason about the relational structure of the problem with negligible computational overhead. Second, we present several metrics to evaluate activity predictors in the context of real-world applications. Third, we evaluate our approach using real sensor data collected from 24 smart home testbeds. We also embed the learned predictor into a mobile-device-based activity prompter and evaluate the app for 9 participants living in smart homes. Our results indicate that our activity predictor performs better than the baseline methods, and offers a simple approach for predicting activities from sensor data.\n\n\nMachine Learning Algorithms for $b$-Jet Tagging at the ATLAS Experiment\nCERN Document Server\nPaganini, Michela; The ATLAS collaboration\n2017-01-01\nThe separation of $b$-quark initiated jets from those coming from lighter quark flavors ($b$-tagging) is a fundamental tool for the ATLAS physics program at the CERN Large Hadron Collider. The most powerful $b$-tagging algorithms combine information from low-level taggers, exploiting reconstructed track and vertex information, into machine learning classifiers. The potential of modern deep learning techniques is explored using simulated events, and compared to that achievable from more traditional classifiers such as boosted decision trees.\n\n\nSparse representation, modeling and learning in visual recognition theory, algorithms and applications\nCERN Document Server\nCheng, Hong\n2015-01-01\nThis unique text/reference presents a comprehensive review of the state of the art in sparse representations, modeling and learning. The book examines both the theoretical foundations and details of algorithm implementation, highlighting the practical application of compressed sensing research in visual recognition and computer vision. Topics and features: provides a thorough introduction to the fundamentals of sparse representation, modeling and learning, and the application of these techniques in visual recognition; describes sparse recovery approaches, robust and efficient sparse represen\n\n\nJoint optimization of algorithmic suites for EEG analysis.\nScience.gov (United States)\nSantana, Eder; Brockmeier, Austin J; Principe, Jose C\n2014-01-01\nElectroencephalogram (EEG) data analysis algorithms consist of multiple processing steps each with a number of free parameters. A joint optimization methodology can be used as a wrapper to fine-tune these parameters for the patient or application. This approach is inspired by deep learning neural network models, but differs because the processing layers for EEG are heterogeneous with different approaches used for processing space and time. Nonetheless, we treat the processing stages as a neural network and apply backpropagation to jointly optimize the parameters. This approach outperforms previous results on the BCI Competition II - dataset IV; additionally, it outperforms the common spatial patterns (CSP) algorithm on the BCI Competition III dataset IV. In addition, the optimized parameters in the architecture are still interpretable.\n\n\nAlgorithms\nIndian Academy of Sciences (India)\n\n\nwill become clear in the next article when we discuss a simple logo like programming language. ... Rod B may be used as an auxiliary store. The problem is to find an algorithm which performs this task. ... No disks are moved from A to Busing C as auxiliary rod. \u00e2\u20ac\u00a2 move _disk (A, C);. (No + l)th disk is moved from A to C directly\u00c2\u00a0...\n\n\nBioinformatics algorithm based on a parallel implementation of a machine learning approach using transducers\nInternational Nuclear Information System (INIS) \nRoche-Lima, Abiel; Thulasiram, Ruppa K\n2012-01-01\nFinite automata, in which each transition is augmented with an output label in addition to the familiar input label, are considered finite-state transducers. Transducers have been used to analyze some fundamental issues in bioinformatics. Weighted finite-state transducers have been proposed to pairwise alignments of DNA and protein sequences; as well as to develop kernels for computational biology. Machine learning algorithms for conditional transducers have been implemented and used for DNA sequence analysis. Transducer learning algorithms are based on conditional probability computation. It is calculated by using techniques, such as pair-database creation, normalization (with Maximum-Likelihood normalization) and parameters optimization (with Expectation-Maximization - EM). These techniques are intrinsically costly for computation, even worse when are applied to bioinformatics, because the databases sizes are large. In this work, we describe a parallel implementation of an algorithm to learn conditional transducers using these techniques. The algorithm is oriented to bioinformatics applications, such as alignments, phylogenetic trees, and other genome evolution studies. Indeed, several experiences were developed using the parallel and sequential algorithm on Westgrid (specifically, on the Breeze cluster). As results, we obtain that our parallel algorithm is scalable, because execution times are reduced considerably when the data size parameter is increased. Another experience is developed by changing precision parameter. In this case, we obtain smaller execution times using the parallel algorithm. Finally, number of threads used to execute the parallel algorithm on the Breezy cluster is changed. In this last experience, we obtain as result that speedup is considerably increased when more threads are used; however there is a convergence for number of threads equal to or greater than 16.\n\n\nMachine learning algorithms to classify spinal muscular atrophy subtypes.\nScience.gov (United States)\nSrivastava, Tuhin; Darras, Basil T; Wu, Jim S; Rutkove, Seward B\n2012-07-24\nThe development of better biomarkers for disease assessment remains an ongoing effort across the spectrum of neurologic illnesses. One approach for refining biomarkers is based on the concept of machine learning, in which individual, unrelated biomarkers are simultaneously evaluated. In this cross-sectional study, we assess the possibility of using machine learning, incorporating both quantitative muscle ultrasound (QMU) and electrical impedance myography (EIM) data, for classification of muscles affected by spinal muscular atrophy (SMA). Twenty-one normal subjects, 15 subjects with SMA type 2, and 10 subjects with SMA type 3 underwent EIM and QMU measurements of unilateral biceps, wrist extensors, quadriceps, and tibialis anterior. EIM and QMU parameters were then applied in combination using a support vector machine (SVM), a type of machine learning, in an attempt to accurately categorize 165 individual muscles. For all 3 classification problems, normal vs SMA, normal vs SMA 3, and SMA 2 vs SMA 3, use of SVM provided the greatest accuracy in discrimination, surpassing both EIM and QMU individually. For example, the accuracy, as measured by the receiver operating characteristic area under the curve (ROC-AUC) for the SVM discriminating SMA 2 muscles from SMA 3 muscles was 0.928; in comparison, the ROC-AUCs for EIM and QMU parameters alone were only 0.877 (p < 0.05) and 0.627 (p < 0.05), respectively. Combining EIM and QMU data categorizes individual SMA-affected muscles with very high accuracy. Further investigation of this approach for classifying and for following the progression of neuromuscular illness is warranted.\n\n\nLMS learning algorithms: misconceptions and new results on converence.\nScience.gov (United States)\nWang, Z Q; Manry, M T; Schiano, J L\n2000-01-01\nThe Widrow-Hoff delta rule is one of the most popular rules used in training neural networks. It was originally proposed for the ADALINE, but has been successfully applied to a few nonlinear neural networks as well. Despite its popularity, there exist a few misconceptions on its convergence properties. In this paper we consider repetitive learning (i.e., a fixed set of samples are used for training) and provide an in-depth analysis in the least mean square (LMS) framework. Our main result is that contrary to common belief, the nonbatch Widrow-Hoff rule does not converge in general. It converges only to a limit cycle.\n\n\nAlgorithms for Learning Preferences for Sets of Objects\nScience.gov (United States)\nWagstaff, Kiri L.; desJardins, Marie; Eaton, Eric\n2010-01-01\nA method is being developed that provides for an artificial-intelligence system to learn a user's preferences for sets of objects and to thereafter automatically select subsets of objects according to those preferences. The method was originally intended to enable automated selection, from among large sets of images acquired by instruments aboard spacecraft, of image subsets considered to be scientifically valuable enough to justify use of limited communication resources for transmission to Earth. The method is also applicable to other sets of objects: examples of sets of objects considered in the development of the method include food menus, radio-station music playlists, and assortments of colored blocks for creating mosaics. The method does not require the user to perform the often-difficult task of quantitatively specifying preferences; instead, the user provides examples of preferred sets of objects. This method goes beyond related prior artificial-intelligence methods for learning which individual items are preferred by the user: this method supports a concept of setbased preferences, which include not only preferences for individual items but also preferences regarding types and degrees of diversity of items in a set. Consideration of diversity in this method involves recognition that members of a set may interact with each other in the sense that when considered together, they may be regarded as being complementary, redundant, or incompatible to various degrees. The effects of such interactions are loosely summarized in the term portfolio effect. The learning method relies on a preference representation language, denoted DD-PREF, to express set-based preferences. In DD-PREF, a preference is represented by a tuple that includes quality (depth) functions to estimate how desired a specific value is, weights for each feature preference, the desired diversity of feature values, and the relative importance of diversity versus depth. The system applies statistical\n\n\nLearning-based traffic signal control algorithms with neighborhood information sharing: An application for sustainable mobility\nEnergy Technology Data Exchange (ETDEWEB)\nAziz, H. M. Abdul [Oak Ridge National Lab. (ORNL), Oak Ridge, TN (United States); Zhu, Feng [Purdue University, West Lafayette, IN (United States). Lyles School of Civil Engineering; Ukkusuri, Satish V. [Purdue University, West Lafayette, IN (United States). Lyles School of Civil Engineering\n2017-10-04\nHere, this research applies R-Markov Average Reward Technique based reinforcement learning (RL) algorithm, namely RMART, for vehicular signal control problem leveraging information sharing among signal controllers in connected vehicle environment. We implemented the algorithm in a network of 18 signalized intersections and compare the performance of RMART with fixed, adaptive, and variants of the RL schemes. Results show significant improvement in system performance for RMART algorithm with information sharing over both traditional fixed signal timing plans and real time adaptive control schemes. Additionally, the comparison with reinforcement learning algorithms including Q learning and SARSA indicate that RMART performs better at higher congestion levels. Further, a multi-reward structure is proposed that dynamically adjusts the reward function with varying congestion states at the intersection. Finally, the results from test networks show significant reduction in emissions (CO, CO2, NOx, VOC, PM10) when RL algorithms are implemented compared to fixed signal timings and adaptive schemes.\n\n\nA learning algorithm for oscillatory cellular neural networks.\nScience.gov (United States)\nHo, C Y.; Kurokawa, H\n1999-07-01\nWe present a cellular type oscillatory neural network for temporal segregation of stationary input patterns. The model comprises an array of locally connected neural oscillators with connections limited to a 4-connected neighborhood. The architecture is reminiscent of the well-known cellular neural network that consists of local connection for feature extraction. By means of a novel learning rule and an initialization scheme, global synchronization can be accomplished without incurring any erroneous synchrony among uncorrelated objects. Each oscillator comprises two mutually coupled neurons, and neurons share a piecewise-linear activation function characteristic. The dynamics of traditional oscillatory models is simplified by using only one plastic synapse, and the overall complexity for hardware implementation is reduced. Based on the connectedness of image segments, it is shown that global synchronization and desynchronization can be achieved by means of locally connected synapses, and this opens up a tremendous application potential for the proposed architecture. Furthermore, by using special grouping synapses it is demonstrated that temporal segregation of overlapping gray-level and color segments can also be achieved. Finally, simulation results show that the learning rule proposed circumvents the problem of component mismatches, and hence facilitates a large-scale integration.\n\n\nApplication of Machine Learning Algorithms for the Query Performance Prediction\nDirectory of Open Access Journals (Sweden)\nMILICEVIC, M.\n2015-08-01\nFull Text Available This paper analyzes the relationship between the system load/throughput and the query response time in a real Online transaction processing (OLTP system environment. Although OLTP systems are characterized by short transactions, which normally entail high availability and consistent short response times, the need for operational reporting may jeopardize these objectives. We suggest a new approach to performance prediction for concurrent database workloads, based on the system state vector which consists of 36 attributes. There is no bias to the importance of certain attributes, but the machine learning methods are used to determine which attributes better describe the behavior of the particular database server and how to model that system. During the learning phase, the system's profile is created using multiple reference queries, which are selected to represent frequent business processes. The possibility of the accurate response time prediction may be a foundation for automated decision-making for database (DB query scheduling. Possible applications of the proposed method include adaptive resource allocation, quality of service (QoS management or real-time dynamic query scheduling (e.g. estimation of the optimal moment for a complex query execution.\n\n\nThink big: learning contexts, algorithms and data science\nDirectory of Open Access Journals (Sweden)\nBaldassarre Michele\n2016-12-01\nFull Text Available Due to the increasing growth in available data in recent years, all areas of research and the managements of institutions and organisations, specifically schools and universities, feel the need to give meaning to this availability of data. This article, after a brief reference to the definition of big data, intends to focus attention and reflection on their type to proceed to an extension of their characterisation. One of the hubs to make feasible the use of Big Data in operational contexts is to give a theoretical basis to which to refer. The Data, Information, Knowledge and Wisdom (DIKW model correlates these four aspects, concluding in Data Science, which in many ways could revolutionise the established pattern of scientific investigation. The Learning Analytics applications on online learning platforms can be tools for evaluating the quality of teaching. And that is where some problems arise. It becomes necessary to handle with care the available data. Finally, a criterion for deciding whether it makes sense to think of an analysis based on Big Data can be to think about the interpretability and relevance in relation to both institutional and personal processes.\n\n\nClassification and Diagnostic Output Prediction of Cancer Using Gene Expression Profiling and Supervised Machine Learning Algorithms\nDEFF Research Database (Denmark)\nYoo, C.; Gernaey, Krist\n2008-01-01\nimportance in the projection (VIP) information of the DPLS method. The power of the gene selection method and the proposed supervised hierarchical clustering method is illustrated on a three microarray data sets of leukemia, breast, and colon cancer. Supervised machine learning algorithms thus enable...\n\n\nEvaluation of a Didactic Method for the Active Learning of Greedy Algorithms\nScience.gov (United States)\nEsteban-S\u00c3\u00a1nchez, Natalia; Pizarro, Celeste; Vel\u00c3\u00a1zquez-Iturbide, J. \u00c3\ufffdngel\n2014-01-01\nAn evaluation of the educational effectiveness of a didactic method for the active learning of greedy algorithms is presented. The didactic method sets students structured-inquiry challenges to be addressed with a specific experimental method, supported by the interactive system GreedEx. This didactic method has been refined over several years of\u00e2\u20ac\u00a6\n\n\nUsing machine learning algorithms to guide rehabilitation planning for home care clients.\nScience.gov (United States)\nZhu, Mu; Zhang, Zhanyang; Hirdes, John P; Stolee, Paul\n2007-12-20\nTargeting older clients for rehabilitation is a clinical challenge and a research priority. We investigate the potential of machine learning algorithms - Support Vector Machine (SVM) and K-Nearest Neighbors (KNN) - to guide rehabilitation planning for home care clients. This study is a secondary analysis of data on 24,724 longer-term clients from eight home care programs in Ontario. Data were collected with the RAI-HC assessment system, in which the Activities of Daily Living Clinical Assessment Protocol (ADLCAP) is used to identify clients with rehabilitation potential. For study purposes, a client is defined as having rehabilitation potential if there was: i) improvement in ADL functioning, or ii) discharge home. SVM and KNN results are compared with those obtained using the ADLCAP. For comparison, the machine learning algorithms use the same functional and health status indicators as the ADLCAP. The KNN and SVM algorithms achieved similar substantially improved performance over the ADLCAP, although false positive and false negative rates were still fairly high (FP > .18, FN > .34 versus FP > .29, FN. > .58 for ADLCAP). Results are used to suggest potential revisions to the ADLCAP. Machine learning algorithms achieved superior predictions than the current protocol. Machine learning results are less readily interpretable, but can also be used to guide development of improved clinical protocols.\n\n\nA semi-learning algorithm for noise rejection: an fNIRS study on ADHD children\nScience.gov (United States)\nSutoko, Stephanie; Funane, Tsukasa; Katura, Takusige; Sato, Hiroki; Kiguchi, Masashi; Maki, Atsushi; Monden, Yukifumi; Nagashima, Masako; Yamagata, Takanori; Dan, Ippeita\n2017-02-01\nIn pediatrics studies, the quality of functional near infrared spectroscopy (fNIRS) signals is often reduced by motion artifacts. These artifacts likely mislead brain functionality analysis, causing false discoveries. While noise correction methods and their performance have been investigated, these methods require several parameter assumptions that apparently result in noise overfitting. In contrast, the rejection of noisy signals serves as a preferable method because it maintains the originality of the signal waveform. Here, we describe a semi-learning algorithm to detect and eliminate noisy signals. The algorithm dynamically adjusts noise detection according to the predetermined noise criteria, which are spikes, unusual activation values (averaged amplitude signals within the brain activation period), and high activation variances (among trials). Criteria were sequentially organized in the algorithm and orderly assessed signals based on each criterion. By initially setting an acceptable rejection rate, particular criteria causing excessive data rejections are neglected, whereas others with tolerable rejections practically eliminate noises. fNIRS data measured during the attention response paradigm (oddball task) in children with attention deficit/hyperactivity disorder (ADHD) were utilized to evaluate and optimize the algorithm's performance. This algorithm successfully substituted the visual noise identification done in the previous studies and consistently found significantly lower activation of the right prefrontal and parietal cortices in ADHD patients than in typical developing children. Thus, we conclude that the semi-learning algorithm confers more objective and standardized judgment for noise rejection and presents a promising alternative to visual noise rejection\n\n\nASSESSMENT OF PERFORMANCES OF VARIOUS MACHINE LEARNING ALGORITHMS DURING AUTOMATED EVALUATION OF DESCRIPTIVE ANSWERS\nDirectory of Open Access Journals (Sweden)\nC. Sunil Kumar\n2014-07-01\nFull Text Available Automation of descriptive answers evaluation is the need of the hour because of the huge increase in the number of students enrolling each year in educational institutions and the limited staff available to spare their time for evaluations. In this paper, we use a machine learning workbench called LightSIDE to accomplish auto evaluation and scoring of descriptive answers. We attempted to identify the best supervised machine learning algorithm given a limited training set sample size scenario. We evaluated performances of Bayes, SVM, Logistic Regression, Random forests, Decision stump and Decision trees algorithms. We confirmed SVM as best performing algorithm based on quantitative measurements across accuracy, kappa, training speed and prediction accuracy with supplied test set.\n\n\n\n\n\u00ab\n14\n15\n16\n17\n18\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n15\n16\n17\n18\n19\n\u00bb\n\n\n\n\n\n\n\n\nReview of Recommender Systems Algorithms Utilized in Social Networks based e-Learning Systems & Neutrosophic System\nDirectory of Open Access Journals (Sweden)\nA. A. Salama\n2015-03-01\nFull Text Available In this paper, we present a review of different recommender system algorithms that are utilized in social networks based e-Learning systems. Future research will include our proposed our e-Learning system that utilizes Recommender System and Social Network. Since the world is full of indeterminacy, the neutrosophics found their place into contemporary research. The fundamental concepts of neutrosophic set, introduced by Smarandache in [21, 22, 23] and Salama et al. in [24-66].The purpose of this paper is to utilize a neutrosophic set to analyze social networks data conducted through learning activities.\n\n\nEfficient Online Learning Algorithms Based on LSTM Neural Networks.\nScience.gov (United States)\nErgen, Tolga; Kozat, Suleyman Serdar\n2017-09-13\nWe investigate online nonlinear regression and introduce novel regression structures based on the long short term memory (LSTM) networks. For the introduced structures, we also provide highly efficient and effective online training methods. To train these novel LSTM-based structures, we put the underlying architecture in a state space form and introduce highly efficient and effective particle filtering (PF)-based updates. We also provide stochastic gradient descent and extended Kalman filter-based updates. Our PF-based training method guarantees convergence to the optimal parameter estimation in the mean square error sense provided that we have a sufficient number of particles and satisfy certain technical conditions. More importantly, we achieve this performance with a computational complexity in the order of the first-order gradient-based methods by controlling the number of particles. Since our approach is generic, we also introduce a gated recurrent unit (GRU)-based approach by directly replacing the LSTM architecture with the GRU architecture, where we demonstrate the superiority of our LSTM-based approach in the sequential prediction task via different real life data sets. In addition, the experimental results illustrate significant performance improvements achieved by the introduced algorithms with respect to the conventional methods over several different benchmark real life data sets.\n\n\nA stochastic learning algorithm for layered neural networks\nInternational Nuclear Information System (INIS) \nBartlett, E.B.; Uhrig, R.E.\n1992-01-01\nThe random optimization method typically uses a Gaussian probability density function (PDF) to generate a random search vector. In this paper the random search technique is applied to the neural network training problem and is modified to dynamically seek out the optimal probability density function (OPDF) from which to select the search vector. The dynamic OPDF search process, combined with an auto-adaptive stratified sampling technique and a dynamic node architecture (DNA) learning scheme, completes the modifications of the basic method. The DNA technique determines the appropriate number of hidden nodes needed for a given training problem. By using DNA, researchers do not have to set the neural network architectures before training is initiated. The approach is applied to networks of generalized, fully interconnected, continuous perceptions. Computer simulation results are given\n\n\nComputational Modeling of Teaching and Learning through Application of Evolutionary Algorithms\nDirectory of Open Access Journals (Sweden)\nRichard Lamb\n2015-09-01\nFull Text Available Within the mind, there are a myriad of ideas that make sense within the bounds of everyday experience, but are not reflective of how the world actually exists; this is particularly true in the domain of science. Classroom learning with teacher explanation are a bridge through which these naive understandings can be brought in line with scientific reality. The purpose of this paper is to examine how the application of a Multiobjective Evolutionary Algorithm (MOEA can work in concert with an existing computational-model to effectively model critical-thinking in the science classroom. An evolutionary algorithm is an algorithm that iteratively optimizes machine learning based computational models. The research question is, does the application of an evolutionary algorithm provide a means to optimize the Student Task and Cognition Model (STAC-M and does the optimized model sufficiently represent and predict teaching and learning outcomes in the science classroom? Within this computational study, the authors outline and simulate the effect of teaching on the ability of a \u00e2\u20ac\u0153virtual\u00e2\u20ac\ufffd student to solve a Piagetian task. Using the Student Task and Cognition Model (STAC-M a computational model of student cognitive processing in science class developed in 2013, the authors complete a computational experiment which examines the role of cognitive retraining on student learning. Comparison of the STAC-M and the STAC-M with inclusion of the Multiobjective Evolutionary Algorithm shows greater success in solving the Piagetian science-tasks post cognitive retraining with the Multiobjective Evolutionary Algorithm. This illustrates the potential uses of cognitive and neuropsychological computational modeling in educational research. The authors also outline the limitations and assumptions of computational modeling.\n\n\nClustering and Candidate Motif Detection in Exosomal miRNAs by Application of Machine Learning Algorithms.\nScience.gov (United States)\nGaur, Pallavi; Chaturvedi, Anoop\n2017-07-22\nThe clustering pattern and motifs give immense information about any biological data. An application of machine learning algorithms for clustering and candidate motif detection in miRNAs derived from exosomes is depicted in this paper. Recent progress in the field of exosome research and more particularly regarding exosomal miRNAs has led much bioinformatic-based research to come into existence. The information on clustering pattern and candidate motifs in miRNAs of exosomal origin would help in analyzing existing, as well as newly discovered miRNAs within exosomes. Along with obtaining clustering pattern and candidate motifs in exosomal miRNAs, this work also elaborates the usefulness of the machine learning algorithms that can be efficiently used and executed on various programming languages/platforms. Data were clustered and sequence candidate motifs were detected successfully. The results were compared and validated with some available web tools such as 'BLASTN' and 'MEME suite'. The machine learning algorithms for aforementioned objectives were applied successfully. This work elaborated utility of machine learning algorithms and language platforms to achieve the tasks of clustering and candidate motif detection in exosomal miRNAs. With the information on mentioned objectives, deeper insight would be gained for analyses of newly discovered miRNAs in exosomes which are considered to be circulating biomarkers. In addition, the execution of machine learning algorithms on various language platforms gives more flexibility to users to try multiple iterations according to their requirements. This approach can be applied to other biological data-mining tasks as well.\n\n\nEfficient Actor-Critic Algorithm with Hierarchical Model Learning and Planning\nScience.gov (United States)\nFu, QiMing\n2016-01-01\nTo improve the convergence rate and the sample efficiency, two efficient learning methods AC-HMLP and RAC-HMLP (AC-HMLP with \u00e2\u201e\u201c 2-regularization) are proposed by combining actor-critic algorithm with hierarchical model learning and planning. The hierarchical models consisting of the local and the global models, which are learned at the same time during learning of the value function and the policy, are approximated by local linear regression (LLR) and linear function approximation (LFA), respectively. Both the local model and the global model are applied to generate samples for planning; the former is used only if the state-prediction error does not surpass the threshold at each time step, while the latter is utilized at the end of each episode. The purpose of taking both models is to improve the sample efficiency and accelerate the convergence rate of the whole algorithm through fully utilizing the local and global information. Experimentally, AC-HMLP and RAC-HMLP are compared with three representative algorithms on two Reinforcement Learning (RL) benchmark problems. The results demonstrate that they perform best in terms of convergence rate and sample efficiency. PMID:27795704\n\n\nNight-Time Vehicle Detection Algorithm Based on Visual Saliency and Deep Learning\nDirectory of Open Access Journals (Sweden)\nYingfeng Cai\n2016-01-01\nFull Text Available Night vision systems get more and more attention in the field of automotive active safety field. In this area, a number of researchers have proposed far-infrared sensor based night-time vehicle detection algorithm. However, existing algorithms have low performance in some indicators such as the detection rate and processing time. To solve this problem, we propose a far-infrared image vehicle detection algorithm based on visual saliency and deep learning. Firstly, most of the nonvehicle pixels will be removed with visual saliency computation. Then, vehicle candidate will be generated by using prior information such as camera parameters and vehicle size. Finally, classifier trained with deep belief networks will be applied to verify the candidates generated in last step. The proposed algorithm is tested in around 6000 images and achieves detection rate of 92.3% and processing time of 25\u00e2\u20ac\u2030Hz which is better than existing methods.\n\n\nAn Online Dictionary Learning-Based Compressive Data Gathering Algorithm in Wireless Sensor Networks.\nScience.gov (United States)\nWang, Donghao; Wan, Jiangwen; Chen, Junying; Zhang, Qiang\n2016-09-22\nTo adapt to sense signals of enormous diversities and dynamics, and to decrease the reconstruction errors caused by ambient noise, a novel online dictionary learning method-based compressive data gathering (ODL-CDG) algorithm is proposed. The proposed dictionary is learned from a two-stage iterative procedure, alternately changing between a sparse coding step and a dictionary update step. The self-coherence of the learned dictionary is introduced as a penalty term during the dictionary update procedure. The dictionary is also constrained with sparse structure. It's theoretically demonstrated that the sensing matrix satisfies the restricted isometry property (RIP) with high probability. In addition, the lower bound of necessary number of measurements for compressive sensing (CS) reconstruction is given. Simulation results show that the proposed ODL-CDG algorithm can enhance the recovery accuracy in the presence of noise, and reduce the energy consumption in comparison with other dictionary based data gathering methods.\n\n\nAn Online Dictionary Learning-Based Compressive Data Gathering Algorithm in Wireless Sensor Networks\nDirectory of Open Access Journals (Sweden)\nDonghao Wang\n2016-09-01\nFull Text Available To adapt to sense signals of enormous diversities and dynamics, and to decrease the reconstruction errors caused by ambient noise, a novel online dictionary learning method-based compressive data gathering (ODL-CDG algorithm is proposed. The proposed dictionary is learned from a two-stage iterative procedure, alternately changing between a sparse coding step and a dictionary update step. The self-coherence of the learned dictionary is introduced as a penalty term during the dictionary update procedure. The dictionary is also constrained with sparse structure. It\u00e2\u20ac\u2122s theoretically demonstrated that the sensing matrix satisfies the restricted isometry property (RIP with high probability. In addition, the lower bound of necessary number of measurements for compressive sensing (CS reconstruction is given. Simulation results show that the proposed ODL-CDG algorithm can enhance the recovery accuracy in the presence of noise, and reduce the energy consumption in comparison with other dictionary based data gathering methods.\n\n\nAlgorithm Building and Learning Programming Languages Using a New Educational Paradigm\nScience.gov (United States)\nJain, Anshul K.; Singhal, Manik; Gupta, Manu Sheel\n2011-08-01\nThis research paper presents a new concept of using a single tool to associate syntax of various programming languages, algorithms and basic coding techniques. A simple framework has been programmed in Python that helps students learn skills to develop algorithms, and implement them in various programming languages. The tool provides an innovative and a unified graphical user interface for development of multimedia objects, educational games and applications. It also aids collaborative learning amongst students and teachers through an integrated mechanism based on Remote Procedure Calls. The paper also elucidates an innovative method for code generation to enable students to learn the basics of programming languages using drag-n-drop methods for image objects.\n\n\nUsing Genetic Algorithms in Secured Business Intelligence Mobile Applications\nDirectory of Open Access Journals (Sweden)\nSilvia TRIF\n2011-01-01\nFull Text Available The paper aims to assess the use of genetic algorithms for training neural networks used in secured Business Intelligence Mobile Applications. A comparison is made between classic back-propagation method and a genetic algorithm based training. The design of these algorithms is presented. A comparative study is realized for determining the better way of training neural networks, from the point of view of time and memory usage. The results show that genetic algorithms based training offer better performance and memory usage than back-propagation and they are fit to be implemented on mobile devices.\n\n\nA robust cloud registration method based on redundant data reduction using backpropagation neural network and shift window\nScience.gov (United States)\nXin, Meiting; Li, Bing; Yan, Xiao; Chen, Lei; Wei, Xiang\n2018-02-01\nA robust coarse-to-fine registration method based on the backpropagation (BP) neural network and shift window technology is proposed in this study. Specifically, there are three steps: coarse alignment between the model data and measured data, data simplification based on the BP neural network and point reservation in the contour region of point clouds, and fine registration with the reweighted iterative closest point algorithm. In the process of rough alignment, the initial rotation matrix and the translation vector between the two datasets are obtained. After performing subsequent simplification operations, the number of points can be reduced greatly. Therefore, the time and space complexity of the accurate registration can be significantly reduced. The experimental results show that the proposed method improves the computational efficiency without loss of accuracy.\n\n\nLecturers' and Students\u00e2\u20ac\u2122 Perception on Learning Dijkstra\u00e2\u20ac\u2122s Shortest Path Algorithm Through Mobile Devices\nDirectory of Open Access Journals (Sweden)\nMazyar Seraj\n2014-06-01\nFull Text Available In recent years, many studies have been carried out on how to engage and support students in e-learning environments. Portable devices such as Personal Digital Assistants (PDAs, Tablet PCs, mobile phones and other mobile equipment have been used as parts of electronic learning environments to facilitate learning and teaching for both lecturers and students. However, there is still a dearth of study investigating the effects of small screen interfaces on mobile-based learning environments. This study aims to address two objectives: (i investigate lecturer and student difficulties encountered in teaching-learning process in traditional face-to-face classroom settings, and (ii to explore lecturer and student perceptions about learning the subject through mobile devices. This paper presents the results of a qualitative study using structured interviews to investigate lecturer and student experiences and perceptions on teaching and learning Dijkstra\u00e2\u20ac\u2122s shortest path algorithm via mobile devices. The interview insights were then used as inputs to define user requirements for a mobile learning prototype. The findings show that the lecturers and students raised many issues about interactivity and the flexibility of effective learning applications on small screen devices, especially for a technical subject.\n\n\nLearning Algorithm of Boltzmann Machine Based on Spatial Monte Carlo Integration Method\nDirectory of Open Access Journals (Sweden)\nMuneki Yasuda\n2018-04-01\nFull Text Available The machine learning techniques for Markov random fields are fundamental in various fields involving pattern recognition, image processing, sparse modeling, and earth science, and a Boltzmann machine is one of the most important models in Markov random fields. However, the inference and learning problems in the Boltzmann machine are NP-hard. The investigation of an effective learning algorithm for the Boltzmann machine is one of the most important challenges in the field of statistical machine learning. In this paper, we study Boltzmann machine learning based on the (first-order spatial Monte Carlo integration method, referred to as the 1-SMCI learning method, which was proposed in the author\u00e2\u20ac\u2122s previous paper. In the first part of this paper, we compare the method with the maximum pseudo-likelihood estimation (MPLE method using a theoretical and a numerical approaches, and show the 1-SMCI learning method is more effective than the MPLE. In the latter part, we compare the 1-SMCI learning method with other effective methods, ratio matching and minimum probability flow, using a numerical experiment, and show the 1-SMCI learning method outperforms them.\n\n\nDevelopment of cyberblog-based intelligent tutorial system to improve students learning ability algorithm\nScience.gov (United States)\nWahyudin; Riza, L. S.; Putro, B. L.\n2018-05-01\nE-learning as a learning activity conducted online by the students with the usual tools is favoured by students. The use of computer media in learning provides benefits that are not owned by other learning media that is the ability of computers to interact individually with students. But the weakness of many learning media is to assume that all students have a uniform ability, when in reality this is not the case. The concept of Intelligent Tutorial System (ITS) combined with cyberblog application can overcome the weaknesses in neglecting diversity. An Intelligent Tutorial System-based Cyberblog application (ITS) is a web-based interactive application program that implements artificial intelligence which can be used as a learning and evaluation media in the learning process. The use of ITS-based Cyberblog in learning is one of the alternative learning media that is interesting and able to help students in measuring ability in understanding the material. This research will be associated with the improvement of logical thinking ability (logical thinking) of students, especially in algorithm subjects.\n\n\nThe algorithm for duration acceleration of repetitive projects considering the learning effect\nScience.gov (United States)\nChen, Hongtao; Wang, Keke; Du, Yang; Wang, Liwan\n2018-03-01\nRepetitive project optimization problem is common in project scheduling. Repetitive Scheduling Method (RSM) has many irreplaceable advantages in the field of repetitive projects. As the same or similar work is repeated, the proficiency of workers will be correspondingly low to high, and workers will gain experience and improve the efficiency of operations. This is learning effect. Learning effect is one of the important factors affecting the optimization results in repetitive project scheduling. This paper analyzes the influence of the learning effect on the controlling path in RSM from two aspects: one is that the learning effect changes the controlling path, the other is that the learning effect doesn't change the controlling path. This paper proposes corresponding methods to accelerate duration for different types of critical activities and proposes the algorithm for duration acceleration based on the learning effect in RSM. And the paper chooses graphical method to identity activities' types and considers the impacts of the learning effect on duration. The method meets the requirement of duration while ensuring the lowest acceleration cost. A concrete bridge construction project is given to verify the effectiveness of the method. The results of this study will help project managers understand the impacts of the learning effect on repetitive projects, and use the learning effect to optimize project scheduling.\n\n\nCan We Train Machine Learning Methods to Outperform the High-dimensional Propensity Score Algorithm?\nScience.gov (United States)\nKarim, Mohammad Ehsanul; Pang, Menglan; Platt, Robert W\n2018-03-01\nThe use of retrospective health care claims datasets is frequently criticized for the lack of complete information on potential confounders. Utilizing patient's health status-related information from claims datasets as surrogates or proxies for mismeasured and unobserved confounders, the high-dimensional propensity score algorithm enables us to reduce bias. Using a previously published cohort study of postmyocardial infarction statin use (1998-2012), we compare the performance of the algorithm with a number of popular machine learning approaches for confounder selection in high-dimensional covariate spaces: random forest, least absolute shrinkage and selection operator, and elastic net. Our results suggest that, when the data analysis is done with epidemiologic principles in mind, machine learning methods perform as well as the high-dimensional propensity score algorithm. Using a plasmode framework that mimicked the empirical data, we also showed that a hybrid of machine learning and high-dimensional propensity score algorithms generally perform slightly better than both in terms of mean squared error, when a bias-based analysis is used.\n\n\nAn Orthogonal Learning Differential Evolution Algorithm for Remote Sensing Image Registration\nDirectory of Open Access Journals (Sweden)\nWenping Ma\n2014-01-01\nFull Text Available We introduce an area-based method for remote sensing image registration. We use orthogonal learning differential evolution algorithm to optimize the similarity metric between the reference image and the target image. Many local and global methods have been used to achieve the optimal similarity metric in the last few years. Because remote sensing images are usually influenced by large distortions and high noise, local methods will fail in some cases. For this reason, global methods are often required. The orthogonal learning (OL strategy is efficient when searching in complex problem spaces. In addition, it can discover more useful information via orthogonal experimental design (OED. Differential evolution (DE is a heuristic algorithm. It has shown to be efficient in solving the remote sensing image registration problem. So orthogonal learning differential evolution algorithm (OLDE is efficient for many optimization problems. The OLDE method uses the OL strategy to guide the DE algorithm to discover more useful information. Experiments show that the OLDE method is more robust and efficient for registering remote sensing images.\n\n\nAn efficient dictionary learning algorithm and its application to 3-D medical image denoising.\nScience.gov (United States)\nLi, Shutao; Fang, Leyuan; Yin, Haitao\n2012-02-01\nIn this paper, we propose an efficient dictionary learning algorithm for sparse representation of given data and suggest a way to apply this algorithm to 3-D medical image denoising. Our learning approach is composed of two main parts: sparse coding and dictionary updating. On the sparse coding stage, an efficient algorithm named multiple clusters pursuit (MCP) is proposed. The MCP first applies a dictionary structuring strategy to cluster the atoms with high coherence together, and then employs a multiple-selection strategy to select several competitive atoms at each iteration. These two strategies can greatly reduce the computation complexity of the MCP and assist it to obtain better sparse solution. On the dictionary updating stage, the alternating optimization that efficiently approximates the singular value decomposition is introduced. Furthermore, in the 3-D medical image denoising application, a joint 3-D operation is proposed for taking the learning capabilities of the presented algorithm to simultaneously capture the correlations within each slice and correlations across the nearby slices, thereby obtaining better denoising results. The experiments on both synthetically generated data and real 3-D medical images demonstrate that the proposed approach has superior performance compared to some well-known methods. \u00c2\u00a9 2011 IEEE\n\n\nA New Fuzzy Cognitive Map Learning Algorithm for Speech Emotion Recognition\nDirectory of Open Access Journals (Sweden)\nWei Zhang\n2017-01-01\nFull Text Available Selecting an appropriate recognition method is crucial in speech emotion recognition applications. However, the current methods do not consider the relationship between emotions. Thus, in this study, a speech emotion recognition system based on the fuzzy cognitive map (FCM approach is constructed. Moreover, a new FCM learning algorithm for speech emotion recognition is proposed. This algorithm includes the use of the pleasure-arousal-dominance emotion scale to calculate the weights between emotions and certain mathematical derivations to determine the network structure. The proposed algorithm can handle a large number of concepts, whereas a typical FCM can handle only relatively simple networks (maps. Different acoustic features, including fundamental speech features and a new spectral feature, are extracted to evaluate the performance of the proposed method. Three experiments are conducted in this paper, namely, single feature experiment, feature combination experiment, and comparison between the proposed algorithm and typical networks. All experiments are performed on TYUT2.0 and EMO-DB databases. Results of the feature combination experiments show that the recognition rates of the combination features are 10%\u00e2\u20ac\u201c20% better than those of single features. The proposed FCM learning algorithm generates 5%\u00e2\u20ac\u201c20% performance improvement compared with traditional classification networks.\n\n\n\n\n\u00ab\n15\n16\n17\n18\n19\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n16\n17\n18\n19\n20\n\u00bb\n\n\n\n\n\n\n\n\nMachine-Learning Algorithms to Automate Morphological and Functional Assessments in 2D Echocardiography.\nScience.gov (United States)\nNarula, Sukrit; Shameer, Khader; Salem Omar, Alaa Mabrouk; Dudley, Joel T; Sengupta, Partho P\n2016-11-29\nMachine-learning models may aid cardiac phenotypic recognition by using features of cardiac tissue\u00c2\u00a0deformation. This study investigated the diagnostic value of a machine-learning framework that incorporates speckle-tracking echocardiographic data for automated discrimination of hypertrophic cardiomyopathy (HCM) from physiological hypertrophy seen in athletes (ATH). Expert-annotated speckle-tracking echocardiographic datasets obtained from 77 ATH and 62 HCM patients\u00c2\u00a0were used for developing an automated system. An ensemble machine-learning model with 3 different machine-learning algorithms (support vector machines, random forests, and artificial neural networks) was developed\u00c2\u00a0and a majority voting method was used for conclusive predictions with further K-fold cross-validation. Feature selection using an information gain (IG) algorithm revealed that volume was the best predictor for differentiating between HCM ands. ATH (IG\u00c2\u00a0= 0.24) followed by mid-left ventricular segmental (IG\u00c2\u00a0= 0.134) and average longitudinal strain (IG\u00c2\u00a0= 0.131). The ensemble machine-learning model showed increased sensitivity and specificity compared with early-to-late diastolic transmitral velocity ratio (p\u00c2\u00a013 mm. In this subgroup analysis, the automated\u00c2\u00a0model continued to show equal sensitivity, but increased specificity relative to early-to-late diastolic transmitral velocity ratio, e', and strain. Our results suggested that machine-learning algorithms can assist in the discrimination of\u00c2\u00a0physiological\u00c2\u00a0versus pathological patterns of hypertrophic remodeling. This effort represents a step toward\u00c2\u00a0the\u00c2\u00a0development of a real-time, machine-learning-based system for automated interpretation of echocardiographic images,\u00c2\u00a0which may help novice readers with limited experience. Copyright \u00c2\u00a9 2016 American College of Cardiology Foundation. Published by Elsevier Inc. All rights reserved.\n\n\nA Comparison Study of Machine Learning Based Algorithms for Fatigue Crack Growth Calculation.\nScience.gov (United States)\nWang, Hongxun; Zhang, Weifang; Sun, Fuqiang; Zhang, Wei\n2017-05-18\nThe relationships between the fatigue crack growth rate ( d a / d N ) and stress intensity factor range ( \u00ce\u201d K ) are not always linear even in the Paris region. The stress ratio effects on fatigue crack growth rate are diverse in different materials. However, most existing fatigue crack growth models cannot handle these nonlinearities appropriately. The machine learning method provides a flexible approach to the modeling of fatigue crack growth because of its excellent nonlinear approximation and multivariable learning ability. In this paper, a fatigue crack growth calculation method is proposed based on three different machine learning algorithms (MLAs): extreme learning machine (ELM), radial basis function network (RBFN) and genetic algorithms optimized back propagation network (GABP). The MLA based method is validated using testing data of different materials. The three MLAs are compared with each other as well as the classical two-parameter model ( K * approach). The results show that the predictions of MLAs are superior to those of K * approach in accuracy and effectiveness, and the ELM based algorithms show overall the best agreement with the experimental data out of the three MLAs, for its global optimization and extrapolation ability.\n\n\nSampling algorithms for validation of supervised learning models for Ising-like systems\nScience.gov (United States)\nPortman, Nataliya; Tamblyn, Isaac\n2017-12-01\nIn this paper, we build and explore supervised learning models of ferromagnetic system behavior, using Monte-Carlo sampling of the spin configuration space generated by the 2D Ising model. Given the enormous size of the space of all possible Ising model realizations, the question arises as to how to choose a reasonable number of samples that will form physically meaningful and non-intersecting training and testing datasets. Here, we propose a sampling technique called ;ID-MH; that uses the Metropolis-Hastings algorithm creating Markov process across energy levels within the predefined configuration subspace. We show that application of this method retains phase transitions in both training and testing datasets and serves the purpose of validation of a machine learning algorithm. For larger lattice dimensions, ID-MH is not feasible as it requires knowledge of the complete configuration space. As such, we develop a new ;block-ID; sampling strategy: it decomposes the given structure into square blocks with lattice dimension N \u00e2\u2030\u00a4 5 and uses ID-MH sampling of candidate blocks. Further comparison of the performance of commonly used machine learning methods such as random forests, decision trees, k nearest neighbors and artificial neural networks shows that the PCA-based Decision Tree regressor is the most accurate predictor of magnetizations of the Ising model. For energies, however, the accuracy of prediction is not satisfactory, highlighting the need to consider more algorithmically complex methods (e.g., deep learning).\n\n\nPerformance Evaluation of Machine Learning Algorithms for Urban Pattern Recognition from Multi-spectral Satellite Images\nDirectory of Open Access Journals (Sweden)\nMarc Wieland\n2014-03-01\nFull Text Available In this study, a classification and performance evaluation framework for the recognition of urban patterns in medium (Landsat ETM, TM and MSS and very high resolution (WorldView-2, Quickbird, Ikonos multi-spectral satellite images is presented. The study aims at exploring the potential of machine learning algorithms in the context of an object-based image analysis and to thoroughly test the algorithm\u00e2\u20ac\u2122s performance under varying conditions to optimize their usage for urban pattern recognition tasks. Four classification algorithms, Normal Bayes, K Nearest Neighbors, Random Trees and Support Vector Machines, which represent different concepts in machine learning (probabilistic, nearest neighbor, tree-based, function-based, have been selected and implemented on a free and open-source basis. Particular focus is given to assess the generalization ability of machine learning algorithms and the transferability of trained learning machines between different image types and image scenes. Moreover, the influence of the number and choice of training data, the influence of the size and composition of the feature vector and the effect of image segmentation on the classification accuracy is evaluated.\n\n\nUnsupervised Learning Through Randomized Algorithms for High-Volume High-Velocity Data (ULTRA-HV).\nEnergy Technology Data Exchange (ETDEWEB)\nPinar, Ali [Sandia National Lab. (SNL-NM), Albuquerque, NM (United States); Kolda, Tamara G. [Sandia National Lab. (SNL-NM), Albuquerque, NM (United States); Carlberg, Kevin Thomas [Wake Forest Univ., Winston-Salem, MA (United States); Ballard, Grey [Sandia National Lab. (SNL-NM), Albuquerque, NM (United States); Mahoney, Michael [Univ. of California, Berkeley, CA (United States)\n2018-01-01\nThrough long-term investments in computing, algorithms, facilities, and instrumentation, DOE is an established leader in massive-scale, high-fidelity simulations, as well as science-leading experimentation. In both cases, DOE is generating more data than it can analyze and the problem is intensifying quickly. The need for advanced algorithms that can automatically convert the abundance of data into a wealth of useful information by discovering hidden structures is well recognized. Such efforts however, are hindered by the massive volume of the data and its high velocity. Here, the challenge is developing unsupervised learning methods to discover hidden structure in high-volume, high-velocity data.\n\n\nModified Bat Algorithm Based on L\u00c3\u00a9vy Flight and Opposition Based Learning\nDirectory of Open Access Journals (Sweden)\nXian Shan\n2016-01-01\nFull Text Available Bat Algorithm (BA is a swarm intelligence algorithm which has been intensively applied to solve academic and real life optimization problems. However, due to the lack of good balance between exploration and exploitation, BA sometimes fails at finding global optimum and is easily trapped into local optima. In order to overcome the premature problem and improve the local searching ability of Bat Algorithm for optimization problems, we propose an improved BA called OBMLBA. In the proposed algorithm, a modified search equation with more useful information from the search experiences is introduced to generate a candidate solution, and L\u00c3\u00a9vy Flight random walk is incorporated with BA in order to avoid being trapped into local optima. Furthermore, the concept of opposition based learning (OBL is embedded to BA to enhance the diversity and convergence capability. To evaluate the performance of the proposed approach, 16 benchmark functions have been employed. The results obtained by the experiments demonstrate the effectiveness and efficiency of OBMLBA for global optimization problems. Comparisons with some other BA variants and other state-of-the-art algorithms have shown the proposed approach significantly improves the performance of BA. Performances of the proposed algorithm on large scale optimization problems and real world optimization problems are not discussed in the paper, and it will be studied in the future work.\n\n\nImpedance learning for robotic contact tasks using natural actor-critic algorithm.\nScience.gov (United States)\nKim, Byungchan; Park, Jooyoung; Park, Shinsuk; Kang, Sungchul\n2010-04-01\nCompared with their robotic counterparts, humans excel at various tasks by using their ability to adaptively modulate arm impedance parameters. This ability allows us to successfully perform contact tasks even in uncertain environments. This paper considers a learning strategy of motor skill for robotic contact tasks based on a human motor control theory and machine learning schemes. Our robot learning method employs impedance control based on the equilibrium point control theory and reinforcement learning to determine the impedance parameters for contact tasks. A recursive least-square filter-based episodic natural actor-critic algorithm is used to find the optimal impedance parameters. The effectiveness of the proposed method was tested through dynamic simulations of various contact tasks. The simulation results demonstrated that the proposed method optimizes the performance of the contact tasks in uncertain conditions of the environment.\n\n\nAn e-Learning environment for algorithmic: toward an active construction of skills\nDirectory of Open Access Journals (Sweden)\nAbdelghani Babori\n2016-07-01\nFull Text Available Assimilating an algorithmic course is a persistent problem for many undergraduate students. The major problem faced by students is the lack of problem solving ability and flexibility. Therefore, students are generally passive, unmotivated and unable to mobilize all the acquired knowledge (loops, test, variables, etc. to deal with new encountered problems. Our study is structured around building, step by step, problem solving skills among novice learners. Our approach is based on the use of problem based learning in an e-Learning environment. We begin by establishing a cognitive model which represents knowledge elements, grouped into categories of skills, judged necessary to be appropriated. We then propose a problem built on a concrete situation which aims to actively construct a skill category. We conclude by presenting around the proposed problem a pedagogical scenario for the set of learning activities designed to be incorporated in an E-learning platform.\n\n\nMachine Learning Algorithms for $b$-Jet Tagging at the ATLAS Experiment\nCERN Document Server\nPaganini, Michela; The ATLAS collaboration\n2017-01-01\nThe separation of b-quark initiated jets from those coming from lighter quark flavours (b-tagging) is a fundamental tool for the ATLAS physics program at the CERN Large Hadron Collider. The most powerful b-tagging algorithms combine information from low-level taggers exploiting reconstructed track and vertex information using a multivariate classifier. The potential of modern Machine Learning techniques such as Recurrent Neural Networks and Deep Learning is explored using simulated events, and compared to that achievable from more traditional classifiers such as boosted decision trees.\n\n\nAutomated sleep stage detection with a classical and a neural learning algorithm--methodological aspects.\nScience.gov (United States)\nSchwaibold, M; Sch\u00c3\u00b6chlin, J; Bolz, A\n2002-01-01\nFor classification tasks in biosignal processing, several strategies and algorithms can be used. Knowledge-based systems allow prior knowledge about the decision process to be integrated, both by the developer and by self-learning capabilities. For the classification stages in a sleep stage detection framework, three inference strategies were compared regarding their specific strengths: a classical signal processing approach, artificial neural networks and neuro-fuzzy systems. Methodological aspects were assessed to attain optimum performance and maximum transparency for the user. Due to their effective and robust learning behavior, artificial neural networks could be recommended for pattern recognition, while neuro-fuzzy systems performed best for the processing of contextual information.\n\n\nClassification of large-sized hyperspectral imagery using fast machine learning algorithms\nScience.gov (United States)\nXia, Junshi; Yokoya, Naoto; Iwasaki, Akira\n2017-07-01\nWe present a framework of fast machine learning algorithms in the context of large-sized hyperspectral images classification from the theoretical to a practical viewpoint. In particular, we assess the performance of random forest (RF), rotation forest (RoF), and extreme learning machine (ELM) and the ensembles of RF and ELM. These classifiers are applied to two large-sized hyperspectral images and compared to the support vector machines. To give the quantitative analysis, we pay attention to comparing these methods when working with high input dimensions and a limited/sufficient training set. Moreover, other important issues such as the computational cost and robustness against the noise are also discussed.\n\n\nA Spectral Reconstruction Algorithm of Miniature Spectrometer Based on Sparse Optimization and Dictionary Learning.\nScience.gov (United States)\nZhang, Shang; Dong, Yuhan; Fu, Hongyan; Huang, Shao-Lun; Zhang, Lin\n2018-02-22\nThe miniaturization of spectrometer can broaden the application area of spectrometry, which has huge academic and industrial value. Among various miniaturization approaches, filter-based miniaturization is a promising implementation by utilizing broadband filters with distinct transmission functions. Mathematically, filter-based spectral reconstruction can be modeled as solving a system of linear equations. In this paper, we propose an algorithm of spectral reconstruction based on sparse optimization and dictionary learning. To verify the feasibility of the reconstruction algorithm, we design and implement a simple prototype of a filter-based miniature spectrometer. The experimental results demonstrate that sparse optimization is well applicable to spectral reconstruction whether the spectra are directly sparse or not. As for the non-directly sparse spectra, their sparsity can be enhanced by dictionary learning. In conclusion, the proposed approach has a bright application prospect in fabricating a practical miniature spectrometer.\n\n\nDevelopment of fuzzy algorithm with learning function for nuclear steam generator level control\nInternational Nuclear Information System (INIS) \nPark, Gee Yong; Seong, Poong Hyun\n1993-01-01\nA fuzzy algorithm with learning function is applied to the steam generator level control of nuclear power plant. This algorithm can make its rule base and membership functions suited for steam generator level control by use of the data obtained from the control actions of a skilled operator or of other controllers (i.e., PID controller). The rule base of fuzzy controller with learning function is divided into two parts. One part of the rule base is provided to level control of steam generator at low power level (0 % - 30 % of full power) and the other to level control at high power level (30 % - 100 % of full power). Response time of steam generator level control at low power range with this rule base is shown to be shorter than that of fuzzy controller with direct inference. (Author)\n\n\nA Plane Target Detection Algorithm in Remote Sensing Images based on Deep Learning Network Technology\nScience.gov (United States)\nShuxin, Li; Zhilong, Zhang; Biao, Li\n2018-01-01\nPlane is an important target category in remote sensing targets and it is of great value to detect the plane targets automatically. As remote imaging technology developing continuously, the resolution of the remote sensing image has been very high and we can get more detailed information for detecting the remote sensing targets automatically. Deep learning network technology is the most advanced technology in image target detection and recognition, which provided great performance improvement in the field of target detection and recognition in the everyday scenes. We combined the technology with the application in the remote sensing target detection and proposed an algorithm with end to end deep network, which can learn from the remote sensing images to detect the targets in the new images automatically and robustly. Our experiments shows that the algorithm can capture the feature information of the plane target and has better performance in target detection with the old methods.\n\n\nA Spectral Reconstruction Algorithm of Miniature Spectrometer Based on Sparse Optimization and Dictionary Learning\nScience.gov (United States)\nZhang, Shang; Fu, Hongyan; Huang, Shao-Lun; Zhang, Lin\n2018-01-01\nThe miniaturization of spectrometer can broaden the application area of spectrometry, which has huge academic and industrial value. Among various miniaturization approaches, filter-based miniaturization is a promising implementation by utilizing broadband filters with distinct transmission functions. Mathematically, filter-based spectral reconstruction can be modeled as solving a system of linear equations. In this paper, we propose an algorithm of spectral reconstruction based on sparse optimization and dictionary learning. To verify the feasibility of the reconstruction algorithm, we design and implement a simple prototype of a filter-based miniature spectrometer. The experimental results demonstrate that sparse optimization is well applicable to spectral reconstruction whether the spectra are directly sparse or not. As for the non-directly sparse spectra, their sparsity can be enhanced by dictionary learning. In conclusion, the proposed approach has a bright application prospect in fabricating a practical miniature spectrometer. PMID:29470406\n\n\nComparison of four machine learning algorithms for their applicability in satellite-based optical rainfall retrievals\nScience.gov (United States)\nMeyer, Hanna; K\u00c3\u00bchnlein, Meike; Appelhans, Tim; Nauss, Thomas\n2016-03-01\nMachine learning (ML) algorithms have successfully been demonstrated to be valuable tools in satellite-based rainfall retrievals which show the practicability of using ML algorithms when faced with high dimensional and complex data. Moreover, recent developments in parallel computing with ML present new possibilities for training and prediction speed and therefore make their usage in real-time systems feasible. This study compares four ML algorithms - random forests (RF), neural networks (NNET), averaged neural networks (AVNNET) and support vector machines (SVM) - for rainfall area detection and rainfall rate assignment using MSG SEVIRI data over Germany. Satellite-based proxies for cloud top height, cloud top temperature, cloud phase and cloud water path serve as predictor variables. The results indicate an overestimation of rainfall area delineation regardless of the ML algorithm (averaged bias = 1.8) but a high probability of detection ranging from 81% (SVM) to 85% (NNET). On a 24-hour basis, the performance of the rainfall rate assignment yielded R2 values between 0.39 (SVM) and 0.44 (AVNNET). Though the differences in the algorithms' performance were rather small, NNET and AVNNET were identified as the most suitable algorithms. On average, they demonstrated the best performance in rainfall area delineation as well as in rainfall rate assignment. NNET's computational speed is an additional advantage in work with large datasets such as in remote sensing based rainfall retrievals. However, since no single algorithm performed considerably better than the others we conclude that further research in providing suitable predictors for rainfall is of greater necessity than an optimization through the choice of the ML algorithm.\n\n\nA hybrid bird mating optimizer algorithm with teaching-learning-based optimization for global numerical optimization\nDirectory of Open Access Journals (Sweden)\nQingyang Zhang\n2015-02-01\nFull Text Available Bird Mating Optimizer (BMO is a novel meta-heuristic optimization algorithm inspired by intelligent mating behavior of birds. However, it is still insufficient in convergence of speed and quality of solution. To overcome these drawbacks, this paper proposes a hybrid algorithm (TLBMO, which is established by combining the advantages of Teaching-learning-based optimization (TLBO and Bird Mating Optimizer (BMO. The performance of TLBMO is evaluated on 23 benchmark functions, and compared with seven state-of-the-art approaches, namely BMO, TLBO, Artificial Bee Bolony (ABC, Particle Swarm Optimization (PSO, Fast Evolution Programming (FEP, Differential Evolution (DE, Group Search Optimization (GSO. Experimental results indicate that the proposed method performs better than other existing algorithms for global numerical optimization.\n\n\nRobust total energy demand estimation with a hybrid Variable Neighborhood Search \u00e2\u20ac\u201c Extreme Learning Machine algorithm\nInternational Nuclear Information System (INIS) \nS\u00c3\u00a1nchez-Oro, J.; Duarte, A.; Salcedo-Sanz, S.\n2016-01-01\nHighlights: \u00e2\u20ac\u00a2 The total energy demand in Spain is estimated with a Variable Neighborhood algorithm. \u00e2\u20ac\u00a2 Socio-economic variables are used, and one year ahead prediction horizon is considered. \u00e2\u20ac\u00a2 Improvement of the prediction with an Extreme Learning Machine network is considered. \u00e2\u20ac\u00a2 Experiments are carried out in real data for the case of Spain. - Abstract: Energy demand prediction is an important problem whose solution is evaluated by policy makers in order to take key decisions affecting the economy of a country. A number of previous approaches to improve the quality of this estimation have been proposed in the last decade, the majority of them applying different machine learning techniques. In this paper, the performance of a robust hybrid approach, composed of a Variable Neighborhood Search algorithm and a new class of neural network called Extreme Learning Machine, is discussed. The Variable Neighborhood Search algorithm is focused on obtaining the most relevant features among the set of initial ones, by including an exponential prediction model. While previous approaches consider that the number of macroeconomic variables used for prediction is a parameter of the algorithm (i.e., it is fixed a priori), the proposed Variable Neighborhood Search method optimizes both: the number of variables and the best ones. After this first step of feature selection, an Extreme Learning Machine network is applied to obtain the final energy demand prediction. Experiments in a real case of energy demand estimation in Spain show the excellent performance of the proposed approach. In particular, the whole method obtains an estimation of the energy demand with an error lower than 2%, even when considering the crisis years, which are a real challenge.\n\n\nAnomaly detection in wide area network mesh using two machine learning anomaly detection algorithms\nOpenAIRE\nZhang, James; Vukotic, Ilija; Gardner, Robert\n2018-01-01\nAnomaly detection is the practice of identifying items or events that do not conform to an expected behavior or do not correlate with other items in a dataset. It has previously been applied to areas such as intrusion detection, system health monitoring, and fraud detection in credit card transactions. In this paper, we describe a new method for detecting anomalous behavior over network performance data, gathered by perfSONAR, using two machine learning algorithms: Boosted Decision Trees (BDT...\n\n\nThe Novel Quantitative Technique for Assessment of Gait Symmetry Using Advanced Statistical Learning Algorithm\nOpenAIRE\nWu, Jianning; Wu, Bin\n2015-01-01\nThe accurate identification of gait asymmetry is very beneficial to the assessment of at-risk gait in the clinical applications. This paper investigated the application of classification method based on statistical learning algorithm to quantify gait symmetry based on the assumption that the degree of intrinsic change in dynamical system of gait is associated with the different statistical distributions between gait variables from left-right side of lower limbs; that is, the discrimination of...\n\n\n\n\n\u00ab\n16\n17\n18\n19\n20\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n17\n18\n19\n20\n21\n\u00bb\n\n\n\n\n\n\n\n\nSimulating Visual Learning and Optical Illusions via a Network-Based Genetic Algorithm\nScience.gov (United States)\nSiu, Theodore; Vivar, Miguel; Shinbrot, Troy\n\nWe present a neural network model that uses a genetic algorithm to identify spatial patterns. We show that the model both learns and reproduces common visual patterns and optical illusions. Surprisingly, we find that the illusions generated are a direct consequence of the network architecture used. We discuss the implications of our results and the insights that we gain on how humans fall for optical illusions\n\n\nSolar Flare Prediction Model with Three Machine-learning Algorithms using Ultraviolet Brightening and Vector Magnetograms\nScience.gov (United States)\nNishizuka, N.; Sugiura, K.; Kubo, Y.; Den, M.; Watari, S.; Ishii, M.\n2017-02-01\nWe developed a flare prediction model using machine learning, which is optimized to predict the maximum class of flares occurring in the following 24 hr. Machine learning is used to devise algorithms that can learn from and make decisions on a huge amount of data. We used solar observation data during the period 2010-2015, such as vector magnetograms, ultraviolet (UV) emission, and soft X-ray emission taken by the Solar Dynamics Observatory and the Geostationary Operational Environmental Satellite. We detected active regions (ARs) from the full-disk magnetogram, from which \u00cb\u015360 features were extracted with their time differentials, including magnetic neutral lines, the current helicity, the UV brightening, and the flare history. After standardizing the feature database, we fully shuffled and randomly separated it into two for training and testing. To investigate which algorithm is best for flare prediction, we compared three machine-learning algorithms: the support vector machine, k-nearest neighbors (k-NN), and extremely randomized trees. The prediction score, the true skill statistic, was higher than 0.9 with a fully shuffled data set, which is higher than that for human forecasts. It was found that k-NN has the highest performance among the three algorithms. The ranking of the feature importance showed that previous flare activity is most effective, followed by the length of magnetic neutral lines, the unsigned magnetic flux, the area of UV brightening, and the time differentials of features over 24 hr, all of which are strongly correlated with the flux emergence dynamics in an AR.\n\n\nSolar Flare Prediction Model with Three Machine-learning Algorithms using Ultraviolet Brightening and Vector Magnetograms\nEnergy Technology Data Exchange (ETDEWEB)\nNishizuka, N.; Kubo, Y.; Den, M.; Watari, S.; Ishii, M. [Applied Electromagnetic Research Institute, National Institute of Information and Communications Technology, 4-2-1, Nukui-Kitamachi, Koganei, Tokyo 184-8795 (Japan); Sugiura, K., E-mail: nishizuka.naoto@nict.go.jp [Advanced Speech Translation Research and Development Promotion Center, National Institute of Information and Communications Technology (Japan)\n2017-02-01\nWe developed a flare prediction model using machine learning, which is optimized to predict the maximum class of flares occurring in the following 24 hr. Machine learning is used to devise algorithms that can learn from and make decisions on a huge amount of data. We used solar observation data during the period 2010\u00e2\u20ac\u201c2015, such as vector magnetograms, ultraviolet (UV) emission, and soft X-ray emission taken by the Solar Dynamics Observatory and the Geostationary Operational Environmental Satellite . We detected active regions (ARs) from the full-disk magnetogram, from which \u00e2\u02c6\u00bc60 features were extracted with their time differentials, including magnetic neutral lines, the current helicity, the UV brightening, and the flare history. After standardizing the feature database, we fully shuffled and randomly separated it into two for training and testing. To investigate which algorithm is best for flare prediction, we compared three machine-learning algorithms: the support vector machine, k-nearest neighbors (k-NN), and extremely randomized trees. The prediction score, the true skill statistic, was higher than 0.9 with a fully shuffled data set, which is higher than that for human forecasts. It was found that k-NN has the highest performance among the three algorithms. The ranking of the feature importance showed that previous flare activity is most effective, followed by the length of magnetic neutral lines, the unsigned magnetic flux, the area of UV brightening, and the time differentials of features over 24 hr, all of which are strongly correlated with the flux emergence dynamics in an AR.\n\n\nSolar Flare Prediction Model with Three Machine-learning Algorithms using Ultraviolet Brightening and Vector Magnetograms\nInternational Nuclear Information System (INIS) \nNishizuka, N.; Kubo, Y.; Den, M.; Watari, S.; Ishii, M.; Sugiura, K.\n2017-01-01\nWe developed a flare prediction model using machine learning, which is optimized to predict the maximum class of flares occurring in the following 24 hr. Machine learning is used to devise algorithms that can learn from and make decisions on a huge amount of data. We used solar observation data during the period 2010\u00e2\u20ac\u201c2015, such as vector magnetograms, ultraviolet (UV) emission, and soft X-ray emission taken by the Solar Dynamics Observatory and the Geostationary Operational Environmental Satellite . We detected active regions (ARs) from the full-disk magnetogram, from which \u00e2\u02c6\u00bc60 features were extracted with their time differentials, including magnetic neutral lines, the current helicity, the UV brightening, and the flare history. After standardizing the feature database, we fully shuffled and randomly separated it into two for training and testing. To investigate which algorithm is best for flare prediction, we compared three machine-learning algorithms: the support vector machine, k-nearest neighbors (k-NN), and extremely randomized trees. The prediction score, the true skill statistic, was higher than 0.9 with a fully shuffled data set, which is higher than that for human forecasts. It was found that k-NN has the highest performance among the three algorithms. The ranking of the feature importance showed that previous flare activity is most effective, followed by the length of magnetic neutral lines, the unsigned magnetic flux, the area of UV brightening, and the time differentials of features over 24 hr, all of which are strongly correlated with the flux emergence dynamics in an AR.\n\n\nMachine learning algorithm accurately detects fMRI signature of vulnerability to major depression\nOpenAIRE\nSato, Jo?o R.; Moll, Jorge; Green, Sophie; Deakin, John F.W.; Thomaz, Carlos E.; Zahn, Roland\n2015-01-01\nStandard functional magnetic resonance imaging (fMRI) analyses cannot assess the potential of a neuroimaging signature as a biomarker to predict individual vulnerability to major depression (MD). Here, we use machine learning for the first time to address this question. Using a recently identified neural signature of guilt-selective functional disconnection, the classification algorithm was able to distinguish remitted MD from control participants with 78.3% accuracy. This demonstrates the hi...\n\n\nHow the machine \u00e2\u20ac\u02dcthinks\u00e2\u20ac\u2122: Understanding opacity in machine learning algorithms\nDirectory of Open Access Journals (Sweden)\nJenna Burrell\n2016-01-01\nFull Text Available This article considers the issue of opacity as a problem for socially consequential mechanisms of classification and ranking, such as spam filters, credit card fraud detection, search engines, news trends, market segmentation and advertising, insurance or loan qualification, and credit scoring. These mechanisms of classification all frequently rely on computational algorithms, and in many cases on machine learning algorithms to do this work. In this article, I draw a distinction between three forms of opacity: (1 opacity as intentional corporate or state secrecy, (2 opacity as technical illiteracy, and (3 an opacity that arises from the characteristics of machine learning algorithms and the scale required to apply them usefully. The analysis in this article gets inside the algorithms themselves. I cite existing literatures in computer science, known industry practices (as they are publicly presented, and do some testing and manipulation of code as a form of lightweight code audit. I argue that recognizing the distinct forms of opacity that may be coming into play in a given application is a key to determining which of a variety of technical and non-technical solutions could help to prevent harm.\n\n\nAUTOCLASSIFICATION OF THE VARIABLE 3XMM SOURCES USING THE RANDOM FOREST MACHINE LEARNING ALGORITHM\nInternational Nuclear Information System (INIS) \nFarrell, Sean A.; Murphy, Tara; Lo, Kitty K.\n2015-01-01\nIn the current era of large surveys and massive data sets, autoclassification of astrophysical sources using intelligent algorithms is becoming increasingly important. In this paper we present the catalog of variable sources in the Third XMM-Newton Serendipitous Source catalog (3XMM) autoclassified using the Random Forest machine learning algorithm. We used a sample of manually classified variable sources from the second data release of the XMM-Newton catalogs (2XMMi-DR2) to train the classifier, obtaining an accuracy of \u00e2\u02c6\u00bc92%. We also evaluated the effectiveness of identifying spurious detections using a sample of spurious sources, achieving an accuracy of \u00e2\u02c6\u00bc95%. Manual investigation of a random sample of classified sources confirmed these accuracy levels and showed that the Random Forest machine learning algorithm is highly effective at automatically classifying 3XMM sources. Here we present the catalog of classified 3XMM variable sources. We also present three previously unidentified unusual sources that were flagged as outlier sources by the algorithm: a new candidate supergiant fast X-ray transient, a 400 s X-ray pulsar, and an eclipsing 5 hr binary system coincident with a known Cepheid.\n\n\nNovel Approaches for Diagnosing Melanoma Skin Lesions Through Supervised and Deep Learning Algorithms.\nScience.gov (United States)\nPremaladha, J; Ravichandran, K S\n2016-04-01\nDermoscopy is a technique used to capture the images of skin, and these images are useful to analyze the different types of skin diseases. Malignant melanoma is a kind of skin cancer whose severity even leads to death. Earlier detection of melanoma prevents death and the clinicians can treat the patients to increase the chances of survival. Only few machine learning algorithms are developed to detect the melanoma using its features. This paper proposes a Computer Aided Diagnosis (CAD) system which equips efficient algorithms to classify and predict the melanoma. Enhancement of the images are done using Contrast Limited Adaptive Histogram Equalization technique (CLAHE) and median filter. A new segmentation algorithm called Normalized Otsu's Segmentation (NOS) is implemented to segment the affected skin lesion from the normal skin, which overcomes the problem of variable illumination. Fifteen features are derived and extracted from the segmented images are fed into the proposed classification techniques like Deep Learning based Neural Networks and Hybrid Adaboost-Support Vector Machine (SVM) algorithms. The proposed system is tested and validated with nearly 992 images (malignant & benign lesions) and it provides a high classification accuracy of 93 %. The proposed CAD system can assist the dermatologists to confirm the decision of the diagnosis and to avoid excisional biopsies.\n\n\nA comparison of algorithms for inference and learning in probabilistic graphical models.\nScience.gov (United States)\nFrey, Brendan J; Jojic, Nebojsa\n2005-09-01\nResearch into methods for reasoning under uncertainty is currently one of the most exciting areas of artificial intelligence, largely because it has recently become possible to record, store, and process large amounts of data. While impressive achievements have been made in pattern classification problems such as handwritten character recognition, face detection, speaker identification, and prediction of gene function, it is even more exciting that researchers are on the verge of introducing systems that can perform large-scale combinatorial analyses of data, decomposing the data into interacting components. For example, computational methods for automatic scene analysis are now emerging in the computer vision community. These methods decompose an input image into its constituent objects, lighting conditions, motion patterns, etc. Two of the main challenges are finding effective representations and models in specific applications and finding efficient algorithms for inference and learning in these models. In this paper, we advocate the use of graph-based probability models and their associated inference and learning algorithms. We review exact techniques and various approximate, computationally efficient techniques, including iterated conditional modes, the expectation maximization (EM) algorithm, Gibbs sampling, the mean field method, variational techniques, structured variational techniques and the sum-product algorithm (\"loopy\" belief propagation). We describe how each technique can be applied in a vision model of multiple, occluding objects and contrast the behaviors and performances of the techniques using a unifying cost function, free energy.\n\n\nEvaluation of machine learning algorithms for improved risk assessment for Down's syndrome.\nScience.gov (United States)\nKoivu, Aki; Korpim\u00c3\u00a4ki, Teemu; Kivel\u00c3\u00a4, Petri; Pahikkala, Tapio; Sairanen, Mikko\n2018-05-04\nPrenatal screening generates a great amount of data that is used for predicting risk of various disorders. Prenatal risk assessment is based on multiple clinical variables and overall performance is defined by how well the risk algorithm is optimized for the population in question. This article evaluates machine learning algorithms to improve performance of first trimester screening of Down syndrome. Machine learning algorithms pose an adaptive alternative to develop better risk assessment models using the existing clinical variables. Two real-world data sets were used to experiment with multiple classification algorithms. Implemented models were tested with a third, real-world, data set and performance was compared to a predicate method, a commercial risk assessment software. Best performing deep neural network model gave an area under the curve of 0.96 and detection rate of 78% with 1% false positive rate with the test data. Support vector machine model gave area under the curve of 0.95 and detection rate of 61% with 1% false positive rate with the same test data. When compared with the predicate method, the best support vector machine model was slightly inferior, but an optimized deep neural network model was able to give higher detection rates with same false positive rate or similar detection rate but with markedly lower false positive rate. This finding could further improve the first trimester screening for Down syndrome, by using existing clinical variables and a large training data derived from a specific population. Copyright \u00c2\u00a9 2018 Elsevier Ltd. All rights reserved.\n\n\nThe Novel Quantitative Technique for Assessment of Gait Symmetry Using Advanced Statistical Learning Algorithm\nDirectory of Open Access Journals (Sweden)\nJianning Wu\n2015-01-01\nFull Text Available The accurate identification of gait asymmetry is very beneficial to the assessment of at-risk gait in the clinical applications. This paper investigated the application of classification method based on statistical learning algorithm to quantify gait symmetry based on the assumption that the degree of intrinsic change in dynamical system of gait is associated with the different statistical distributions between gait variables from left-right side of lower limbs; that is, the discrimination of small difference of similarity between lower limbs is considered the reorganization of their different probability distribution. The kinetic gait data of 60 participants were recorded using a strain gauge force platform during normal walking. The classification method is designed based on advanced statistical learning algorithm such as support vector machine algorithm for binary classification and is adopted to quantitatively evaluate gait symmetry. The experiment results showed that the proposed method could capture more intrinsic dynamic information hidden in gait variables and recognize the right-left gait patterns with superior generalization performance. Moreover, our proposed techniques could identify the small significant difference between lower limbs when compared to the traditional symmetry index method for gait. The proposed algorithm would become an effective tool for early identification of the elderly gait asymmetry in the clinical diagnosis.\n\n\nThe novel quantitative technique for assessment of gait symmetry using advanced statistical learning algorithm.\nScience.gov (United States)\nWu, Jianning; Wu, Bin\n2015-01-01\nThe accurate identification of gait asymmetry is very beneficial to the assessment of at-risk gait in the clinical applications. This paper investigated the application of classification method based on statistical learning algorithm to quantify gait symmetry based on the assumption that the degree of intrinsic change in dynamical system of gait is associated with the different statistical distributions between gait variables from left-right side of lower limbs; that is, the discrimination of small difference of similarity between lower limbs is considered the reorganization of their different probability distribution. The kinetic gait data of 60 participants were recorded using a strain gauge force platform during normal walking. The classification method is designed based on advanced statistical learning algorithm such as support vector machine algorithm for binary classification and is adopted to quantitatively evaluate gait symmetry. The experiment results showed that the proposed method could capture more intrinsic dynamic information hidden in gait variables and recognize the right-left gait patterns with superior generalization performance. Moreover, our proposed techniques could identify the small significant difference between lower limbs when compared to the traditional symmetry index method for gait. The proposed algorithm would become an effective tool for early identification of the elderly gait asymmetry in the clinical diagnosis.\n\n\nSeparation of pulsar signals from noise using supervised machine learning algorithms\nScience.gov (United States)\nBethapudi, S.; Desai, S.\n2018-04-01\nWe evaluate the performance of four different machine learning (ML) algorithms: an Artificial Neural Network Multi-Layer Perceptron (ANN MLP), Adaboost, Gradient Boosting Classifier (GBC), and XGBoost, for the separation of pulsars from radio frequency interference (RFI) and other sources of noise, using a dataset obtained from the post-processing of a pulsar search pipeline. This dataset was previously used for the cross-validation of the SPINN-based machine learning engine, obtained from the reprocessing of the HTRU-S survey data (Morello et al., 2014). We have used the Synthetic Minority Over-sampling Technique (SMOTE) to deal with high-class imbalance in the dataset. We report a variety of quality scores from all four of these algorithms on both the non-SMOTE and SMOTE datasets. For all the above ML methods, we report high accuracy and G-mean for both the non-SMOTE and SMOTE cases. We study the feature importances using Adaboost, GBC, and XGBoost and also from the minimum Redundancy Maximum Relevance approach to report algorithm-agnostic feature ranking. From these methods, we find that the signal to noise of the folded profile to be the best feature. We find that all the ML algorithms report FPRs about an order of magnitude lower than the corresponding FPRs obtained in Morello et al. (2014), for the same recall value.\n\n\nDevelopment of a general learning algorithm with applications in nuclear reactor systems\nInternational Nuclear Information System (INIS) \nBrittain, C.R.; Otaduy, P.J.; Perez, R.B.\n1989-12-01\nThe objective of this study was development of a generalized learning algorithm that can learn to predict a particular feature of a process by observation of a set of representative input examples. The algorithm uses pattern matching and statistical analysis techniques to find a functional relationship between descriptive attributes of the input examples and the feature to be predicted. The algorithm was tested by applying it to a set of examples consisting of performance descriptions for 277 fuel cycles of Oak Ridge National Laboratory's High Flux Isotope Reactor (HFIR). The program learned to predict the critical rod position for the HFIR from core configuration data prior to reactor startup. The functional relationship bases its predictions on initial core reactivity, the number of certain targets placed in the center of the reactor, and the total exposure of the control plates. Twelve characteristic fuel cycle clusters were identified. Nine fuel cycles were diagnosed as having noisy data, and one could not be predicted by the functional relationship. 13 refs., 6 figs\n\n\nDevelopment of a general learning algorithm with applications in nuclear reactor systems\nEnergy Technology Data Exchange (ETDEWEB)\nBrittain, C.R.; Otaduy, P.J.; Perez, R.B.\n1989-12-01\nThe objective of this study was development of a generalized learning algorithm that can learn to predict a particular feature of a process by observation of a set of representative input examples. The algorithm uses pattern matching and statistical analysis techniques to find a functional relationship between descriptive attributes of the input examples and the feature to be predicted. The algorithm was tested by applying it to a set of examples consisting of performance descriptions for 277 fuel cycles of Oak Ridge National Laboratory's High Flux Isotope Reactor (HFIR). The program learned to predict the critical rod position for the HFIR from core configuration data prior to reactor startup. The functional relationship bases its predictions on initial core reactivity, the number of certain targets placed in the center of the reactor, and the total exposure of the control plates. Twelve characteristic fuel cycle clusters were identified. Nine fuel cycles were diagnosed as having noisy data, and one could not be predicted by the functional relationship. 13 refs., 6 figs.\n\n\nSequence-based prediction of protein protein interaction using a deep-learning algorithm.\nScience.gov (United States)\nSun, Tanlin; Zhou, Bo; Lai, Luhua; Pei, Jianfeng\n2017-05-25\nProtein-protein interactions (PPIs) are critical for many biological processes. It is therefore important to develop accurate high-throughput methods for identifying PPI to better understand protein function, disease occurrence, and therapy design. Though various computational methods for predicting PPI have been developed, their robustness for prediction with external datasets is unknown. Deep-learning algorithms have achieved successful results in diverse areas, but their effectiveness for PPI prediction has not been tested. We used a stacked autoencoder, a type of deep-learning algorithm, to study the sequence-based PPI prediction. The best model achieved an average accuracy of 97.19% with 10-fold cross-validation. The prediction accuracies for various external datasets ranged from 87.99% to 99.21%, which are superior to those achieved with previous methods. To our knowledge, this research is the first to apply a deep-learning algorithm to sequence-based PPI prediction, and the results demonstrate its potential in this field.\n\n\nSistem Klasifikasi Tipe Kepribadian dan Penerimaan Teman Sebaya Menggunakan Jaringan Syaraf Tiruan Backpropagation\nDirectory of Open Access Journals (Sweden)\nYusuf Dwi Santoso\n2017-06-01\nFull Text Available Kepribadian merupakan gambaran tingkah laku dari individu. Penerimaan teman sebaya merupakan penilaian individu bahwa dirinya diterima, didengar, diperhatikan, dihargai, serta dapat merasa aman dan nyaman saat bersama dengan teman-teman dengan umur yang sama. Kepribadian dan penerimaan teman sebaya penting untuk diketahui agar dapat mengenal potensi diri. Tes kepribadian merupakan salah satu sarana untuk mengetahui dan mengklasifikasikan kepribadian seseorang ke tipe kepribadian tertentu. Jaringan syaraf tiruan Backpropagation dapat digunakan untuk melakukan klasifikasi sebuah pola berdasarkan permasalahan tertentu seperti halnya dalam mengklasifikasi tipe kepribadian dan penerimaan teman sebaya seseorang. Sistem klasifikasi tipe kepribadian dan penerimaan teman sebaya menggunakan jaringan syaraf tiruan Backpropagation dapat digunakan untuk mengklasifikasi tipe kepribadian dan penerimaan teman sebaya seseorang ke dalam beberapa tipe yaitu introvert diterima, introvert ditolak, ekstrovert diterima dan ekstrovert ditolak berdasarkan sejumlah set pertanyaan yang menjadi alat ukur dalam penentuan kepribadian. Sistem klasifikasi tipe kepribadian dan penerimaan teman sebaya menggunakan jaringan syaraf tiruan Backpropagation menghasilkan arsitektur Backpropagation terbaik untuk klasifikasi kepribadian dan penerimaan teman sebaya pada saat menggunakan 1 hidden layer dengan 7 neuron, 10000 epoch, nilai target error 0.01 dan laju pembelajaran 0.1. Hasil eksperimen jaringan syaraf tiruan Backpropagation pada sistem ini menghasilkan rata-rata tingkat akurasi 98.75% dan tingkat error 1.25%.\n\n\nA multi-objective improved teaching-learning based optimization algorithm for unconstrained and constrained optimization problems\nDirectory of Open Access Journals (Sweden)\nR. Venkata Rao\n2014-01-01\nFull Text Available The present work proposes a multi-objective improved teaching-learning based optimization (MO-ITLBO algorithm for unconstrained and constrained multi-objective function optimization. The MO-ITLBO algorithm is the improved version of basic teaching-learning based optimization (TLBO algorithm adapted for multi-objective problems. The basic TLBO algorithm is improved to enhance its exploration and exploitation capacities by introducing the concept of number of teachers, adaptive teaching factor, tutorial training and self-motivated learning. The MO-ITLBO algorithm uses a grid-based approach to adaptively assess the non-dominated solutions (i.e. Pareto front maintained in an external archive. The performance of the MO-ITLBO algorithm is assessed by implementing it on unconstrained and constrained test problems proposed for the Congress on Evolutionary Computation 2009 (CEC 2009 competition. The performance assessment is done by using the inverted generational distance (IGD measure. The IGD measures obtained by using the MO-ITLBO algorithm are compared with the IGD measures of the other state-of-the-art algorithms available in the literature. Finally, Lexicographic ordering is used to assess the overall performance of competitive algorithms. Results have shown that the proposed MO-ITLBO algorithm has obtained the 1st rank in the optimization of unconstrained test functions and the 3rd rank in the optimization of constrained test functions.\n\n\nImproved teaching-learning-based and JAYA optimization algorithms for solving flexible flow shop scheduling problems\nScience.gov (United States)\nBuddala, Raviteja; Mahapatra, Siba Sankar\n2017-11-01\nFlexible flow shop (or a hybrid flow shop) scheduling problem is an extension of classical flow shop scheduling problem. In a simple flow shop configuration, a job having `g' operations is performed on `g' operation centres (stages) with each stage having only one machine. If any stage contains more than one machine for providing alternate processing facility, then the problem becomes a flexible flow shop problem (FFSP). FFSP which contains all the complexities involved in a simple flow shop and parallel machine scheduling problems is a well-known NP-hard (Non-deterministic polynomial time) problem. Owing to high computational complexity involved in solving these problems, it is not always possible to obtain an optimal solution in a reasonable computation time. To obtain near-optimal solutions in a reasonable computation time, a large variety of meta-heuristics have been proposed in the past. However, tuning algorithm-specific parameters for solving FFSP is rather tricky and time consuming. To address this limitation, teaching-learning-based optimization (TLBO) and JAYA algorithm are chosen for the study because these are not only recent meta-heuristics but they do not require tuning of algorithm-specific parameters. Although these algorithms seem to be elegant, they lose solution diversity after few iterations and get trapped at the local optima. To alleviate such drawback, a new local search procedure is proposed in this paper to improve the solution quality. Further, mutation strategy (inspired from genetic algorithm) is incorporated in the basic algorithm to maintain solution diversity in the population. Computational experiments have been conducted on standard benchmark problems to calculate makespan and computational time. It is found that the rate of convergence of TLBO is superior to JAYA. From the results, it is found that TLBO and JAYA outperform many algorithms reported in the literature and can be treated as efficient methods for solving the FFSP.\n\n\nA STUDENT MODEL AND LEARNING ALGORITHM FOR THE EXPERT TUTORING SYSTEM OF POLISH GRAMMAR\nDirectory of Open Access Journals (Sweden)\nKostikov Mykola\n2014-11-01\nFull Text Available When creating computer-assisted language learning software, it is necessary to use the potential of information technology in controlling the learning process fully. Modern intelligent tutoring systems help to make this process adaptive and personalized thanks to modeling the domain and students\u00e2\u20ac\u2122 knowledge. The aim of the paper is to investigate possibilities for applying these methods in teaching Polish grammar in Ukraine taking into account its specifics. The article is concerned with the approaches of using student models in modern intelligent tutoring systems in order to provide personalized learning. A structure of the student model and a general working algorithm of the expert tutoring system of Polish grammar have been developed. The modeling of knowing and forgetting particular learning elements within the probabilistic (stochastic model has been studied, as well as the prognostication of future probabilities of students\u00e2\u20ac\u2122 knowledge, taking into account their individual forgetting rates. The objective function of instruction quality with allowance for frequency of grammar rules within a certain amount of words being learned and their connections to another rules has been formulated. The problem of generating the next learning step taking into account the need for mastering previous, connected rules has been studied, as well as determining the optimal time period between the lessons depending on the current knowledge level.\n\n\n\n\n\u00ab\n17\n18\n19\n20\n21\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n18\n19\n20\n21\n22\n\u00bb\n\n\n\n\n\n\n\n\nOptimization of thermal performance of a smooth flat-plate solar air heater using teaching\u00e2\u20ac\u201clearning-based optimization algorithm\nDirectory of Open Access Journals (Sweden)\nR. Venkata Rao\n2015-12-01\nFull Text Available This paper presents the performance of teaching\u00e2\u20ac\u201clearning-based optimization (TLBO algorithm to obtain the optimum set of design and operating parameters for a smooth flat plate solar air heater (SFPSAH. The TLBO algorithm is a recently proposed population-based algorithm, which simulates the teaching\u00e2\u20ac\u201clearning process of the classroom. Maximization of thermal efficiency is considered as an objective function for the thermal performance of SFPSAH. The number of glass plates, irradiance, and the Reynolds number are considered as the design parameters and wind velocity, tilt angle, ambient temperature, and emissivity of the plate are considered as the operating parameters to obtain the thermal performance of the SFPSAH using the TLBO algorithm. The computational results have shown that the TLBO algorithm is better or competitive to other optimization algorithms recently reported in the literature for the considered problem.\n\n\nPrediction of insemination outcomes in Holstein dairy cattle using alternative machine learning algorithms.\nScience.gov (United States)\nShahinfar, Saleh; Page, David; Guenther, Jerry; Cabrera, Victor; Fricke, Paul; Weigel, Kent\n2014-02-01\nWhen making the decision about whether or not to breed a given cow, knowledge about the expected outcome would have an economic impact on profitability of the breeding program and net income of the farm. The outcome of each breeding can be affected by many management and physiological features that vary between farms and interact with each other. Hence, the ability of machine learning algorithms to accommodate complex relationships in the data and missing values for explanatory variables makes these algorithms well suited for investigation of reproduction performance in dairy cattle. The objective of this study was to develop a user-friendly and intuitive on-farm tool to help farmers make reproduction management decisions. Several different machine learning algorithms were applied to predict the insemination outcomes of individual cows based on phenotypic and genotypic data. Data from 26 dairy farms in the Alta Genetics (Watertown, WI) Advantage Progeny Testing Program were used, representing a 10-yr period from 2000 to 2010. Health, reproduction, and production data were extracted from on-farm dairy management software, and estimated breeding values were downloaded from the US Department of Agriculture Agricultural Research Service Animal Improvement Programs Laboratory (Beltsville, MD) database. The edited data set consisted of 129,245 breeding records from primiparous Holstein cows and 195,128 breeding records from multiparous Holstein cows. Each data point in the final data set included 23 and 25 explanatory variables and 1 binary outcome for of 0.756 \u00c2\u00b1 0.005 and 0.736 \u00c2\u00b1 0.005 for primiparous and multiparous cows, respectively. The na\u00c3\u00afve Bayes algorithm, Bayesian network, and decision tree algorithms showed somewhat poorer classification performance. An information-based variable selection procedure identified herd average conception rate, incidence of ketosis, number of previous (failed) inseminations, days in milk at breeding, and mastitis as the most\n\n\nAutomatic feature learning using multichannel ROI based on deep structured algorithms for computerized lung cancer diagnosis.\nScience.gov (United States)\nSun, Wenqing; Zheng, Bin; Qian, Wei\n2017-10-01\nThis study aimed to analyze the ability of extracting automatically generated features using deep structured algorithms in lung nodule CT image diagnosis, and compare its performance with traditional computer aided diagnosis (CADx) systems using hand-crafted features. All of the 1018 cases were acquired from Lung Image Database Consortium (LIDC) public lung cancer database. The nodules were segmented according to four radiologists' markings, and 13,668 samples were generated by rotating every slice of nodule images. Three multichannel ROI based deep structured algorithms were designed and implemented in this study: convolutional neural network (CNN), deep belief network (DBN), and stacked denoising autoencoder (SDAE). For the comparison purpose, we also implemented a CADx system using hand-crafted features including density features, texture features and morphological features. The performance of every scheme was evaluated by using a 10-fold cross-validation method and an assessment index of the area under the receiver operating characteristic curve (AUC). The observed highest area under the curve (AUC) was 0.899\u00c2\u00b10.018 achieved by CNN, which was significantly higher than traditional CADx with the AUC=0.848\u00c2\u00b10.026. The results from DBN was also slightly higher than CADx, while SDAE was slightly lower. By visualizing the automatic generated features, we found some meaningful detectors like curvy stroke detectors from deep structured schemes. The study results showed the deep structured algorithms with automatically generated features can achieve desirable performance in lung nodule diagnosis. With well-tuned parameters and large enough dataset, the deep learning algorithms can have better performance than current popular CADx. We believe the deep learning algorithms with similar data preprocessing procedure can be used in other medical image analysis areas as well. Copyright \u00c2\u00a9 2017. Published by Elsevier Ltd.\n\n\nDefinition and Analysis of a System for the Automated Comparison of Curriculum Sequencing Algorithms in Adaptive Distance Learning\nScience.gov (United States)\nLimongelli, Carla; Sciarrone, Filippo; Temperini, Marco; Vaste, Giulia\n2011-01-01\nLS-Lab provides automatic support to comparison/evaluation of the Learning Object Sequences produced by different Curriculum Sequencing Algorithms. Through this framework a teacher can verify the correspondence between the behaviour of different sequencing algorithms and her pedagogical preferences. In fact the teacher can compare algorithms\u00e2\u20ac\u00a6\n\n\nSYNTHESIS AND REDUCED LOGIC GATE REALIZATION OF MULTI-VALUED LOGIC FUNCTIONS USING NEURAL NETWORK DEPLOYMENT ALGORITHM\nDirectory of Open Access Journals (Sweden)\nA. K. CHOWDHURY\n2016-02-01\nFull Text Available In this paper an evolutionary technique for synthesizing Multi-Valued Logic (MVL functions using Neural Network Deployment Algorithm (NNDA is presented. The algorithm is combined with back-propagation learning capability and neural MVL operators. This research article is done to observe the anomalistic characteristics of MVL neural operators and their role in synthesis. The advantages of NNDA-MVL algorithm is demonstrated with realization of synthesized many valued functions with lesser MVL operators. The characteristic feature set consists of MVL gate count, network link count, network propagation delay and accuracy achieved in training. In brief, this paper depicts an effort of reduced network size for synthesized MVL functions. Trained MVL operators improve the basic architecture by reducing MIN gate and interlink connection by 52.94% and 23.38% respectively.\n\n\nEvaluation of machine learning algorithms for prediction of regions of high Reynolds averaged Navier Stokes uncertainty\nScience.gov (United States)\nLing, J.; Templeton, J.\n2015-08-01\nReynolds Averaged Navier Stokes (RANS) models are widely used in industry to predict fluid flows, despite their acknowledged deficiencies. Not only do RANS models often produce inaccurate flow predictions, but there are very limited diagnostics available to assess RANS accuracy for a given flow configuration. If experimental or higher fidelity simulation results are not available for RANS validation, there is no reliable method to evaluate RANS accuracy. This paper explores the potential of utilizing machine learning algorithms to identify regions of high RANS uncertainty. Three different machine learning algorithms were evaluated: support vector machines, Adaboost decision trees, and random forests. The algorithms were trained on a database of canonical flow configurations for which validated direct numerical simulation or large eddy simulation results were available, and were used to classify RANS results on a point-by-point basis as having either high or low uncertainty, based on the breakdown of specific RANS modeling assumptions. Classifiers were developed for three different basic RANS eddy viscosity model assumptions: the isotropy of the eddy viscosity, the linearity of the Boussinesq hypothesis, and the non-negativity of the eddy viscosity. It is shown that these classifiers are able to generalize to flows substantially different from those on which they were trained. Feature selection techniques, model evaluation, and extrapolation detection are discussed in the context of turbulence modeling applications.\n\n\nFMRQ-A Multiagent Reinforcement Learning Algorithm for Fully Cooperative Tasks.\nScience.gov (United States)\nZhang, Zhen; Zhao, Dongbin; Gao, Junwei; Wang, Dongqing; Dai, Yujie\n2017-06-01\nIn this paper, we propose a multiagent reinforcement learning algorithm dealing with fully cooperative tasks. The algorithm is called frequency of the maximum reward Q-learning (FMRQ). FMRQ aims to achieve one of the optimal Nash equilibria so as to optimize the performance index in multiagent systems. The frequency of obtaining the highest global immediate reward instead of immediate reward is used as the reinforcement signal. With FMRQ each agent does not need the observation of the other agents' actions and only shares its state and reward at each step. We validate FMRQ through case studies of repeated games: four cases of two-player two-action and one case of three-player two-action. It is demonstrated that FMRQ can converge to one of the optimal Nash equilibria in these cases. Moreover, comparison experiments on tasks with multiple states and finite steps are conducted. One is box-pushing and the other one is distributed sensor network problem. Experimental results show that the proposed algorithm outperforms others with higher performance.\n\n\nDesigning Artificial Neural Networks Using Particle Swarm Optimization Algorithms.\nScience.gov (United States)\nGarro, Beatriz A; V\u00c3\u00a1zquez, Roberto A\n2015-01-01\nArtificial Neural Network (ANN) design is a complex task because its performance depends on the architecture, the selected transfer function, and the learning algorithm used to train the set of synaptic weights. In this paper we present a methodology that automatically designs an ANN using particle swarm optimization algorithms such as Basic Particle Swarm Optimization (PSO), Second Generation of Particle Swarm Optimization (SGPSO), and a New Model of PSO called NMPSO. The aim of these algorithms is to evolve, at the same time, the three principal components of an ANN: the set of synaptic weights, the connections or architecture, and the transfer functions for each neuron. Eight different fitness functions were proposed to evaluate the fitness of each solution and find the best design. These functions are based on the mean square error (MSE) and the classification error (CER) and implement a strategy to avoid overtraining and to reduce the number of connections in the ANN. In addition, the ANN designed with the proposed methodology is compared with those designed manually using the well-known Back-Propagation and Levenberg-Marquardt Learning Algorithms. Finally, the accuracy of the method is tested with different nonlinear pattern classification problems.\n\n\nMachine learning algorithms for meteorological event classification in the coastal area using in-situ data\nScience.gov (United States)\nSokolov, Anton; Gengembre, Cyril; Dmitriev, Egor; Delbarre, Herv\u00c3\u00a9\n2017-04-01\nThe problem is considered of classification of local atmospheric meteorological events in the coastal area such as sea breezes, fogs and storms. The in-situ meteorological data as wind speed and direction, temperature, humidity and turbulence are used as predictors. Local atmospheric events of 2013-2014 were analysed manually to train classification algorithms in the coastal area of English Channel in Dunkirk (France). Then, ultrasonic anemometer data and LIDAR wind profiler data were used as predictors. A few algorithms were applied to determine meteorological events by local data such as a decision tree, the nearest neighbour classifier, a support vector machine. The comparison of classification algorithms was carried out, the most important predictors for each event type were determined. It was shown that in more than 80 percent of the cases machine learning algorithms detect the meteorological class correctly. We expect that this methodology could be applied also to classify events by climatological in-situ data or by modelling data. It allows estimating frequencies of each event in perspective of climate change.\n\n\nFeature Selection for Motor Imagery EEG Classification Based on Firefly Algorithm and Learning Automata\nDirectory of Open Access Journals (Sweden)\nAiming Liu\n2017-11-01\nFull Text Available Motor Imagery (MI electroencephalography (EEG is widely studied for its non-invasiveness, easy availability, portability, and high temporal resolution. As for MI EEG signal processing, the high dimensions of features represent a research challenge. It is necessary to eliminate redundant features, which not only create an additional overhead of managing the space complexity, but also might include outliers, thereby reducing classification accuracy. The firefly algorithm (FA can adaptively select the best subset of features, and improve classification accuracy. However, the FA is easily entrapped in a local optimum. To solve this problem, this paper proposes a method of combining the firefly algorithm and learning automata (LA to optimize feature selection for motor imagery EEG. We employed a method of combining common spatial pattern (CSP and local characteristic-scale decomposition (LCD algorithms to obtain a high dimensional feature set, and classified it by using the spectral regression discriminant analysis (SRDA classifier. Both the fourth brain\u00e2\u20ac\u201ccomputer interface competition data and real-time data acquired in our designed experiments were used to verify the validation of the proposed method. Compared with genetic and adaptive weight particle swarm optimization algorithms, the experimental results show that our proposed method effectively eliminates redundant features, and improves the classification accuracy of MI EEG signals. In addition, a real-time brain\u00e2\u20ac\u201ccomputer interface system was implemented to verify the feasibility of our proposed methods being applied in practical brain\u00e2\u20ac\u201ccomputer interface systems.\n\n\nPredicting the Occurrence of Haze Events in Southeast Asia using Machine Learning Algorithms\nScience.gov (United States)\nLee, H. H.; Chulakadabba, A.; Tonks, A.; Yang, Z.; Wang, C.\n2017-12-01\nSevere local- and regional-scale air pollution episodes typically originate from 1) high emissions of air pollutants, 2) poor dispersion conditions, and 3) trans-boundary pollutant transport. Biomass burning activities have become more frequent in Southeast Asia, especially in Sumatra, Borneo, and the mainland Southeast. Trans-boundary transport of biomass burning aerosols often lead to air quality problems in the region. Furthermore, particulate pollutants from human activities besides biomass burning also play an important role in the air quality of Southeast Asia. Singapore, for example, has a dynamic industrial sector including chemical, electric and metallurgic industries, and is the region's major petroleum-refining center. In addition, natural gas and oil power plants, waste incinerators, active port traffic, and a major regional airport further complicate Singapore's air quality issues. In this study, we compare five Machine Learning algorithms: k-Nearest Neighbors, Linear Support Vector Machine, Decision Tree, Random Forest and Artificial Neural Network, to identify haze patterns and determine variable importance. The algorithms were trained using local atmospheric data (i.e. months, atmospheric conditions, wind direction and relative humidity) from three observation stations in Singapore (Changi, Seletar and Paya Labar). We find that the algorithms reveal the associations in data within and between the stations, and provide in-depth interpretation of the haze sources. The algorithms also allow us to predict the probability of haze episodes in Singapore and to determine the correlation between this probability and atmospheric conditions.\n\n\nFeature Selection for Motor Imagery EEG Classification Based on Firefly Algorithm and Learning Automata.\nScience.gov (United States)\nLiu, Aiming; Chen, Kun; Liu, Quan; Ai, Qingsong; Xie, Yi; Chen, Anqi\n2017-11-08\nMotor Imagery (MI) electroencephalography (EEG) is widely studied for its non-invasiveness, easy availability, portability, and high temporal resolution. As for MI EEG signal processing, the high dimensions of features represent a research challenge. It is necessary to eliminate redundant features, which not only create an additional overhead of managing the space complexity, but also might include outliers, thereby reducing classification accuracy. The firefly algorithm (FA) can adaptively select the best subset of features, and improve classification accuracy. However, the FA is easily entrapped in a local optimum. To solve this problem, this paper proposes a method of combining the firefly algorithm and learning automata (LA) to optimize feature selection for motor imagery EEG. We employed a method of combining common spatial pattern (CSP) and local characteristic-scale decomposition (LCD) algorithms to obtain a high dimensional feature set, and classified it by using the spectral regression discriminant analysis (SRDA) classifier. Both the fourth brain-computer interface competition data and real-time data acquired in our designed experiments were used to verify the validation of the proposed method. Compared with genetic and adaptive weight particle swarm optimization algorithms, the experimental results show that our proposed method effectively eliminates redundant features, and improves the classification accuracy of MI EEG signals. In addition, a real-time brain-computer interface system was implemented to verify the feasibility of our proposed methods being applied in practical brain-computer interface systems.\n\n\nOptimal design of planar slider-crank mechanism using teaching-learning-based optimization algorithm\nInternational Nuclear Information System (INIS) \nChaudhary, Kailash; Chaudhary, Himanshu\n2015-01-01\nIn this paper, a two stage optimization technique is presented for optimum design of planar slider-crank mechanism. The slider crank mechanism needs to be dynamically balanced to reduce vibrations and noise in the engine and to improve the vehicle performance. For dynamic balancing, minimization of the shaking force and the shaking moment is achieved by finding optimum mass distribution of crank and connecting rod using the equipemental system of point-masses in the first stage of the optimization. In the second stage, their shapes are synthesized systematically by closed parametric curve, i.e., cubic B-spline curve corresponding to the optimum inertial parameters found in the first stage. The multi-objective optimization problem to minimize both the shaking force and the shaking moment is solved using Teaching-learning-based optimization algorithm (TLBO) and its computational performance is compared with Genetic algorithm (GA).\n\n\nAuto-SEIA: simultaneous optimization of image processing and machine learning algorithms\nScience.gov (United States)\nNegro Maggio, Valentina; Iocchi, Luca\n2015-02-01\nObject classification from images is an important task for machine vision and it is a crucial ingredient for many computer vision applications, ranging from security and surveillance to marketing. Image based object classification techniques properly integrate image processing and machine learning (i.e., classification) procedures. In this paper we present a system for automatic simultaneous optimization of algorithms and parameters for object classification from images. More specifically, the proposed system is able to process a dataset of labelled images and to return a best configuration of image processing and classification algorithms and of their parameters with respect to the accuracy of classification. Experiments with real public datasets are used to demonstrate the effectiveness of the developed system.\n\n\nOptimal design of planar slider-crank mechanism using teaching-learning-based optimization algorithm\nEnergy Technology Data Exchange (ETDEWEB)\nChaudhary, Kailash; Chaudhary, Himanshu [Malaviya National Institute of Technology, Jaipur (Malaysia)\n2015-11-15\nIn this paper, a two stage optimization technique is presented for optimum design of planar slider-crank mechanism. The slider crank mechanism needs to be dynamically balanced to reduce vibrations and noise in the engine and to improve the vehicle performance. For dynamic balancing, minimization of the shaking force and the shaking moment is achieved by finding optimum mass distribution of crank and connecting rod using the equipemental system of point-masses in the first stage of the optimization. In the second stage, their shapes are synthesized systematically by closed parametric curve, i.e., cubic B-spline curve corresponding to the optimum inertial parameters found in the first stage. The multi-objective optimization problem to minimize both the shaking force and the shaking moment is solved using Teaching-learning-based optimization algorithm (TLBO) and its computational performance is compared with Genetic algorithm (GA).\n\n\nDiscrete Teaching-learning-based optimization Algorithm for Traveling Salesman Problems\nDirectory of Open Access Journals (Sweden)\nWu Lehui\n2017-01-01\nFull Text Available In this paper, a discrete variant of TLBO (DTLBO is proposed for solving the traveling salesman problem (TSP. In the proposed method, an effective learner representation scheme is redefined based on the characteristics of TSP problem. Moreover, all learners are randomly divided into several sub-swarms with equal amounts of learners so as to increase the diversity of population and reduce the probability of being trapped in local optimum. In each sub-swarm, the new positions of learners in the teaching phase and the learning phase are generated by the crossover operation, the legality detection and mutation operation, and then the offspring learners are determined based on greedy selection. Finally, to verify the performance of the proposed algorithm, benchmark TSP problems are examined and the results indicate that DTLBO is effective compared with other algorithms used for TSP problems.\n\n\nMachine learning based cloud mask algorithm driven by radiative transfer modeling\nScience.gov (United States)\nChen, N.; Li, W.; Tanikawa, T.; Hori, M.; Shimada, R.; Stamnes, K. H.\n2017-12-01\nCloud detection is a critically important first step required to derive many satellite data products. Traditional threshold based cloud mask algorithms require a complicated design process and fine tuning for each sensor, and have difficulty over snow/ice covered areas. With the advance of computational power and machine learning techniques, we have developed a new algorithm based on a neural network classifier driven by extensive radiative transfer modeling. Statistical validation results obtained by using collocated CALIOP and MODIS data show that its performance is consistent over different ecosystems and significantly better than the MODIS Cloud Mask (MOD35 C6) during the winter seasons over mid-latitude snow covered areas. Simulations using a reduced number of satellite channels also show satisfactory results, indicating its flexibility to be configured for different sensors.\n\n\nBeam-column joint shear prediction using hybridized deep learning neural network with genetic algorithm\nScience.gov (United States)\nMundher Yaseen, Zaher; Abdulmohsin Afan, Haitham; Tran, Minh-Tung\n2018-04-01\nScientifically evidenced that beam-column joints are a critical point in the reinforced concrete (RC) structure under the fluctuation loads effects. In this novel hybrid data-intelligence model developed to predict the joint shear behavior of exterior beam-column structure frame. The hybrid data-intelligence model is called genetic algorithm integrated with deep learning neural network model (GA-DLNN). The genetic algorithm is used as prior modelling phase for the input approximation whereas the DLNN predictive model is used for the prediction phase. To demonstrate this structural problem, experimental data is collected from the literature that defined the dimensional and specimens\u00e2\u20ac\u2122 properties. The attained findings evidenced the efficitveness of the hybrid GA-DLNN in modelling beam-column joint shear problem. In addition, the accurate prediction achived with less input variables owing to the feasibility of the evolutionary phase.\n\n\nRandom neural Q-learning for obstacle avoidance of a mobile robot in unknown environments\nDirectory of Open Access Journals (Sweden)\nJing Yang\n2016-07-01\nFull Text Available The article presents a random neural Q-learning strategy for the obstacle avoidance problem of an autonomous mobile robot in unknown environments. In the proposed strategy, two independent modules, namely, avoidance without considering the target and goal-seeking without considering obstacles, are first trained using the proposed random neural Q-learning algorithm to obtain their best control policies. Then, the two trained modules are combined based on a switching function to realize the obstacle avoidance in unknown environments. For the proposed random neural Q-learning algorithm, a single-hidden layer feedforward network is used to approximate the Q-function to estimate the Q-value. The parameters of the single-hidden layer feedforward network are modified using the recently proposed neural algorithm named the online sequential version of extreme learning machine, where the parameters of the hidden nodes are assigned randomly and the sample data can come one by one. However, different from the original online sequential version of extreme learning machine algorithm, the initial output weights are estimated subjected to quadratic inequality constraint to improve the convergence speed. Finally, the simulation results demonstrate that the proposed random neural Q-learning strategy can successfully solve the obstacle avoidance problem. Also, the higher learning efficiency and better generalization ability are achieved by the proposed random neural Q-learning algorithm compared with the Q-learning based on the back-propagation method.\n\n\nDevelopment of a Machine Learning Algorithm for the Surveillance of Autism Spectrum Disorder.\nDirectory of Open Access Journals (Sweden)\nMatthew J Maenner\n\nFull Text Available The Autism and Developmental Disabilities Monitoring (ADDM Network conducts population-based surveillance of autism spectrum disorder (ASD among 8-year old children in multiple US sites. To classify ASD, trained clinicians review developmental evaluations collected from multiple health and education sources to determine whether the child meets the ASD surveillance case criteria. The number of evaluations collected has dramatically increased since the year 2000, challenging the resources and timeliness of the surveillance system. We developed and evaluated a machine learning approach to classify case status in ADDM using words and phrases contained in children's developmental evaluations. We trained a random forest classifier using data from the 2008 Georgia ADDM site which included 1,162 children with 5,396 evaluations (601 children met ADDM ASD criteria using standard ADDM methods. The classifier used the words and phrases from the evaluations to predict ASD case status. We evaluated its performance on the 2010 Georgia ADDM surveillance data (1,450 children with 9,811 evaluations; 754 children met ADDM ASD criteria. We also estimated ASD prevalence using predictions from the classification algorithm. Overall, the machine learning approach predicted ASD case statuses that were 86.5% concordant with the clinician-determined case statuses (84.0% sensitivity, 89.4% predictive value positive. The area under the resulting receiver-operating characteristic curve was 0.932. Algorithm-derived ASD \"prevalence\" was 1.46% compared to the published (clinician-determined estimate of 1.55%. Using only the text contained in developmental evaluations, a machine learning algorithm was able to discriminate between children that do and do not meet ASD surveillance criteria at one surveillance site.\n\n\n\n\n\u00ab\n18\n19\n20\n21\n22\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n19\n20\n21\n22\n23\n\u00bb\n\n\n\n\n\n\n\n\nLearning in the machine: The symmetries of the deep learning channel.\nScience.gov (United States)\nBaldi, Pierre; Sadowski, Peter; Lu, Zhiqin\n2017-11-01\nIn a physical neural system, learning rules must be local both in space and time. In order for learning to occur, non-local information must be communicated to the deep synapses through a communication channel, the deep learning channel. We identify several possible architectures for this learning channel (Bidirectional, Conjoined, Twin, Distinct) and six symmetry challenges: (1) symmetry of architectures; (2) symmetry of weights; (3) symmetry of neurons; (4) symmetry of derivatives; (5) symmetry of processing; and (6) symmetry of learning rules. Random backpropagation (RBP) addresses the second and third symmetry, and some of its variations, such as skipped RBP (SRBP) address the first and the fourth symmetry. Here we address the last two desirable symmetries showing through simulations that they can be achieved and that the learning channel is particularly robust to symmetry variations. Specifically, random backpropagation and its variations can be performed with the same non-linear neurons used in the main input-output forward channel, and the connections in the learning channel can be adapted using the same algorithm used in the forward channel, removing the need for any specialized hardware in the learning channel. Finally, we provide mathematical results in simple cases showing that the learning equations in the forward and backward channels converge to fixed points, for almost any initial conditions. In symmetric architectures, if the weights in both channels are small at initialization, adaptation in both channels leads to weights that are essentially symmetric during and after learning. Biological connections are discussed. Copyright \u00c2\u00a9 2017 Elsevier Ltd. All rights reserved.\n\n\nAlgorithm for personal identification in distance learning system based on registration of keyboard rhythm\nScience.gov (United States)\nNikitin, P. V.; Savinov, A. N.; Bazhenov, R. I.; Sivandaev, S. V.\n2018-05-01\nThe article describes the method of identifying a person in distance learning systems based on a keyboard rhythm. An algorithm for the organization of access control is proposed, which implements authentication, identification and verification of a person using the keyboard rhythm. Authentication methods based on biometric personal parameters, including those based on the keyboard rhythm, due to the inexistence of biometric characteristics without a particular person, are able to provide an advanced accuracy and inability to refuse authorship and convenience for operators of automated systems, in comparison with other methods of conformity checking. Methods of permanent hidden keyboard monitoring allow detecting the substitution of a student and blocking the key system.\n\n\nSecondary Structure Prediction of Protein using Resilient Back Propagation Learning Algorithm\nDirectory of Open Access Journals (Sweden)\nJyotshna Dongardive\n2015-12-01\nFull Text Available The paper proposes a neural network based approach to predict secondary structure of protein. It uses Multilayer Feed Forward Network (MLFN with resilient back propagation as the learning algorithm. Point Accepted Mutation (PAM is adopted as the encoding scheme and CB396 data set is used for the training and testing of the network. Overall accuracy of the network has been experimentally calculated with different window sizes for the sliding window scheme and by varying the number of units in the hidden layer. The best results were obtained with eleven as the window size and seven as the number of units in the hidden layer.\n\n\nOn the best learning algorithm for web services response time prediction\nDEFF Research Database (Denmark)\nMadsen, Henrik; Albu, Razvan-Daniel; Popentiu-Vladicescu, Florin\n2013-01-01\nIn this article we will examine the effect of different learning algorithms, while training the MLP (Multilayer Perceptron) with the intention of predicting web services response time. Web services do not necessitate a user interface. This may seem contradictory to most people's concept of what...... an application is. A Web service is better imagined as an application \"segment,\" or better as a program enabler. Performance is an important quality aspect of Web services because of their distributed nature. Predicting the response of web services during their operation is very important....\n\n\nLearning-Based Precool Algorithms for Exploiting Foodstuff as Thermal Energy Reserve\nDEFF Research Database (Denmark)\nVinther, Kasper; Rasmussen, Henrik; Izadi-Zamanabadi, Roozbeh\n2015-01-01\nRefrigeration is important to sustain high foodstuff quality and lifetime. Keeping the foodstuff within temperature thresholds in supermarkets is also important due to legislative requirements. Failure to do so can result in discarded foodstuff, a penalty fine to the shop owner, and health issues....... However, the refrigeration system might not be dimensioned to cope with hot summer days or performance degradation over time. Two learning-based algorithms are therefore proposed for thermostatically controlled loads, which precools the foodstuff in display cases in an anticipatory manner based on how...\n\n\nA Learning Based Precool Algorithm for Utilization of Foodstuff as Thermal Energy Storage\nDEFF Research Database (Denmark)\nVinther, Kasper; Rasmussen, Henrik; Izadi-Zamanabadi, Roozbeh\n2013-01-01\nMaintaining foodstuff within predefined temperature thresholds is important due to legislative requirements and to sustain high foodstuff quality. This is achieved using a refrigeration system. However, these systems might not be dimensioned for hot summer days or possible component performance...... degradation. A learning based algorithm is proposed in this paper, which precools the foodstuff in an anticipatory manner based on the saturation level in the system on recent days. The method is evaluated using a simulation model of a supermarket refrigeration system and simulations show that thermal energy...\n\n\nMachine learning algorithm accurately detects fMRI signature of vulnerability to major depression.\nScience.gov (United States)\nSato, Jo\u00c3\u00a3o R; Moll, Jorge; Green, Sophie; Deakin, John F W; Thomaz, Carlos E; Zahn, Roland\n2015-08-30\nStandard functional magnetic resonance imaging (fMRI) analyses cannot assess the potential of a neuroimaging signature as a biomarker to predict individual vulnerability to major depression (MD). Here, we use machine learning for the first time to address this question. Using a recently identified neural signature of guilt-selective functional disconnection, the classification algorithm was able to distinguish remitted MD from control participants with 78.3% accuracy. This demonstrates the high potential of our fMRI signature as a biomarker of MD vulnerability. Crown Copyright \u00c2\u00a9 2015. Published by Elsevier Ireland Ltd. All rights reserved.\n\n\nA new evolutionary algorithm with LVQ learning for the optimization of combinatory problems as a reload of nuclear reactors\nInternational Nuclear Information System (INIS) \nMachado, Marcelo Dornellas\n1999-04-01\nGenetic algorithms are biologically motivated adaptive systems which have been used, with good results, for function optimization. In this work, a new learning mode, to be used by the Population-Based Incremental Learning (PBIL) algorithm, who combines mechanisms of standard genetic algorithm with simple competitive learning, has the aim to build a new evolutionary algorithm to be used in optimization of numerical problems and combinatorial problems. This new learning mode uses a variable learning rate during the optimization process, constituting a process know as proportional reward. The development of this new algorithm aims its application in the optimization of reload problem of PWR nuclear reactors. This problem can be interpreted as search of a load pattern to be used in the nucleus of the reactor in order to increase the useful life of the nuclear fuel. For the test, two classes of problems are used: numerical problems and combinatorial problem, the major interest relies on the last class. The results achieved with the tests indicate the applicability of the new learning mode, showing its potential as a developing tool in the solution of reload problem. (author)\n\n\nA new learning algorithm for a fully connected neuro-fuzzy inference system.\nScience.gov (United States)\nChen, C L Philip; Wang, Jing; Wang, Chi-Hsu; Chen, Long\n2014-10-01\nA traditional neuro-fuzzy system is transformed into an equivalent fully connected three layer neural network (NN), namely, the fully connected neuro-fuzzy inference systems (F-CONFIS). The F-CONFIS differs from traditional NNs by its dependent and repeated weights between input and hidden layers and can be considered as the variation of a kind of multilayer NN. Therefore, an efficient learning algorithm for the F-CONFIS to cope these repeated weights is derived. Furthermore, a dynamic learning rate is proposed for neuro-fuzzy systems via F-CONFIS where both premise (hidden) and consequent portions are considered. Several simulation results indicate that the proposed approach achieves much better accuracy and fast convergence.\n\n\nTranscriptome-guided amyloid imaging genetic analysis via a novel structured sparse learning algorithm.\nScience.gov (United States)\nYan, Jingwen; Du, Lei; Kim, Sungeun; Risacher, Shannon L; Huang, Heng; Moore, Jason H; Saykin, Andrew J; Shen, Li\n2014-09-01\nImaging genetics is an emerging field that studies the influence of genetic variation on brain structure and function. The major task is to examine the association between genetic markers such as single-nucleotide polymorphisms (SNPs) and quantitative traits (QTs) extracted from neuroimaging data. The complexity of these datasets has presented critical bioinformatics challenges that require new enabling tools. Sparse canonical correlation analysis (SCCA) is a bi-multivariate technique used in imaging genetics to identify complex multi-SNP-multi-QT associations. However, most of the existing SCCA algorithms are designed using the soft thresholding method, which assumes that the input features are independent from one another. This assumption clearly does not hold for the imaging genetic data. In this article, we propose a new knowledge-guided SCCA algorithm (KG-SCCA) to overcome this limitation as well as improve learning results by incorporating valuable prior knowledge. The proposed KG-SCCA method is able to model two types of prior knowledge: one as a group structure (e.g. linkage disequilibrium blocks among SNPs) and the other as a network structure (e.g. gene co-expression network among brain regions). The new model incorporates these prior structures by introducing new regularization terms to encourage weight similarity between grouped or connected features. A new algorithm is designed to solve the KG-SCCA model without imposing the independence constraint on the input features. We demonstrate the effectiveness of our algorithm with both synthetic and real data. For real data, using an Alzheimer's disease (AD) cohort, we examine the imaging genetic associations between all SNPs in the APOE gene (i.e. top AD gene) and amyloid deposition measures among cortical regions (i.e. a major AD hallmark). In comparison with a widely used SCCA implementation, our KG-SCCA algorithm produces not only improved cross-validation performances but also biologically meaningful\n\n\nA deep learning method for lincRNA detection using auto-encoder algorithm.\nScience.gov (United States)\nYu, Ning; Yu, Zeng; Pan, Yi\n2017-12-06\nRNA sequencing technique (RNA-seq) enables scientists to develop novel data-driven methods for discovering more unidentified lincRNAs. Meantime, knowledge-based technologies are experiencing a potential revolution ignited by the new deep learning methods. By scanning the newly found data set from RNA-seq, scientists have found that: (1) the expression of lincRNAs appears to be regulated, that is, the relevance exists along the DNA sequences; (2) lincRNAs contain some conversed patterns/motifs tethered together by non-conserved regions. The two evidences give the reasoning for adopting knowledge-based deep learning methods in lincRNA detection. Similar to coding region transcription, non-coding regions are split at transcriptional sites. However, regulatory RNAs rather than message RNAs are generated. That is, the transcribed RNAs participate the biological process as regulatory units instead of generating proteins. Identifying these transcriptional regions from non-coding regions is the first step towards lincRNA recognition. The auto-encoder method achieves 100% and 92.4% prediction accuracy on transcription sites over the putative data sets. The experimental results also show the excellent performance of predictive deep neural network on the lincRNA data sets compared with support vector machine and traditional neural network. In addition, it is validated through the newly discovered lincRNA data set and one unreported transcription site is found by feeding the whole annotated sequences through the deep learning machine, which indicates that deep learning method has the extensive ability for lincRNA prediction. The transcriptional sequences of lincRNAs are collected from the annotated human DNA genome data. Subsequently, a two-layer deep neural network is developed for the lincRNA detection, which adopts the auto-encoder algorithm and utilizes different encoding schemes to obtain the best performance over intergenic DNA sequence data. Driven by those newly\n\n\nConvolutional Neural Network Based on Extreme Learning Machine for Maritime Ships Recognition in Infrared Images.\nScience.gov (United States)\nKhellal, Atmane; Ma, Hongbin; Fei, Qing\n2018-05-09\nThe success of Deep Learning models, notably convolutional neural networks (CNNs), makes them the favorable solution for object recognition systems in both visible and infrared domains. However, the lack of training data in the case of maritime ships research leads to poor performance due to the problem of overfitting. In addition, the back-propagation algorithm used to train CNN is very slow and requires tuning many hyperparameters. To overcome these weaknesses, we introduce a new approach fully based on Extreme Learning Machine (ELM) to learn useful CNN features and perform a fast and accurate classification, which is suitable for infrared-based recognition systems. The proposed approach combines an ELM based learning algorithm to train CNN for discriminative features extraction and an ELM based ensemble for classification. The experimental results on VAIS dataset, which is the largest dataset of maritime ships, confirm that the proposed approach outperforms the state-of-the-art models in term of generalization performance and training speed. For instance, the proposed model is up to 950 times faster than the traditional back-propagation based training of convolutional neural networks, primarily for low-level features extraction.\n\n\nOn the use of harmony search algorithm in the training of wavelet neural networks\nScience.gov (United States)\nLai, Kee Huong; Zainuddin, Zarita; Ong, Pauline\n2015-10-01\nWavelet neural networks (WNNs) are a class of feedforward neural networks that have been used in a wide range of industrial and engineering applications to model the complex relationships between the given inputs and outputs. The training of WNNs involves the configuration of the weight values between neurons. The backpropagation training algorithm, which is a gradient-descent method, can be used for this training purpose. Nonetheless, the solutions found by this algorithm often get trapped at local minima. In this paper, a harmony search-based algorithm is proposed for the training of WNNs. The training of WNNs, thus can be formulated as a continuous optimization problem, where the objective is to maximize the overall classification accuracy. Each candidate solution proposed by the harmony search algorithm represents a specific WNN architecture. In order to speed up the training process, the solution space is divided into disjoint partitions during the random initialization step of harmony search algorithm. The proposed training algorithm is tested onthree benchmark problems from the UCI machine learning repository, as well as one real life application, namely, the classification of electroencephalography signals in the task of epileptic seizure detection. The results obtained show that the proposed algorithm outperforms the traditional harmony search algorithm in terms of overall classification accuracy.\n\n\nMachine learning algorithms for mode-of-action classification in toxicity assessment.\nScience.gov (United States)\nZhang, Yile; Wong, Yau Shu; Deng, Jian; Anton, Cristina; Gabos, Stephan; Zhang, Weiping; Huang, Dorothy Yu; Jin, Can\n2016-01-01\nReal Time Cell Analysis (RTCA) technology is used to monitor cellular changes continuously over the entire exposure period. Combining with different testing concentrations, the profiles have potential in probing the mode of action (MOA) of the testing substances. In this paper, we present machine learning approaches for MOA assessment. Computational tools based on artificial neural network (ANN) and support vector machine (SVM) are developed to analyze the time-concentration response curves (TCRCs) of human cell lines responding to tested chemicals. The techniques are capable of learning data from given TCRCs with known MOA information and then making MOA classification for the unknown toxicity. A novel data processing step based on wavelet transform is introduced to extract important features from the original TCRC data. From the dose response curves, time interval leading to higher classification success rate can be selected as input to enhance the performance of the machine learning algorithm. This is particularly helpful when handling cases with limited and imbalanced data. The validation of the proposed method is demonstrated by the supervised learning algorithm applied to the exposure data of HepG2 cell line to 63 chemicals with 11 concentrations in each test case. Classification success rate in the range of 85 to 95 % are obtained using SVM for MOA classification with two clusters to cases up to four clusters. Wavelet transform is capable of capturing important features of TCRCs for MOA classification. The proposed SVM scheme incorporated with wavelet transform has a great potential for large scale MOA classification and high-through output chemical screening.\n\n\nOcean wave parameters estimation using backpropagation neural networks\nDigital Repository Service at National Institute of Oceanography (India)\nMandal, S.; SubbaRao; Raju, D.H.\n\n: the RPROP algorithm. San Francisco: ICNN; 1993. p. 586\u00e2\u20ac\u201c591. [15] Demuth H, Beale M. Neural network toolbox for use with MATLAB, user guide. USA: The Math Works Inc.; 2000 (http://www.mathworks.com). [16] Baba M, Dattatri J. Ocean wave spectra off cochin...\n\n\nA Fast C++ Implementation of Neural Network Backpropagation Training Algorithm: Application to Bayesian Optimal Image Demosaicing\nDirectory of Open Access Journals (Sweden)\nYi-Qing Wang\n2015-09-01\nFull Text Available Recent years have seen a surge of interest in multilayer neural networks fueled by their successful applications in numerous image processing and computer vision tasks. In this article, we describe a C++ implementation of the stochastic gradient descent to train a multilayer neural network, where a fast and accurate acceleration of tanh(\u00c2\u00b7 is achieved with linear interpolation. As an example of application, we present a neural network able to deliver state-of-the-art performance in image demosaicing.\n\n\nPEDLA: predicting enhancers with a deep learning-based algorithmic framework.\nScience.gov (United States)\nLiu, Feng; Li, Hao; Ren, Chao; Bo, Xiaochen; Shu, Wenjie\n2016-06-22\nTranscriptional enhancers are non-coding segments of DNA that play a central role in the spatiotemporal regulation of gene expression programs. However, systematically and precisely predicting enhancers remain a major challenge. Although existing methods have achieved some success in enhancer prediction, they still suffer from many issues. We developed a deep learning-based algorithmic framework named PEDLA (https://github.com/wenjiegroup/PEDLA), which can directly learn an enhancer predictor from massively heterogeneous data and generalize in ways that are mostly consistent across various cell types/tissues. We first trained PEDLA with 1,114-dimensional heterogeneous features in H1 cells, and demonstrated that PEDLA framework integrates diverse heterogeneous features and gives state-of-the-art performance relative to five existing methods for enhancer prediction. We further extended PEDLA to iteratively learn from 22 training cell types/tissues. Our results showed that PEDLA manifested superior performance consistency in both training and independent test sets. On average, PEDLA achieved 95.0% accuracy and a 96.8% geometric mean (GM) of sensitivity and specificity across 22 training cell types/tissues, as well as 95.7% accuracy and a 96.8% GM across 20 independent test cell types/tissues. Together, our work illustrates the power of harnessing state-of-the-art deep learning techniques to consistently identify regulatory elements at a genome-wide scale from massively heterogeneous data across diverse cell types/tissues.\n\n\nSemi-supervised prediction of gene regulatory networks using machine learning algorithms.\nScience.gov (United States)\nPatel, Nihir; Wang, Jason T L\n2015-10-01\nUse of computational methods to predict gene regulatory networks (GRNs) from gene expression data is a challenging task. Many studies have been conducted using unsupervised methods to fulfill the task; however, such methods usually yield low prediction accuracies due to the lack of training data. In this article, we propose semi-supervised methods for GRN prediction by utilizing two machine learning algorithms, namely, support vector machines (SVM) and random forests (RF). The semi-supervised methods make use of unlabelled data for training. We investigated inductive and transductive learning approaches, both of which adopt an iterative procedure to obtain reliable negative training data from the unlabelled data. We then applied our semi-supervised methods to gene expression data of Escherichia coli and Saccharomyces cerevisiae, and evaluated the performance of our methods using the expression data. Our analysis indicated that the transductive learning approach outperformed the inductive learning approach for both organisms. However, there was no conclusive difference identified in the performance of SVM and RF. Experimental results also showed that the proposed semi-supervised methods performed better than existing supervised methods for both organisms.\n\n\nThe development of interactive multimedia based on auditory, intellectually, repetition in repetition algorithm learning to increase learning outcome\nScience.gov (United States)\nMunir; Sutarno, H.; Aisyah, N. S.\n2018-05-01\nThis research aims to find out how the development of interactive multimedia based on auditory, intellectually, and repetition can improve student learning outcomes. This interactive multimedia is developed through 5 stages. Analysis stages include the study of literature, questionnaire, interviews and observations. The design phase is done by the database design, flowchart, storyboards and repetition algorithm material while the development phase is done by the creation of web-based framework. Presentation material is adapted to the model of learning such as auditory, intellectually, repetition. Auditory points are obtained by recording the narrative material that presented by a variety of intellectual points. Multimedia as a product is validated by material and media experts. Implementation phase conducted on grade XI-TKJ2 SMKN 1 Garut. Based on index\u00e2\u20ac\u2122s gain, an increasing of student learning outcomes in this study is 0.46 which is fair due to interest of student in using interactive multimedia. While the multimedia assessment earned 84.36% which is categorized as very well.\n\n\nApplication of Reinforcement Learning in Cognitive Radio Networks: Models and Algorithms\nDirectory of Open Access Journals (Sweden)\nKok-Lim Alvin Yau\n2014-01-01\nFull Text Available Cognitive radio (CR enables unlicensed users to exploit the underutilized spectrum in licensed spectrum whilst minimizing interference to licensed users. Reinforcement learning (RL, which is an artificial intelligence approach, has been applied to enable each unlicensed user to observe and carry out optimal actions for performance enhancement in a wide range of schemes in CR, such as dynamic channel selection and channel sensing. This paper presents new discussions of RL in the context of CR networks. It provides an extensive review on how most schemes have been approached using the traditional and enhanced RL algorithms through state, action, and reward representations. Examples of the enhancements on RL, which do not appear in the traditional RL approach, are rules and cooperative learning. This paper also reviews performance enhancements brought about by the RL algorithms and open issues. This paper aims to establish a foundation in order to spark new research interests in this area. Our discussion has been presented in a tutorial manner so that it is comprehensive to readers outside the specialty of RL and CR.\n\n\n\n\n\u00ab\n19\n20\n21\n22\n23\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n20\n21\n22\n23\n24\n\u00bb\n\n\n\n\n\n\n\n\nBrake fault diagnosis using Clonal Selection Classification Algorithm (CSCA \u00e2\u20ac\u201c A statistical learning approach\nDirectory of Open Access Journals (Sweden)\nR. Jegadeeshwaran\n2015-03-01\nFull Text Available In automobile, brake system is an essential part responsible for control of the vehicle. Any failure in the brake system impacts the vehicle's motion. It will generate frequent catastrophic effects on the vehicle cum passenger's safety. Thus the brake system plays a vital role in an automobile and hence condition monitoring of the brake system is essential. Vibration based condition monitoring using machine learning techniques are gaining momentum. This study is one such attempt to perform the condition monitoring of a hydraulic brake system through vibration analysis. In this research, the performance of a Clonal Selection Classification Algorithm (CSCA for brake fault diagnosis has been reported. A hydraulic brake system test rig was fabricated. Under good and faulty conditions of a brake system, the vibration signals were acquired using a piezoelectric transducer. The statistical parameters were extracted from the vibration signal. The best feature set was identified for classification using attribute evaluator. The selected features were then classified using CSCA. The classification accuracy of such artificial intelligence technique has been compared with other machine learning approaches and discussed. The Clonal Selection Classification Algorithm performs better and gives the maximum classification accuracy (96% for the fault diagnosis of a hydraulic brake system.\n\n\nDevelopment of Predictive QSAR Models of 4-Thiazolidinones Antitrypanosomal Activity using Modern Machine Learning Algorithms.\nScience.gov (United States)\nKryshchyshyn, Anna; Devinyak, Oleg; Kaminskyy, Danylo; Grellier, Philippe; Lesyk, Roman\n2017-11-14\nThis paper presents novel QSAR models for the prediction of antitrypanosomal activity among thiazolidines and related heterocycles. The performance of four machine learning algorithms: Random Forest regression, Stochastic gradient boosting, Multivariate adaptive regression splines and Gaussian processes regression have been studied in order to reach better levels of predictivity. The results for Random Forest and Gaussian processes regression are comparable and outperform other studied methods. The preliminary descriptor selection with Boruta method improved the outcome of machine learning methods. The two novel QSAR-models developed with Random Forest and Gaussian processes regression algorithms have good predictive ability, which was proved by the external evaluation of the test set with corresponding Q 2 ext =0.812 and Q 2 ext =0.830. The obtained models can be used further for in silico screening of virtual libraries in the same chemical domain in order to find new antitrypanosomal agents. Thorough analysis of descriptors influence in the QSAR models and interpretation of their chemical meaning allows to highlight a number of structure-activity relationships. The presence of phenyl rings with electron-withdrawing atoms or groups in para-position, increased number of aromatic rings, high branching but short chains, high HOMO energy, and the introduction of 1-substituted 2-indolyl fragment into the molecular structure have been recognized as trypanocidal activity prerequisites. \u00c2\u00a9 2017 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim.\n\n\nCell segmentation in histopathological images with deep learning algorithms by utilizing spatial relationships.\nScience.gov (United States)\nHatipoglu, Nuh; Bilgin, Gokhan\n2017-10-01\nIn many computerized methods for cell detection, segmentation, and classification in digital histopathology that have recently emerged, the task of cell segmentation remains a chief problem for image processing in designing computer-aided diagnosis (CAD) systems. In research and diagnostic studies on cancer, pathologists can use CAD systems as second readers to analyze high-resolution histopathological images. Since cell detection and segmentation are critical for cancer grade assessments, cellular and extracellular structures should primarily be extracted from histopathological images. In response, we sought to identify a useful cell segmentation approach with histopathological images that uses not only prominent deep learning algorithms (i.e., convolutional neural networks, stacked autoencoders, and deep belief networks), but also spatial relationships, information of which is critical for achieving better cell segmentation results. To that end, we collected cellular and extracellular samples from histopathological images by windowing in small patches with various sizes. In experiments, the segmentation accuracies of the methods used improved as the window sizes increased due to the addition of local spatial and contextual information. Once we compared the effects of training sample size and influence of window size, results revealed that the deep learning algorithms, especially convolutional neural networks and partly stacked autoencoders, performed better than conventional methods in cell segmentation.\n\n\nShort-Term Solar Forecasting Performance of Popular Machine Learning Algorithms: Preprint\nEnergy Technology Data Exchange (ETDEWEB)\nFlorita, Anthony R [National Renewable Energy Laboratory (NREL), Golden, CO (United States); Elgindy, Tarek [National Renewable Energy Laboratory (NREL), Golden, CO (United States); Hodge, Brian S [National Renewable Energy Laboratory (NREL), Golden, CO (United States); Dobbs, Alex [National Renewable Energy Laboratory (NREL), Golden, CO (United States)\n2017-10-03\nA framework for assessing the performance of short-term solar forecasting is presented in conjunction with a range of numerical results using global horizontal irradiation (GHI) from the open-source Surface Radiation Budget (SURFRAD) data network. A suite of popular machine learning algorithms is compared according to a set of statistically distinct metrics and benchmarked against the persistence-of-cloudiness forecast and a cloud motion forecast. Results show significant improvement compared to the benchmarks with trade-offs among the machine learning algorithms depending on the desired error metric. Training inputs include time series observations of GHI for a history of years, historical weather and atmospheric measurements, and corresponding date and time stamps such that training sensitivities might be inferred. Prediction outputs are GHI forecasts for 1, 2, 3, and 4 hours ahead of the issue time, and they are made for every month of the year for 7 locations. Photovoltaic power and energy outputs can then be made using the solar forecasts to better understand power system impacts.\n\n\nA measurement fusion method for nonlinear system identification using a cooperative learning algorithm.\nScience.gov (United States)\nXia, Youshen; Kamel, Mohamed S\n2007-06-01\nIdentification of a general nonlinear noisy system viewed as an estimation of a predictor function is studied in this article. A measurement fusion method for the predictor function estimate is proposed. In the proposed scheme, observed data are first fused by using an optimal fusion technique, and then the optimal fused data are incorporated in a nonlinear function estimator based on a robust least squares support vector machine (LS-SVM). A cooperative learning algorithm is proposed to implement the proposed measurement fusion method. Compared with related identification methods, the proposed method can minimize both the approximation error and the noise error. The performance analysis shows that the proposed optimal measurement fusion function estimate has a smaller mean square error than the LS-SVM function estimate. Moreover, the proposed cooperative learning algorithm can converge globally to the optimal measurement fusion function estimate. Finally, the proposed measurement fusion method is applied to ARMA signal and spatial temporal signal modeling. Experimental results show that the proposed measurement fusion method can provide a more accurate model.\n\n\nOpen source machine-learning algorithms for the prediction of optimal cancer drug therapies.\nScience.gov (United States)\nHuang, Cai; Mezencev, Roman; McDonald, John F; Vannberg, Fredrik\n2017-01-01\nPrecision medicine is a rapidly growing area of modern medical science and open source machine-learning codes promise to be a critical component for the successful development of standardized and automated analysis of patient data. One important goal of precision cancer medicine is the accurate prediction of optimal drug therapies from the genomic profiles of individual patient tumors. We introduce here an open source software platform that employs a highly versatile support vector machine (SVM) algorithm combined with a standard recursive feature elimination (RFE) approach to predict personalized drug responses from gene expression profiles. Drug specific models were built using gene expression and drug response data from the National Cancer Institute panel of 60 human cancer cell lines (NCI-60). The models are highly accurate in predicting the drug responsiveness of a variety of cancer cell lines including those comprising the recent NCI-DREAM Challenge. We demonstrate that predictive accuracy is optimized when the learning dataset utilizes all probe-set expression values from a diversity of cancer cell types without pre-filtering for genes generally considered to be \"drivers\" of cancer onset/progression. Application of our models to publically available ovarian cancer (OC) patient gene expression datasets generated predictions consistent with observed responses previously reported in the literature. By making our algorithm \"open source\", we hope to facilitate its testing in a variety of cancer types and contexts leading to community-driven improvements and refinements in subsequent applications.\n\n\nAutomated Quality Assessment of Structural Magnetic Resonance Brain Images Based on a Supervised Machine Learning Algorithm\nDirectory of Open Access Journals (Sweden)\nRicardo Andres Pizarro\n2016-12-01\nFull Text Available High-resolution three-dimensional magnetic resonance imaging (3D-MRI is being increasingly used to delineate morphological changes underlying neuropsychiatric disorders. Unfortunately, artifacts frequently compromise the utility of 3D-MRI yielding irreproducible results, from both type I and type II errors. It is therefore critical to screen 3D-MRIs for artifacts before use. Currently, quality assessment involves slice-wise visual inspection of 3D-MRI volumes, a procedure that is both subjective and time consuming. Automating the quality rating of 3D-MRI could improve the efficiency and reproducibility of the procedure. The present study is one of the first efforts to apply a support vector machine (SVM algorithm in the quality assessment of structural brain images, using global and region of interest (ROI automated image quality features developed in-house. SVM is a supervised machine-learning algorithm that can predict the category of test datasets based on the knowledge acquired from a learning dataset. The performance (accuracy of the automated SVM approach was assessed, by comparing the SVM-predicted quality labels to investigator-determined quality labels. The accuracy for classifying 1457 3D-MRI volumes from our database using the SVM approach is around 80%. These results are promising and illustrate the possibility of using SVM as an automated quality assessment tool for 3D-MRI.\n\n\nAutomated Quality Assessment of Structural Magnetic Resonance Brain Images Based on a Supervised Machine Learning Algorithm.\nScience.gov (United States)\nPizarro, Ricardo A; Cheng, Xi; Barnett, Alan; Lemaitre, Herve; Verchinski, Beth A; Goldman, Aaron L; Xiao, Ena; Luo, Qian; Berman, Karen F; Callicott, Joseph H; Weinberger, Daniel R; Mattay, Venkata S\n2016-01-01\nHigh-resolution three-dimensional magnetic resonance imaging (3D-MRI) is being increasingly used to delineate morphological changes underlying neuropsychiatric disorders. Unfortunately, artifacts frequently compromise the utility of 3D-MRI yielding irreproducible results, from both type I and type II errors. It is therefore critical to screen 3D-MRIs for artifacts before use. Currently, quality assessment involves slice-wise visual inspection of 3D-MRI volumes, a procedure that is both subjective and time consuming. Automating the quality rating of 3D-MRI could improve the efficiency and reproducibility of the procedure. The present study is one of the first efforts to apply a support vector machine (SVM) algorithm in the quality assessment of structural brain images, using global and region of interest (ROI) automated image quality features developed in-house. SVM is a supervised machine-learning algorithm that can predict the category of test datasets based on the knowledge acquired from a learning dataset. The performance (accuracy) of the automated SVM approach was assessed, by comparing the SVM-predicted quality labels to investigator-determined quality labels. The accuracy for classifying 1457 3D-MRI volumes from our database using the SVM approach is around 80%. These results are promising and illustrate the possibility of using SVM as an automated quality assessment tool for 3D-MRI.\n\n\nOpen source machine-learning algorithms for the prediction of optimal cancer drug therapies.\nDirectory of Open Access Journals (Sweden)\nCai Huang\n\nFull Text Available Precision medicine is a rapidly growing area of modern medical science and open source machine-learning codes promise to be a critical component for the successful development of standardized and automated analysis of patient data. One important goal of precision cancer medicine is the accurate prediction of optimal drug therapies from the genomic profiles of individual patient tumors. We introduce here an open source software platform that employs a highly versatile support vector machine (SVM algorithm combined with a standard recursive feature elimination (RFE approach to predict personalized drug responses from gene expression profiles. Drug specific models were built using gene expression and drug response data from the National Cancer Institute panel of 60 human cancer cell lines (NCI-60. The models are highly accurate in predicting the drug responsiveness of a variety of cancer cell lines including those comprising the recent NCI-DREAM Challenge. We demonstrate that predictive accuracy is optimized when the learning dataset utilizes all probe-set expression values from a diversity of cancer cell types without pre-filtering for genes generally considered to be \"drivers\" of cancer onset/progression. Application of our models to publically available ovarian cancer (OC patient gene expression datasets generated predictions consistent with observed responses previously reported in the literature. By making our algorithm \"open source\", we hope to facilitate its testing in a variety of cancer types and contexts leading to community-driven improvements and refinements in subsequent applications.\n\n\nUsing Deep Learning Algorithm to Enhance Image-review Software for Surveillance Cameras\nEnergy Technology Data Exchange (ETDEWEB)\nCui, Yonggang\n2018-05-07\nWe propose the development of proven deep learning algorithms to flag objects and events of interest in Next Generation Surveillance System (NGSS) surveillance to make IAEA image review more efficient. Video surveillance is one of the core monitoring technologies used by the IAEA Department of Safeguards when implementing safeguards at nuclear facilities worldwide. The current image review software GARS has limited automated functions, such as scene-change detection, black image detection and missing scene analysis, but struggles with highly cluttered backgrounds. A cutting-edge algorithm to be developed in this project will enable efficient and effective searches in images and video streams by identifying and tracking safeguards relevant objects and detect anomalies in their vicinity. In this project, we will develop the algorithm, test it with the IAEA surveillance cameras and data sets collected at simulated nuclear facilities at BNL and SNL, and implement it in a software program for potential integration into the IAEA\u00e2\u20ac\u2122s IRAP (Integrated Review and Analysis Program).\n\n\nBasis Expansion Approaches for Regularized Sequential Dictionary Learning Algorithms With Enforced Sparsity for fMRI Data Analysis.\nScience.gov (United States)\nSeghouane, Abd-Krim; Iqbal, Asif\n2017-09-01\nSequential dictionary learning algorithms have been successfully applied to functional magnetic resonance imaging (fMRI) data analysis. fMRI data sets are, however, structured data matrices with the notions of temporal smoothness in the column direction. This prior information, which can be converted into a constraint of smoothness on the learned dictionary atoms, has seldomly been included in classical dictionary learning algorithms when applied to fMRI data analysis. In this paper, we tackle this problem by proposing two new sequential dictionary learning algorithms dedicated to fMRI data analysis by accounting for this prior information. These algorithms differ from the existing ones in their dictionary update stage. The steps of this stage are derived as a variant of the power method for computing the SVD. The proposed algorithms generate regularized dictionary atoms via the solution of a left regularized rank-one matrix approximation problem where temporal smoothness is enforced via regularization through basis expansion and sparse basis expansion in the dictionary update stage. Applications on synthetic data experiments and real fMRI data sets illustrating the performance of the proposed algorithms are provided.\n\n\nCorticostriatal circuit mechanisms of value-based action selection: Implementation of reinforcement learning algorithms and beyond.\nScience.gov (United States)\nMorita, Kenji; Jitsev, Jenia; Morrison, Abigail\n2016-09-15\nValue-based action selection has been suggested to be realized in the corticostriatal local circuits through competition among neural populations. In this article, we review theoretical and experimental studies that have constructed and verified this notion, and provide new perspectives on how the local-circuit selection mechanisms implement reinforcement learning (RL) algorithms and computations beyond them. The striatal neurons are mostly inhibitory, and lateral inhibition among them has been classically proposed to realize \"Winner-Take-All (WTA)\" selection of the maximum-valued action (i.e., 'max' operation). Although this view has been challenged by the revealed weakness, sparseness, and asymmetry of lateral inhibition, which suggest more complex dynamics, WTA-like competition could still occur on short time scales. Unlike the striatal circuit, the cortical circuit contains recurrent excitation, which may enable retention or temporal integration of information and probabilistic \"soft-max\" selection. The striatal \"max\" circuit and the cortical \"soft-max\" circuit might co-implement an RL algorithm called Q-learning; the cortical circuit might also similarly serve for other algorithms such as SARSA. In these implementations, the cortical circuit presumably sustains activity representing the executed action, which negatively impacts dopamine neurons so that they can calculate reward-prediction-error. Regarding the suggested more complex dynamics of striatal, as well as cortical, circuits on long time scales, which could be viewed as a sequence of short WTA fragments, computational roles remain open: such a sequence might represent (1) sequential state-action-state transitions, constituting replay or simulation of the internal model, (2) a single state/action by the whole trajectory, or (3) probabilistic sampling of state/action. Copyright \u00c2\u00a9 2016. Published by Elsevier B.V.\n\n\nClassification and authentication of unknown water samples using machine learning algorithms.\nScience.gov (United States)\nKundu, Palash K; Panchariya, P C; Kundu, Madhusree\n2011-07-01\nThis paper proposes the development of water sample classification and authentication, in real life which is based on machine learning algorithms. The proposed techniques used experimental measurements from a pulse voltametry method which is based on an electronic tongue (E-tongue) instrumentation system with silver and platinum electrodes. E-tongue include arrays of solid state ion sensors, transducers even of different types, data collectors and data analysis tools, all oriented to the classification of liquid samples and authentication of unknown liquid samples. The time series signal and the corresponding raw data represent the measurement from a multi-sensor system. The E-tongue system, implemented in a laboratory environment for 6 numbers of different ISI (Bureau of Indian standard) certified water samples (Aquafina, Bisleri, Kingfisher, Oasis, Dolphin, and McDowell) was the data source for developing two types of machine learning algorithms like classification and regression. A water data set consisting of 6 numbers of sample classes containing 4402 numbers of features were considered. A PCA (principal component analysis) based classification and authentication tool was developed in this study as the machine learning component of the E-tongue system. A proposed partial least squares (PLS) based classifier, which was dedicated as well; to authenticate a specific category of water sample evolved out as an integral part of the E-tongue instrumentation system. The developed PCA and PLS based E-tongue system emancipated an overall encouraging authentication percentage accuracy with their excellent performances for the aforesaid categories of water samples. Copyright \u00c2\u00a9 2011 ISA. Published by Elsevier Ltd. All rights reserved.\n\n\nThe island model for parallel implementation of evolutionary algorithm of Population-Based Incremental Learning (PBIL) optimization\nInternational Nuclear Information System (INIS) \nLima, Alan M.M. de; Schirru, Roberto\n2000-01-01\nGenetic algorithms are biologically motivated adaptive systems which have been used, with good results, for function optimization. The purpose of this work is to introduce a new parallelization method to be applied to the Population-Based Incremental Learning (PBIL) algorithm. PBIL combines standard genetic algorithm mechanisms with simple competitive learning and has ben successfully used in combinatorial optimization problems. The development of this algorithm aims its application to the reload optimization of PWR nuclear reactors. Tests have been performed with combinatorial optimization problems similar to the reload problem. Results are compared to the serial PBIL ones, showing the new method's superiority and its viability as a tool for the nuclear core reload problem solution. (author)\n\n\nSupervised machine learning algorithms to diagnose stress for vehicle drivers based on physiological sensor signals.\nScience.gov (United States)\nBarua, Shaibal; Begum, Shahina; Ahmed, Mobyen Uddin\n2015-01-01\nMachine learning algorithms play an important role in computer science research. Recent advancement in sensor data collection in clinical sciences lead to a complex, heterogeneous data processing, and analysis for patient diagnosis and prognosis. Diagnosis and treatment of patients based on manual analysis of these sensor data are difficult and time consuming. Therefore, development of Knowledge-based systems to support clinicians in decision-making is important. However, it is necessary to perform experimental work to compare performances of different machine learning methods to help to select appropriate method for a specific characteristic of data sets. This paper compares classification performance of three popular machine learning methods i.e., case-based reasoning, neutral networks and support vector machine to diagnose stress of vehicle drivers using finger temperature and heart rate variability. The experimental results show that case-based reasoning outperforms other two methods in terms of classification accuracy. Case-based reasoning has achieved 80% and 86% accuracy to classify stress using finger temperature and heart rate variability. On contrary, both neural network and support vector machine have achieved less than 80% accuracy by using both physiological signals.\n\n\nIdentification of Differentially Expressed Genes between Original Breast Cancer and Xenograft Using Machine Learning Algorithms\nDirectory of Open Access Journals (Sweden)\nDeling Wang\n2018-03-01\nFull Text Available Breast cancer is one of the most common malignancies in women. Patient-derived tumor xenograft (PDX model is a cutting-edge approach for drug research on breast cancer. However, PDX still exhibits differences from original human tumors, thereby challenging the molecular understanding of tumorigenesis. In particular, gene expression changes after tissues are transplanted from human to mouse model. In this study, we propose a novel computational method by incorporating several machine learning algorithms, including Monte Carlo feature selection (MCFS, random forest (RF, and rough set-based rule learning, to identify genes with significant expression differences between PDX and original human tumors. First, 831 breast tumors, including 657 PDX and 174 human tumors, were collected. Based on MCFS and RF, 32 genes were then identified to be informative for the prediction of PDX and human tumors and can be used to construct a prediction model. The prediction model exhibits a Matthews coefficient correlation value of 0.777. Seven interpretable interactions within the informative gene were detected based on the rough set-based rule learning. Furthermore, the seven interpretable interactions can be well supported by previous experimental studies. Our study not only presents a method for identifying informative genes with differential expression but also provides insights into the mechanism through which gene expression changes after being transplanted from human tumor into mouse model. This work would be helpful for research and drug development for breast cancer.\n\n\nIdentification of Differentially Expressed Genes between Original Breast Cancer and Xenograft Using Machine Learning Algorithms.\nScience.gov (United States)\nWang, Deling; Li, Jia-Rui; Zhang, Yu-Hang; Chen, Lei; Huang, Tao; Cai, Yu-Dong\n2018-03-12\nBreast cancer is one of the most common malignancies in women. Patient-derived tumor xenograft (PDX) model is a cutting-edge approach for drug research on breast cancer. However, PDX still exhibits differences from original human tumors, thereby challenging the molecular understanding of tumorigenesis. In particular, gene expression changes after tissues are transplanted from human to mouse model. In this study, we propose a novel computational method by incorporating several machine learning algorithms, including Monte Carlo feature selection (MCFS), random forest (RF), and rough set-based rule learning, to identify genes with significant expression differences between PDX and original human tumors. First, 831 breast tumors, including 657 PDX and 174 human tumors, were collected. Based on MCFS and RF, 32 genes were then identified to be informative for the prediction of PDX and human tumors and can be used to construct a prediction model. The prediction model exhibits a Matthews coefficient correlation value of 0.777. Seven interpretable interactions within the informative gene were detected based on the rough set-based rule learning. Furthermore, the seven interpretable interactions can be well supported by previous experimental studies. Our study not only presents a method for identifying informative genes with differential expression but also provides insights into the mechanism through which gene expression changes after being transplanted from human tumor into mouse model. This work would be helpful for research and drug development for breast cancer.\n\n\nNovel maximum-margin training algorithms for supervised neural networks.\nScience.gov (United States)\nLudwig, Oswaldo; Nunes, Urbano\n2010-06-01\nThis paper proposes three novel training methods, two of them based on the backpropagation approach and a third one based on information theory for multilayer perceptron (MLP) binary classifiers. Both backpropagation methods are based on the maximal-margin (MM) principle. The first one, based on the gradient descent with adaptive learning rate algorithm (GDX) and named maximum-margin GDX (MMGDX), directly increases the margin of the MLP output-layer hyperplane. The proposed method jointly optimizes both MLP layers in a single process, backpropagating the gradient of an MM-based objective function, through the output and hidden layers, in order to create a hidden-layer space that enables a higher margin for the output-layer hyperplane, avoiding the testing of many arbitrary kernels, as occurs in case of support vector machine (SVM) training. The proposed MM-based objective function aims to stretch out the margin to its limit. An objective function based on Lp-norm is also proposed in order to take into account the idea of support vectors, however, overcoming the complexity involved in solving a constrained optimization problem, usually in SVM training. In fact, all the training methods proposed in this paper have time and space complexities O(N) while usual SVM training methods have time complexity O(N (3)) and space complexity O(N (2)) , where N is the training-data-set size. The second approach, named minimization of interclass interference (MICI), has an objective function inspired on the Fisher discriminant analysis. Such algorithm aims to create an MLP hidden output where the patterns have a desirable statistical distribution. In both training methods, the maximum area under ROC curve (AUC) is applied as stop criterion. The third approach offers a robust training framework able to take the best of each proposed training method. The main idea is to compose a neural model by using neurons extracted from three other neural networks, each one previously trained by\n\n\nAlgorithmic analysis of relational learning processes in instructional technology: Some implications for basic, translational, and applied research.\nScience.gov (United States)\nMcIlvane, William J; Kledaras, Joanne B; Gerard, Christophe J; Wilde, Lorin; Smelson, David\n2018-07-01\nA few noteworthy exceptions notwithstanding, quantitative analyses of relational learning are most often simple descriptive measures of study outcomes. For example, studies of stimulus equivalence have made much progress using measures such as percentage consistent with equivalence relations, discrimination ratio, and response latency. Although procedures may have ad hoc variations, they remain fairly similar across studies. Comparison studies of training variables that lead to different outcomes are few. Yet to be developed are tools designed specifically for dynamic and/or parametric analyses of relational learning processes. This paper will focus on recent studies to develop (1) quality computer-based programmed instruction for supporting relational learning in children with autism spectrum disorders and intellectual disabilities and (2) formal algorithms that permit ongoing, dynamic assessment of learner performance and procedure changes to optimize instructional efficacy and efficiency. Because these algorithms have a strong basis in evidence and in theories of stimulus control, they may have utility also for basic and translational research. We present an overview of the research program, details of algorithm features, and summary results that illustrate their possible benefits. It also presents arguments that such algorithm development may encourage parametric research, help in integrating new research findings, and support in-depth quantitative analyses of stimulus control processes in relational learning. Such algorithms may also serve to model control of basic behavioral processes that is important to the design of effective programmed instruction for human learners with and without functional disabilities. Copyright \u00c2\u00a9 2018 Elsevier B.V. All rights reserved.\n\n\nA Large-Scale Multi-Hop Localization Algorithm Based on Regularized Extreme Learning for Wireless Networks.\nScience.gov (United States)\nZheng, Wei; Yan, Xiaoyong; Zhao, Wei; Qian, Chengshan\n2017-12-20\nA novel large-scale multi-hop localization algorithm based on regularized extreme learning is proposed in this paper. The large-scale multi-hop localization problem is formulated as a learning problem. Unlike other similar localization algorithms, the proposed algorithm overcomes the shortcoming of the traditional algorithms which are only applicable to an isotropic network, therefore has a strong adaptability to the complex deployment environment. The proposed algorithm is composed of three stages: data acquisition, modeling and location estimation. In data acquisition stage, the training information between nodes of the given network is collected. In modeling stage, the model among the hop-counts and the physical distances between nodes is constructed using regularized extreme learning. In location estimation stage, each node finds its specific location in a distributed manner. Theoretical analysis and several experiments show that the proposed algorithm can adapt to the different topological environments with low computational cost. Furthermore, high accuracy can be achieved by this method without setting complex parameters.\n\n\n\n\n\u00ab\n20\n21\n22\n23\n24\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n21\n22\n23\n24\n25\n\u00bb\n\n\n\n\n\n\n\n\nHybrid attribute-based recommender system for learning material using genetic algorithm and a multidimensional information model\nDirectory of Open Access Journals (Sweden)\nMojtaba Salehi\n2013-03-01\nFull Text Available In recent years, the explosion of learning materials in the web-based educational systems has caused difficulty of locating appropriate learning materials to learners. A personalized recommendation is an enabling mechanism to overcome information overload occurred in the new learning environments and deliver suitable materials to learners. Since users express their opinions based on some specific attributes of items, this paper proposes a hybrid recommender system for learning materials based on their attributes to improve the accuracy and quality of recommendation. The presented system has two main modules: explicit attribute-based recommender and implicit attribute-based recommender. In the first module, weights of implicit or latent attributes of materials for learner are considered as chromosomes in genetic algorithm then this algorithm optimizes the weights according to historical rating. Then, recommendation is generated by Nearest Neighborhood Algorithm (NNA using the optimized weight vectors implicit attributes that represent the opinions of learners. In the second, preference matrix (PM is introduced that can model the interests of learner based on explicit attributes of learning materials in a multidimensional information model. Then, a new similarity measure between PMs is introduced and recommendations are generated by NNA. The experimental results show that our proposed method outperforms current algorithms on accuracy measures and can alleviate some problems such as cold-start and sparsity.\n\n\nSingle-Iteration Learning Algorithm for Feed-Forward Neural Networks\nEnergy Technology Data Exchange (ETDEWEB)\nBarhen, J.; Cogswell, R.; Protopopescu, V.\n1999-07-31\nA new methodology for neural learning is presented, whereby only a single iteration is required to train a feed-forward network with near-optimal results. To this aim, a virtual input layer is added to the multi-layer architecture. The virtual input layer is connected to the nominal input layer by a specird nonlinear transfer function, and to the fwst hidden layer by regular (linear) synapses. A sequence of alternating direction singular vrdue decompositions is then used to determine precisely the inter-layer synaptic weights. This algorithm exploits the known separability of the linear (inter-layer propagation) and nonlinear (neuron activation) aspects of information &ansfer within a neural network.\n\n\nA Distributed Algorithm for the Cluster-Based Outlier Detection Using Unsupervised Extreme Learning Machines\nDirectory of Open Access Journals (Sweden)\nXite Wang\n2017-01-01\nFull Text Available Outlier detection is an important data mining task, whose target is to find the abnormal or atypical objects from a given dataset. The techniques for detecting outliers have a lot of applications, such as credit card fraud detection and environment monitoring. Our previous work proposed the Cluster-Based (CB outlier and gave a centralized method using unsupervised extreme learning machines to compute CB outliers. In this paper, we propose a new distributed algorithm for the CB outlier detection (DACB. On the master node, we collect a small number of points from the slave nodes to obtain a threshold. On each slave node, we design a new filtering method that can use the threshold to efficiently speed up the computation. Furthermore, we also propose a ranking method to optimize the order of cluster scanning. At last, the effectiveness and efficiency of the proposed approaches are verified through a plenty of simulation experiments.\n\n\nA learning algorithm for adaptive canonical correlation analysis of several data sets.\nScience.gov (United States)\nV\u00c3\u00ada, Javier; Santamar\u00c3\u00ada, Ignacio; P\u00c3\u00a9rez, Jes\u00c3\u00bas\n2007-01-01\nCanonical correlation analysis (CCA) is a classical tool in statistical analysis to find the projections that maximize the correlation between two data sets. In this work we propose a generalization of CCA to several data sets, which is shown to be equivalent to the classical maximum variance (MAXVAR) generalization proposed by Kettenring. The reformulation of this generalization as a set of coupled least squares regression problems is exploited to develop a neural structure for CCA. In particular, the proposed CCA model is a two layer feedforward neural network with lateral connections in the output layer to achieve the simultaneous extraction of all the CCA eigenvectors through deflation. The CCA neural model is trained using a recursive least squares (RLS) algorithm. Finally, the convergence of the proposed learning rule is proved by means of stochastic approximation techniques and their performance is analyzed through simulations.\n\n\nDesign optimization under uncertainties of a mesoscale implant in biological tissues using a probabilistic learning algorithm\nScience.gov (United States)\nSoize, C.\n2017-11-01\nThis paper deals with the optimal design of a titanium mesoscale implant in a cortical bone for which the apparent elasticity tensor is modeled by a non-Gaussian random field at mesoscale, which has been experimentally identified. The external applied forces are also random. The design parameters are geometrical dimensions related to the geometry of the implant. The stochastic elastostatic boundary value problem is discretized by the finite element method. The objective function and the constraints are related to normal, shear, and von Mises stresses inside the cortical bone. The constrained nonconvex optimization problem in presence of uncertainties is solved by using a probabilistic learning algorithm that allows for considerably reducing the numerical cost with respect to the classical approaches.\n\n\nImpacts of Different Mobile User Interfaces on Students\u00e2\u20ac\u2122 Satisfaction for Learning Dijkstra\u00e2\u20ac\u2122s Shortest Path Algorithm\nDirectory of Open Access Journals (Sweden)\nMazyar Seraj\n2014-10-01\nFull Text Available This paper describes an experimental study of learning Dijkstra\u00e2\u20ac\u2122s shortest path algorithm on mobile devices. The aim of the study is to investigate and compare the impacts of two different mobile screen user interfaces on students\u00e2\u20ac\u2122 satisfaction for learning the technical subject. A mobile learning prototype was developed for learning Dijkstra\u00e2\u20ac\u2122s shortest path algorithm on Apple iPhone 4 operated on iPhone operating system (iOS, and Acer Inconia Tab operated on an Android operating system. Thirty students, who are either currently studying or had previously studied Computer Networks, were recruited for the usability trial. At the end of each single session, students\u00e2\u20ac\u2122 satisfaction interacting with the two mobile devices was measured using QUIS questionnaire. Although there is no significant difference in students\u00e2\u20ac\u2122 satisfaction between the two different mobile screen interfaces, the subjective findings indicate that Acer Inconia Tab gained higher scores as compared to Apple iPhone 4.\n\n\nApplications of machine-learning algorithms for infrared colour selection of Galactic Wolf-Rayet stars\nScience.gov (United States)\nMorello, Giuseppe; Morris, P. W.; Van Dyk, S. D.; Marston, A. P.; Mauerhan, J. C.\n2018-01-01\nWe have investigated and applied machine-learning algorithms for infrared colour selection of Galactic Wolf-Rayet (WR) candidates. Objects taken from the Spitzer Galactic Legacy Infrared Midplane Survey Extraordinaire (GLIMPSE) catalogue of the infrared objects in the Galactic plane can be classified into different stellar populations based on the colours inferred from their broad-band photometric magnitudes [J, H and Ks from 2 Micron All Sky Survey (2MASS), and the four Spitzer/IRAC bands]. The algorithms tested in this pilot study are variants of the k-nearest neighbours approach, which is ideal for exploratory studies of classification problems where interrelations between variables and classes are complicated. The aims of this study are (1) to provide an automated tool to select reliable WR candidates and potentially other classes of objects, (2) to measure the efficiency of infrared colour selection at performing these tasks and (3) to lay the groundwork for statistically inferring the total number of WR stars in our Galaxy. We report the performance results obtained over a set of known objects and selected candidates for which we have carried out follow-up spectroscopic observations, and confirm the discovery of four new WR stars.\n\n\nLinear Subpixel Learning Algorithm for Land Cover Classification from WELD using High Performance Computing\nScience.gov (United States)\nGanguly, S.; Kumar, U.; Nemani, R. R.; Kalia, S.; Michaelis, A.\n2017-12-01\nIn this work, we use a Fully Constrained Least Squares Subpixel Learning Algorithm to unmix global WELD (Web Enabled Landsat Data) to obtain fractions or abundances of substrate (S), vegetation (V) and dark objects (D) classes. Because of the sheer nature of data and compute needs, we leveraged the NASA Earth Exchange (NEX) high performance computing architecture to optimize and scale our algorithm for large-scale processing. Subsequently, the S-V-D abundance maps were characterized into 4 classes namely, forest, farmland, water and urban areas (with NPP-VIIRS - national polar orbiting partnership visible infrared imaging radiometer suite nighttime lights data) over California, USA using Random Forest classifier. Validation of these land cover maps with NLCD (National Land Cover Database) 2011 products and NAFD (North American Forest Dynamics) static forest cover maps showed that an overall classification accuracy of over 91% was achieved, which is a 6% improvement in unmixing based classification relative to per-pixel based classification. As such, abundance maps continue to offer an useful alternative to high-spatial resolution data derived classification maps for forest inventory analysis, multi-class mapping for eco-climatic models and applications, fast multi-temporal trend analysis and for societal and policy-relevant applications needed at the watershed scale.\n\n\nWater quality of Danube Delta systems: ecological status and prediction using machine-learning algorithms.\nScience.gov (United States)\nStoica, C; Camejo, J; Banciu, A; Nita-Lazar, M; Paun, I; Cristofor, S; Pacheco, O R; Guevara, M\n2016-01-01\nEnvironmental issues have a worldwide impact on water bodies, including the Danube Delta, the largest European wetland. The Water Framework Directive (2000/60/EC) implementation operates toward solving environmental issues from European and national level. As a consequence, the water quality and the biocenosis structure was altered, especially the composition of the macro invertebrate community which is closely related to habitat and substrate heterogeneity. This study aims to assess the ecological status of Southern Branch of the Danube Delta, Saint Gheorghe, using benthic fauna and a computational method as an alternative for monitoring the water quality in real time. The analysis of spatial and temporal variability of unicriterial and multicriterial indices were used to assess the current status of aquatic systems. In addition, chemical status was characterized. Coliform bacteria and several chemical parameters were used to feed machine-learning (ML) algorithms to simulate a real-time classification method. Overall, the assessment of the water bodies indicated a moderate ecological status based on the biological quality elements or a good ecological status based on chemical and ML algorithms criteria.\n\n\nMultiple Kernel Learning for Heterogeneous Anomaly Detection: Algorithm and Aviation Safety Case Study\nScience.gov (United States)\nDas, Santanu; Srivastava, Ashok N.; Matthews, Bryan L.; Oza, Nikunj C.\n2010-01-01\nThe world-wide aviation system is one of the most complex dynamical systems ever developed and is generating data at an extremely rapid rate. Most modern commercial aircraft record several hundred flight parameters including information from the guidance, navigation, and control systems, the avionics and propulsion systems, and the pilot inputs into the aircraft. These parameters may be continuous measurements or binary or categorical measurements recorded in one second intervals for the duration of the flight. Currently, most approaches to aviation safety are reactive, meaning that they are designed to react to an aviation safety incident or accident. In this paper, we discuss a novel approach based on the theory of multiple kernel learning to detect potential safety anomalies in very large data bases of discrete and continuous data from world-wide operations of commercial fleets. We pose a general anomaly detection problem which includes both discrete and continuous data streams, where we assume that the discrete streams have a causal influence on the continuous streams. We also assume that atypical sequence of events in the discrete streams can lead to off-nominal system performance. We discuss the application domain, novel algorithms, and also discuss results on real-world data sets. Our algorithm uncovers operationally significant events in high dimensional data streams in the aviation industry which are not detectable using state of the art methods\n\n\nAn approach to the interpretation of backpropagation neural network models in QSAR studies.\nScience.gov (United States)\nBaskin, I I; Ait, A O; Halberstam, N M; Palyulin, V A; Zefirov, N S\n2002-03-01\nAn approach to the interpretation of backpropagation neural network models for quantitative structure-activity and structure-property relationships (QSAR/QSPR) studies is proposed. The method is based on analyzing the first and second moments of distribution of the values of the first and the second partial derivatives of neural network outputs with respect to inputs calculated at data points. The use of such statistics makes it possible not only to obtain actually the same characteristics as for the case of traditional \"interpretable\" statistical methods, such as the linear regression analysis, but also to reveal important additional information regarding the non-linear character of QSAR/QSPR relationships. The approach is illustrated by an example of interpreting a backpropagation neural network model for predicting position of the long-wave absorption band of cyane dyes.\n\n\nPengenalan Citra Wajah Dengan Menggunakan Transformasi Wavelet Diskrit dan Jaringan Saraf Tiruan Back-Propagation\nDirectory of Open Access Journals (Sweden)\nSuhendry Effendy\n2010-12-01\nFull Text Available This paper discusses the facial image recognition system using Discrete Wavelet Transform and back-propagation artificial neural network. Discrete Wavelet Transform processes the input image to obtain the essential features found on the face image. These features are then classified using an back-propagation artificial neural network for the input image to be identified. Testing the system using facial images in AT & T Database of Faces of 400 images comprising 40 facial images of individuals and web-camera catches as many as 100 images of 10 individuals. The accuracy of level of recognition on AT & T Database of Faces reaches 93.5%, while the accuracy of level of recognition on a web-camera capture images up to 96%. Testing is also done on image of AT & T Database of Faces with given noise. Apparently the noise in the image does not give meaningful effect on the level of recognition accuracy.\u00c2\u00a0\n\n\nIdentifikasi Penyakit Diabetes Millitus Menggunakan Jaringan Syaraf Tiruan Dengan Metode Perambatan-Balik (Backpropagation)\nOpenAIRE\nSriyanto, -; Sutedi, -\n2010-01-01\nDiabetes Melitus (DM) is dangerous disease that affect many of the various layer of work society. This disease is not easy to accurately recognized by the general society. So we need to develop a system that can identify accurately. System is built using neural networks with backpropagation methods and the function activation sigmoid. Neural network architecture using 8 input layer, 2 output layer and 5 hidden layer. The results show that this methods succesfully clasifies data diabetics and ...\n\n\nIdentifikasi Penyakit Diabetes Millitus Menggunakan Jaringan Syaraf Tiruan Dengan Metode Perambatan-Balik (Backpropagation)\nOpenAIRE\nSutedi, Sutedi\n2018-01-01\nDiabetes Melitus (DM) is dangerous disease that affect many of the various layer of work society. This disease is not easy to accurately recognized by the general society. So we need to develop a system that can identify accurately. System is built using neural networks with backpropagation methods and the function activation sigmoid. Neural network architecture using 8 input layer, 2 output layer and 5 hidden layer. The results show that this methods succesfully clasifies data diabetics and ...\n\n\nTowards a HPC-oriented parallel implementation of a learning algorithm for bioinformatics applications.\nScience.gov (United States)\nD'Angelo, Gianni; Rampone, Salvatore\n2014-01-01\nThe huge quantity of data produced in Biomedical research needs sophisticated algorithmic methodologies for its storage, analysis, and processing. High Performance Computing (HPC) appears as a magic bullet in this challenge. However, several hard to solve parallelization and load balancing problems arise in this context. Here we discuss the HPC-oriented implementation of a general purpose learning algorithm, originally conceived for DNA analysis and recently extended to treat uncertainty on data (U-BRAIN). The U-BRAIN algorithm is a learning algorithm that finds a Boolean formula in disjunctive normal form (DNF), of approximately minimum complexity, that is consistent with a set of data (instances) which may have missing bits. The conjunctive terms of the formula are computed in an iterative way by identifying, from the given data, a family of sets of conditions that must be satisfied by all the positive instances and violated by all the negative ones; such conditions allow the computation of a set of coefficients (relevances) for each attribute (literal), that form a probability distribution, allowing the selection of the term literals. The great versatility that characterizes it, makes U-BRAIN applicable in many of the fields in which there are data to be analyzed. However the memory and the execution time required by the running are of O(n(3)) and of O(n(5)) order, respectively, and so, the algorithm is unaffordable for huge data sets. We find mathematical and programming solutions able to lead us towards the implementation of the algorithm U-BRAIN on parallel computers. First we give a Dynamic Programming model of the U-BRAIN algorithm, then we minimize the representation of the relevances. When the data are of great size we are forced to use the mass memory, and depending on where the data are actually stored, the access times can be quite different. According to the evaluation of algorithmic efficiency based on the Disk Model, in order to reduce the costs of\n\n\nMachine learning algorithms for the creation of clinical healthcare enterprise systems\nScience.gov (United States)\nMandal, Indrajit\n2017-10-01\nClinical recommender systems are increasingly becoming popular for improving modern healthcare systems. Enterprise systems are persuasively used for creating effective nurse care plans to provide nurse training, clinical recommendations and clinical quality control. A novel design of a reliable clinical recommender system based on multiple classifier system (MCS) is implemented. A hybrid machine learning (ML) ensemble based on random subspace method and random forest is presented. The performance accuracy and robustness of proposed enterprise architecture are quantitatively estimated to be above 99% and 97%, respectively (above 95% confidence interval). The study then extends to experimental analysis of the clinical recommender system with respect to the noisy data environment. The ranking of items in nurse care plan is demonstrated using machine learning algorithms (MLAs) to overcome the drawback of the traditional association rule method. The promising experimental results are compared against the sate-of-the-art approaches to highlight the advancement in recommendation technology. The proposed recommender system is experimentally validated using five benchmark clinical data to reinforce the research findings.\n\n\nUSING THE POPULATION-BASED INCREMENTAL LEARNING ALGORITHM WITH COMPUTER SIMULATION: SOME APPLICATIONS\nDirectory of Open Access Journals (Sweden)\nJ. Bekker\n2012-01-01\nFull Text Available ENGLISH ABSTRACT: The integration of the population-based incremental learning (PBIL algorithm with computer simulation shows how this particular combination can be applied to find good solutions to combinatorial optimisation problems. Two illustrative examples are used: the classical inventory problem of finding a reorder point and reorder quantity that minimises costs while achieving a required service level (a stochastic problem; and the signal timing of a complex traffic intersection. Any traffic control system must be designed to minimise the duration of interruptions at intersections while maximising traffic throughput. The duration of the phases of traffic lights is of primary importance in this regard.AFRIKAANSE OPSOMMING: Die integrasie van die population-based incremental learning (PBIL algoritme met rekenaarsimulasie word bespreek, en daar word getoon hoe hierdie spesifieke kombinasie aangewend kan word om goeie oplossings vir kombinatoriese optimeringsprobleme te vind. Twee voorbeelde dien as illustrasie: die klassieke voorraadprobleem waarin \u00e2\u20ac\u2122n herbestelvlak en herbestelhoeveelheid bepaal moet word om koste te minimeer maar nogtans \u00e2\u20ac\u2122n vasgestelde diensvlak te handhaaf (\u00e2\u20ac\u2122n stochastiese probleem; en die bepaling van die seintye van \u00e2\u20ac\u2122n komplekse verkeerskruising. Enige verkeerbeheerstelsel moet ontwerp word om die duur van die vloeionderbrekings by verkeerskruisings te minimeer en verkeerdeurset te maksimeer. Die tydsduur van die fases van verkeersligte is dus baie belangrik.\n\n\nField tests and machine learning approaches for refining algorithms and correlations of driver's model parameters.\nScience.gov (United States)\nTango, Fabio; Minin, Luca; Tesauri, Francesco; Montanari, Roberto\n2010-03-01\nThis paper describes the field tests on a driving simulator carried out to validate the algorithms and the correlations of dynamic parameters, specifically driving task demand and drivers' distraction, able to predict drivers' intentions. These parameters belong to the driver's model developed by AIDE (Adaptive Integrated Driver-vehicle InterfacE) European Integrated Project. Drivers' behavioural data have been collected from the simulator tests to model and validate these parameters using machine learning techniques, specifically the adaptive neuro fuzzy inference systems (ANFIS) and the artificial neural network (ANN). Two models of task demand and distraction have been developed, one for each adopted technique. The paper provides an overview of the driver's model, the description of the task demand and distraction modelling and the tests conducted for the validation of these parameters. A test comparing predicted and expected outcomes of the modelled parameters for each machine learning technique has been carried out: for distraction, in particular, promising results (low prediction errors) have been obtained by adopting an artificial neural network.\n\n\nDeveloping Novel Machine Learning Algorithms to Improve Sedentary Assessment for Youth Health Enhancement.\nScience.gov (United States)\nGolla, Gowtham Kumar; Carlson, Jordan A; Huan, Jun; Kerr, Jacqueline; Mitchell, Tarrah; Borner, Kelsey\n2016-10-01\nSedentary behavior of youth is an important determinant of health. However, better measures are needed to improve understanding of this relationship and the mechanisms at play, as well as to evaluate health promotion interventions. Wearable accelerometers are considered as the standard for assessing physical activity in research, but do not perform well for assessing posture (i.e., sitting vs. standing), a critical component of sedentary behavior. The machine learning algorithms that we propose for assessing sedentary behavior will allow us to re-examine existing accelerometer data to better understand the association between sedentary time and health in various populations. We collected two datasets, a laboratory-controlled dataset and a free-living dataset. We trained machine learning classifiers separately on each dataset and compared performance across datasets. The classifiers predict five postures: sit, stand, sit-stand, stand-sit, and stand\\\\walk. We compared a manually constructed Hidden Markov model (HMM) with an automated HMM from existing software. The manually constructed HMM gave more F1-Macro score on both datasets.\n\n\nA Logical Deduction Based Clause Learning Algorithm for Boolean Satisfiability Problems\nDirectory of Open Access Journals (Sweden)\nQingshan Chen\n2017-01-01\nFull Text Available Clause learning is the key component of modern SAT solvers, while conflict analysis based on the implication graph is the mainstream technology to generate the learnt clauses. Whenever a clause in the clause database is falsified by the current variable assignments, the SAT solver will try to analyze the reason by using different cuts (i.e., the Unique Implication Points on the implication graph. Those schemes reflect only the conflict on the current search subspace, does not reflect the inherent conflict directly involved in the rest space. In this paper, we propose a new advanced clause learning algorithm based on the conflict analysis and the logical deduction, which reconstructs a linear logical deduction by analyzing the relationship of different decision variables between the backjumping level and the current decision level. The logical deduction result is then added into the clause database as a newly learnt clause. The resulting implementation in Minisat improves the state-of-the-art performance in SAT solving.\n\n\n\n\n\u00ab\n21\n22\n23\n24\n25\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n21\n22\n23\n24\n25\n\u00bb\n\n\n\n\n\n\n\n\nApplication of machine learning algorithms to the study of noise artifacts in gravitational-wave data\nScience.gov (United States)\nBiswas, Rahul; Blackburn, Lindy; Cao, Junwei; Essick, Reed; Hodge, Kari Alison; Katsavounidis, Erotokritos; Kim, Kyungmin; Kim, Young-Min; Le Bigot, Eric-Olivier; Lee, Chang-Hwan; Oh, John J.; Oh, Sang Hoon; Son, Edwin J.; Tao, Ye; Vaulin, Ruslan; Wang, Xiaoge\n2013-09-01\nThe sensitivity of searches for astrophysical transients in data from the Laser Interferometer Gravitational-wave Observatory (LIGO) is generally limited by the presence of transient, non-Gaussian noise artifacts, which occur at a high enough rate such that accidental coincidence across multiple detectors is non-negligible. These \u00e2\u20ac\u0153glitches\u00e2\u20ac\ufffd can easily be mistaken for transient gravitational-wave signals, and their robust identification and removal will help any search for astrophysical gravitational waves. We apply machine-learning algorithms (MLAs) to the problem, using data from auxiliary channels within the LIGO detectors that monitor degrees of freedom unaffected by astrophysical signals. Noise sources may produce artifacts in these auxiliary channels as well as the gravitational-wave channel. The number of auxiliary-channel parameters describing these disturbances may also be extremely large; high dimensionality is an area where MLAs are particularly well suited. We demonstrate the feasibility and applicability of three different MLAs: artificial neural networks, support vector machines, and random forests. These classifiers identify and remove a substantial fraction of the glitches present in two different data sets: four weeks of LIGO\u00e2\u20ac\u2122s fourth science run and one week of LIGO\u00e2\u20ac\u2122s sixth science run. We observe that all three algorithms agree on which events are glitches to within 10% for the sixth-science-run data, and support this by showing that the different optimization criteria used by each classifier generate the same decision surface, based on a likelihood-ratio statistic. Furthermore, we find that all classifiers obtain similar performance to the benchmark algorithm, the ordered veto list, which is optimized to detect pairwise correlations between transients in LIGO auxiliary channels and glitches in the gravitational-wave data. This suggests that most of the useful information currently extracted from the auxiliary channels is already described\n\n\nLow dose CT reconstruction via L1 norm dictionary learning using alternating minimization algorithm and balancing principle.\nScience.gov (United States)\nWu, Junfeng; Dai, Fang; Hu, Gang; Mou, Xuanqin\n2018-04-18\nExcessive radiation exposure in computed tomography (CT) scans increases the chance of developing cancer and has become a major clinical concern. Recently, statistical iterative reconstruction (SIR) with l0-norm dictionary learning regularization has been developed to reconstruct CT images from the low dose and few-view dataset in order to reduce radiation dose. Nonetheless, the sparse regularization term adopted in this approach is l0-norm, which cannot guarantee the global convergence of the proposed algorithm. To address this problem, in this study we introduced the l1-norm dictionary learning penalty into SIR framework for low dose CT image reconstruction, and developed an alternating minimization algorithm to minimize the associated objective function, which transforms CT image reconstruction problem into a sparse coding subproblem and an image updating subproblem. During the image updating process, an efficient model function approach based on balancing principle is applied to choose the regularization parameters. The proposed alternating minimization algorithm was evaluated first using real projection data of a sheep lung CT perfusion and then using numerical simulation based on sheep lung CT image and chest image. Both visual assessment and quantitative comparison using terms of root mean square error (RMSE) and structural similarity (SSIM) index demonstrated that the new image reconstruction algorithm yielded similar performance with l0-norm dictionary learning penalty and outperformed the conventional filtered backprojection (FBP) and total variation (TV) minimization algorithms.\n\n\nAn Energy-Efficient Spectrum-Aware Reinforcement Learning-Based Clustering Algorithm for Cognitive Radio Sensor Networks.\nScience.gov (United States)\nMustapha, Ibrahim; Mohd Ali, Borhanuddin; Rasid, Mohd Fadlee A; Sali, Aduwati; Mohamad, Hafizal\n2015-08-13\nIt is well-known that clustering partitions network into logical groups of nodes in order to achieve energy efficiency and to enhance dynamic channel access in cognitive radio through cooperative sensing. While the topic of energy efficiency has been well investigated in conventional wireless sensor networks, the latter has not been extensively explored. In this paper, we propose a reinforcement learning-based spectrum-aware clustering algorithm that allows a member node to learn the energy and cooperative sensing costs for neighboring clusters to achieve an optimal solution. Each member node selects an optimal cluster that satisfies pairwise constraints, minimizes network energy consumption and enhances channel sensing performance through an exploration technique. We first model the network energy consumption and then determine the optimal number of clusters for the network. The problem of selecting an optimal cluster is formulated as a Markov Decision Process (MDP) in the algorithm and the obtained simulation results show convergence, learning and adaptability of the algorithm to dynamic environment towards achieving an optimal solution. Performance comparisons of our algorithm with the Groupwise Spectrum Aware (GWSA)-based algorithm in terms of Sum of Square Error (SSE), complexity, network energy consumption and probability of detection indicate improved performance from the proposed approach. The results further reveal that an energy savings of 9% and a significant Primary User (PU) detection improvement can be achieved with the proposed approach.\n\n\nAn improved method of early diagnosis of smoking-induced respiratory changes using machine learning algorithms.\nScience.gov (United States)\nAmaral, Jorge L M; Lopes, Agnaldo J; Jansen, Jos\u00c3\u00a9 M; Faria, Alvaro C D; Melo, Pedro L\n2013-12-01\nThe purpose of this study was to develop an automatic classifier to increase the accuracy of the forced oscillation technique (FOT) for diagnosing early respiratory abnormalities in smoking patients. The data consisted of FOT parameters obtained from 56 volunteers, 28 healthy and 28 smokers with low tobacco consumption. Many supervised learning techniques were investigated, including logistic linear classifiers, k nearest neighbor (KNN), neural networks and support vector machines (SVM). To evaluate performance, the ROC curve of the most accurate parameter was established as baseline. To determine the best input features and classifier parameters, we used genetic algorithms and a 10-fold cross-validation using the average area under the ROC curve (AUC). In the first experiment, the original FOT parameters were used as input. We observed a significant improvement in accuracy (KNN=0.89 and SVM=0.87) compared with the baseline (0.77). The second experiment performed a feature selection on the original FOT parameters. This selection did not cause any significant improvement in accuracy, but it was useful in identifying more adequate FOT parameters. In the third experiment, we performed a feature selection on the cross products of the FOT parameters. This selection resulted in a further increase in AUC (KNN=SVM=0.91), which allows for high diagnostic accuracy. In conclusion, machine learning classifiers can help identify early smoking-induced respiratory alterations. The use of FOT cross products and the search for the best features and classifier parameters can markedly improve the performance of machine learning classifiers. Copyright \u00c2\u00a9 2013 Elsevier Ireland Ltd. All rights reserved.\n\n\nAn algorithm for finding biologically significant features in microarray data based on a priori manifold learning.\nDirectory of Open Access Journals (Sweden)\nZena M Hira\n\nFull Text Available Microarray databases are a large source of genetic data, which, upon proper analysis, could enhance our understanding of biology and medicine. Many microarray experiments have been designed to investigate the genetic mechanisms of cancer, and analytical approaches have been applied in order to classify different types of cancer or distinguish between cancerous and non-cancerous tissue. However, microarrays are high-dimensional datasets with high levels of noise and this causes problems when using machine learning methods. A popular approach to this problem is to search for a set of features that will simplify the structure and to some degree remove the noise from the data. The most widely used approach to feature extraction is principal component analysis (PCA which assumes a multivariate Gaussian model of the data. More recently, non-linear methods have been investigated. Among these, manifold learning algorithms, for example Isomap, aim to project the data from a higher dimensional space onto a lower dimension one. We have proposed a priori manifold learning for finding a manifold in which a representative set of microarray data is fused with relevant data taken from the KEGG pathway database. Once the manifold has been constructed the raw microarray data is projected onto it and clustering and classification can take place. In contrast to earlier fusion based methods, the prior knowledge from the KEGG databases is not used in, and does not bias the classification process--it merely acts as an aid to find the best space in which to search the data. In our experiments we have found that using our new manifold method gives better classification results than using either PCA or conventional Isomap.\n\n\nFast learning method for convolutional neural networks using extreme learning machine and its application to lane detection.\nScience.gov (United States)\nKim, Jihun; Kim, Jonghong; Jang, Gil-Jin; Lee, Minho\n2017-03-01\nDeep learning has received significant attention recently as a promising solution to many problems in the area of artificial intelligence. Among several deep learning architectures, convolutional neural networks (CNNs) demonstrate superior performance when compared to other machine learning methods in the applications of object detection and recognition. We use a CNN for image enhancement and the detection of driving lanes on motorways. In general, the process of lane detection consists of edge extraction and line detection. A CNN can be used to enhance the input images before lane detection by excluding noise and obstacles that are irrelevant to the edge detection result. However, training conventional CNNs requires considerable computation and a big dataset. Therefore, we suggest a new learning algorithm for CNNs using an extreme learning machine (ELM). The ELM is a fast learning method used to calculate network weights between output and hidden layers in a single iteration and thus, can dramatically reduce learning time while producing accurate results with minimal training data. A conventional ELM can be applied to networks with a single hidden layer; as such, we propose a stacked ELM architecture in the CNN framework. Further, we modify the backpropagation algorithm to find the targets of hidden layers and effectively learn network weights while maintaining performance. Experimental results confirm that the proposed method is effective in reducing learning time and improving performance. Copyright \u00c2\u00a9 2016 Elsevier Ltd. All rights reserved.\n\n\nAn evaluation of scanpath-comparison and machine-learning classification algorithms used to study the dynamics of analogy making.\nScience.gov (United States)\nFrench, Robert M; Glady, Yannick; Thibaut, Jean-Pierre\n2017-08-01\nIn recent years, eyetracking has begun to be used to study the dynamics of analogy making. Numerous scanpath-comparison algorithms and machine-learning techniques are available that can be applied to the raw eyetracking data. We show how scanpath-comparison algorithms, combined with multidimensional scaling and a classification algorithm, can be used to resolve an outstanding question in analogy making-namely, whether or not children's and adults' strategies in solving analogy problems are different. (They are.) We show which of these scanpath-comparison algorithms is best suited to the kinds of analogy problems that have formed the basis of much analogy-making research over the years. Furthermore, we use machine-learning classification algorithms to examine the item-to-item saccade vectors making up these scanpaths. We show which of these algorithms best predicts, from very early on in a trial, on the basis of the frequency of various item-to-item saccades, whether a child or an adult is doing the problem. This type of analysis can also be used to predict, on the basis of the item-to-item saccade dynamics in the first third of a trial, whether or not a problem will be solved correctly.\n\n\nA Scalable Neuro-inspired Robot Controller Integrating a Machine Learning Algorithm and a Spiking Cerebellar-like Network\nDEFF Research Database (Denmark)\nBaira Ojeda, Ismael; Tolu, Silvia; Lund, Henrik Hautop\n2017-01-01\nCombining Fable robot, a modular robot, with a neuroinspired controller, we present the proof of principle of a system that can scale to several neurally controlled compliant modules. The motor control and learning of a robot module are carried out by a Unit Learning Machine (ULM) that embeds...... the Locally Weighted Projection Regression algorithm (LWPR) and a spiking cerebellar-like microcircuit. The LWPR guarantees both an optimized representation of the input space and the learning of the dynamic internal model (IM) of the robot. However, the cerebellar-like sub-circuit integrates LWPR input...\n\n\nBack propagation and Monte Carlo algorithms for neural network computations\nInternational Nuclear Information System (INIS) \nJunczys, R.; Wit, R.\n1996-01-01\nResults of teaching procedures for neural network for two different algorithms are presented. The first one is based on the well known back-propagation technique, the second is an adopted version of the Monte Carlo global minimum seeking method. Combination of these two, different in nature, approaches provides promising results. (author) nature, approaches provides promising results. (author)\n\n\nSimplification of neural network model for predicting local power distributions of BWR fuel bundle using learning algorithm with forgetting\nInternational Nuclear Information System (INIS) \nTanabe, Akira; Yamamoto, Toru; Shinfuku, Kimihiro; Nakamae, Takuji; Nishide, Fusayo.\n1995-01-01\nPreviously a two-layered neural network model was developed to predict the relation between fissile enrichment of each fuel rod and local power distribution in a BWR fuel bundle. This model was obtained intuitively based on 33 patterns of training signals after an intensive survey of the models. Recently, a learning algorithm with forgetting was reported to simplify neural network models. It is an interesting subject what kind of model will be obtained if this algorithm is applied to the complex three-layered model which learns the same training signals. A three-layered model which is expanded to have direct connections between the 1st and the 3rd layer elements has been constructed and the learning method of normal back propagation was applied first to this model. The forgetting algorithm was then added to this learning process. The connections concerned with the 2nd layer elements disappeared and the 2nd layer has become unnecessary. It took a longer computing time by an order to learn the same training signals than the simple back propagation, but the two-layered model was obtained autonomously from the expanded three-layered model. (author)\n\n\nOn structure-exploiting trust-region regularized nonlinear least squares algorithms for neural-network learning.\nScience.gov (United States)\nMizutani, Eiji; Demmel, James W\n2003-01-01\nThis paper briefly introduces our numerical linear algebra approaches for solving structured nonlinear least squares problems arising from 'multiple-output' neural-network (NN) models. Our algorithms feature trust-region regularization, and exploit sparsity of either the 'block-angular' residual Jacobian matrix or the 'block-arrow' Gauss-Newton Hessian (or Fisher information matrix in statistical sense) depending on problem scale so as to render a large class of NN-learning algorithms 'efficient' in both memory and operation costs. Using a relatively large real-world nonlinear regression application, we shall explain algorithmic strengths and weaknesses, analyzing simulation results obtained by both direct and iterative trust-region algorithms with two distinct NN models: 'multilayer perceptrons' (MLP) and 'complementary mixtures of MLP-experts' (or neuro-fuzzy modular networks).\n\n\nRule Extraction Based on Extreme Learning Machine and an Improved Ant-Miner Algorithm for Transient Stability Assessment.\nScience.gov (United States)\nLi, Yang; Li, Guoqing; Wang, Zhenhao\n2015-01-01\nIn order to overcome the problems of poor understandability of the pattern recognition-based transient stability assessment (PRTSA) methods, a new rule extraction method based on extreme learning machine (ELM) and an improved Ant-miner (IAM) algorithm is presented in this paper. First, the basic principles of ELM and Ant-miner algorithm are respectively introduced. Then, based on the selected optimal feature subset, an example sample set is generated by the trained ELM-based PRTSA model. And finally, a set of classification rules are obtained by IAM algorithm to replace the original ELM network. The novelty of this proposal is that transient stability rules are extracted from an example sample set generated by the trained ELM-based transient stability assessment model by using IAM algorithm. The effectiveness of the proposed method is shown by the application results on the New England 39-bus power system and a practical power system--the southern power system of Hebei province.\n\n\nComplex scenes and situations visualization in hierarchical learning algorithm with dynamic 3D NeoAxis engine\nScience.gov (United States)\nGraham, James; Ternovskiy, Igor V.\n2013-06-01\nWe applied a two stage unsupervised hierarchical learning system to model complex dynamic surveillance and cyber space monitoring systems using a non-commercial version of the NeoAxis visualization software. The hierarchical scene learning and recognition approach is based on hierarchical expectation maximization, and was linked to a 3D graphics engine for validation of learning and classification results and understanding the human - autonomous system relationship. Scene recognition is performed by taking synthetically generated data and feeding it to a dynamic logic algorithm. The algorithm performs hierarchical recognition of the scene by first examining the features of the objects to determine which objects are present, and then determines the scene based on the objects present. This paper presents a framework within which low level data linked to higher-level visualization can provide support to a human operator and be evaluated in a detailed and systematic way.\n\n\nToward a Progress Indicator for Machine Learning Model Building and Data Mining Algorithm Execution: A Position Paper\nScience.gov (United States)\nLuo, Gang\n2017-01-01\nFor user-friendliness, many software systems offer progress indicators for long-duration tasks. A typical progress indicator continuously estimates the remaining task execution time as well as the portion of the task that has been finished. Building a machine learning model often takes a long time, but no existing machine learning software supplies a non-trivial progress indicator. Similarly, running a data mining algorithm often takes a long time, but no existing data mining software provides a nontrivial progress indicator. In this article, we consider the problem of offering progress indicators for machine learning model building and data mining algorithm execution. We discuss the goals and challenges intrinsic to this problem. Then we describe an initial framework for implementing such progress indicators and two advanced, potential uses of them, with the goal of inspiring future research on this topic. PMID:29177022\n\n\nAn Efficient Supervised Training Algorithm for Multilayer Spiking Neural Networks.\nScience.gov (United States)\nXie, Xiurui; Qu, Hong; Liu, Guisong; Zhang, Malu; Kurths, J\u00c3\u00bcrgen\n2016-01-01\nThe spiking neural networks (SNNs) are the third generation of neural networks and perform remarkably well in cognitive tasks such as pattern recognition. The spike emitting and information processing mechanisms found in biological cognitive systems motivate the application of the hierarchical structure and temporal encoding mechanism in spiking neural networks, which have exhibited strong computational capability. However, the hierarchical structure and temporal encoding approach require neurons to process information serially in space and time respectively, which reduce the training efficiency significantly. For training the hierarchical SNNs, most existing methods are based on the traditional back-propagation algorithm, inheriting its drawbacks of the gradient diffusion and the sensitivity on parameters. To keep the powerful computation capability of the hierarchical structure and temporal encoding mechanism, but to overcome the low efficiency of the existing algorithms, a new training algorithm, the Normalized Spiking Error Back Propagation (NSEBP) is proposed in this paper. In the feedforward calculation, the output spike times are calculated by solving the quadratic function in the spike response model instead of detecting postsynaptic voltage states at all time points in traditional algorithms. Besides, in the feedback weight modification, the computational error is propagated to previous layers by the presynaptic spike jitter instead of the gradient decent rule, which realizes the layer-wised training. Furthermore, our algorithm investigates the mathematical relation between the weight variation and voltage error change, which makes the normalization in the weight modification applicable. Adopting these strategies, our algorithm outperforms the traditional SNN multi-layer algorithms in terms of learning efficiency and parameter sensitivity, that are also demonstrated by the comprehensive experimental results in this paper.\n\n\nSuperior arm-movement decoding from cortex with a new, unsupervised-learning algorithm\nScience.gov (United States)\nMakin, Joseph G.; O'Doherty, Joseph E.; Cardoso, Mariana M. B.; Sabes, Philip N.\n2018-04-01\nObjective. The aim of this work is to improve the state of the art for motor-control with a brain-machine interface (BMI). BMIs use neurological recording devices and decoding algorithms to transform brain activity directly into real-time control of a machine, archetypically a robotic arm or a cursor. The standard procedure treats neural activity\u00e2\u20ac\u201dvectors of spike counts in small temporal windows\u00e2\u20ac\u201das noisy observations of the kinematic state (position, velocity, acceleration) of the fingertip. Inferring the state from the observations then takes the form of a dynamical filter, typically some variant on Kalman\u00e2\u20ac\u2122s (KF). The KF, however, although fairly robust in practice, is optimal only when the relationships between variables are linear and the noise is Gaussian, conditions usually violated in practice. Approach. To overcome these limitations we introduce a new filter, the \u00e2\u20ac\u02dcrecurrent exponential-family harmonium\u00e2\u20ac\u2122 (rEFH), that models the spike counts explicitly as Poisson-distributed, and allows for arbitrary nonlinear dynamics and observation models. Furthermore, the model underlying the filter is acquired through unsupervised learning, which allows temporal correlations in spike counts to be explained by latent dynamics that do not necessarily correspond to the kinematic state of the fingertip. Main results. We test the rEFH on offline reconstruction of the kinematics of reaches in the plane. The rEFH outperforms the standard, as well as three other state-of-the-art, decoders, across three monkeys, two different tasks, most kinematic variables, and a range of bin widths, amounts of training data, and numbers of neurons. Significance. Our algorithm establishes a new state of the art for offline decoding of reaches\u00e2\u20ac\u201din particular, for fingertip velocities, the variable used for control in most online decoders.\n\n\nA New Tool for CME Arrival Time Prediction using Machine Learning Algorithms: CAT-PUMA\nScience.gov (United States)\nLiu, Jiajia; Ye, Yudong; Shen, Chenglong; Wang, Yuming; Erd\u00c3\u00a9lyi, Robert\n2018-03-01\nCoronal mass ejections (CMEs) are arguably the most violent eruptions in the solar system. CMEs can cause severe disturbances in interplanetary space and can even affect human activities in many aspects, causing damage to infrastructure and loss of revenue. Fast and accurate prediction of CME arrival time is vital to minimize the disruption that CMEs may cause when interacting with geospace. In this paper, we propose a new approach for partial-/full halo CME Arrival Time Prediction Using Machine learning Algorithms (CAT-PUMA). Via detailed analysis of the CME features and solar-wind parameters, we build a prediction engine taking advantage of 182 previously observed geo-effective partial-/full halo CMEs and using algorithms of the Support Vector Machine. We demonstrate that CAT-PUMA is accurate and fast. In particular, predictions made after applying CAT-PUMA to a test set unknown to the engine show a mean absolute prediction error of \u00e2\u02c6\u00bc5.9 hr within the CME arrival time, with 54% of the predictions having absolute errors less than 5.9 hr. Comparisons with other models reveal that CAT-PUMA has a more accurate prediction for 77% of the events investigated that can be carried out very quickly, i.e., within minutes of providing the necessary input parameters of a CME. A practical guide containing the CAT-PUMA engine and the source code of two examples are available in the Appendix, allowing the community to perform their own applications for prediction using CAT-PUMA.\n\n\nApplication of Machine Learning Algorithms to the Study of Noise Artifacts in Gravitational-Wave Data\nScience.gov (United States)\nBiswas, Rahul; Blackburn, Lindy L.; Cao, Junwei; Essick, Reed; Hodge, Kari Alison; Katsavounidis, Erotokritos; Kim, Kyungmin; Young-Min, Kim; Le Bigot, Eric-Olivier; Lee, Chang-Hwan;   \n2014-01-01\nThe sensitivity of searches for astrophysical transients in data from the Laser Interferometer Gravitationalwave Observatory (LIGO) is generally limited by the presence of transient, non-Gaussian noise artifacts, which occur at a high-enough rate such that accidental coincidence across multiple detectors is non-negligible. Furthermore, non-Gaussian noise artifacts typically dominate over the background contributed from stationary noise. These \"glitches\" can easily be confused for transient gravitational-wave signals, and their robust identification and removal will help any search for astrophysical gravitational-waves. We apply Machine Learning Algorithms (MLAs) to the problem, using data from auxiliary channels within the LIGO detectors that monitor degrees of freedom unaffected by astrophysical signals. Terrestrial noise sources may manifest characteristic disturbances in these auxiliary channels, inducing non-trivial correlations with glitches in the gravitational-wave data. The number of auxiliary-channel parameters describing these disturbances may also be extremely large; high dimensionality is an area where MLAs are particularly well-suited. We demonstrate the feasibility and applicability of three very different MLAs: Artificial Neural Networks, Support Vector Machines, and Random Forests. These classifiers identify and remove a substantial fraction of the glitches present in two very different data sets: four weeks of LIGO's fourth science run and one week of LIGO's sixth science run. We observe that all three algorithms agree on which events are glitches to within 10% for the sixth science run data, and support this by showing that the different optimization criteria used by each classifier generate the same decision surface, based on a likelihood-ratio statistic. Furthermore, we find that all classifiers obtain similar limiting performance, suggesting that most of the useful information currently contained in the auxiliary channel parameters we extract\n\n\nClassification of the Clinical Images for Benign and Malignant Cutaneous Tumors Using a Deep Learning Algorithm.\nScience.gov (United States)\nHan, Seung Seog; Kim, Myoung Shin; Lim, Woohyung; Park, Gyeong Hun; Park, Ilwoo; Chang, Sung Eun\n2018-02-08\nWe tested the use of a deep learning algorithm to classify the clinical images of 12 skin diseases-basal cell carcinoma, squamous cell carcinoma, intraepithelial carcinoma, actinic keratosis, seborrheic keratosis, malignant melanoma, melanocytic nevus, lentigo, pyogenic granuloma, hemangioma, dermatofibroma, and wart. The convolutional neural network (Microsoft ResNet-152 model; Microsoft Research Asia, Beijing, China) was fine-tuned with images from the training portion of the Asan dataset, MED-NODE dataset, and atlas site images (19,398 images in total). The trained model was validated with the testing portion of the Asan, Hallym and Edinburgh datasets. With the Asan dataset, the area under the curve for the diagnosis of basal cell carcinoma, squamous cell carcinoma, intraepithelial carcinoma, and melanoma was 0.96 \u00c2\u00b1 0.01, 0.83 \u00c2\u00b1 0.01, 0.82 \u00c2\u00b1 0.02, and 0.96 \u00c2\u00b1 0.00, respectively. With the Edinburgh dataset, the area under the curve for the corresponding diseases was 0.90 \u00c2\u00b1 0.01, 0.91 \u00c2\u00b1 0.01, 0.83 \u00c2\u00b1 0.01, and 0.88 \u00c2\u00b1 0.01, respectively. With the Hallym dataset, the sensitivity for basal cell carcinoma diagnosis was 87.1% \u00c2\u00b1 6.0%. The tested algorithm performance with 480 Asan and Edinburgh images was comparable to that of 16 dermatologists. To improve the performance of convolutional neural network, additional images with a broader range of ages and ethnicities should be collected. Copyright \u00c2\u00a9 2018 The Authors. Published by Elsevier Inc. All rights reserved.\n\n\nGenetic Algorithms for Optimization of Machine-learning Models and their Applications in Bioinformatics\nKAUST Repository\nMagana-Mora, Arturo\n2017-04-29\nMachine-learning (ML) techniques have been widely applied to solve different problems in biology. However, biological data are large and complex, which often result in extremely intricate ML models. Frequently, these models may have a poor performance or may be computationally unfeasible. This study presents a set of novel computational methods and focuses on the application of genetic algorithms (GAs) for the simplification and optimization of ML models and their applications to biological problems. The dissertation addresses the following three challenges. The first is to develop a generalizable classification methodology able to systematically derive competitive models despite the complexity and nature of the data. Although several algorithms for the induction of classification models have been proposed, the algorithms are data dependent. Consequently, we developed OmniGA, a novel and generalizable framework that uses different classification models in a treeXlike decision structure, along with a parallel GA for the optimization of the OmniGA structure. Results show that OmniGA consistently outperformed existing commonly used classification models. The second challenge is the prediction of translation initiation sites (TIS) in plants genomic DNA. We performed a statistical analysis of the genomic DNA and proposed a new set of discriminant features for this problem. We developed a wrapper method based on GAs for selecting an optimal feature subset, which, in conjunction with a classification model, produced the most accurate framework for the recognition of TIS in plants. Finally, results demonstrate that despite the evolutionary distance between different plants, our approach successfully identified conserved genomic elements that may serve as the starting point for the development of a generic model for prediction of TIS in eukaryotic organisms. Finally, the third challenge is the accurate prediction of polyadenylation signals in human genomic DNA. To achieve\n\n\n\n\n\u00ab\n21\n22\n23\n24\n25\n\u00bb\n\n\n\n\n\n\n\n\n\n\n\u00ab\n21\n22\n23\n24\n25\n\u00bb\n\n\n\n\n\n\n\n\nA comparative study of breast cancer diagnosis based on neural network ensemble via improved training algorithms.\nScience.gov (United States)\nAzami, Hamed; Escudero, Javier\n2015-08-01\nBreast cancer is one of the most common types of cancer in women all over the world. Early diagnosis of this kind of cancer can significantly increase the chances of long-term survival. Since diagnosis of breast cancer is a complex problem, neural network (NN) approaches have been used as a promising solution. Considering the low speed of the back-propagation (BP) algorithm to train a feed-forward NN, we consider a number of improved NN trainings for the Wisconsin breast cancer dataset: BP with momentum, BP with adaptive learning rate, BP with adaptive learning rate and momentum, Polak-Ribikre conjugate gradient algorithm (CGA), Fletcher-Reeves CGA, Powell-Beale CGA, scaled CGA, resilient BP (RBP), one-step secant and quasi-Newton methods. An NN ensemble, which is a learning paradigm to combine a number of NN outputs, is used to improve the accuracy of the classification task. Results demonstrate that NN ensemble-based classification methods have better performance than NN-based algorithms. The highest overall average accuracy is 97.68% obtained by NN ensemble trained by RBP for 50%-50% training-test evaluation method.\n\n\nShort communication: Prediction of retention pay-off using a machine learning algorithm.\nScience.gov (United States)\nShahinfar, Saleh; Kalantari, Afshin S; Cabrera, Victor; Weigel, Kent\n2014-05-01\nReplacement decisions have a major effect on dairy farm profitability. Dynamic programming (DP) has been widely studied to find the optimal replacement policies in dairy cattle. However, DP models are computationally intensive and might not be practical for daily decision making. Hence, the ability of applying machine learning on a prerun DP model to provide fast and accurate predictions of nonlinear and intercorrelated variables makes it an ideal methodology. Milk class (1 to 5), lactation number (1 to 9), month in milk (1 to 20), and month of pregnancy (0 to 9) were used to describe all cows in a herd in a DP model. Twenty-seven scenarios based on all combinations of 3 levels (base, 20% above, and 20% below) of milk production, milk price, and replacement cost were solved with the DP model, resulting in a data set of 122,716 records, each with a calculated retention pay-off (RPO). Then, a machine learning model tree algorithm was used to mimic the evaluated RPO with DP. The correlation coefficient factor was used to observe the concordance of RPO evaluated by DP and RPO predicted by the model tree. The obtained correlation coefficient was 0.991, with a corresponding value of 0.11 for relative absolute error. At least 100 instances were required per model constraint, resulting in 204 total equations (models). When these models were used for binary classification of positive and negative RPO, error rates were 1% false negatives and 9% false positives. Applying this trained model from simulated data for prediction of RPO for 102 actual replacement records from the University of Wisconsin-Madison dairy herd resulted in a 0.994 correlation with 0.10 relative absolute error rate. Overall results showed that model tree has a potential to be used in conjunction with DP to assist farmers in their replacement decisions. Copyright \u00c2\u00a9 2014 American Dairy Science Association. Published by Elsevier Inc. All rights reserved.\n\n\nAssessing the Performance of a Machine Learning Algorithm in Identifying Bubbles in Dust Emission\nScience.gov (United States)\nXu, Duo; Offner, Stella S. R.\n2017-12-01\nStellar feedback created by radiation and winds from massive stars plays a significant role in both physical and chemical evolution of molecular clouds. This energy and momentum leaves an identifiable signature (\u00e2\u20ac\u0153bubbles\u00e2\u20ac\ufffd) that affects the dynamics and structure of the cloud. Most bubble searches are performed \u00e2\u20ac\u0153by eye,\u00e2\u20ac\ufffd which is usually time-consuming, subjective, and difficult to calibrate. Automatic classifications based on machine learning make it possible to perform systematic, quantifiable, and repeatable searches for bubbles. We employ a previously developed machine learning algorithm, Brut, and quantitatively evaluate its performance in identifying bubbles using synthetic dust observations. We adopt magnetohydrodynamics simulations, which model stellar winds launching within turbulent molecular clouds, as an input to generate synthetic images. We use a publicly available three-dimensional dust continuum Monte Carlo radiative transfer code, HYPERION, to generate synthetic images of bubbles in three Spitzer bands (4.5, 8, and 24 \u00ce\u00bcm). We designate half of our synthetic bubbles as a training set, which we use to train Brut along with citizen-science data from the Milky Way Project (MWP). We then assess Brut\u00e2\u20ac\u2122s accuracy using the remaining synthetic observations. We find that Brut\u00e2\u20ac\u2122s performance after retraining increases significantly, and it is able to identify yellow bubbles, which are likely associated with B-type stars. Brut continues to perform well on previously identified high-score bubbles, and over 10% of the MWP bubbles are reclassified as high-confidence bubbles, which were previously marginal or ambiguous detections in the MWP data. We also investigate the influence of the size of the training set, dust model, evolutionary stage, and background noise on bubble identification.\n\n\nA Deep Learning Algorithm of Neural Network for the Parameterization of Typhoon-Ocean Feedback in Typhoon Forecast Models\nScience.gov (United States)\nJiang, Guo-Qing; Xu, Jing; Wei, Jun\n2018-04-01\nTwo algorithms based on machine learning neural networks are proposed\u00e2\u20ac\u201dthe shallow learning (S-L) and deep learning (D-L) algorithms\u00e2\u20ac\u201dthat can potentially be used in atmosphere-only typhoon forecast models to provide flow-dependent typhoon-induced sea surface temperature cooling (SSTC) for improving typhoon predictions. The major challenge of existing SSTC algorithms in forecast models is how to accurately predict SSTC induced by an upcoming typhoon, which requires information not only from historical data but more importantly also from the target typhoon itself. The S-L algorithm composes of a single layer of neurons with mixed atmospheric and oceanic factors. Such a structure is found to be unable to represent correctly the physical typhoon-ocean interaction. It tends to produce an unstable SSTC distribution, for which any perturbations may lead to changes in both SSTC pattern and strength. The D-L algorithm extends the neural network to a 4 \u00c3\u2014 5 neuron matrix with atmospheric and oceanic factors being separated in different layers of neurons, so that the machine learning can determine the roles of atmospheric and oceanic factors in shaping the SSTC. Therefore, it produces a stable crescent-shaped SSTC distribution, with its large-scale pattern determined mainly by atmospheric factors (e.g., winds) and small-scale features by oceanic factors (e.g., eddies). Sensitivity experiments reveal that the D-L algorithms improve maximum wind intensity errors by 60-70% for four case study simulations, compared to their atmosphere-only model runs.\n\n\nA Pathological Brain Detection System based on Extreme Learning Machine Optimized by Bat Algorithm.\nScience.gov (United States)\nLu, Siyuan; Qiu, Xin; Shi, Jianping; Li, Na; Lu, Zhi-Hai; Chen, Peng; Yang, Meng-Meng; Liu, Fang-Yuan; Jia, Wen-Juan; Zhang, Yudong\n2017-01-01\nIt is beneficial to classify brain images as healthy or pathological automatically, because 3D brain images can generate so much information which is time consuming and tedious for manual analysis. Among various 3D brain imaging techniques, magnetic resonance (MR) imaging is the most suitable for brain, and it is now widely applied in hospitals, because it is helpful in the four ways of diagnosis, prognosis, pre-surgical, and postsurgical procedures. There are automatic detection methods; however they suffer from low accuracy. Therefore, we proposed a novel approach which employed 2D discrete wavelet transform (DWT), and calculated the entropies of the subbands as features. Then, a bat algorithm optimized extreme learning machine (BA-ELM) was trained to identify pathological brains from healthy controls. A 10x10-fold cross validation was performed to evaluate the out-of-sample performance. The method achieved a sensitivity of 99.04%, a specificity of 93.89%, and an overall accuracy of 98.33% over 132 MR brain images. The experimental results suggest that the proposed approach is accurate and robust in pathological brain detection. Copyright\u00c2\u00a9 Bentham Science Publishers; For any queries, please email at epub@benthamscience.org.\n\n\nA novel deep learning algorithm for incomplete face recognition: Low-rank-recovery network.\nScience.gov (United States)\nZhao, Jianwei; Lv, Yongbiao; Zhou, Zhenghua; Cao, Feilong\n2017-10-01\nThere have been a lot of methods to address the recognition of complete face images. However, in real applications, the images to be recognized are usually incomplete, and it is more difficult to realize such a recognition. In this paper, a novel convolution neural network frame, named a low-rank-recovery network (LRRNet), is proposed to conquer the difficulty effectively inspired by matrix completion and deep learning techniques. The proposed LRRNet first recovers the incomplete face images via an approach of matrix completion with the truncated nuclear norm regularization solution, and then extracts some low-rank parts of the recovered images as the filters. With these filters, some important features are obtained by means of the binaryzation and histogram algorithms. Finally, these features are classified with the classical support vector machines (SVMs). The proposed LRRNet method has high face recognition rate for the heavily corrupted images, especially for the images in the large databases. The proposed LRRNet performs well and efficiently for the images with heavily corrupted, especially in the case of large databases. Extensive experiments on several benchmark databases demonstrate that the proposed LRRNet performs better than some other excellent robust face recognition methods. Copyright \u00c2\u00a9 2017 Elsevier Ltd. All rights reserved.\n\n\nGeneralizing and learning protein-DNA binding sequence representations by an evolutionary algorithm\nKAUST Repository\nWong, Ka Chun\n2011-02-05\nProtein-DNA bindings are essential activities. Understanding them forms the basis for further deciphering of biological and genetic systems. In particular, the protein-DNA bindings between transcription factors (TFs) and transcription factor binding sites (TFBSs) play a central role in gene transcription. Comprehensive TF-TFBS binding sequence pairs have been found in a recent study. However, they are in one-to-one mappings which cannot fully reflect the many-to-many mappings within the bindings. An evolutionary algorithm is proposed to learn generalized representations (many-to-many mappings) from the TF-TFBS binding sequence pairs (one-to-one mappings). The generalized pairs are shown to be more meaningful than the original TF-TFBS binding sequence pairs. Some representative examples have been analyzed in this study. In particular, it shows that the TF-TFBS binding sequence pairs are not presumably in one-to-one mappings. They can also exhibit many-to-many mappings. The proposed method can help us extract such many-to-many information from the one-to-one TF-TFBS binding sequence pairs found in the previous study, providing further knowledge in understanding the bindings between TFs and TFBSs. \u00c2\u00a9 2011 Springer-Verlag.\n\n\nGeneralizing and learning protein-DNA binding sequence representations by an evolutionary algorithm\nKAUST Repository\nWong, Ka Chun; Peng, Chengbin; Wong, Manhon; Leung, Kwongsak\n2011-01-01\nProtein-DNA bindings are essential activities. Understanding them forms the basis for further deciphering of biological and genetic systems. In particular, the protein-DNA bindings between transcription factors (TFs) and transcription factor binding sites (TFBSs) play a central role in gene transcription. Comprehensive TF-TFBS binding sequence pairs have been found in a recent study. However, they are in one-to-one mappings which cannot fully reflect the many-to-many mappings within the bindings. An evolutionary algorithm is proposed to learn generalized representations (many-to-many mappings) from the TF-TFBS binding sequence pairs (one-to-one mappings). The generalized pairs are shown to be more meaningful than the original TF-TFBS binding sequence pairs. Some representative examples have been analyzed in this study. In particular, it shows that the TF-TFBS binding sequence pairs are not presumably in one-to-one mappings. They can also exhibit many-to-many mappings. The proposed method can help us extract such many-to-many information from the one-to-one TF-TFBS binding sequence pairs found in the previous study, providing further knowledge in understanding the bindings between TFs and TFBSs. \u00c2\u00a9 2011 Springer-Verlag.\n\n\nParameterization of typhoon-induced ocean cooling using temperature equation and machine learning algorithms: an example of typhoon Soulik (2013)\nScience.gov (United States)\nWei, Jun; Jiang, Guo-Qing; Liu, Xin\n2017-09-01\nThis study proposed three algorithms that can potentially be used to provide sea surface temperature (SST) conditions for typhoon prediction models. Different from traditional data assimilation approaches, which provide prescribed initial/boundary conditions, our proposed algorithms aim to resolve a flow-dependent SST feedback between growing typhoons and oceans in the future time. Two of these algorithms are based on linear temperature equations (TE-based), and the other is based on an innovative technique involving machine learning (ML-based). The algorithms are then implemented into a Weather Research and Forecasting model for the simulation of typhoon to assess their effectiveness, and the results show significant improvement in simulated storm intensities by including ocean cooling feedback. The TE-based algorithm I considers wind-induced ocean vertical mixing and upwelling processes only, and thus obtained a synoptic and relatively smooth sea surface temperature cooling. The TE-based algorithm II incorporates not only typhoon winds but also ocean information, and thus resolves more cooling features. The ML-based algorithm is based on a neural network, consisting of multiple layers of input variables and neurons, and produces the best estimate of the cooling structure, in terms of its amplitude and position. Sensitivity analysis indicated that the typhoon-induced ocean cooling is a nonlinear process involving interactions of multiple atmospheric and oceanic variables. Therefore, with an appropriate selection of input variables and neuron sizes, the ML-based algorithm appears to be more efficient in prognosing the typhoon-induced ocean cooling and in predicting typhoon intensity than those algorithms based on linear regression methods.\n\n\nOptical implementation of neural learning algorithms based on cross-gain modulation in a semiconductor optical amplifier\nScience.gov (United States)\nLi, Qiang; Wang, Zhi; Le, Yansi; Sun, Chonghui; Song, Xiaojia; Wu, Chongqing\n2016-10-01\nNeuromorphic engineering has a wide range of applications in the fields of machine learning, pattern recognition, adaptive control, etc. Photonics, characterized by its high speed, wide bandwidth, low power consumption and massive parallelism, is an ideal way to realize ultrafast spiking neural networks (SNNs). Synaptic plasticity is believed to be critical for learning, memory and development in neural circuits. Experimental results have shown that changes of synapse are highly dependent on the relative timing of pre- and postsynaptic spikes. Synaptic plasticity in which presynaptic spikes preceding postsynaptic spikes results in strengthening, while the opposite timing results in weakening is called antisymmetric spike-timing-dependent plasticity (STDP) learning rule. And synaptic plasticity has the opposite effect under the same conditions is called antisymmetric anti-STDP learning rule. We proposed and experimentally demonstrated an optical implementation of neural learning algorithms, which can achieve both of antisymmetric STDP and anti-STDP learning rule, based on the cross-gain modulation (XGM) within a single semiconductor optical amplifier (SOA). The weight and height of the potentitation and depression window can be controlled by adjusting the injection current of the SOA, to mimic the biological antisymmetric STDP and anti-STDP learning rule more realistically. As the injection current increases, the width of depression and potentitation window decreases and height increases, due to the decreasing of recovery time and increasing of gain under a stronger injection current. Based on the demonstrated optical STDP circuit, ultrafast learning in optical SNNs can be realized.\n\n\nDiagnosis and prediction of periodontally compromised teeth using a deep learning-based convolutional neural network algorithm.\nScience.gov (United States)\nLee, Jae-Hong; Kim, Do-Hyung; Jeong, Seong-Nyum; Choi, Seong-Ho\n2018-04-01\nThe aim of the current study was to develop a computer-assisted detection system based on a deep convolutional neural network (CNN) algorithm and to evaluate the potential usefulness and accuracy of this system for the diagnosis and prediction of periodontally compromised teeth (PCT). Combining pretrained deep CNN architecture and a self-trained network, periapical radiographic images were used to determine the optimal CNN algorithm and weights. The diagnostic and predictive accuracy, sensitivity, specificity, positive predictive value, negative predictive value, receiver operating characteristic (ROC) curve, area under the ROC curve, confusion matrix, and 95% confidence intervals (CIs) were calculated using our deep CNN algorithm, based on a Keras framework in Python. The periapical radiographic dataset was split into training (n=1,044), validation (n=348), and test (n=348) datasets. With the deep learning algorithm, the diagnostic accuracy for PCT was 81.0% for premolars and 76.7% for molars. Using 64 premolars and 64 molars that were clinically diagnosed as severe PCT, the accuracy of predicting extraction was 82.8% (95% CI, 70.1%-91.2%) for premolars and 73.4% (95% CI, 59.9%-84.0%) for molars. We demonstrated that the deep CNN algorithm was useful for assessing the diagnosis and predictability of PCT. Therefore, with further optimization of the PCT dataset and improvements in the algorithm, a computer-aided detection system can be expected to become an effective and efficient method of diagnosing and predicting PCT.\n\n\nDynamics of action potential backpropagation in basal dendrites of prefrontal cortical pyramidal neurons.\nScience.gov (United States)\nZhou, Wen-Liang; Yan, Ping; Wuskell, Joseph P; Loew, Leslie M; Antic, Srdjan D\n2008-02-01\nBasal dendrites of neocortical pyramidal neurons are relatively short and directly attached to the cell body. This allows electrical signals arising in basal dendrites to strongly influence the neuronal output. Likewise, somatic action potentials (APs) should readily propagate back into the basilar dendritic tree to influence synaptic plasticity. Two recent studies, however, determined that sodium APs are severely attenuated in basal dendrites of cortical pyramidal cells, so that they completely fail in distal dendritic segments. Here we used the latest improvements in the voltage-sensitive dye imaging technique (Zhou et al., 2007) to study AP backpropagation in basal dendrites of layer 5 pyramidal neurons of the rat prefrontal cortex. With a signal-to-noise ratio of > 15 and minimal temporal averaging (only four sweeps) we were able to sample AP waveforms from the very last segments of individual dendritic branches (dendritic tips). We found that in short- (< 150 microm) and medium (150-200 microm in length)-range basal dendrites APs backpropagated with modest changes in AP half-width or AP rise-time. The lack of substantial changes in AP shape and dynamics of rise is inconsistent with the AP-failure model. The lack of substantial amplitude boosting of the third AP in the high-frequency burst also suggests that in short- and medium-range basal dendrites backpropagating APs were not severely attenuated. Our results show that the AP-failure concept does not apply in all basal dendrites of the rat prefrontal cortex. The majority of synaptic contacts in the basilar dendritic tree actually received significant AP-associated electrical and calcium transients.\n\n\nMedian Filter Noise Reduction of Image and Backpropagation Neural Network Model for Cervical Cancer Classification\nScience.gov (United States)\nWutsqa, D. U.; Marwah, M.\n2017-06-01\nIn this paper, we consider spatial operation median filter to reduce the noise in the cervical images yielded by colposcopy tool. The backpropagation neural network (BPNN) model is applied to the colposcopy images to classify cervical cancer. The classification process requires an image extraction by using a gray level co-occurrence matrix (GLCM) method to obtain image features that are used as inputs of BPNN model. The advantage of noise reduction is evaluated by comparing the performances of BPNN models with and without spatial operation median filter. The experimental result shows that the spatial operation median filter can improve the accuracy of the BPNN model for cervical cancer classification.\n\n\nChromatic characterization of a three-channel colorimeter using back-propagation neural networks\nScience.gov (United States)\nPardo, P. J.; P\u00c3\u00a9rez, A. L.; Suero, M. I.\n2004-09-01\nThis work describes a method for the chromatic characterization of a three-channel colorimeter of recent design and construction dedicated to color vision research. The colorimeter consists of two fixed monochromators and a third monochromator interchangeable with a cathode ray tube or any other external light source. Back-propagation neural networks were used for the chromatic characterization to establish the relationship between each monochromator's input parameters and the tristimulus values of each chromatic stimulus generated. The results showed the effectiveness of this type of neural-network-based system for the chromatic characterization of the stimuli produced by any monochromator.\n\n\nBayesian Network Constraint-Based Structure Learning Algorithms: Parallel and Optimized Implementations in the bnlearn R Package\nDirectory of Open Access Journals (Sweden)\nMarco Scutari\n2017-03-01\nFull Text Available It is well known in the literature that the problem of learning the structure of Bayesian networks is very hard to tackle: Its computational complexity is super-exponential in the number of nodes in the worst case and polynomial in most real-world scenarios. Efficient implementations of score-based structure learning benefit from past and current research in optimization theory, which can be adapted to the task by using the network score as the objective function to maximize. This is not true for approaches based on conditional independence tests, called constraint-based learning algorithms. The only optimization in widespread use, backtracking, leverages the symmetries implied by the definitions of neighborhood and Markov blanket. In this paper we illustrate how backtracking is implemented in recent versions of the bnlearn R package, and how it degrades the stability of Bayesian network structure learning for little gain in terms of speed. As an alternative, we describe a software architecture and framework that can be used to parallelize constraint-based structure learning algorithms (also implemented in bnlearn and we demonstrate its performance using four reference networks and two real-world data sets from genetics and systems biology. We show that on modern multi-core or multiprocessor hardware parallel implementations are preferable over backtracking, which was developed when single-processor machines were the norm.\n\n\nA Comparison of Supervised Machine Learning Algorithms and Feature Vectors for MS Lesion Segmentation Using Multimodal Structural MRI\nScience.gov (United States)\nSweeney, Elizabeth M.; Vogelstein, Joshua T.; Cuzzocreo, Jennifer L.; Calabresi, Peter A.; Reich, Daniel S.; Crainiceanu, Ciprian M.; Shinohara, Russell T.\n2014-01-01\nMachine learning is a popular method for mining and analyzing large collections of medical data. We focus on a particular problem from medical research, supervised multiple sclerosis (MS) lesion segmentation in structural magnetic resonance imaging (MRI). We examine the extent to which the choice of machine learning or classification algorithm and feature extraction function impacts the performance of lesion segmentation methods. As quantitative measures derived from structural MRI are important clinical tools for research into the pathophysiology and natural history of MS, the development of automated lesion segmentation methods is an active research field. Yet, little is known about what drives performance of these methods. We evaluate the performance of automated MS lesion segmentation methods, which consist of a supervised classification algorithm composed with a feature extraction function. These feature extraction functions act on the observed T1-weighted (T1-w), T2-weighted (T2-w) and fluid-attenuated inversion recovery (FLAIR) MRI voxel intensities. Each MRI study has a manual lesion segmentation that we use to train and validate the supervised classification algorithms. Our main finding is that the differences in predictive performance are due more to differences in the feature vectors, rather than the machine learning or classification algorithms. Features that incorporate information from neighboring voxels in the brain were found to increase performance substantially. For lesion segmentation, we conclude that it is better to use simple, interpretable, and fast algorithms, such as logistic regression, linear discriminant analysis, and quadratic discriminant analysis, and to develop the features to improve performance. PMID:24781953\n\n\nDiagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer.\nScience.gov (United States)\nEhteshami Bejnordi, Babak; Veta, Mitko; Johannes van Diest, Paul; van Ginneken, Bram; Karssemeijer, Nico; Litjens, Geert; van der Laak, Jeroen A W M; Hermsen, Meyke; Manson, Quirine F; Balkenhol, Maschenka; Geessink, Oscar; Stathonikos, Nikolaos; van Dijk, Marcory Crf; Bult, Peter; Beca, Francisco; Beck, Andrew H; Wang, Dayong; Khosla, Aditya; Gargeya, Rishab; Irshad, Humayun; Zhong, Aoxiao; Dou, Qi; Li, Quanzheng; Chen, Hao; Lin, Huang-Jing; Heng, Pheng-Ann; Ha\u00c3\u0178, Christian; Bruni, Elia; Wong, Quincy; Halici, Ugur; \u00c3\u2013ner, Mustafa \u00c3\u0153mit; Cetin-Atalay, Rengul; Berseth, Matt; Khvatkov, Vitali; Vylegzhanin, Alexei; Kraus, Oren; Shaban, Muhammad; Rajpoot, Nasir; Awan, Ruqayya; Sirinukunwattana, Korsuk; Qaiser, Talha; Tsang, Yee-Wah; Tellez, David; Annuscheit, Jonas; Hufnagl, Peter; Valkonen, Mira; Kartasalo, Kimmo; Latonen, Leena; Ruusuvuori, Pekka; Liimatainen, Kaisa; Albarqouni, Shadi; Mungal, Bharti; George, Ami; Demirci, Stefanie; Navab, Nassir; Watanabe, Seiryo; Seno, Shigeto; Takenaka, Yoichi; Matsuda, Hideo; Ahmady Phoulady, Hady; Kovalev, Vassili; Kalinovsky, Alexander; Liauchuk, Vitali; Bueno, Gloria; Fernandez-Carrobles, M Milagro; Serrano, Ismael; Deniz, Oscar; Racoceanu, Daniel; Ven\u00c3\u00a2ncio, Rui\n2017-12-12\nApplication of deep learning algorithms to whole-slide pathology images can potentially improve diagnostic accuracy and efficiency. Assess the performance of automated deep learning algorithms at detecting metastases in hematoxylin and eosin-stained tissue sections of lymph nodes of women with breast cancer and compare it with pathologists' diagnoses in a diagnostic setting. Researcher challenge competition (CAMELYON16) to develop automated solutions for detecting lymph node metastases (November 2015-November 2016). A training data set of whole-slide images from 2 centers in the Netherlands with (n\u00e2\u20ac\u2030=\u00e2\u20ac\u2030110) and without (n\u00e2\u20ac\u2030=\u00e2\u20ac\u2030160) nodal metastases verified by immunohistochemical staining were provided to challenge participants to build algorithms. Algorithm performance was evaluated in an independent test set of 129 whole-slide images (49 with and 80 without metastases). The same test set of corresponding glass slides was also evaluated by a panel of 11 pathologists with time constraint (WTC) from the Netherlands to ascertain likelihood of nodal metastases for each slide in a flexible 2-hour session, simulating routine pathology workflow, and by 1 pathologist without time constraint (WOTC). Deep learning algorithms submitted as part of a challenge competition or pathologist interpretation. The presence of specific metastatic foci and the absence vs presence of lymph node metastasis in a slide or image using receiver operating characteristic curve analysis. The 11 pathologists participating in the simulation exercise rated their diagnostic confidence as definitely normal, probably normal, equivocal, probably tumor, or definitely tumor. The area under the receiver operating characteristic curve (AUC) for the algorithms ranged from 0.556 to 0.994. The top-performing algorithm achieved a lesion-level, true-positive fraction comparable with that of the pathologist WOTC (72.4% [95% CI, 64.3%-80.4%]) at a mean of 0.0125 false-positives per normal whole-slide image\n\n\nComparison of machine-learning algorithms to build a predictive model for detecting undiagnosed diabetes - ELSA-Brasil: accuracy study.\nScience.gov (United States)\nOlivera, Andr\u00c3\u00a9 Rodrigues; Roesler, Valter; Iochpe, Cirano; Schmidt, Maria In\u00c3\u00aas; Vigo, \u00c3\ufffdlvaro; Barreto, Sandhi Maria; Duncan, Bruce Bartholow\n2017-01-01\nType 2 diabetes is a chronic disease associated with a wide range of serious health complications that have a major impact on overall health. The aims here were to develop and validate predictive models for detecting undiagnosed diabetes using data from the Longitudinal Study of Adult Health (ELSA-Brasil) and to compare the performance of different machine-learning algorithms in this task. Comparison of machine-learning algorithms to develop predictive models using data from ELSA-Brasil. After selecting a subset of 27 candidate variables from the literature, models were built and validated in four sequential steps: (i) parameter tuning with tenfold cross-validation, repeated three times; (ii) automatic variable selection using forward selection, a wrapper strategy with four different machine-learning algorithms and tenfold cross-validation (repeated three times), to evaluate each subset of variables; (iii) error estimation of model parameters with tenfold cross-validation, repeated ten times; and (iv) generalization testing on an independent dataset. The models were created with the following machine-learning algorithms: logistic regression, artificial neural network, na\u00c3\u00afve Bayes, K-nearest neighbor and random forest. The best models were created using artificial neural networks and logistic regression. -These achieved mean areas under the curve of, respectively, 75.24% and 74.98% in the error estimation step and 74.17% and 74.41% in the generalization testing step. Most of the predictive models produced similar results, and demonstrated the feasibility of identifying individuals with highest probability of having undiagnosed diabetes, through easily-obtained clinical data.\n\n\nMODIS-Based Estimation of Terrestrial Latent Heat Flux over North America Using Three Machine Learning Algorithms\nDirectory of Open Access Journals (Sweden)\nXuanyu Wang\n2017-12-01\nFull Text Available Terrestrial latent heat flux (LE is a key component of the global terrestrial water, energy, and carbon exchanges. Accurate estimation of LE from moderate resolution imaging spectroradiometer (MODIS data remains a major challenge. In this study, we estimated the daily LE for different plant functional types (PFTs across North America using three machine learning algorithms: artificial neural network (ANN; support vector machines (SVM; and, multivariate adaptive regression spline (MARS driven by MODIS and Modern Era Retrospective Analysis for Research and Applications (MERRA meteorology data. These three predictive algorithms, which were trained and validated using observed LE over the period 2000\u00e2\u20ac\u201c2007, all proved to be accurate. However, ANN outperformed the other two algorithms for the majority of the tested configurations for most PFTs and was the only method that arrived at 80% precision for LE estimation. We also applied three machine learning algorithms for MODIS data and MERRA meteorology to map the average annual terrestrial LE of North America during 2002\u00e2\u20ac\u201c2004 using a spatial resolution of 0.05\u00c2\u00b0, which proved to be useful for estimating the long-term LE over North America.\n\n\nMachine Learning Algorithms For Predicting the Instability Timescales of Compact Planetary Systems\nScience.gov (United States)\nTamayo, Daniel; Ali-Dib, Mohamad; Cloutier, Ryan; Huang, Chelsea; Van Laerhoven, Christa L.; Leblanc, Rejean; Menou, Kristen; Murray, Norman; Obertas, Alysa; Paradise, Adiv; Petrovich, Cristobal; Rachkov, Aleksandar; Rein, Hanno; Silburt, Ari; Tacik, Nick; Valencia, Diana\n2016-10-01\nThe Kepler mission has uncovered hundreds of compact multi-planet systems. The dynamical pathways to instability in these compact systems and their associated timescales are not well understood theoretically. However, long-term stability is often used as a constraint to narrow down the space of orbital solutions from the transit data. This requires a large suite of N-body integrations that can each take several weeks to complete. This computational bottleneck is therefore an important limitation in our ability to characterize compact multi-planet systems.From suites of numerical simulations, previous studies have fit simple scaling relations between the instability timescale and various system parameters. However, the numerically simulated systems can deviate strongly from these empirical fits.We present a new approach to the problem using machine learning algorithms that have enjoyed success across a broad range of high-dimensional industry applications. In particular, we have generated large training sets of direct N-body integrations of synthetic compact planetary systems to train several regression models (support vector machine, gradient boost) that predict the instability timescale. We find that ensembling these models predicts the instability timescale of planetary systems better than previous approaches using the simple scaling relations mentioned above.Finally, we will discuss how these models provide a powerful tool for not only understanding the current Kepler multi-planet sample, but also for characterizing and shaping the radial-velocity follow-up strategies of multi-planet systems from the upcoming Transiting Exoplanet Survey Satellite (TESS) mission, given its shorter observation baselines.\n\n\n\n\n\u00ab\n21\n22\n23\n24\n25\n\u00bb\n\n\n\n\n\n\nSome links on this page may take you to non-federal websites. Their policies may differ from this site.\n\n\n\n\n\n\nWebsite Policies/Important Links\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
  },
  {
    "text": "\n\n\n\n \n\n\n\n\n Accessibility \n Sitemap \n Help\u00a0 \n\n\nListen | Text size\n\u00a0\n                \u00a0\n                \n\n\n\n\n\n | \n\n\n\nSearch\n\n\n\n\n\n |\n ||\n\n\n\n\n\n\n\n\nSearch\n\n\n\n\n\n\n\n\n\n\n\nApply for a licence\nChange your address\nFind a job\nPay a bill\nRenew a library book\n\n\n\n\nFind a school\nFind out about grants\nFind your refuse and recycling collection day\nPay a parking fine\n\n\n\n\nPay your council tax\nRenew a library book\nReport a food establishment\nSearch and comment on planning applications\nView public notices\n\n\n\n\n\n\n\n\n\nHome > Council and Democracy > Agenda and minutes\n\n\n\n\n\n\nAgenda and minutes\n\nCouncilWednesday, 30th September, 2020 6.00 pm\n\n\n\nAttendance details\nAgenda frontsheet\r\n\t\t\t PDF 291 KB \n\nAgenda reports pack\r\n\t\t\t     PDF 2 MB \nPrinted minutes\r\n PDF 209 KB \n\n\n\n\nVenue: via Zoom Conference Call\nContact: Yvonne Burnett\u00a0 \r\n\t\tDemocratic Governance Senior Advisor\r\n\t\t\r\n\t\t\n\nItems\n\nNo.\nItem\n\n\n1.\n\nDECLARATIONS OF INTEREST\n\nMembers are asked to declare any\r\ninterests in the items under consideration and in doing so\r\nstate:\n\u00a0\n(1) the type of interest concerned\r\neither a\n\u00a0\n(a)\u00a0\u00a0\r\npersonal interest\n(b)\u00a0\u00a0\r\nprejudicial interest\n(c)\u00a0\u00a0\u00a0\r\ndisclosable pecuniary interest (DPI)\n\u00a0\nand\n\u00a0\n(2) the nature of the interest\r\nconcerned\n\u00a0\nIf any member requires advice on\r\ndeclarations of interests, they are advised to contact the Head of\r\nDemocratic Governance in advance of the meeting.\n\n\nMinutes:\n\nCouncillors Baker, D Coleman, Farrell, Hugo,\r\nJackson, O\u2019Hara, Owen, Robertson and Stansfield declared\r\nprejudicial interests in agenda item 5 \u2018Call-In \u2013\r\nReferral to full Council\u2019 as members of the Planning\r\nCommittee.\u00a0 Councillors Mrs Callow and\r\nCallow declared personal interests in the same item as they lived\r\nin the vicinity of Stanley Park Golf course.\n\n\n\n\n\n2.\n\nMINUTES OF THE LAST MEETING HELD ON 20 JULY 2020  PDF 315 KB \n\nTo agree the minutes of the last meeting held\r\non 20 July 2020 as a true and correct record.\n\n\nMinutes:\n\nResolved:\u00a0 That the minutes of the Council meeting held on 20\r\nJuly 2020 be signed by the Deputy Mayor as a correct record.\n\n\n\n\n\n3.\n\nANNOUNCEMENTS\n\nTo receive official announcements from the\r\nMayor.\n\n\nMinutes:\n\nThe Mayor announced the sad death on 29 August\r\nof former Mayoress Betty Crichton and, on behalf of the Council,\r\nexpressed condolences to her family.\n\u00a0\nMembers then observed a minute\u2019s\r\nsilence.\n\n\n\n\n\n4.\n\nEXECUTIVE REPORTS AND COMBINED FIRE AUTHORITY REPORT  PDF 367 KB \n\nTo\r\nconsider the attached reports to Council from the Corporate, People\r\nand Place portfolios and the Combined Fire Authority\r\nreport.\n\u00a0\nMembers are reminded that:\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe Lead Executive Member * has up to three minutes to present the\r\nreport, after which there will be a period of no longer than 25\r\nminutes per report for questions/comments (a green card will give a\r\none minute warning, red for the end of the debate).\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThere will be three minutes per question/ comment from any\r\nCouncillor on anything within the portfolio and no limit to the\r\nnumber of times a Councillor can ask a question.\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThere will be a period of up to 25 minutes for responses from any\r\nCabinet Member * on their area of responsibility at the end of the\r\nquestions/ comments for each report.\n\u00a0\n* or\r\nCombined Fire Authority representative.\n\n\nAdditional documents:\n\n\nItem 4(b) - People Portfolios report , item 4.\n PDF 317 KB  \n\nItem 4(c) - Place Portfolios report , item 4.\n PDF 237 KB  \n\nItem 4(d) - Combined Fire Authority report , item 4.\n PDF 200 KB  \n\nMinutes:\n\nPrior to consideration of the Executive and\r\nCombined Fire Authority reports, Dr Arif Rajpura, Director of\r\nPublic Health was invited to address members of the Council in\r\nrespect of the Covid-19 pandemic.\u00a0 Dr\r\nRajpura outlined the latest pandemic developments and government\r\nguidance, as well as the impact upon the Blackpool\r\nlocality.\u00a0 He went on to answer\r\nquestions from councillors in relation to arrangements that were in\r\nplace to protect residents including local testing and \u2018track\r\nand trace\u2019 systems.\u00a0\n\u00a0\nThe Executive Lead Members for the meeting then\r\npresented reports to the Council on work undertaken in the\r\nCorporate, Place and People portfolio areas. The reports covered\r\ncorporate, strategic and policy issues, together with work being\r\nundertaken in transforming services and with partners.\u00a0\u00a0 The report from representatives on the\r\nCombined Fire Authority was also considered.\n\u00a0\nQuestions, comments and debate were invited from\r\nall councillors on each of the report areas and the following\r\nmembers offered written responses to questions raised at the\r\nmeeting:\n\u00a0\n1.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nCouncillor L Williams agreed to provide a written\r\nresponse to Councillor Walsh on the number of\r\nhotels and guesthouses that were being leased by the Council, along\r\nwith details of the financial support for payment of leases/rents\r\nto those establishments that had been unable to trade during the\r\nnational lockdown.\n2.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nFollowing comments from Councillor M Scott,\r\nCouncillor L Williams offered to provide details of the planned\r\nstructure to support the young people in the Council\u2019s care\r\ninto apprenticeships.\n3.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nCouncillor Smith offered to provide Councillor Walsh\r\nwith details of the regulations regarding the compulsory purchase\r\nby the Council, of properties that had been problematic/ derelict\r\nfor over ten years.\n4.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nCouncillor D Scott left the meeting prior to\r\nconsideration of the report from the Combined Fire Authority\r\nrepresentatives.\n5.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nHaving declared prejudicial interests in agenda item\r\n5, Councillors Baker, D Coleman, Farrell, Hugo, Jackson,\r\nO\u2019Hara, Owen, Robertson and Stansfield left the meeting prior\r\nto consideration of the item.\n\n\n\n\n\n5.\n\nCALL IN - REFERRAL TO FULL COUNCIL  PDF 238 KB \n\nTo consider the referral to\r\nCouncil by the Tourism, Economy and Communities Scrutiny Committee\r\nof the Executive Decision EX29/2020 \u2018Proposed\r\nappropriation and disposal of open space land at Stanley Park Golf\r\nCourse, Blackpool\u2019.\n\n\nAdditional documents:\n\n\nAppendix 5(a) - EX29 Stanley Park Golf Course , item 5.\n PDF 395 KB  \n\nAppendix 5(b) - TEC - 23 July 2020 - Call-In - Minutes , item 5.\n PDF 198 KB  \n\nMinutes:\n\nMembers considered the referral from the\r\nTourism, Economy and Communities Scrutiny Committee in respect of\r\nthe Executive Decision EX29/2020 \u2018Proposed appropriation and\r\nopen space land at Stanley Park Golf Course,\r\nBlackpool\u2019.\u00a0\n\u00a0\nMotion 1:\u00a0 Councillor T Williams proposed (and Councillor\r\nClapham seconded):\n\u00a0\n\u2018That the Council refers the item back\r\nto the Executive, that it listens to the people of Blackpool and\r\noverrides the decision to develop the site in order for the Council\r\nto protect and maintain this land for future generations in\r\nperpetuity\u2019.\n\u00a0\nIn moving his motion, Councillor T Williams\r\nreferred to the number of representations that had been received\r\nthat objected to the development on the site and his reasons for\r\ncall-in of the item including that he had considered that there had\r\nbeen a lack of consultation on the proposed development and that it\r\nshould be reserved for open green space.\u00a0\n\u00a0\nA range of views were expressed on the\r\nmotion.\u00a0 A number of members supported\r\nthe proposal to refer the decision back for review, citing that\r\nunlike other developments, the land was not historically a campsite\r\nand should be protected as an opportunity to develop the site for\r\nall users as the proposed development was aimed at tourists rather\r\nthan the town\u2019s residents.\u00a0 It was\r\nalso stated that the current use provided aesthetic green space for\r\nthe town and the proposed development was not in line with the\r\nobjectives in the Council\u2019s Green and Blue Strategy or the\r\nCouncil\u2019s climate change declaration to protect the\r\nenvironment.\u00a0 Concerns were expressed\r\nthat it would be difficult to change any concept once a planning\r\napplication had been submitted, that many developers gained\r\nplanning consent on appeal and that not all members had been\r\ninvolved in considering alternative proposals.\n\u00a0\nA number of members spoke against the notice\r\nof motion, stating that accessibility of the site to residents was\r\ncurrently limited and as such the land was underused by a limited\r\nnumber of people who were golf club members.\u00a0 It was stated that golf courses were not natural\r\nenvironments and therefore did not support indigenous wildlife,\r\nwere ineffective at carbon capture and that the developer had\r\nplanned to plant more trees and commission an environmental\r\nsurvey.\u00a0 In terms of the Executive\r\ndecision, it was expressed that it had been necessary to determine\r\nappropriation whatever the future outcome on use, that the recent\r\npetition included people who were unlikely to use the land, that a\r\ndiligent tender and decision-making process had been followed and\r\nthat the planning process would determine the appropriate use of\r\nland.\u00a0 Members also stated that the\r\ndevelopment would create potential local jobs and opportunities for\r\nsuppliers in the area.\n\u00a0\nPrior to voting, five members of the\r\nCouncil requested that the vote on the motion should be\r\nrecorded.\u00a0 The voting was as follows:\n\n\u00a0\n\u00a0\nFor the motion:\u00a0 Councillors Mrs Callow,\r\nCallow, Clapham, G Coleman, Cox, Galley, Roberts, Mrs Scott, R\r\nScott, Walsh, T Williams, Wilshaw, Wing - total\r\n13.\n\u00a0\nAgainst the motion:\u00a0\r\nCouncillors Benson, Blackburn, Brookes, Burdess, Cain, Campbell,\r\nCollett, \u00a0...\u00a0 \r\nview the full minutes text for item 5.\n\n\n\n\n\n\n\n\n\n\u00a0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNavigate to...2\nChoose another section\nHome\nResidents\nBusiness\nYour Council\nVisitors\nNews\nChoose another section\n\n\n\nHome\nYour Council\nCalendar\nCommittees\nDecisions\n\nForward Plans\nForthcoming Decisions\nLibrary\nMeetings\nOutside Bodies\n\nSearch documents\n\nSubscribe To Updates\nWhat's New\n\nYour Councillors\n\n\n\n\n\n\n        \u00a0\n      \n\n\n\n\n Social Networks \n\n Join us on facebook \n Follow us on twitter \n Find us on Google+ \n Subscribe to our feed \n\n\n\n\u00a0 \n\n\n\u00a0 \n\n\n\u00a0 \n \u00a0\u00a0\n| \n\n\n\n\n\n\n \u00a9 2012 Council \n Back to Mobile Site \n Privacy policy \n Disclaimer \n Contact us\u00a0\u00a0\u00a0 | \u00a0 A-Z search\u00a0\u00a0 \n View Desktop Site \n\n Powered by Contensis| \n\n\n\n\n\n\n"
  },
  { "text": "\n\n\nLoading\n\n" },
  {
    "text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccessibility\nRegister | Sign in\n\nBenefits of Enfield\u00a0ConnectedYour account will ...\n\nmake it easier for you to request many of our services online\nsave you time by pre-filling forms with the details you give us\nprovide confirmation that your request has been received\nhelp you find out what's happening in Enfield\n\n\n\nNewsletters\n\n\n\n\n\n\n\n\nSearch\n\n\n\n\n\n\n\n\n\n\n\nAccessibility\nNewsletters\n\n\n\n\n\n\n\n\n\nSearch\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nK\nL\nM\nN\nO\nP\nQ\nR\nS\nT\nU\nV\nW\nX\nY\nZ\n\n\n\n\n\n\n\n\n\n\n\nHome\nServices\nCouncillors and democracy\nAgenda and draft minutes\n\n\n\n\n\nAgenda and draft minutes\n\nCouncil - Wednesday, 30th September, 2020 7.00 pm\n\n\n\n\nAgenda frontsheet\r\n\t\t\t PDF 206 KB \n\nAgenda reports pack\nCouncillor Questions and Responses  PDF 1 MB \nLate Papers  PDF 61 KB \nPrinted draft minutes\r\n PDF 221 KB \n\n\n\n\nContact: Penelope Williams\u00a0 \r\n\t\t Email:\u00a0penelope.williams@enfield.gov.uk\n\n\nItems\n\nNo.\nItem\n\n\n1.\n\nThe Mayor's Chaplain to give a Blessing\n\nView the background to item 1.\n\nMinutes:\n\nThe Mayor\u2019s Chaplain was unable to\r\nattend the meeting.\n\n\n\n\n\n2.\n\nMayor's Announcements in Connection with the Ordinary Business of the Council\n\nView the background to item 2.\n\nMinutes:\n\nThe Mayor began by wishing everyone good evening\r\nand welcoming them to Council meeting.\u00a0\n\u00a0\n2.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nMayor\u2019s Announcements\u00a0\n\u00a0\nThe Mayor said\r\nthat he trusted that everyone had had a good summer, despite this\r\nstrange time when many people were living with the fear and\r\nisolation of the pandemic, that has hit the world this\r\nyear.\n\u00a0\nHe thanked all\r\nthe staff at the Council who had worked tirelessly throughout the\r\npandemic to provide an excellent service to the public, both\r\nworking alongside and supporting one another.\u00a0\u00a0\n\u00a0\nOn 31 August\r\n2020 he had been invited to Pymmes Park for the Enfield Stands\r\nTogether - The Big Thank You \u2013 where certificates were given\r\nto many volunteers and helpers who had kindly given their time and\r\nsupport to help at the Enfield Food Bank.\u00a0 He said that he knew that there are many more\r\npeople to thank and that this would be arranged. He was very\r\ngrateful to everyone who had been involved and thought that the\r\npandemic had shown that Enfield was a place of solidarity and\r\nrespect.\u00a0 He was very proud to be the\r\nMayor of such a vibrant and enthusiastic Borough.\n\u00a0\nMy Mayoral\r\ncharity was progressing well, and he had decided to dedicate his\r\nfund raising to the following well deserved\r\ncauses:\n\u00a0\n1.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 The\r\nFelix Project (Food Bank)\n2.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nNHS\n3.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Violence\r\nAgainst Women & Children\n4.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Under\r\nprivileged, learning difficulty and special needs\r\nchildren.\n5.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nNightingale Cancer Support Centre\n6.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Eagles\r\nBoxing Club\n\u00a0\nThe Mayor said\r\nthat as the year progresses, he would be adding to these charities\r\nin the hope of helping as many residents of Enfield as\r\npossible.\u00a0 His plan was to launch a\r\nt-shirt campaign where he would personally fund the purchase and\r\nprinting of t-shirts designed by companies and individuals who will\r\nhopefully go on to purchase these for friends and family members.\r\nAll the money from the sale of the t-shirts would go directly the\r\nMayors Charity.\n\u00a0\nThe Mayor said\r\nthat it was a particularly difficult time for fund raising\r\ngenerally and many charities were having difficulties gathering\r\nurgently needed funds.\u00a0 He hoped that\r\nhis t-shirt idea would be a long running event which would be\r\nsuccessful throughout the year.\n\u00a0\nThe Mayor said\r\nthat he knew that his friends and fellow members would support him\r\nand together they would look forward to better times when they\r\ncould get together without isolation to enjoy their lives as\r\nbefore.\n\u00a0\nThe Mayor\r\nconcluded his speech by saying that he wished everyone health and\r\nhappiness.\n\u00a0\nThe Mayor then asked members to\r\nobserve a minute\u2019s silence in memory of Councillor Chris\r\nBond, a longstanding and dedicated councillor who had recently\r\npassed away.\u00a0\n\u00a0\nCouncillors Caliskan, Laban,\r\nTaylor, Levy, Needs, Neville, Aksanoglu, Keazor, Leaver, Barnes,\r\nYusuf and the young mayor spoke in tribute to Chris Bond and his 34\r\nyears of service as a councillor in Enfield.\n\n\n\n\n\n3.\n\nMinutes of the Meeting held on 1 July 2020  PDF 287 KB \n\nView the background to item 3.\n\n\nTo approve the minutes of the meeting held on\r\n1 July 2020 as a correct record.\u00a0\n\n\nMinutes:\n\nThe minutes of the Annual Council meeting held\r\non 1 July 2020 were received and agreed as a correct\r\nrecord.\u00a0\n\n\n\n\n\n4.\n\nApologies\n\nView the background to item 4.\n\nMinutes:\n\nApologies for absence were received from\r\nCouncillors Brown, Chibah, Eren, David-Sanders, Lappage and\r\nStewart.\u00a0\n\n\n\n\n\n5.\n\nDeclaration of Interests\n\nView the background to item 5.\n\n\nMembers of the Council are invited to identify\r\nany disclosable pecuniary, other pecuniary or non pecuniary\r\ninterests relating to items on the agenda.\u00a0\n\n\nMinutes:\n\nCouncillor Rye declared a non-pecuniary\r\ninterest in Motion 1 and Councillor Taylor declared a disclosable\r\npecuniary interest in item 10 (Reardon Court Extra Care Housing\r\nScheme \u2013 Adjustment to the Capital Programme) as he was a\r\ndirector of Energetik.\u00a0\u00a0\n\n\n\n\n\n6.\n\nOpposition Priority Business - Enfield Council Open for Business  PDF 249 KB \n\nView the background to item 6.\n\n\n\u00a0\nAn issues paper prepared by the Opposition\r\nGroup is attached for information.\u00a0\n\u00a0\nThe Council rules relating to Opposition\r\nBusiness are also attached for information.\n\u00a0\n\n\nAdditional documents:\n\n\nCouncil Rules for Oppositiion Business , item 6.\n PDF 145 KB  \n\nMinutes:\n\nCouncillor Laban introduced the issues paper,\r\nprepared by the Opposition Group.\n\u00a0\n1.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nIssues highlighted by Councillor Laban were as follows:\u00a0\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThat Enfield had been slower to open up face to face services\r\nfollowing the Coronavirus lockdown than other city centres and\r\nLondon boroughs.\u00a0\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe Civic Centre has been closed since March and since July only 4\r\nof the main libraries have been open for face to face\r\nenquiries.\u00a0\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nWorks have been taking place in the reception area at the Civic\r\nCentre throughout and there is no clear signage to explain where to\r\ngo to get help and support.\u00a0\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThis has had a detrimental effect on the local economy and retail\r\noutlets.\u00a0\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nIf lockdown restrictions are to be re-imposed the Council needs to\r\nbe more flexible and efficient at opening up.\u00a0\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nAt the libraries that are open, residents have to book appointments\r\nweeks in advance to be able to browse the books, unlike in other\r\nplaces.\u00a0\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe government lifted restrictions on opening of leisure centres on\r\nthe 4 July 2020, but leisure centres were only opened during the\r\nweek of the 17 August and some are still closed.\u00a0\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe household waste and recycling centre at Barrowell Green is\r\nstill only open via appointment.\u00a0 This\r\nhas led to an increase in flytipping.\u00a0\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe Council could and should do more to open up for business. The\r\nclosure of the Civic Centre building had made the Council look as\r\nif it had been closed.\n\u00a0\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nA review should be carried out to find out why the response has\r\nbeen so slow and a plan of action produced to deal with any future\r\nlock downs.\u00a0 The Council should be ready\r\nand agile to do more to open up services and support the local\r\neconomy.\n\u00a0\n2.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nCouncillor Caliskan, the Leader of the Council, responded on behalf\r\nof the Majority Group highlighting:\n\r\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nShe had been astonished at how disingenuous, ineffective and out of\r\ntouch the Conservative group had shown themselves to be in bringing\r\nforward this topic for opposition priority business.\u00a0\n\r\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nIf the Civic Centre had been fully open during this time when Covid\r\n19 infections were increasing it would have been unwise and been in\r\ncontradiction to Central Government advice, that people should work\r\nfrom home wherever possible.\u00a0\n\r\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe administration had taken the decision to keep Council staff\r\nsafe.\u00a0\n\r\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nDespite this approximately 150 members of staff were attending the\r\nCivic Centre to provide vital services every day.\u00a0 During lockdown a supply centre had been set up to\r\ndeliver food parcels where needed, the call centre has taken over\r\n20,000 calls, \u00a31,000m funds have been provided to support\r\nsmall businesses and local town centres.\n\r\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe Council had introduced an appointment system for the recycling\r\ncentre and this had also been done at the leisure centres to help\r\nmanage visitor flow.\u00a0 There has now been\r\na significant reduction in no shows.\u00a0\n\r\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nFusion is not run by the Council.\u00a0 It\r\nwas outsourced by a previous administration. The Council had not\r\nbeen prepared to subsidise this private organisation.\u00a0 However, four leisure \u00a0...\u00a0 \r\nview the full minutes text for item 6.\n\n\n\n\n\n7.\n\nHomelessness in Enfield  PDF 411 KB \n\nView the background to item 7.\n\n\nTo receive a report from the Executive\r\nDirector Place on Homelessness in Enfield.\u00a0 Key Decision Number:\u00a0\r\n4682\n\u00a0\nCouncil is asked to approve the Housing\r\nAllocations Policy.\u00a0\n\u00a0\nThis report was considered at Cabinet on 15\r\nJuly 2020 and recommended onto Council for final\r\napproval.\u00a0\n\n\nAdditional documents:\n\n\nHousing Allocations Scheme , item 7.\n PDF 736 KB  \n\nAllocations EQIA , item 7.\n PDF 379 KB  \n\nMinutes:\n\nCouncillor Needs proposed and Councillor Yusuf\r\nseconded the report of the Executive Director Place on homelessness\r\nin Enfield.\u00a0\n\u00a0\nNOTED\n\u00a0\n\n1.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThat this report had been considered and recommended on to Council\r\nfor approval at the Cabinet meeting held on 15 July 2020.\n\u00a0\n\n2.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nCouncillor Needs in proposing this report highlighted the\r\nfollowing:\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe country was in the middle of a national housing crisis,\r\nfollowing a serious lack of investment in housing.\u00a0 Many people were moving out of Inner London into\r\nOuter London and many had been affected by the Government\u2019s\r\nhousing benefit cap.\u00a0\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe Council planned to step in to prevent people becoming homeless\r\nat the earliest stage and to help equip people with the skills to\r\nmanage their tenancies better to avoid becoming homeless.\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe Council had developed a bold housing strategy to help reshape\r\nthe housing market and improve the quality of rented\r\nhousing.\u00a0 As part of this they would\r\nalso be running a professional ethical lettings agency for private\r\nsector properties.\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe final component of the Council\u2019s recent work in this area\r\nwas this Housing Allocations Policy which will, for the first time,\r\nreward residents who make a success of living in the private rented\r\nsector.\u00a0\u00a0\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe new scheme will increase transparency in the allocation of\r\nsocial rented homes, based on enduring housing needs: it increases\r\npriority for those living in overcrowded situations, increases\r\naccess to a range of properties, introduces local lettings schemes\r\nfor new build properties to enable local residents to directly\r\nbenefit from regeneration activities, increases priority for\r\nhomeless households who move into the private sector rather than\r\nremaining in temporary accommodation.\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nIt is anticipated that the scheme will go live in December\r\n2020.\u00a0\n\u00a0\n\n3.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nIn order to ensure that residents are treated fairly during the\r\nimplementation of the policy the following paragraph (included in\r\nthe council update sheet) has been added to the report:\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n\u00a0\n\u201cWe recognise\r\nthat the gap between the approval of the scheme and its\r\nimplementation will potentially have an adverse impact on some\r\nhouseholds where we are discharging our statutory homeless duties\r\ninto the private rented sector.\u00a0 For\r\nhouseholds in this position we will award points at the time of\r\nimplementation of the scheme based on the points that they would\r\nhave been entitled to, had the scheme been implemented\r\nimmediately\u201d.\n\u00a0\n\n4.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe comments of the Majority Opposition Group including:\n\u00a0\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nWhile welcoming the report and supporting the need for early\r\nintervention, there was regret that the majority opposition group\r\ncould not support the new allocation scheme because of several\r\nissues which are set out below.\u00a0 They\r\nindicated that they would have to abstain on the report, if those\r\nconcerns could not be resolved.\u00a0\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThey felt that the scheme discriminated against those in employment\r\nboth full and part time.\u00a0\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nConcern about the change to the guidelines on local connection (the\r\nGovernment guidelines previously stated that local connections\r\nshould be at least 5 years, the new policy was allowing 3\r\nyears).\u00a0 The three-year rule would make\r\nit easier for those with less \u00a0...\u00a0 \r\nview the full minutes text for item 7.\n\n\n\n\n\n8.\n\nTreasury Management Outturn Report 2019/20  PDF 361 KB \n\nView the background to item 8.\n\n\nTo receive a report from the Executive\r\nDirector of Resources presenting the Council\u2019s Annual\r\nTreasury Management Report for 2019 - 20 in accordance with\r\nTreasury Management Practices.\u00a0\n\u00a0\nCouncil is asked to approve the\r\nrecommendations in the report.\u00a0\n\u00a0\nIt is a regulatory requirement for Council to\r\nreceive this report by 30 September each year. (Key Decision\r\nReference Number: KD: 5152)\n\n\nMinutes:\n\nCouncillor Maguire moved and Councillor\r\nCaliskan seconded the report of the Executive Director Resources\r\npresenting the Council\u2019s Annual Treasury Management Outturn\r\nReport for 2019-20.\n\u00a0\nNOTED\n\u00a0\n\n1.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe report had been considered by Cabinet on 15 July 2020 and\r\nrecommended onto Council for approval.\n\u00a0\n\n2.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe points raised by Councillor Maguire proposing the\r\nreport:\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe outstanding borrowing to 31 March 2020 was \u00a3968.9\r\nincluding \u00a3240m long term borrowing from the Public Works\r\nLoan Board (PWLB) which had replaced higher interest\r\nloans.\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nIn March 2020 \u00a380m PWLB borrowing was raised with an average\r\nrate of 1.45% - loans maturing in 50 years for HRA projects taking\r\nadvantage of the low interest rate.\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nCapital financing was \u00a348.9m less than forecast and there had\r\nbeen no debt rescheduling.\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe table on the first page of the report summarises the Council\r\nposition.\u00a0 Table 1 contains the balance\r\nsheet summary, table 2 the Treasury Management Summary, Table 3 the\r\nTreasury Management Borrowing Summary, Table 4 Capital Financing\r\nRequirements, Table 5 Cost of Borrowing.\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nCapital finance had increased and would increase further to pay for\r\ncapital projects\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe Council had 90 loans repayable over 50 years which helps to\r\nspread the risk.\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nDuring the year the Council\u2019s investment balance ranged\r\nbetween \u00a35million and \u00a3147 due to timing differences\r\nbetween income and expenditure.\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nEnfield had not invested in out of town shopping centres, an issue\r\nthat had been highlighted by the Public Works Loans Board, unlike\r\nsome boroughs\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nApproving the removal of the 75% cap on total aggregate investments\r\nwould give much needed flexibility and increasing money limits will\r\nenable the Council to earn more from cash deposits.\n\r\n\u00a0\n\n3.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe following highlighted by the Majority Opposition\r\nGroup:\u00a0\u00a0\u00a0\u00a0\u00a0\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nConcern about the high levels of borrowing which currently stood at\r\nnearly \u00a31billion.\u00a0\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nConcern that the Council\u2019s money belonged to the people of\r\nEnfield and should be spent prudently.\u00a0\r\nCurrent debt averaged \u00a33,500 per resident.\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe view that too much was being spent on projects such as Meridian\r\nWater and that the properties being built would be out of the reach\r\nof ordinary Enfield people.\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nConcern that \u00a33.2m was being spent from the current revenue\r\naccount to service the debt.\u00a0 The view\r\nthat this should be being spent on day to day services instead.\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nPost Covid, there was a risk that\r\ninterest rates would increase.\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nCurrent levels of borrowing were felt to be unsustainable and could\r\nlead to financial problems in the future.\u00a0 The administration was leaving a legacy of debt\r\nwhich would have to be paid back by future generations.\u00a0\u00a0\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nConcern that borrowing had increased by \u00a3147m in one\r\nyear.\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThat the Council should be looking to the private sector as a\r\nsource of investment, rather than doing things themselves.\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe view that projects such as Meridian Water, Elizabeth House and\r\nReardon Court were being poorly managed and would have succeeded\r\nbetter if the private sector had been involved.\u00a0\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nCommendation for the clarity of the report.\u00a0\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nReprofiling and rescheduling debt was only putting things off into\r\nthe future, at \u00a0...\u00a0 \r\nview the full minutes text for item 8.\n\n\n\n\n\n9.\n\nOverview and Scrutiny Work Programme 2020/21  PDF 286 KB \n\nView the background to item 9.\n\n\nTo receive a report from the Overview &\r\nScrutiny Committee setting out the Scrutiny Annual Work Programme\r\nand Workstreams identified for 2020/21.\n\u00a0\nCouncil is asked to approve the scrutiny work\r\nprogramme for 2020/21.\n\u00a0\nThis report was agreed for recommendation to\r\nCouncil by the Overview and Scrutiny Committee on 15 September 2020\r\nand by Cabinet on 16 September 2020.\u00a0\n\n\nMinutes:\n\nCouncillor Susan Erbil proposed and Councillor\r\nGreer seconded the report of the Overview and Scrutiny Committee\r\nsetting out the scrutiny annual work programmes for\r\n2020/21.\u00a0\n\u00a0\nNOTED\n\u00a0\n\n1.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe report was considered at Cabinet on 16 September 2019 and\r\nrecommended to Council for approval.\u00a0\n\u00a0\n\n2.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe comments of Councillor Susan Erbil in proposing the report:\n\u00a0\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe work programme included programmes for the new scrutiny panels\r\nwhich had been set up following the structural changes agreed at\r\nAnnual Council in July.\u00a0\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThey would focus on those areas which were important to\r\nresidents:\u00a0 four of the eight panels\r\nwould be looking at the impact of Covid 19.\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThey would enable members to make effective and constructive\r\ncomment on Council policies and priorities, taking up concerns of\r\nthe public in an independent and responsible way.\u00a0\n\r\n\u00a0\n\n3.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe comments from the Majority Opposition Group:\u00a0\n\u00a0\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nWelcome and support for the programme and the new structure which\r\nwas now more aligned with Council departments and\r\nservices.\u00a0\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nIt was the Council\u2019s duty to scrutinise and to ensure Council\r\nfunds were wisely spent in the best interests of the residents.\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe scrutiny function was a good way to ensure that all councillors\r\nwere participating the in the running of the Council.\u00a0\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nParticipation also enabled councillors to increase their knowledge\r\non a wide range of issues.\u00a0\n\u00a0\nFollowing the debate, the report was agreed\r\nunanimously.\u00a0\n\u00a0\nAGREED to approve the scrutiny\r\nwork programme and workstreams for 2020/21.\u00a0\n\n\n\n\n\n10.\n\nChange in Order of Business\n\nView the background to item 10.\n\nMinutes:\n\nCouncillor Glynis Vince moved and Councillor\r\nLaban seconded a proposal under paragraph 4.2 of the Council\r\nprocedure rules to propose that the time allowed for reports be\r\nextended.\n\u00a0\nThis was not agreed.\u00a0\n\u00a0\nCouncillor Nesil Caliskan moved and Councillor\r\nGreer seconded a proposal under paragraph 4.2 of the Council\r\nprocedure rules to change the order of items on the agenda so that\r\nMotion 9 under Item 12 motions should be taken as the next item of\r\nbusiness.\u00a0\n\u00a0\nThis was agreed after a vote with the\r\nfollowing result:\n\u00a0\nFor: 37\nAgainst: 15\nAbstentions: 0\u00a0\n\u00a0\nThe minutes reflect the order of the\r\nmeeting.\u00a0\n\n\n\n\n\n11.\n\nMotions  PDF 136 KB \n\n View the declarations of interest for  item 11.\nView the background to item 11.\n\n\nMotion 1 in the name of Councillor Edward Smith\n\u00a0\nThis Council agrees to resist residential\r\ndevelopments on Tube Station car parks in Enfield that are not in\r\nconformity with the existing local plan on the grounds that these\r\ncar parks encourage commuters to use public transport.\nMotion 2 in the name of Councillor Maria Alexandrou\n\u00a0\nCervical screening is a way for\r\nwomen to protect themselves from cancer. The sad reality is that\r\nfewer women are now having cervical screening. Last year 1.3m women\r\ndidn\u2019t attend NHS screenings. There are 3,200 new cases of\r\ncervical cancer every year and of those 870 women die from\r\nit.\n\u00a0\nAccording to CANCER RESEARCH UK\r\n99.8% of cases are preventable. When Jade Goody fought her cancer\r\nbattle, nearly 80% of women went for smear tests.10 years later,\r\nonly 72% of women go. If this rate falls any lower, the rise in\r\ndeaths will shoot up. In the case of Jade Goody, she ignored\r\nletters about her abnormal cells. She needed to go to hospital for\r\nsurgery to remove those abnormal cells, surgery which most probably\r\nwould have saved her life.\n\u00a0\nMany young women in their 20s\r\nand 30s are dying from cervical cancer and the tragedy is they are\r\nleaving behind their partners and young children.\u00a0 We need to\r\nencourage everyone to look after their health and have regular\r\ncheck-ups.\n\u00a0\nEnfield Council therefore\r\nagrees to work together with other agencies for a local campaign on\r\ncervical cancer awareness and encourage women to attend that\r\nimportant screening test. It only takes 5 minutes at the\r\ndoctor\u2019s surgery and this test can save your life.\n\u00a0\nMotion 3 in the name of Councillor Aramaz\n\u00a0\nEnfield Council recognises that\r\nthe Covid 19 Pandemic has disrupted the economy\r\nsignificantly.\u00a0 Lockdown measures have meant that the UK\r\neconomy had shrunk over 20% by the end of August 2020 in comparison\r\nto the previous three months.\n\u00a0\nThis will inevitably mean that\r\ncertain reforms must be made to the economy in order to avoid\r\nexacerbating the economic crisis.\u00a0\n\u00a0\nSince 2010, austerity measures\r\nwere introduced and quantitative easing was used to stimulate the\r\neconomy unsuccessfully.\u00a0 By 2016, up to \u00a3445 billion was\r\ncreated and given to the financial markets whereby a minuscule 8%\r\nof the wealth trickled down to the real economy, toppling the\r\ntrickle-down economics argument. In June 2020, this figure now\r\nstood at a total of \u00a3745billion.\n\u00a0\nRealistically, quantitative\r\neasing should be used not to aid the financial markets but to aid\r\nthe real economy by investing into building homes, developing\r\ninfrastructure and creating jobs.\n\u00a0\nCurrently, Enfield Council\r\nfinds itself at breaking point because of austerity measures\r\nintroduced by the government.\u00a0 Since 2010, the Council has\r\nlost more than 60% of its budget in real terms and cannot survive\r\nanymore.\u00a0\n\u00a0\nTherefore, Enfield Council\r\ndemands that the government does not reintroduce austerity measures\r\npost-pandemic and instead embraces the opportunity to change\r\nsociety for the better by investing in the real economy.\n\u00a0\nMotion 4 in the name of Councillor Aramaz\n\u00a0\nThe Council recognises\r\n\u00a0...\u00a0 view the\r\nfull agenda text for item 11.\n\n\nAdditional documents:\n\n\nAmendment to Motion 6 , item 11.\n PDF 141 KB  \n\nMinutes:\n\nCouncillor Caliskan proposed and Councillor Uddin seconded the\r\nfollowing motion:\u00a0\n\u00a0\nAs of the 16th September\r\n2020, according to the Office for National Statistics (ONS), the\r\nnumber of Covid-19 related deaths in Enfield was 392. According to\r\nNHS Digital, the number of Covid-19 cases in Enfield between 31st\r\nAugust and 13th September was 169. The real figures may well be a\r\nlot higher.\n\u00a0\nNational and local data\r\nis indicating that the country may well be heading towards a second\r\nwave.\n\u00a0\nEnfield Council is\r\nconcerned that the national testing system is not working fully and\r\nthat Enfield residents have struggled to secure a test in recent\r\nweeks. The country desperately needs a functioning test, trace and\r\nisolate system if we are to prevent a devastating second\r\nwave.\n\u00a0\nEnfield Council calls on\r\nthe Government to urgently fix the testing system and ensure that\r\nthere is both testing and laboratory capacity to ensure everyone in\r\nour community, including those in care homes, are able to access a\r\ntest and receive the results quickly.\n\u00a0\nThe impact\r\non black, Asian and minority ethnic (BAME) communities across the\r\ncountry has become increasingly clear with statistics from the\r\nInstitute of Fiscal Studies and the Office for National Statistics\r\n(ONS) showing clear disproportionality. ONS figures show that black\r\nmen and women are nearly twice as likely to die from COVID-19 than\r\nwhite men and women, after taking into account age and\r\nsocio-demographic factors.\nEnfield\r\nCouncil welcomes Public Health England\u2019s recently published\r\nseven-point plan on how to better protect black, Asian and minority\r\nethnic (BAME) communities from COVID-19. The Council urges / calls on the\r\ngovernment to urgently implement the recommendations, before any\r\nfuture waves.\n\u00a0\nDuring the debate Councillor Caliskan proposed and Councillor Anolue seconded a proposal to extend the\r\ntime allowed for the discussion of motions for 5\r\nminutes.\n\u00a0\nThis was agreed without a vote.\n\u00a0\nAt the end of the debate, the motion was\r\nunanimously agreed.\u00a0\n\u00a0\nThe following motions lapsed under the guillotine\r\narrangements:\u00a0 1, 2, 3, 4, 5, 6, 7, 8,10\r\n,11 ,12.\u00a0\n\n\n\n\n\n12.\n\nDuration of Council Meeting\n\nView the background to item 12.\n\nMinutes:\n\nThe Mayor advised, at this stage of the\r\nmeeting, that the time available to complete the agenda had now\r\nelapsed so Council Procedure Rule 9 would apply.\n\u00a0\nNOTED that in accordance with Council\r\nProcedure Rule 8 (page 4-8 \u2013 Part 4), the remaining items of\r\nbusiness on the Council agenda were considered without debate.\n\n\n\n\n\n13.\n\nReardon Court Extra Care Housing Scheme - Adjustment to the Capital Programme  PDF 329 KB \n\n View the declarations of interest for  item 13.\nView the background to item 13.\n\n\nTo receive the report of the Executive\r\nDirector Place on an adjustment to the Capital Programme for the\r\nReardon Court Extra Care Housing Scheme.\n\u00a0\nCouncil is asked to approve an adjustment to\r\nthe capital programme.\u00a0\n\n\nMinutes:\n\nRECEIVED a report from the Executive Director\r\nPeople on an adjustment to the Capital Programme for the Reardon\r\nCourt Extra Care Housing Scheme.\n\u00a0\nAGREED\n\u00a0\n\n1.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nTo approve an increase of \u00a32.611m to the\r\napproved allocation of capital funding in the Council\u2019s\r\nCapital Programme.\n\n2.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nTo note the additional\r\nborrowing requirement of \u00a3400k against the approved budget in\r\nKD 4898.\n\n3.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nTo note the GLA\u2019s Care and Support Specialist\r\nHousing capital grant of \u00a39,443,161 is time limited to 12\r\nMarch 2020 by which date contractually the main works must\r\ncommence. The grant funding will be paid in full on entering into\r\nthe build contract.\n\n4.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nTo note the use of funds from the Kingsdown\r\nCharitable Trust as previously referenced in the July 2019 Cabinet\r\nreport (KD 4898), and as detailed at para 22.\n\n5.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nTo delegate all other necessary approvals and\r\nconsents required to deliver the project to the Executive Director\r\nof Place in consultation with the Executive Director of\r\nPeople.\nThe Leader of the\r\nOpposition, Councillor Joanne Laban, advised that if there had been\r\na vote on this decision, her group would have voted\r\nagainst.\u00a0\n\n\n\n\n\n14.\n\nCouncillor Question Time  PDF 1007 KB \n\nView the background to item 14.\n\n\n12.1\u00a0\u00a0\u00a0\r\nUrgent Questions (Part 4 - Paragraph 9.2.(b) of Constitution\r\n\u2013 Page 4-9)\n\u00a0\nWith the permission of the Mayor, questions on\r\nurgent issues may be tabled with the proviso of a subsequent\r\nwritten response if the issue requires research or is considered by\r\nthe Mayor to be minor.\n\u00a0\nPlease note that the Mayor will decide whether\r\na question is urgent or not.\n\u00a0\nThe definition of an urgent question is\r\n\u201cAn issue which could not reasonably have been foreseen or\r\nanticipated prior to the deadline for the submission of questions\r\nand which needs to be considered before the next meeting of the\r\nCouncil.\u201d\n\u00a0\nSubmission of urgent questions to Council\r\nrequires the Member when submitting the question to specify why the\r\nissue could not have been reasonably foreseen prior to the deadline\r\nand why it has to be considered before the next\r\nmeeting.\u00a0\n\u00a0\n12.2\u00a0\u00a0\u00a0\r\nCouncillors\u2019 Questions (Part 4 \u2013 Paragraph 9.2(a) of\r\nConstitution \u2013 Page 4 - 8)\n\u00a0\nThe list of questions and their written\r\nresponses will be published on Tuesday 29 September\r\n2020.\u00a0\n\n\nMinutes:\n\n1.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nUrgent Questions\n\u00a0\nThere were no urgent questions.\n\u00a0\n2.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nQuestions by Councillors\n\u00a0\nNOTED\n\u00a0\n\n1.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nThe forty four questions on the Council agenda and the written\r\nresponses provided by the relevant Cabinet Members.\n\n\n\n\n\n15.\n\nCommittee Membership  PDF 184 KB \n\nView the background to item 15.\n\n\nTo confirm changes to Committee memberships\r\nagreed since the last meeting.\n\u00a0\nRevised list attached.\u00a0 \u00a0\n\u00a0\nAny changes received once the agenda has been\r\npublished with be tabled on the Council update sheet at the\r\nmeeting.\u00a0\n\n\nMinutes:\n\nAGREED\nto confirm the changes to the committee membership\r\nlist, as sent out with the agenda, as well as the following\r\nadditional amendment:\u00a0\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nCouncillor Savva to fill the vacancy on the\r\nLicensing Committee.\u00a0\n\n\n\n\n\n16.\n\nNominations to Outside Bodies  PDF 206 KB \n\nView the background to item 16.\n\n\nTo confirm any changes to the nominations on\r\noutside bodies agreed since the last meeting.\u00a0\n\u00a0\nRevised list to follow.\u00a0\n\u00a0\nAny changes notified after the agenda has been\r\npublished will be reported to Council on the update sheet tabled at\r\nthe meeting.\u00a0\n\n\nMinutes:\n\nAGREED to confirm the changes to the\r\nnominations to outside bodies put forward since the last meeting,\r\nas set out in the list circulated as \u201cto\r\nfollow\u201d.\u00a0\n\n\n\n\n\n17.\n\nDate of Next Meeting\n\nView the background to item 17.\n\n\nTo note the date agreed for the next Council\r\nmeeting:\n\u00a0\n\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\nWednesday 18 November 2020 at 7pm.\u00a0\n\n\nMinutes:\n\nNOTED that the next ordinary Council meeting\r\nwill take place on Wednesday 18 November 2020 at 7pm.\u00a0\n\n\n\n\n\n\n\n\n\n\u00a0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelated links\n\nCalendar\nChanging the Executive Arrangement\nCouncillor Conduct\nCommittees\nDecisions\nForthcoming Decisions\nKey Decisions\nMayor of Enfield\nMeetings\nOutside bodies\nPetitions\nKey documents\nSearch documents\nSubscribe to updates\nWard Forums\nWhat's New\nYour Councillors\nYour GLA Member\nYour MPs\nYour MEPs\nLogon\n\n\n\n\n\n\nRate this page:\u00a0\r\n        \n\n\n\n\n\n\n\nCouncil opening hours\nContact us / feedback\nPrivacy notice\nTerms of use\nCookie policy\n\n\n\n\n\n\n\n\n\u00a9  Enfield Council\n\n\n\n"
  }
]
